(self["webpackChunkcasaos_main"]=self["webpackChunkcasaos_main"]||[]).push([["vendors-node_modules_pnpm_artplayer_4_6_2_node_modules_artplayer_dist_artplayer_js-node_modul-c8f5d8"],{"./node_modules/.pnpm/artplayer@4.6.2/node_modules/artplayer/dist/artplayer.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/.pnpm/artplayer@4.6.2/node_modules/artplayer/dist/artplayer.js ***!
  \*************************************************************************************/function(module,__unused_webpack_exports,__webpack_require__){eval('/* module decorator */ module = __webpack_require__.nmd(module);\n/*!\n * artplayer.js v4.6.2\n * Github: https://github.com/zhw2590582/ArtPlayer\n * (c) 2017-2023 Harvey Zack\n * Released under the MIT License.\n */\n!function(e,t,r,o,a){var i="undefined"!=typeof globalThis?globalThis:"undefined"!=typeof self?self:"undefined"!=typeof window?window:"undefined"!=typeof __webpack_require__.g?__webpack_require__.g:{},n="function"==typeof i[o]&&i[o],s=n.cache||{},l= true&&"function"==typeof module.require&&module.require.bind(module);function c(t,r){if(!s[t]){if(!e[t]){var a="function"==typeof i[o]&&i[o];if(!r&&a)return a(t,!0);if(n)return n(t,!0);if(l&&"string"==typeof t)return l(t);var p=new Error("Cannot find module \'"+t+"\'");throw p.code="MODULE_NOT_FOUND",p}d.resolve=function(r){var o=e[t][1][r];return null!=o?o:r},d.cache={};var u=s[t]=new c.Module(t);e[t][0].call(u.exports,d,u,u.exports,this)}return s[t].exports;function d(e){var t=d.resolve(e);return!1===t?{}:c(t)}}c.isParcelRequire=!0,c.Module=function(e){this.id=e,this.bundle=c,this.exports={}},c.modules=e,c.cache=s,c.parent=n,c.register=function(t,r){e[t]=[function(e,t){t.exports=r},{}]},Object.defineProperty(c,"root",{get:function(){return i[o]}}),i[o]=c;for(var p=0;p<t.length;p++)c(t[p]);if(r){var u=c(r); true?module.exports=u:0}}({"5lTcX":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("bundle-text:./style/index.less"),i=o.interopDefault(a),n=e("option-validator"),s=o.interopDefault(n),l=e("./utils/emitter"),c=o.interopDefault(l),p=e("./utils"),u=e("./scheme"),d=o.interopDefault(u),f=e("./config"),h=o.interopDefault(f),m=e("./whitelist"),g=o.interopDefault(m),y=e("./template"),v=o.interopDefault(y),b=e("./i18n"),x=o.interopDefault(b),w=e("./player"),j=o.interopDefault(w),k=e("./control"),S=o.interopDefault(k),I=e("./contextmenu"),C=o.interopDefault(I),$=e("./info"),E=o.interopDefault($),P=e("./subtitle"),T=o.interopDefault(P),M=e("./events"),F=o.interopDefault(M),A=e("./hotkey"),z=o.interopDefault(A),H=e("./layer"),D=o.interopDefault(H),O=e("./loading"),R=o.interopDefault(O),L=e("./notice"),N=o.interopDefault(L),V=e("./mask"),Y=o.interopDefault(V),_=e("./icons"),W=o.interopDefault(_),B=e("./setting"),q=o.interopDefault(B),U=e("./storage"),Z=o.interopDefault(U),G=e("./plugins"),K=o.interopDefault(G),X=e("./mobile"),J=o.interopDefault(X);let Q=0;const ee=[];class te extends c.default{constructor(e,t){super(),this.id=++Q;const r=p.mergeDeep(te.option,e);if(this.option=(0,s.default)(r,d.default),this.isLock=!1,this.isReady=!1,this.isFocus=!1,this.isInput=!1,this.isRotate=!1,this.isDestroy=!1,this.whitelist=new(0,g.default)(this),this.template=new(0,v.default)(this),this.events=new(0,F.default)(this),this.whitelist.state?(this.storage=new(0,Z.default)(this),this.icons=new(0,W.default)(this),this.i18n=new(0,x.default)(this),this.notice=new(0,N.default)(this),this.player=new(0,j.default)(this),this.layers=new(0,D.default)(this),this.controls=new(0,S.default)(this),this.contextmenu=new(0,C.default)(this),this.subtitle=new(0,T.default)(this),this.info=new(0,E.default)(this),this.loading=new(0,R.default)(this),this.hotkey=new(0,z.default)(this),this.mask=new(0,Y.default)(this),this.setting=new(0,q.default)(this),this.plugins=new(0,K.default)(this)):this.mobile=new(0,J.default)(this),"function"==typeof t&&this.on("ready",(()=>t.call(this,this))),te.DEBUG){const e=e=>console.log(`[ART.${this.id}] -> ${e}`);e("Version@"+te.version),e("Env@"+te.env),e("Build@"+te.build);for(let t=0;t<h.default.events.length;t++)this.on("video:"+h.default.events[t],(t=>e("Event@"+t.type)))}ee.push(this)}static get instances(){return ee}static get version(){return"4.6.2"}static get env(){return"production"}static get build(){return"2023-01-26 15:26:58"}static get config(){return h.default}static get utils(){return p}static get scheme(){return d.default}static get Emitter(){return c.default}static get validator(){return s.default}static get kindOf(){return s.default.kindOf}static get html(){return v.default.html}static get option(){return{id:"",container:"#artplayer",url:"",poster:"",title:"",type:"",theme:"#f00",volume:.7,isLive:!1,muted:!1,autoplay:!1,autoSize:!1,autoMini:!1,loop:!1,flip:!1,playbackRate:!1,aspectRatio:!1,screenshot:!1,setting:!1,hotkey:!0,pip:!1,mutex:!0,backdrop:!0,fullscreen:!1,fullscreenWeb:!1,subtitleOffset:!1,miniProgressBar:!1,useSSR:!1,playsInline:!0,lock:!1,fastForward:!1,autoPlayback:!1,autoOrientation:!1,airplay:!1,layers:[],contextmenu:[],controls:[],settings:[],quality:[],highlight:[],plugins:[],whitelist:[],thumbnails:{url:"",number:60,column:10,width:0,height:0},subtitle:{url:"",type:"",style:{},escape:!0,encoding:"utf-8"},moreVideoAttr:{controls:!1,preload:p.isSafari?"auto":"metadata"},i18n:{},icons:{},customType:{},lang:navigator.language.toLowerCase()}}get proxy(){return this.events.proxy}get query(){return this.template.query}get video(){return this.template.$video}destroy(e=!0){this.events.destroy(),this.template.destroy(e),ee.splice(ee.indexOf(this),1),this.isDestroy=!0,this.emit("destroy")}}if(r.default=te,te.DEBUG=!1,te.CONTEXTMENU=!0,te.NOTICE_TIME=2e3,te.SETTING_WIDTH=250,te.SETTING_ITEM_WIDTH=200,te.SETTING_ITEM_HEIGHT=35,te.INDICATOR_SIZE=14,te.INDICATOR_SIZE_ICON=16,te.INDICATOR_SIZE_MOBILE=18,te.INDICATOR_SIZE_MOBILE_ICON=20,te.VOLUME_PANEL_WIDTH=60,te.VOLUME_HANDLE_WIDTH=12,te.RESIZE_TIME=500,te.SCROLL_TIME=200,te.SCROLL_GAP=50,te.AUTO_PLAYBACK_MAX=10,te.AUTO_PLAYBACK_MIN=5,te.AUTO_PLAYBACK_TIMEOUT=3e3,te.RECONNECT_TIME_MAX=5,te.RECONNECT_SLEEP_TIME=1e3,te.CONTROL_HIDE_TIME=3e3,te.DB_CLICE_TIME=300,te.MOBILE_AUTO_PLAYBACKRATE=3,te.MOBILE_AUTO_PLAYBACKRATE_TIME=1e3,te.MOBILE_AUTO_ORIENTATION_TIME=200,te.INFO_LOOP_TIME=1e3,te.FAST_FORWARD_VALUE=3,te.FAST_FORWARD_TIME=1e3,te.TOUCH_MOVE_RATIO=.5,te.VOLUME_STEP=.1,te.SEEK_STEP=5,te.PROGRESS_HEIGHT=6,te.PLAYBACK_RATE=[.5,.75,1,1.25,1.5,2],te.ASPECT_RATIO=["default","4:3","16:9"],te.FLIP=["normal","horizontal","vertical"],te.FULLSCREEN_WEB_IN_BODY=!1,"undefined"!=typeof document&&!document.getElementById("artplayer-style")){const e=p.createElement("style");e.id="artplayer-style",e.textContent=i.default,document.head.appendChild(e)}"undefined"!=typeof window&&(window.Artplayer=te),console.log(`%c ArtPlayer %c ${te.version} %c https://artplayer.org`,"color: #fff; background: #5f5f5f","color: #fff; background: #4bc729","")},{"bundle-text:./style/index.less":"0016T","option-validator":"bAWi2","./utils/emitter":"66mFZ","./utils":"71aH7","./scheme":"AKEiO","./config":"lyjeQ","./whitelist":"9L0ao","./template":"X13Zf","./i18n":"3jKkj","./player":"a90nx","./control":"8Z0Uf","./contextmenu":"2KYsr","./info":"02ajl","./subtitle":"eSWto","./events":"jo4S1","./hotkey":"6NoFy","./layer":"6G6hZ","./loading":"3dsEe","./notice":"dWGTw","./mask":"5POkG","./icons":"6OeNg","./setting":"3eYNH","./storage":"2aaJe","./plugins":"8MTUM","./mobile":"7mil2","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"0016T":[function(e,t,r){t.exports=\'.art-video-player{z-index:20;width:100%;height:100%;zoom:1;color:#eee;text-align:left;direction:ltr;user-select:none;-webkit-tap-highlight-color:#0000;touch-action:manipulation;-ms-high-contrast-adjust:none;background-color:#000;outline:0;margin:0 auto;font-family:Roboto,Arial,Helvetica,sans-serif;font-size:14px;line-height:1.3;display:flex;position:relative}.art-video-player *,.art-video-player :before,.art-video-player :after{box-sizing:border-box;margin:0;padding:0}.art-video-player ::-webkit-scrollbar{width:5px;height:5px}.art-video-player ::-webkit-scrollbar-thumb{background-color:#666}.art-video-player ::-webkit-scrollbar-thumb:hover{background-color:#ccc}.art-video-player .art-icon{justify-content:center;align-items:center;line-height:1.5;display:inline-flex}.art-video-player .art-icon svg{fill:#fff}.art-video-player img{max-width:100%;vertical-align:top}@supports ((-webkit-backdrop-filter: initial) or (backdrop-filter: initial)){.art-video-player .art-backdrop-filter{-webkit-backdrop-filter:saturate(180%)blur(20px);backdrop-filter:saturate(180%)blur(20px);background-color:#000000b3!important}}.art-video-player .art-video{z-index:10;width:100%;height:100%;cursor:pointer;background-color:#000;position:absolute;inset:0}.art-video-player .art-poster{z-index:11;width:100%;height:100%;user-select:none;pointer-events:none;background-position:50%;background-repeat:no-repeat;background-size:cover;position:absolute;inset:0}.art-video-player .art-subtitle{z-index:20;width:100%;text-align:center;color:#fff;pointer-events:none;text-shadow:1px 0 1px #000,0 1px 1px #000,-1px 0 1px #000,0 -1px 1px #000,1px 1px 1px #000,-1px -1px 1px #000,1px -1px 1px #000,-1px 1px 1px #000;padding:0 20px;font-size:20px;transition:bottom .2s;display:none;position:absolute;bottom:10px}.art-video-player .art-subtitle p{word-break:break-all;height:fit-content;margin:5px 0 0;line-height:1.2}.art-video-player.art-subtitle-show .art-subtitle{display:block}.art-video-player.art-control-show .art-subtitle{bottom:50px}.art-video-player .art-danmuku{z-index:30;width:100%;height:100%;pointer-events:none;position:absolute;inset:0;overflow:hidden}.art-video-player .art-layers{z-index:40;width:100%;height:100%;pointer-events:none;display:none;position:absolute;inset:0;overflow:hidden}.art-video-player .art-layers .art-layer{pointer-events:auto}.art-video-player.art-layer-show .art-layers{display:block}.art-video-player .art-mask{z-index:50;width:100%;height:100%;pointer-events:none;justify-content:center;align-items:center;display:none;position:absolute;inset:0;overflow:hidden}.art-video-player .art-mask .art-state{width:60px;height:60px;opacity:.85;cursor:pointer;pointer-events:auto;justify-content:center;align-items:center;display:flex;position:absolute;bottom:65px;right:30px}.art-video-player.art-mask-show .art-mask{display:flex}.art-video-player.art-mobile .art-state{position:static}.art-video-player .art-loading{z-index:70;width:100%;height:100%;pointer-events:none;justify-content:center;align-items:center;display:none;position:absolute;inset:0}.art-video-player.art-loading-show .art-loading{display:flex}.art-video-player .art-bottom{z-index:60;height:100px;opacity:0;visibility:hidden;pointer-events:none;background-image:linear-gradient(#0000,#0006,#000);background-position:bottom;background-repeat:repeat-x;flex-direction:column;justify-content:space-between;padding:50px 10px 0;transition:all .2s ease-in-out;display:flex;position:absolute;bottom:0;left:0;right:0}.art-video-player .art-bottom .art-progress{z-index:0;pointer-events:auto;flex:1;position:relative}.art-video-player .art-bottom .art-progress .art-control-progress{height:4px;cursor:pointer;flex-direction:row;align-items:center;display:flex;position:relative}.art-video-player .art-bottom .art-progress .art-control-progress .art-control-progress-inner{height:50%;width:100%;background:#fff3;align-items:center;transition:all .2s;display:flex;position:relative}.art-video-player .art-bottom .art-progress .art-control-progress .art-control-progress-inner .art-progress-loaded{z-index:10;height:100%;width:0;background:#fff6;position:absolute;inset:0}.art-video-player .art-bottom .art-progress .art-control-progress .art-control-progress-inner .art-progress-played{z-index:20;height:100%;width:0;position:absolute;inset:0}.art-video-player .art-bottom .art-progress .art-control-progress .art-control-progress-inner .art-progress-highlight{z-index:30;height:100%;pointer-events:none;position:absolute;inset:0}.art-video-player .art-bottom .art-progress .art-control-progress .art-control-progress-inner .art-progress-highlight span{width:7px;height:100%;pointer-events:auto;background:#ffffff80;display:inline-block;position:absolute;top:0;left:0}.art-video-player .art-bottom .art-progress .art-control-progress .art-control-progress-inner .art-progress-indicator{visibility:hidden;z-index:40;border-radius:50%;justify-content:center;align-items:center;transition:transform .1s ease-in-out;position:absolute;transform:scale(.1)}.art-video-player .art-bottom .art-progress .art-control-progress .art-control-progress-inner .art-progress-indicator .art-icon{width:100%;height:100%;pointer-events:none;user-select:none}.art-video-player .art-bottom .art-progress .art-control-progress .art-control-progress-inner .art-progress-indicator:hover{transform:scale(1.2)!important}.art-video-player .art-bottom .art-progress .art-control-progress .art-control-progress-inner .art-progress-tip{z-index:50;height:20px;color:#fff;text-align:center;white-space:nowrap;background:#000000b3;border-radius:3px;padding:0 5px;font-size:12px;font-weight:700;line-height:20px;display:none;position:absolute;top:-25px;left:0}.art-video-player .art-bottom .art-progress .art-control-thumbnails{pointer-events:none;background-color:#000000b3;border-radius:3px;display:none;position:absolute;bottom:10px;left:0;box-shadow:0 1px 3px #0003,0 1px 2px -1px #0003}.art-video-player .art-bottom .art-progress .art-control-loop{width:100%;height:100%;pointer-events:none;display:none;position:absolute;inset:0}.art-video-player .art-bottom .art-progress .art-control-loop .art-loop-point{width:2px;height:8px;background:#ffffffbf;position:absolute;top:-2px;left:0}.art-video-player .art-bottom .art-controls{z-index:1;pointer-events:auto;height:45px;justify-content:space-between;align-items:center;display:flex;position:relative}.art-video-player .art-bottom .art-controls .art-controls-left,.art-video-player .art-bottom .art-controls .art-controls-right{display:flex}.art-video-player .art-bottom .art-controls .art-controls-center{height:100%;flex:1;justify-content:center;align-items:center;padding:0 10px;display:flex}.art-video-player .art-bottom .art-controls .art-controls-right{justify-content:flex-end}.art-video-player .art-bottom .art-controls .art-control{opacity:.75;min-height:36px;min-width:36px;text-align:center;cursor:pointer;white-space:nowrap;justify-content:center;align-items:center;font-size:12px;line-height:1;transition:opacity .1s ease-in-out;display:flex}.art-video-player .art-bottom .art-controls .art-control .art-icon{float:left;height:36px;width:36px;justify-content:center;align-items:center;transition:transform .2s ease-in-out;display:flex;transform:scale(1)}.art-video-player .art-bottom .art-controls .art-control .art-icon:active{transform:scale(.85)}.art-video-player .art-bottom .art-controls .art-control:hover{opacity:1}.art-video-player .art-bottom .art-controls .art-control-volume .art-volume-panel{float:left;width:0;height:100%;transition:margin .2s cubic-bezier(.4,0,1,1),width .2s cubic-bezier(.4,0,1,1);position:relative;overflow:hidden}.art-video-player .art-bottom .art-controls .art-control-volume .art-volume-panel .art-volume-slider-handle{width:12px;height:12px;background:#fff;border-radius:12px;margin-top:-6px;position:absolute;top:50%;left:0}.art-video-player .art-bottom .art-controls .art-control-volume .art-volume-panel .art-volume-slider-handle:before{background:#fff;left:-54px}.art-video-player .art-bottom .art-controls .art-control-volume .art-volume-panel .art-volume-slider-handle:after{background:#fff3;left:6px}.art-video-player .art-bottom .art-controls .art-control-volume .art-volume-panel .art-volume-slider-handle:before,.art-video-player .art-bottom .art-controls .art-control-volume .art-volume-panel .art-volume-slider-handle:after{content:"";height:3px;width:60px;margin-top:-2px;display:block;position:absolute;top:50%}.art-video-player .art-bottom .art-controls .art-control-volume:hover .art-volume-panel{width:60px}.art-video-player .art-bottom .art-controls .art-control-quality{z-index:30;position:relative}.art-video-player .art-bottom .art-controls .art-control-quality .art-qualitys{width:100px;text-align:center;color:#fff;background:#000c;border-radius:3px;padding:5px 0;display:none;position:absolute;bottom:35px}.art-video-player .art-bottom .art-controls .art-control-quality .art-qualitys .art-quality-item{height:30px;text-overflow:ellipsis;white-space:nowrap;text-shadow:0 0 2px #00000080;line-height:30px;overflow:hidden}.art-video-player .art-bottom .art-controls .art-control-quality .art-qualitys .art-quality-item:hover{background-color:#ffffff1a}.art-video-player .art-bottom .art-controls .art-control-quality:hover .art-qualitys{display:block}.art-video-player .art-bottom:hover .art-progress .art-control-progress .art-control-progress-inner .art-progress-indicator{visibility:visible;transform:scale(1)}.art-video-player.art-control-show .art-bottom,.art-video-player.art-hover .art-bottom{opacity:1;visibility:visible}.art-video-player.art-error .art-progress-indicator,.art-video-player.art-destroy .art-progress-indicator,.art-video-player.art-error .art-progress-tip,.art-video-player.art-destroy .art-progress-tip{display:none!important}.art-video-player.art-mobile .art-bottom{height:105px;padding:50px 7px 0}.art-video-player.art-mobile .art-bottom .art-controls{height:40px}.art-video-player.art-mobile .art-bottom .art-progress-indicator{visibility:visible!important;transform:scale(1)!important}.art-video-player .art-notice{z-index:80;width:100%;pointer-events:none;padding:10px;font-size:14px;display:none;position:absolute;top:0;left:0}.art-video-player .art-notice .art-notice-inner{color:#fff;background-color:#0009;border-radius:3px;padding:5px 10px;display:inline-block}.art-video-player.art-notice-show .art-notice{display:flex}.art-video-player .art-contextmenus{z-index:120;min-width:200px;background-color:#000000e6;border-radius:3px;flex-direction:column;padding:5px 0;display:none;position:absolute;top:10px;left:10px}.art-video-player .art-contextmenus .art-contextmenu{cursor:pointer;color:#fff;text-overflow:ellipsis;white-space:nowrap;text-shadow:0 0 2px #00000080;border-bottom:1px solid #ffffff1a;padding:10px 15px;font-size:12px;display:block;overflow:hidden}.art-video-player .art-contextmenus .art-contextmenu a{color:#fff;text-decoration:none}.art-video-player .art-contextmenus .art-contextmenu span{padding:0 7px;display:inline-block}.art-video-player .art-contextmenus .art-contextmenu span:hover,.art-video-player .art-contextmenus .art-contextmenu span.art-current{color:var(--theme)}.art-video-player .art-contextmenus .art-contextmenu:hover{background-color:#ffffff1a}.art-video-player .art-contextmenus .art-contextmenu:last-child{border-bottom:none}.art-video-player.art-contextmenu-show .art-contextmenus{display:flex}.art-video-player .art-settings{z-index:90;height:auto;max-height:300px;background-color:#000000e6;border-radius:3px;font-size:13px;transition:all .2s;display:none;position:absolute;bottom:60px;left:0;overflow:auto}.art-video-player .art-settings .art-setting-panel{display:none}.art-video-player .art-settings .art-setting-panel.art-current{display:block}.art-video-player .art-settings .art-setting-panel .art-setting-item{height:35px;cursor:pointer;color:#fffc;justify-content:space-between;align-items:center;padding:0 5px;line-height:1;display:flex;overflow:hidden}.art-video-player .art-settings .art-setting-panel .art-setting-item:hover{color:#fff;background-color:#ffffff1a}.art-video-player .art-settings .art-setting-panel .art-setting-item.art-current{color:var(--theme)}.art-video-player .art-settings .art-setting-panel .art-setting-item .art-icon{width:30px;height:30px;justify-content:center;align-items:center;display:flex}.art-video-player .art-settings .art-setting-panel .art-setting-item .art-icon-check{visibility:hidden;height:15px}.art-video-player .art-settings .art-setting-panel .art-setting-item.art-current .art-icon-check{visibility:visible}.art-video-player .art-settings .art-setting-panel .art-setting-item .art-setting-item-left{white-space:nowrap;align-items:center;display:flex}.art-video-player .art-settings .art-setting-panel .art-setting-item .art-setting-item-left .art-setting-item-left-icon{height:24px;width:24px;justify-content:center;align-items:center;margin-right:10px;display:flex}.art-video-player .art-settings .art-setting-panel .art-setting-item .art-setting-item-right{align-items:center;display:flex}.art-video-player .art-settings .art-setting-panel .art-setting-item .art-setting-item-right .art-setting-item-right-tooltip{white-space:nowrap;color:#ffffff80;margin-right:5px;font-size:12px}.art-video-player .art-settings .art-setting-panel .art-setting-item .art-setting-item-right .art-setting-item-right-icon{height:24px;justify-content:center;align-items:center;display:flex}.art-video-player .art-settings .art-setting-panel .art-setting-item .art-setting-item-right .art-setting-range{height:3px;width:80px;appearance:none;background-color:#fff3;outline:none}.art-video-player .art-settings .art-setting-panel .art-setting-item-back{border-bottom:1px solid #ffffff1a}.art-video-player.art-setting-show .art-settings{display:block}.art-video-player.art-mobile .art-settings{max-height:200px}.art-video-player .art-info{z-index:100;width:350px;color:#fff;-webkit-font-smoothing:antialiased;background-color:#000000e6;flex-direction:column;padding:10px;font-family:Noto Sans CJK SC DemiLight,Roboto,Segoe UI,Tahoma,Arial,Helvetica,sans-serif;font-size:12px;display:none;position:absolute;top:10px;left:10px}.art-video-player .art-info .art-info-item{margin-bottom:5px;display:flex}.art-video-player .art-info .art-info-item .art-info-title{width:100px;text-align:right}.art-video-player .art-info .art-info-item .art-info-content{text-overflow:ellipsis;white-space:nowrap;user-select:all;flex:1;padding-left:5px;overflow:hidden}.art-video-player .art-info .art-info-item:last-child{margin-bottom:0}.art-video-player .art-info .art-info-close{cursor:pointer;position:absolute;top:5px;right:5px}.art-video-player.art-info-show .art-info{display:flex}.art-video-player.art-hide-cursor *{cursor:none!important}.art-video-player[data-aspect-ratio] video{box-sizing:content-box;object-fit:fill}.art-video-player.art-fullscreen-web{z-index:9999;width:100%;height:100%;position:fixed;inset:0}.art-video-player .art-mini-header{z-index:110;height:35px;color:#fff;opacity:0;visibility:hidden;background-color:#00000080;justify-content:space-between;align-items:center;line-height:35px;transition:all .2s ease-in-out;display:none;position:absolute;top:0;left:0;right:0}.art-video-player .art-mini-header .art-mini-title{text-overflow:ellipsis;white-space:nowrap;cursor:move;flex:1;padding:0 10px;overflow:hidden}.art-video-player .art-mini-header .art-mini-close{width:35px;text-align:center;cursor:pointer;font-size:22px}.art-video-player.art-is-dragging{opacity:.7}.art-video-player.art-mini{z-index:9999;width:400px;height:225px;position:fixed;box-shadow:0 2px 5px #00000029,0 3px 6px #0003}.art-video-player.art-mini .art-mini-header{user-select:none;display:flex}.art-video-player.art-mini.art-hover .art-mini-header{opacity:1;visibility:visible}.art-video-player.art-mini .art-mask .art-state{position:static}.art-video-player.art-mini .art-contextmenu,.art-video-player.art-mini .art-bottom,.art-video-player.art-mini .art-danmu,.art-video-player.art-mini .art-info,.art-video-player.art-mini .art-layers,.art-video-player.art-mini .art-notice,.art-video-player.art-mini .art-settings,.art-video-player.art-mini .art-subtitle{display:none!important}.art-auto-size{justify-content:center;align-items:center;display:flex}.art-auto-size .art-video-player{transition:all .2s}.art-video-player[data-flip=horizontal] .art-video{transform:scaleX(-1)}.art-video-player[data-flip=vertical] .art-video{transform:scaleY(-1)}.art-video-player .art-layer-miniProgressBar{height:2px;background-color:var(--theme);display:block;position:absolute;bottom:0;left:0;right:0}.art-video-player .art-layer-lock{height:34px;width:34px;color:#fff;background-color:#00000080;border-radius:50%;justify-content:center;align-items:center;display:none;position:absolute;top:calc(50% - 17px);left:15px}.art-video-player .art-layer-autoPlayback{background-color:#000c;border-radius:3px;align-items:center;padding:10px;line-height:1;display:none;position:absolute;bottom:60px;left:20px}.art-video-player .art-layer-autoPlayback .art-autoPlayback-close{cursor:pointer;align-items:center;margin-right:10px;display:flex}.art-video-player .art-layer-autoPlayback .art-autoPlayback-close svg{width:15px;height:15px;fill:var(--theme)}.art-video-player .art-layer-autoPlayback .art-autoPlayback-last{margin-right:10px}.art-video-player .art-layer-autoPlayback .art-autoPlayback-jump{color:var(--theme);cursor:pointer}.art-video-player.art-lock .art-bottom{display:none!important}.art-video-player.art-lock .art-subtitle{bottom:10px!important}.art-video-player.art-lock .art-layer-miniProgressBar{display:block!important}.art-video-player.art-control-show .art-layer-miniProgressBar{display:none}.art-video-player.art-control-show .art-layer-lock{display:flex}.art-video-player .art-control-selector{position:relative}.art-video-player .art-control-selector .art-selector-list{min-width:100px;max-width:200px;max-height:200px;text-align:center;color:#fff;background-color:#000c;border-radius:3px;padding:5px 0;display:none;position:absolute;bottom:35px;overflow:auto}.art-video-player .art-control-selector .art-selector-list .art-selector-item{height:30px;text-overflow:ellipsis;white-space:nowrap;text-shadow:0 0 2px #00000080;padding:0 5px;line-height:30px;overflow:hidden}.art-video-player .art-control-selector .art-selector-list .art-selector-item:hover{background-color:#ffffff1a}.art-video-player .art-control-selector .art-selector-list .art-selector-item:hover,.art-video-player .art-control-selector .art-selector-list .art-selector-item.art-current{color:var(--theme)}.art-video-player .art-control-selector:hover .art-selector-list{display:block}[class*=hint--]{font-style:normal;display:inline-block;position:relative}[class*=hint--]:before,[class*=hint--]:after{visibility:hidden;opacity:0;z-index:1000000;pointer-events:none;transition:all .3s;position:absolute;transform:translate(0,0)}[class*=hint--]:hover:before,[class*=hint--]:hover:after{visibility:visible;opacity:1;transition-delay:.1s}[class*=hint--]:before{content:"";z-index:1000001;background:0 0;border:6px solid #0000;position:absolute}[class*=hint--]:after{color:#fff;white-space:nowrap;background:#000;padding:8px 10px;font-family:Helvetica Neue,Helvetica,Arial,sans-serif;font-size:12px;line-height:12px}[class*=hint--][aria-label]:after{content:attr(aria-label)}[class*=hint--][data-hint]:after{content:attr(data-hint)}[aria-label=""]:before,[aria-label=""]:after,[data-hint=""]:before,[data-hint=""]:after{display:none!important}.hint--top-left:before,.hint--top-right:before,.hint--top:before{border-top-color:#000}.hint--bottom-left:before,.hint--bottom-right:before,.hint--bottom:before{border-bottom-color:#000}.hint--left:before{border-left-color:#000}.hint--right:before{border-right-color:#000}.hint--top:before{margin-bottom:-11px}.hint--top:before,.hint--top:after{bottom:100%;left:50%}.hint--top:before{left:calc(50% - 6px)}.hint--top:after{transform:translate(-50%)}.hint--top:hover:before{transform:translateY(-8px)}.hint--top:hover:after{transform:translate(-50%)translateY(-8px)}.hint--bottom:before{margin-top:-11px}.hint--bottom:before,.hint--bottom:after{top:100%;left:50%}.hint--bottom:before{left:calc(50% - 6px)}.hint--bottom:after{transform:translate(-50%)}.hint--bottom:hover:before{transform:translateY(8px)}.hint--bottom:hover:after{transform:translate(-50%)translateY(8px)}.hint--right:before{margin-bottom:-6px;margin-left:-11px}.hint--right:after{margin-bottom:-14px}.hint--right:before,.hint--right:after{bottom:50%;left:100%}.hint--right:hover:before,.hint--right:hover:after{transform:translate(8px)}.hint--left:before{margin-bottom:-6px;margin-right:-11px}.hint--left:after{margin-bottom:-14px}.hint--left:before,.hint--left:after{bottom:50%;right:100%}.hint--left:hover:before,.hint--left:hover:after{transform:translate(-8px)}.hint--top-left:before{margin-bottom:-11px}.hint--top-left:before,.hint--top-left:after{bottom:100%;left:50%}.hint--top-left:before{left:calc(50% - 6px)}.hint--top-left:after{margin-left:12px;transform:translate(-100%)}.hint--top-left:hover:before{transform:translateY(-8px)}.hint--top-left:hover:after{transform:translate(-100%)translateY(-8px)}.hint--top-right:before{margin-bottom:-11px}.hint--top-right:before,.hint--top-right:after{bottom:100%;left:50%}.hint--top-right:before{left:calc(50% - 6px)}.hint--top-right:after{margin-left:-12px;transform:translate(0)}.hint--top-right:hover:before,.hint--top-right:hover:after{transform:translateY(-8px)}.hint--bottom-left:before{margin-top:-11px}.hint--bottom-left:before,.hint--bottom-left:after{top:100%;left:50%}.hint--bottom-left:before{left:calc(50% - 6px)}.hint--bottom-left:after{margin-left:12px;transform:translate(-100%)}.hint--bottom-left:hover:before{transform:translateY(8px)}.hint--bottom-left:hover:after{transform:translate(-100%)translateY(8px)}.hint--bottom-right:before{margin-top:-11px}.hint--bottom-right:before,.hint--bottom-right:after{top:100%;left:50%}.hint--bottom-right:before{left:calc(50% - 6px)}.hint--bottom-right:after{margin-left:-12px;transform:translate(0)}.hint--bottom-right:hover:before,.hint--bottom-right:hover:after{transform:translateY(8px)}.hint--small:after,.hint--medium:after,.hint--large:after{white-space:normal;word-wrap:break-word;line-height:1.4em}.hint--small:after{width:80px}.hint--medium:after{width:150px}.hint--large:after{width:300px}[class*=hint--]:after{text-shadow:0 -1px #000;box-shadow:4px 4px 8px #0000004d}.hint--error:after{text-shadow:0 -1px #592726;background-color:#b34e4d}.hint--error.hint--top-left:before,.hint--error.hint--top-right:before,.hint--error.hint--top:before{border-top-color:#b34e4d}.hint--error.hint--bottom-left:before,.hint--error.hint--bottom-right:before,.hint--error.hint--bottom:before{border-bottom-color:#b34e4d}.hint--error.hint--left:before{border-left-color:#b34e4d}.hint--error.hint--right:before{border-right-color:#b34e4d}.hint--warning:after{text-shadow:0 -1px #6c5328;background-color:#c09854}.hint--warning.hint--top-left:before,.hint--warning.hint--top-right:before,.hint--warning.hint--top:before{border-top-color:#c09854}.hint--warning.hint--bottom-left:before,.hint--warning.hint--bottom-right:before,.hint--warning.hint--bottom:before{border-bottom-color:#c09854}.hint--warning.hint--left:before{border-left-color:#c09854}.hint--warning.hint--right:before{border-right-color:#c09854}.hint--info:after{text-shadow:0 -1px #1a3c4d;background-color:#3986ac}.hint--info.hint--top-left:before,.hint--info.hint--top-right:before,.hint--info.hint--top:before{border-top-color:#3986ac}.hint--info.hint--bottom-left:before,.hint--info.hint--bottom-right:before,.hint--info.hint--bottom:before{border-bottom-color:#3986ac}.hint--info.hint--left:before{border-left-color:#3986ac}.hint--info.hint--right:before{border-right-color:#3986ac}.hint--success:after{text-shadow:0 -1px #1a321a;background-color:#458746}.hint--success.hint--top-left:before,.hint--success.hint--top-right:before,.hint--success.hint--top:before{border-top-color:#458746}.hint--success.hint--bottom-left:before,.hint--success.hint--bottom-right:before,.hint--success.hint--bottom:before{border-bottom-color:#458746}.hint--success.hint--left:before{border-left-color:#458746}.hint--success.hint--right:before{border-right-color:#458746}.hint--always:after,.hint--always:before{opacity:1;visibility:visible}.hint--always.hint--top:before{transform:translateY(-8px)}.hint--always.hint--top:after{transform:translate(-50%)translateY(-8px)}.hint--always.hint--top-left:before{transform:translateY(-8px)}.hint--always.hint--top-left:after{transform:translate(-100%)translateY(-8px)}.hint--always.hint--top-right:before,.hint--always.hint--top-right:after{transform:translateY(-8px)}.hint--always.hint--bottom:before{transform:translateY(8px)}.hint--always.hint--bottom:after{transform:translate(-50%)translateY(8px)}.hint--always.hint--bottom-left:before{transform:translateY(8px)}.hint--always.hint--bottom-left:after{transform:translate(-100%)translateY(8px)}.hint--always.hint--bottom-right:before,.hint--always.hint--bottom-right:after{transform:translateY(8px)}.hint--always.hint--left:before,.hint--always.hint--left:after{transform:translate(-8px)}.hint--always.hint--right:before,.hint--always.hint--right:after{transform:translate(8px)}.hint--rounded:after{border-radius:4px}.hint--no-animate:before,.hint--no-animate:after{transition-duration:0s}.hint--bounce:before,.hint--bounce:after{-webkit-transition:opacity .3s,visibility .3s,-webkit-transform .3s cubic-bezier(.71,1.7,.77,1.24);-moz-transition:opacity .3s,visibility .3s,-moz-transform .3s cubic-bezier(.71,1.7,.77,1.24);transition:opacity .3s,visibility .3s,transform .3s cubic-bezier(.71,1.7,.77,1.24)}.hint--no-shadow:before,.hint--no-shadow:after{text-shadow:initial;box-shadow:initial}.hint--no-arrow:before{display:none}\'},{}],bAWi2:[function(e,t,r){t.exports=function(){"use strict";function e(t){return(e="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&"function"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?"symbol":typeof e})(t)}var t=Object.prototype.toString,r=function(r){if(void 0===r)return"undefined";if(null===r)return"null";var a=e(r);if("boolean"===a)return"boolean";if("string"===a)return"string";if("number"===a)return"number";if("symbol"===a)return"symbol";if("function"===a)return function(e){return"GeneratorFunction"===o(e)}(r)?"generatorfunction":"function";if(function(e){return Array.isArray?Array.isArray(e):e instanceof Array}(r))return"array";if(function(e){return!(!e.constructor||"function"!=typeof e.constructor.isBuffer)&&e.constructor.isBuffer(e)}(r))return"buffer";if(function(e){try{if("number"==typeof e.length&&"function"==typeof e.callee)return!0}catch(e){if(-1!==e.message.indexOf("callee"))return!0}return!1}(r))return"arguments";if(function(e){return e instanceof Date||"function"==typeof e.toDateString&&"function"==typeof e.getDate&&"function"==typeof e.setDate}(r))return"date";if(function(e){return e instanceof Error||"string"==typeof e.message&&e.constructor&&"number"==typeof e.constructor.stackTraceLimit}(r))return"error";if(function(e){return e instanceof RegExp||"string"==typeof e.flags&&"boolean"==typeof e.ignoreCase&&"boolean"==typeof e.multiline&&"boolean"==typeof e.global}(r))return"regexp";switch(o(r)){case"Symbol":return"symbol";case"Promise":return"promise";case"WeakMap":return"weakmap";case"WeakSet":return"weakset";case"Map":return"map";case"Set":return"set";case"Int8Array":return"int8array";case"Uint8Array":return"uint8array";case"Uint8ClampedArray":return"uint8clampedarray";case"Int16Array":return"int16array";case"Uint16Array":return"uint16array";case"Int32Array":return"int32array";case"Uint32Array":return"uint32array";case"Float32Array":return"float32array";case"Float64Array":return"float64array"}if(function(e){return"function"==typeof e.throw&&"function"==typeof e.return&&"function"==typeof e.next}(r))return"generator";switch(a=t.call(r)){case"[object Object]":return"object";case"[object Map Iterator]":return"mapiterator";case"[object Set Iterator]":return"setiterator";case"[object String Iterator]":return"stringiterator";case"[object Array Iterator]":return"arrayiterator"}return a.slice(8,-1).toLowerCase().replace(/\\s/g,"")};function o(e){return e.constructor?e.constructor.name:null}function a(e,t){var o=2<arguments.length&&void 0!==arguments[2]?arguments[2]:["option"];return i(e,t,o),n(e,t,o),function(e,t,o){var s=r(t),l=r(e);if("object"===s){if("object"!==l)throw new Error("[Type Error]: \'".concat(o.join("."),"\' require \'object\' type, but got \'").concat(l,"\'"));Object.keys(t).forEach((function(r){var s=e[r],l=t[r],c=o.slice();c.push(r),i(s,l,c),n(s,l,c),a(s,l,c)}))}if("array"===s){if("array"!==l)throw new Error("[Type Error]: \'".concat(o.join("."),"\' require \'array\' type, but got \'").concat(l,"\'"));e.forEach((function(r,s){var l=e[s],c=t[s]||t[0],p=o.slice();p.push(s),i(l,c,p),n(l,c,p),a(l,c,p)}))}}(e,t,o),e}function i(e,t,o){if("string"===r(t)){var a=r(e);if("?"===t[0]&&(t=t.slice(1)+"|undefined"),!(-1<t.indexOf("|")?t.split("|").map((function(e){return e.toLowerCase().trim()})).filter(Boolean).some((function(e){return a===e})):t.toLowerCase().trim()===a))throw new Error("[Type Error]: \'".concat(o.join("."),"\' require \'").concat(t,"\' type, but got \'").concat(a,"\'"))}}function n(e,t,o){if("function"===r(t)){var a=t(e,r(e),o);if(!0!==a){var i=r(a);throw"string"===i?new Error(a):"error"===i?a:new Error("[Validator Error]: The scheme for \'".concat(o.join("."),"\' validator require return true, but got \'").concat(a,"\'"))}}}return a.kindOf=r,a}()},{}],"66mFZ":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);r.default=class{on(e,t,r){const o=this.e||(this.e={});return(o[e]||(o[e]=[])).push({fn:t,ctx:r}),this}once(e,t,r){const o=this;function a(...i){o.off(e,a),t.apply(r,i)}return a._=t,this.on(e,a,r)}emit(e,...t){const r=((this.e||(this.e={}))[e]||[]).slice();for(let e=0;e<r.length;e+=1)r[e].fn.apply(r[e].ctx,t);return this}off(e,t){const r=this.e||(this.e={}),o=r[e],a=[];if(o&&t)for(let e=0,r=o.length;e<r;e+=1)o[e].fn!==t&&o[e].fn._!==t&&a.push(o[e]);return a.length?r[e]=a:delete r[e],this}}},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"9pCYc":[function(e,t,r){r.interopDefault=function(e){return e&&e.__esModule?e:{default:e}},r.defineInteropFlag=function(e){Object.defineProperty(e,"__esModule",{value:!0})},r.exportAll=function(e,t){return Object.keys(e).forEach((function(r){"default"===r||"__esModule"===r||t.hasOwnProperty(r)||Object.defineProperty(t,r,{enumerable:!0,get:function(){return e[r]}})})),t},r.export=function(e,t,r){Object.defineProperty(e,t,{enumerable:!0,get:r})}},{}],"71aH7":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("./dom");o.exportAll(a,r);var i=e("./error");o.exportAll(i,r);var n=e("./subtitle");o.exportAll(n,r);var s=e("./file");o.exportAll(s,r);var l=e("./property");o.exportAll(l,r);var c=e("./time");o.exportAll(c,r);var p=e("./format");o.exportAll(p,r);var u=e("./compatibility");o.exportAll(u,r)},{"./dom":"bSNiV","./error":"hwmZz","./subtitle":"inzwq","./file":"6b7Ip","./property":"5NSdr","./time":"epmNy","./format":"gapRl","./compatibility":"6ZTr6","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],bSNiV:[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r),o.export(r,"query",(()=>i)),o.export(r,"queryAll",(()=>n)),o.export(r,"addClass",(()=>s)),o.export(r,"removeClass",(()=>l)),o.export(r,"hasClass",(()=>c)),o.export(r,"append",(()=>p)),o.export(r,"remove",(()=>u)),o.export(r,"setStyle",(()=>d)),o.export(r,"setStyles",(()=>f)),o.export(r,"getStyle",(()=>h)),o.export(r,"sublings",(()=>m)),o.export(r,"inverseClass",(()=>g)),o.export(r,"tooltip",(()=>y)),o.export(r,"isInViewport",(()=>v)),o.export(r,"includeFromEvent",(()=>b)),o.export(r,"replaceElement",(()=>x)),o.export(r,"createElement",(()=>w));var a=e("./compatibility");function i(e,t=document){return t.querySelector(e)}function n(e,t=document){return Array.from(t.querySelectorAll(e))}function s(e,t){return e.classList.add(t)}function l(e,t){return e.classList.remove(t)}function c(e,t){return e.classList.contains(t)}function p(e,t){return t instanceof Element?e.appendChild(t):e.insertAdjacentHTML("beforeend",String(t)),e.lastElementChild||e.lastChild}function u(e){return e.parentNode.removeChild(e)}function d(e,t,r){return e.style[t]=r,e}function f(e,t){return Object.keys(t).forEach((r=>{d(e,r,t[r])})),e}function h(e,t,r=!0){const o=window.getComputedStyle(e,null).getPropertyValue(t);return r?parseFloat(o):o}function m(e){return Array.from(e.parentElement.children).filter((t=>t!==e))}function g(e,t){m(e).forEach((e=>l(e,t))),s(e,t)}function y(e,t,r="top"){a.isMobile||(e.setAttribute("aria-label",t),s(e,"hint--rounded"),s(e,`hint--${r}`))}function v(e,t=0){const r=e.getBoundingClientRect(),o=window.innerHeight||document.documentElement.clientHeight,a=window.innerWidth||document.documentElement.clientWidth,i=r.top-t<=o&&r.top+r.height+t>=0,n=r.left-t<=a+t&&r.left+r.width+t>=0;return i&&n}function b(e,t){return e.composedPath&&e.composedPath().indexOf(t)>-1}function x(e,t){return t.parentNode.replaceChild(e,t),e}function w(e){return document.createElement(e)}},{"./compatibility":"6ZTr6","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"6ZTr6":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r),o.export(r,"userAgent",(()=>a)),o.export(r,"isMobile",(()=>i)),o.export(r,"isSafari",(()=>n)),o.export(r,"isWechat",(()=>s)),o.export(r,"isIE",(()=>l)),o.export(r,"isAndroid",(()=>c)),o.export(r,"isIOS",(()=>p));const a="undefined"!=typeof window?window.navigator.userAgent:"",i=/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(a),n=/^((?!chrome|android).)*safari/i.test(a),s=/MicroMessenger/i.test(a),l=/MSIE|Trident/i.test(a),c=/android/i.test(a),p=/iPad|iPhone|iPod/i.test(a)&&!window.MSStream},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],hwmZz:[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r),o.export(r,"ArtPlayerError",(()=>a)),o.export(r,"errorHandle",(()=>i));class a extends Error{constructor(e,t){super(e),"function"==typeof Error.captureStackTrace&&Error.captureStackTrace(this,t||this.constructor),this.name="ArtPlayerError"}}function i(e,t){if(!e)throw new a(t);return e}},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],inzwq:[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");function a(e){return"WEBVTT \\r\\n\\r\\n".concat((t=e,t.replace(/(\\d\\d:\\d\\d:\\d\\d)[,.](\\d+)/g,((e,t,r)=>{let o=r.slice(0,3);return 1===r.length&&(o=r+"00"),2===r.length&&(o=r+"0"),`${t},${o}`}))).replace(/\\{\\\\([ibu])\\}/g,"</$1>").replace(/\\{\\\\([ibu])1\\}/g,"<$1>").replace(/\\{([ibu])\\}/g,"<$1>").replace(/\\{\\/([ibu])\\}/g,"</$1>").replace(/(\\d\\d:\\d\\d:\\d\\d),(\\d\\d\\d)/g,"$1.$2").replace(/{[\\s\\S]*?}/g,"").concat("\\r\\n\\r\\n"));var t}function i(e){return URL.createObjectURL(new Blob([e],{type:"text/vtt"}))}function n(e){const t=new RegExp("Dialogue:\\\\s\\\\d,(\\\\d+:\\\\d\\\\d:\\\\d\\\\d.\\\\d\\\\d),(\\\\d+:\\\\d\\\\d:\\\\d\\\\d.\\\\d\\\\d),([^,]*),([^,]*),(?:[^,]*,){4}([\\\\s\\\\S]*)$","i");function r(e=""){return e.split(/[:.]/).map(((e,t,r)=>{if(t===r.length-1){if(1===e.length)return`.${e}00`;if(2===e.length)return`.${e}0`}else if(1===e.length)return(0===t?"0":":0")+e;return 0===t?e:t===r.length-1?`.${e}`:`:${e}`})).join("")}return`WEBVTT\\n\\n${e.split(/\\r?\\n/).map((e=>{const o=e.match(t);return o?{start:r(o[1].trim()),end:r(o[2].trim()),text:o[5].replace(/{[\\s\\S]*?}/g,"").replace(/(\\\\N)/g,"\\n").trim().split(/\\r?\\n/).map((e=>e.trim())).join("\\n")}:null})).filter((e=>e)).map(((e,t)=>e?`${t+1}\\n${e.start} --\\x3e ${e.end}\\n${e.text}`:"")).filter((e=>e.trim())).join("\\n\\n")}`}o.defineInteropFlag(r),o.export(r,"srtToVtt",(()=>a)),o.export(r,"vttToBlob",(()=>i)),o.export(r,"assToVtt",(()=>n))},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"6b7Ip":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");function a(e){return e.includes("?")?a(e.split("?")[0]):e.includes("#")?a(e.split("#")[0]):e.trim().toLowerCase().split(".").pop()}function i(e,t){const r=document.createElement("a");r.style.display="none",r.href=e,r.download=t,document.body.appendChild(r),r.click(),document.body.removeChild(r)}o.defineInteropFlag(r),o.export(r,"getExt",(()=>a)),o.export(r,"download",(()=>i))},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"5NSdr":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r),o.export(r,"def",(()=>a)),o.export(r,"has",(()=>n)),o.export(r,"get",(()=>s)),o.export(r,"mergeDeep",(()=>l));const a=Object.defineProperty,{hasOwnProperty:i}=Object.prototype;function n(e,t){return i.call(e,t)}function s(e,t){return Object.getOwnPropertyDescriptor(e,t)}function l(...e){const t=e=>e&&"object"==typeof e&&!Array.isArray(e);return e.reduce(((e,r)=>(Object.keys(r).forEach((o=>{const a=e[o],i=r[o];Array.isArray(a)&&Array.isArray(i)?e[o]=a.concat(...i):!t(a)||!t(i)||i instanceof Element?e[o]=i:e[o]=l(a,i)})),e)),{})}},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],epmNy:[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");function a(e=0){return new Promise((t=>setTimeout(t,e)))}function i(e,t,r){let o;function a(...a){clearTimeout(o),o=setTimeout((function(){o=null,e.apply(r,a)}),t)}return a.clearTimeout=function(){clearTimeout(o)},a}function n(e,t){let r,o,a=!1;return function i(...n){if(a)return r=n,void(o=this);a=!0,e.apply(this,n),setTimeout((()=>{a=!1,r&&(i.apply(o,r),r=null,o=null)}),t)}}o.defineInteropFlag(r),o.export(r,"sleep",(()=>a)),o.export(r,"debounce",(()=>i)),o.export(r,"throttle",(()=>n))},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],gapRl:[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");function a(e,t,r){return Math.max(Math.min(e,Math.max(t,r)),Math.min(t,r))}function i(e){return e.charAt(0).toUpperCase()+e.slice(1)}function n(e){return["string","number"].includes(typeof e)}function s(e){const t=Math.floor(e/3600),r=Math.floor((e-3600*t)/60),o=Math.floor(e-3600*t-60*r);return(t>0?[t,r,o]:[r,o]).map((e=>e<10?`0${e}`:String(e))).join(":")}function l(e){return e.replace(/[&<>\'"]/g,(e=>({"&":"&amp;","<":"&lt;",">":"&gt;","\'":"&#39;",\'"\':"&quot;"}[e]||e)))}o.defineInteropFlag(r),o.export(r,"clamp",(()=>a)),o.export(r,"capitalize",(()=>i)),o.export(r,"isStringOrNumber",(()=>n)),o.export(r,"secondToTime",(()=>s)),o.export(r,"escape",(()=>l))},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],AKEiO:[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r),o.export(r,"ComponentOption",(()=>d));var a=e("../utils");const i="array",n="boolean",s="string",l="number",c="object",p="function";function u(e,t,r){return(0,a.errorHandle)(t===s||t===l||e instanceof Element,`${r.join(".")} require \'${s}\' or \'Element\' type`)}const d={html:u,disable:`?${n}`,name:`?${s}`,index:`?${l}`,style:`?${c}`,click:`?${p}`,mounted:`?${p}`,tooltip:`?${s}|${l}`,width:`?${l}`,selector:`?${i}`,onSelect:`?${p}`,switch:`?${n}`,onSwitch:`?${p}`,range:`?${i}`,onRange:`?${p}`,onChange:`?${p}`};r.default={id:s,container:u,url:s,poster:s,title:s,type:s,theme:s,lang:s,volume:l,isLive:n,muted:n,autoplay:n,autoSize:n,autoMini:n,loop:n,flip:n,playbackRate:n,aspectRatio:n,screenshot:n,setting:n,hotkey:n,pip:n,mutex:n,backdrop:n,fullscreen:n,fullscreenWeb:n,subtitleOffset:n,miniProgressBar:n,useSSR:n,playsInline:n,lock:n,fastForward:n,autoPlayback:n,autoOrientation:n,airplay:n,plugins:[p],whitelist:[`${s}|${p}|regexp`],layers:[d],contextmenu:[d],settings:[d],controls:[{...d,position:(e,t,r)=>{const o=["top","left","right"];return(0,a.errorHandle)(o.includes(e),`${r.join(".")} only accept ${o.toString()} as parameters`)}}],quality:[{default:`?${n}`,html:s,url:s}],highlight:[{time:l,text:s}],thumbnails:{url:s,number:l,column:l,width:l,height:l},subtitle:{url:s,type:s,style:c,escape:n,encoding:s},moreVideoAttr:c,i18n:c,icons:c,customType:c}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],lyjeQ:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r),r.default={propertys:["audioTracks","autoplay","buffered","controller","controls","crossOrigin","currentSrc","currentTime","defaultMuted","defaultPlaybackRate","duration","ended","error","loop","mediaGroup","muted","networkState","paused","playbackRate","played","preload","readyState","seekable","seeking","src","startDate","textTracks","videoTracks","volume"],methods:["addTextTrack","canPlayType","load","play","pause"],events:["abort","canplay","canplaythrough","durationchange","emptied","ended","error","loadeddata","loadedmetadata","loadstart","pause","play","playing","progress","ratechange","seeked","seeking","stalled","suspend","timeupdate","volumechange","waiting"],prototypes:["width","height","videoWidth","videoHeight","poster","webkitDecodedFrameCount","webkitDroppedFrameCount","playsInline","webkitSupportsFullscreen","webkitDisplayingFullscreen","onenterpictureinpicture","onleavepictureinpicture","disablePictureInPicture","cancelVideoFrameCallback","requestVideoFrameCallback","getVideoPlaybackQuality","requestPictureInPicture","webkitEnterFullScreen","webkitEnterFullscreen","webkitExitFullScreen","webkitExitFullscreen"]}},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"9L0ao":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("./utils");r.default=class{constructor(e){this.art=e}get state(){const{option:e,constructor:{kindOf:t}}=this.art;return!o.isMobile||!e.whitelist.length||e.whitelist.some((e=>{switch(t(e)){case"string":return"*"===e||o.userAgent.indexOf(e)>-1;case"function":return e(o.userAgent);case"regexp":return e.test(o.userAgent);default:return!1}}))}}},{"./utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],X13Zf:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("./utils");class a{constructor(e){this.art=e;const{option:t,constructor:r,whitelist:a}=e;t.container instanceof Element?this.$container=t.container:(this.$container=(0,o.query)(t.container),(0,o.errorHandle)(this.$container,`No container element found by ${t.container}`));const i=this.$container.tagName.toLowerCase();(0,o.errorHandle)("div"===i,`Unsupported container element type, only support \'div\' but got \'${i}\'`),(0,o.errorHandle)(r.instances.every((e=>e.template.$container!==this.$container)),"Cannot mount multiple instances on the same dom element"),this.query=this.query.bind(this),this.$container.dataset.artId=e.id,this.$original=this.$container.cloneNode(!0),a.state?this.desktop():this.mobile()}static get html(){return\'<div class="art-video-player art-subtitle-show art-layer-show art-control-show art-mask-show"><video class="art-video"><track default kind="metadata" src=""></track></video><div class="art-poster"></div><div class="art-subtitle"></div><div class="art-danmuku"></div><div class="art-layers"></div><div class="art-mask"><div class="art-state"></div></div><div class="art-bottom"><div class="art-progress"></div><div class="art-controls"><div class="art-controls-left"></div><div class="art-controls-center"></div><div class="art-controls-right"></div></div></div><div class="art-loading"></div><div class="art-notice"><div class="art-notice-inner"></div></div><div class="art-settings"></div><div class="art-info"><div class="art-info-panel"><div class="art-info-item"><div class="art-info-title">Player version:</div><div class="art-info-content">4.6.2</div></div><div class="art-info-item"><div class="art-info-title">Video url:</div><div class="art-info-content" data-video="src"></div></div><div class="art-info-item"><div class="art-info-title">Video volume:</div><div class="art-info-content" data-video="volume"></div></div><div class="art-info-item"><div class="art-info-title">Video time:</div><div class="art-info-content" data-video="currentTime"></div></div><div class="art-info-item"><div class="art-info-title">Video duration:</div><div class="art-info-content" data-video="duration"></div></div><div class="art-info-item"><div class="art-info-title">Video resolution:</div><div class="art-info-content"><span data-video="videoWidth"></span> x <span data-video="videoHeight"></span></div></div></div><div class="art-info-close">[x]</div></div><div class="art-mini-header"><div class="art-mini-title"></div><div class="art-mini-close"></div></div><div class="art-contextmenus"></div></div>\'}query(e){return(0,o.query)(e,this.$container)}desktop(){const{option:e}=this.art;e.useSSR||(this.$container.innerHTML=a.html),this.$player=this.query(".art-video-player"),this.$video=this.query(".art-video"),this.$track=this.query("track"),this.$poster=this.query(".art-poster"),this.$subtitle=this.query(".art-subtitle"),this.$danmuku=this.query(".art-danmuku"),this.$bottom=this.query(".art-bottom"),this.$progress=this.query(".art-progress"),this.$controls=this.query(".art-controls"),this.$controlsLeft=this.query(".art-controls-left"),this.$controlsCenter=this.query(".art-controls-center"),this.$controlsRight=this.query(".art-controls-right"),this.$layer=this.query(".art-layers"),this.$loading=this.query(".art-loading"),this.$notice=this.query(".art-notice"),this.$noticeInner=this.query(".art-notice-inner"),this.$mask=this.query(".art-mask"),this.$state=this.query(".art-state"),this.$setting=this.query(".art-settings"),this.$info=this.query(".art-info"),this.$infoPanel=this.query(".art-info-panel"),this.$infoClose=this.query(".art-info-close"),this.$miniHeader=this.query(".art-mini-header"),this.$miniTitle=this.query(".art-mini-title"),this.$miniClose=this.query(".art-mini-close"),this.$contextmenu=this.query(".art-contextmenus"),e.backdrop&&((0,o.addClass)(this.$setting,"art-backdrop-filter"),(0,o.addClass)(this.$contextmenu,"art-backdrop-filter"),(0,o.addClass)(this.$info,"art-backdrop-filter")),o.isMobile&&(0,o.addClass)(this.$player,"art-mobile")}mobile(){this.$container.innerHTML=\'<div class="art-video-player"><video class="art-video"></video></div>\',this.$player=this.query(".art-video-player"),this.$video=this.query(".art-video")}destroy(e){e?(0,o.replaceElement)(this.$original,this.$container):(0,o.addClass)(this.$player,"art-destroy")}}r.default=a},{"./utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"3jKkj":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("../utils"),i=e("./zh-cn.json"),n=o.interopDefault(i),s=e("./zh-tw.json"),l=o.interopDefault(s),c=e("./pl.json"),p=o.interopDefault(c),u=e("./cs.json"),d=o.interopDefault(u),f=e("./es.json"),h=o.interopDefault(f),m=e("./fa.json"),g=o.interopDefault(m);r.default=class{constructor(e){this.art=e,this.languages={"zh-cn":n.default,"zh-tw":l.default,pl:p.default,cs:d.default,es:h.default,fa:g.default},this.update(e.option.i18n)}init(){const e=this.art.option.lang.toLowerCase();this.language=this.languages[e]||{}}get(e){return this.language[e]||e}update(e){this.languages=(0,a.mergeDeep)(this.languages,e),this.init()}}},{"../utils":"71aH7","./zh-cn.json":"lNQi5","./zh-tw.json":"eRpom","./pl.json":"iEpPa","./cs.json":"dBgp3","./es.json":"dNIrL","./fa.json":"7Plhe","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],lNQi5:[function(e,t,r){t.exports=JSON.parse(\'{"Video Info":"","Close":"","Video Load Failed":"","Volume":"","Play":"","Pause":"","Rate":"","Mute":"","Video Flip":"","Horizontal":"","Vertical":"","Reconnect":"","Show Setting":"","Hide Setting":"","Screenshot":"","Play Speed":"","Aspect Ratio":"","Default":"","Normal":"","Open":"","Switch Video":"","Switch Subtitle":"","Fullscreen":"","Exit Fullscreen":"","Web Fullscreen":"","Exit Web Fullscreen":"","Mini Player":"","PIP Mode":"","Exit PIP Mode":"","PIP Not Supported":"","Fullscreen Not Supported":"","Subtitle Offset":"","Last Seen":"","Jump Play":"","AirPlay":"","AirPlay Not Available":""}\')},{}],eRpom:[function(e,t,r){t.exports=JSON.parse(\'{"Video Info":"","Close":"","Video Load Failed":"","Volume":"","Play":"","Pause":"","Rate":"","Mute":"","Video Flip":"","Horizontal":"","Vertical":"","Reconnect":"","Show Setting":"","Hide Setting":"","Screenshot":"","Play Speed":"","Aspect Ratio":"","Default":"","Normal":"","Open":"","Switch Video":"","Switch Subtitle":"","Fullscreen":"","Exit Fullscreen":"","Web Fullscreen":"","Exit Web Fullscreen":"","Mini Player":"","PIP Mode":"","Exit PIP Mode":"","PIP Not Supported":"","Fullscreen Not Supported":"","Subtitle Offset":"","Last Seen":"","Jump Play":"","AirPlay":"","AirPlay Not Available":""}\')},{}],iEpPa:[function(e,t,r){t.exports=JSON.parse(\'{"Video Info":"Informacje o wideo","Close":"Zamknij","Video Load Failed":"Bd adowania wideo","Volume":"Gono","Play":"Odtwrz","Pause":"Wstrzymaj","Rate":"Oce","Mute":"Wycisz","Video Flip":"Rotacja wideo","Horizontal":"Pozioma","Vertical":"Pionowa","Reconnect":"Pocz ponownie","Show Setting":"Poka ustawienia","Hide Setting":"Ukryj ustawienia","Screenshot":"Zrzut ekranu","Play Speed":"Prdko odtwarzania","Aspect Ratio":"Wspczynnik proporcji","Default":"Domylny","Normal":"Normalny","Open":"Otwrz","Switch Video":"Przecz wideo","Switch Subtitle":"Przecz napisy","Fullscreen":"Peny ekran","Exit Fullscreen":"Zamknij peny ekran","Web Fullscreen":"Tryb penej strony","Exit Web Fullscreen":"Zamknij tryb penej strony","Mini Player":"Miniodtwarzacz","PIP Mode":"Tryb PiP","Exit PIP Mode":"Zamknij tryb PiP","PIP Not Supported":"Tryb PiP nieobsugiwany","Fullscreen Not Supported":"Peny ekran nieobsugiwany","Subtitle Offset":"Przesunicie napisw","Last Seen":"Ostatnio widziany","Jump Play":"Skocz do gry","AirPlay":"AirPlay","AirPlay Not Available":"AirPlay nie jest dostpny"}\')},{}],dBgp3:[function(e,t,r){t.exports=JSON.parse(\'{"Video Info":"Info o videu","Close":"Zavt","Video Load Failed":"Nahrn videa selhalo","Volume":"Hlasitost","Play":"Pehrt","Pause":"Pozastavit","Rate":"Hodnocen","Mute":"Ztlumit","Video Flip":"Otoit video","Horizontal":"Horizontln","Vertical":"Vertikln","Reconnect":"Optovn pipojen","Show Setting":"Zobrazit nastaven","Hide Setting":"Skrt nastaven","Screenshot":"Snmek obrazovky","Play Speed":"Rychlost pehrvn","Aspect Ratio":"Pomr stran","Default":"Vchoz","Normal":"Normln","Open":"Otevt","Switch Video":"Pepnout video","Switch Subtitle":"Pepnout titulky","Fullscreen":"Cel obrazovka","Exit Fullscreen":"Opustit reim cel obrazovky","Web Fullscreen":"Cel strnka","Exit Web Fullscreen":"Zavt reim cel strnky","Mini Player":"Mini pehrva","PIP Mode":"Reim PIP","Exit PIP Mode":"Opustit reim PIP","PIP Not Supported":"Reim PIP nen podporovn","Fullscreen Not Supported":"Reim cel obrazovky nen podporovn","Subtitle Offset":"Posun titulk","Last Seen":"Naposledy vidn","Jump Play":"Hra na skok","AirPlay":"AirPlay","AirPlay Not Available":"AirPlay nen k dispozici"}\')},{}],dNIrL:[function(e,t,r){t.exports=JSON.parse(\'{"Video Info":"Informacin del video","Close":"Cerrar","Video Load Failed":"Fall carga de video","Volume":"Volumen","Play":"Reproduciendo","Pause":"Pausa","Rate":"Velocidad","Mute":"Silencio","Video Flip":"Rotar video","Horizontal":"Horizontal","Vertical":"Vertical","Reconnect":"Reconectando","Show Setting":"Mostrar ajustes","Hide Setting":"Ocultar ajustes","Screenshot":"Captura de Pantalla","Play Speed":"Velocidad de reproduccin","Aspect Ratio":"Relacin de aspecto","Default":"Por defecto","Normal":"Normal","Open":"Abrir","Switch Video":"Cambiar video","Switch Subtitle":"Cambiar subttulo","Fullscreen":"Pantalla completa","Exit Fullscreen":"Salir de Pantalla completa","Web Fullscreen":"Pantalla completa Web","Exit Web Fullscreen":"Salir de Pantalla completa","Mini Player":"Mini reproductor","PIP Mode":"Modo PiP","Exit PIP Mode":"Cerrar modo PiP","PIP Not Supported":"Modo PiP no compatible","Fullscreen Not Supported":"Pantalla completa no soportada","Subtitle Offset":"Ajuste subttulo","Last Seen":"Visto ltima vez","Jump Play":"Saltar","AirPlay":"AirPlay","AirPlay Not Available":"AirPlay no disponible"}\')},{}],"7Plhe":[function(e,t,r){t.exports=JSON.parse(\'{"Video Info":" ","Close":"","Video Load Failed":" ","Play":"","Volume":" ","Pause":"","Rate":"","Mute":"","Video Flip":" ","Horizontal":"","Vertical":"","Reconnect":" ","Show Setting":"","Hide Setting":" ","Screenshot":"  ","Play Speed":" ","Aspect Ratio":" ","Default":" ","Normal":"  ","Open":"","Switch Video":" ","Switch Subtitle":" ","Fullscreen":" ","Exit Fullscreen":" ","Web Fullscreen":" ","Exit Web Fullscreen":"   ","Mini Player":"  ","PIP Mode":"  ","Exit PIP Mode":"   ","PIP Not Supported":"    ","Fullscreen Not Supported":"     ","Subtitle Offset":" ","Last Seen":" ","Jump Play":" ","AirPlay":" ","AirPlay Not Available":"   "}\')},{}],a90nx:[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("./urlMix"),i=o.interopDefault(a),n=e("./attrMix"),s=o.interopDefault(n),l=e("./playMix"),c=o.interopDefault(l),p=e("./pauseMix"),u=o.interopDefault(p),d=e("./toggleMix"),f=o.interopDefault(d),h=e("./seekMix"),m=o.interopDefault(h),g=e("./volumeMix"),y=o.interopDefault(g),v=e("./currentTimeMix"),b=o.interopDefault(v),x=e("./durationMix"),w=o.interopDefault(x),j=e("./switchMix"),k=o.interopDefault(j),S=e("./playbackRateMix"),I=o.interopDefault(S),C=e("./aspectRatioMix"),$=o.interopDefault(C),E=e("./screenshotMix"),P=o.interopDefault(E),T=e("./fullscreenMix"),M=o.interopDefault(T),F=e("./fullscreenWebMix"),A=o.interopDefault(F),z=e("./pipMix"),H=o.interopDefault(z),D=e("./loadedMix"),O=o.interopDefault(D),R=e("./playedMix"),L=o.interopDefault(R),N=e("./playingMix"),V=o.interopDefault(N),Y=e("./autoSizeMix"),_=o.interopDefault(Y),W=e("./rectMix"),B=o.interopDefault(W),q=e("./flipMix"),U=o.interopDefault(q),Z=e("./miniMix"),G=o.interopDefault(Z),K=e("./loopMix"),X=o.interopDefault(K),J=e("./posterMix"),Q=o.interopDefault(J),ee=e("./autoHeightMix"),te=o.interopDefault(ee),re=e("./themeMix"),oe=o.interopDefault(re),ae=e("./titleMix"),ie=o.interopDefault(ae),ne=e("./typeMix"),se=o.interopDefault(ne),le=e("./normalSizeMix"),ce=o.interopDefault(le),pe=e("./subtitleOffsetMix"),ue=o.interopDefault(pe),de=e("./airplayMix"),fe=o.interopDefault(de),he=e("./optionInit"),me=o.interopDefault(he),ge=e("./eventInit"),ye=o.interopDefault(ge);r.default=class{constructor(e){(0,i.default)(e),(0,s.default)(e),(0,c.default)(e),(0,u.default)(e),(0,f.default)(e),(0,m.default)(e),(0,y.default)(e),(0,b.default)(e),(0,w.default)(e),(0,k.default)(e),(0,I.default)(e),(0,$.default)(e),(0,P.default)(e),(0,M.default)(e),(0,A.default)(e),(0,H.default)(e),(0,O.default)(e),(0,L.default)(e),(0,V.default)(e),(0,_.default)(e),(0,B.default)(e),(0,U.default)(e),(0,G.default)(e),(0,X.default)(e),(0,Q.default)(e),(0,te.default)(e),(0,oe.default)(e),(0,ie.default)(e),(0,se.default)(e),(0,ce.default)(e),(0,ue.default)(e),(0,fe.default)(e),(0,ye.default)(e),(0,me.default)(e)}}},{"./urlMix":"kQoac","./attrMix":"deCma","./playMix":"fOJuP","./pauseMix":"fzHAy","./toggleMix":"cBHxQ","./seekMix":"koAPr","./volumeMix":"6eyuR","./currentTimeMix":"faaWv","./durationMix":"5y91K","./switchMix":"iceD8","./playbackRateMix":"keKwh","./aspectRatioMix":"jihET","./screenshotMix":"36kPY","./fullscreenMix":"2GYOJ","./fullscreenWebMix":"5aYAP","./pipMix":"7EnIB","./loadedMix":"3N9mP","./playedMix":"et96R","./playingMix":"9DzzM","./autoSizeMix":"i1LDY","./rectMix":"IqARI","./flipMix":"7E7Vs","./miniMix":"gpugx","./loopMix":"f1hVG","./posterMix":"1SuFS","./autoHeightMix":"8x4te","./themeMix":"2FqhO","./titleMix":"7Am53","./typeMix":"1fQQs","./normalSizeMix":"ePkBr","./subtitleOffsetMix":"6vlBV","./airplayMix":"eftqT","./optionInit":"fCWZK","./eventInit":"f8Lv3","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],kQoac:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{option:t,template:{$video:r}}=e;(0,o.def)(e,"url",{get:()=>r.currentSrc,async set(a){if(a){const i=t.type||(0,o.getExt)(a),n=t.customType[i];i&&n?(await(0,o.sleep)(),e.loading.show=!0,n.call(e,r,a,e)):(e.url&&e.url!==a&&e.once("video:canplay",(()=>{e.isReady&&e.emit("restart")})),r.src=a,e.option.url=a,e.emit("url",a))}else await(0,o.sleep)(),e.loading.show=!0}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],deCma:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{template:{$video:t}}=e;(0,o.def)(e,"attr",{value(e,r){if(void 0===r)return t[e];t[e]=r}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],fOJuP:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{i18n:t,notice:r,option:a,constructor:{instances:i},template:{$video:n}}=e;(0,o.def)(e,"play",{value:async function(){const o=await n.play();if(r.show=t.get("Play"),e.emit("play"),a.mutex)for(let t=0;t<i.length;t++){const r=i[t];r!==e&&r.pause()}return o}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],fzHAy:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{template:{$video:t},i18n:r,notice:a}=e;(0,o.def)(e,"pause",{value(){const o=t.pause();return a.show=r.get("Pause"),e.emit("pause"),o}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],cBHxQ:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){(0,o.def)(e,"toggle",{value:()=>e.playing?e.pause():e.play()})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],koAPr:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{notice:t}=e;(0,o.def)(e,"seek",{set(r){e.currentTime=r,e.emit("seek",e.currentTime),e.duration&&(t.show=`${(0,o.secondToTime)(e.currentTime)} / ${(0,o.secondToTime)(e.duration)}`)}}),(0,o.def)(e,"forward",{set(t){e.seek=e.currentTime+t}}),(0,o.def)(e,"backward",{set(t){e.seek=e.currentTime-t}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"6eyuR":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{template:{$video:t},i18n:r,notice:a,storage:i}=e;(0,o.def)(e,"volume",{get:()=>t.volume||0,set:e=>{t.volume=(0,o.clamp)(e,0,1),a.show=`${r.get("Volume")}: ${parseInt(100*t.volume,10)}`,0!==t.volume&&i.set("volume",t.volume)}}),(0,o.def)(e,"muted",{get:()=>t.muted,set:e=>{t.muted=e}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],faaWv:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{$video:t}=e.template;(0,o.def)(e,"currentTime",{get:()=>t.currentTime||0,set:r=>{r=parseFloat(r),Number.isNaN(r)||(t.currentTime=(0,o.clamp)(r,0,e.duration))}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"5y91K":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){(0,o.def)(e,"duration",{get:()=>{const{duration:t}=e.template.$video;return t===1/0?0:t||0}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],iceD8:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{i18n:t,option:r,notice:a}=e;function i(o,i,n){return new Promise((s=>{if(o===e.url)return s(o);const{playing:l}=e;e.pause(),URL.revokeObjectURL(e.url),e.url=o,e.once("video:canplay",(()=>{e.playbackRate=!1,e.aspectRatio=!1,e.flip="normal",e.autoSize=r.autoSize,e.currentTime=n,e.notice.show="",l&&e.play(),i&&(a.show=`${t.get("Switch Video")}: ${i}`),s(o)}))}))}(0,o.def)(e,"switchQuality",{value:(t,r)=>i(t,r,e.currentTime)}),(0,o.def)(e,"switchUrl",{value:(e,t)=>i(e,t,0)})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],keKwh:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{template:{$video:t},i18n:r,notice:a}=e;(0,o.def)(e,"playbackRate",{get:()=>t.playbackRate,set(o){if(o){if(o===t.playbackRate)return;t.playbackRate=o,a.show=`${r.get("Rate")}: ${1===o?r.get("Normal"):`${o}x`}`}else e.playbackRate=1}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],jihET:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{template:{$video:t,$player:r},i18n:a,notice:i}=e;(0,o.def)(e,"aspectRatio",{get:()=>r.dataset.aspectRatio||"default",set(n){if(n||(n="default"),"default"===n)(0,o.setStyle)(t,"width",null),(0,o.setStyle)(t,"height",null),(0,o.setStyle)(t,"padding",null),delete r.dataset.aspectRatio;else{const e=n.split(":").map(Number),{videoWidth:a,videoHeight:i}=t,{clientWidth:s,clientHeight:l}=r,c=a/i,p=e[0]/e[1];if(c>p){const e=p*i/a;(0,o.setStyle)(t,"width",100*e+"%"),(0,o.setStyle)(t,"height","100%"),(0,o.setStyle)(t,"padding",`0 ${(s-s*e)/2}px`)}else{const e=a/p/i;(0,o.setStyle)(t,"width","100%"),(0,o.setStyle)(t,"height",100*e+"%"),(0,o.setStyle)(t,"padding",(l-l*e)/2+"px 0")}r.dataset.aspectRatio=n}i.show=`${a.get("Aspect Ratio")}: ${"default"===n?a.get("Default"):n}`,e.emit("aspectRatio",n)}}),(0,o.def)(e,"aspectRatioReset",{set(t){if(t){const{aspectRatio:t}=e;e.aspectRatio=t}}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"36kPY":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{option:t,notice:r,template:{$video:a}}=e,i=(0,o.createElement)("canvas");(0,o.def)(e,"getDataURL",{value:()=>new Promise(((e,t)=>{try{i.width=a.videoWidth,i.height=a.videoHeight,i.getContext("2d").drawImage(a,0,0),e(i.toDataURL("image/png"))}catch(e){r.show=e,t(e)}}))}),(0,o.def)(e,"getBlobUrl",{value:()=>new Promise(((e,t)=>{try{i.width=a.videoWidth,i.height=a.videoHeight,i.getContext("2d").drawImage(a,0,0),i.toBlob((t=>{e(URL.createObjectURL(t))}))}catch(e){r.show=e,t(e)}}))}),(0,o.def)(e,"screenshot",{value:async()=>{const r=await e.getDataURL();return(0,o.download)(r,`${t.title||"artplayer"}_${(0,o.secondToTime)(a.currentTime)}.png`),e.emit("screenshot",r),r}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"2GYOJ":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("../libs/screenfull"),i=o.interopDefault(a),n=e("../utils");r.default=function(e){const{i18n:t,notice:r,template:{$video:o,$player:a}}=e;e.once("video:loadedmetadata",(()=>{i.default.isEnabled?(e=>{i.default.on("change",(()=>{e.emit("fullscreen",i.default.isFullscreen)})),(0,n.def)(e,"fullscreen",{get:()=>i.default.isFullscreen,async set(t){t?(e.normalSize="fullscreen",e.aspectRatioReset=!0,e.autoSize=!1,await i.default.request(a),(0,n.addClass)(a,"art-fullscreen"),e.emit("resize"),r.show=""):(e.aspectRatioReset=!0,e.autoSize=e.option.autoSize,await i.default.exit(),(0,n.removeClass)(a,"art-fullscreen"),e.emit("resize"),r.show="")}})})(e):document.fullscreenEnabled||o.webkitSupportsFullscreen?(e=>{(0,n.def)(e,"fullscreen",{get:()=>o.webkitDisplayingFullscreen,set(t){t?(e.normalSize="fullscreen",o.webkitEnterFullscreen(),e.emit("fullscreen",!0),r.show=""):(o.webkitExitFullscreen(),e.emit("fullscreen",!1),r.show="")}})})(e):(0,n.def)(e,"fullscreen",{get:()=>!1,set(){r.show=t.get("Fullscreen Not Supported")}}),(0,n.def)(e,"fullscreen",(0,n.get)(e,"fullscreen"))}))}},{"../libs/screenfull":"8v40z","../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"8v40z":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);const o=[["requestFullscreen","exitFullscreen","fullscreenElement","fullscreenEnabled","fullscreenchange","fullscreenerror"],["webkitRequestFullscreen","webkitExitFullscreen","webkitFullscreenElement","webkitFullscreenEnabled","webkitfullscreenchange","webkitfullscreenerror"],["webkitRequestFullScreen","webkitCancelFullScreen","webkitCurrentFullScreenElement","webkitCancelFullScreen","webkitfullscreenchange","webkitfullscreenerror"],["mozRequestFullScreen","mozCancelFullScreen","mozFullScreenElement","mozFullScreenEnabled","mozfullscreenchange","mozfullscreenerror"],["msRequestFullscreen","msExitFullscreen","msFullscreenElement","msFullscreenEnabled","MSFullscreenChange","MSFullscreenError"]],a=(()=>{if("undefined"==typeof document)return!1;const e=o[0],t={};for(const r of o){if(r[1]in document){for(const[o,a]of r.entries())t[e[o]]=a;return t}}return!1})(),i={change:a.fullscreenchange,error:a.fullscreenerror};let n={request:(e=document.documentElement,t)=>new Promise(((r,o)=>{const i=()=>{n.off("change",i),r()};n.on("change",i);const s=e[a.requestFullscreen](t);s instanceof Promise&&s.then(i).catch(o)})),exit:()=>new Promise(((e,t)=>{if(!n.isFullscreen)return void e();const r=()=>{n.off("change",r),e()};n.on("change",r);const o=document[a.exitFullscreen]();o instanceof Promise&&o.then(r).catch(t)})),toggle:(e,t)=>n.isFullscreen?n.exit():n.request(e,t),onchange(e){n.on("change",e)},onerror(e){n.on("error",e)},on(e,t){const r=i[e];r&&document.addEventListener(r,t,!1)},off(e,t){const r=i[e];r&&document.removeEventListener(r,t,!1)},raw:a};Object.defineProperties(n,{isFullscreen:{get:()=>Boolean(document[a.fullscreenElement])},element:{enumerable:!0,get:()=>document[a.fullscreenElement]},isEnabled:{enumerable:!0,get:()=>Boolean(document[a.fullscreenEnabled])}}),a||(n={isEnabled:!1}),r.default=n},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"5aYAP":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{notice:t,constructor:r,template:{$container:a,$player:i}}=e;(0,o.def)(e,"fullscreenWeb",{get:()=>(0,o.hasClass)(i,"art-fullscreen-web"),set(n){n?(r.FULLSCREEN_WEB_IN_BODY&&(0,o.append)(document.body,i),e.normalSize="fullscreenWeb",(0,o.addClass)(i,"art-fullscreen-web"),e.aspectRatioReset=!0,e.autoSize=!1,e.emit("resize"),e.emit("fullscreenWeb",!0),t.show=""):(r.FULLSCREEN_WEB_IN_BODY&&(0,o.append)(a,i),(0,o.removeClass)(i,"art-fullscreen-web"),e.aspectRatioReset=!0,e.autoSize=e.option.autoSize,e.emit("resize"),e.emit("fullscreenWeb",!1),t.show="")}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"7EnIB":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{i18n:t,notice:r,template:{$video:a}}=e;document.pictureInPictureEnabled?function(e){const{template:{$video:t},proxy:r,notice:a}=e;t.disablePictureInPicture=!1,(0,o.def)(e,"pip",{get:()=>document.pictureInPictureElement,set(r){r?(e.normalSize="pip",t.requestPictureInPicture().catch((e=>{throw a.show=e,e}))):document.exitPictureInPicture().catch((e=>{throw a.show=e,e}))}}),r(t,"enterpictureinpicture",(()=>{e.emit("pip",!0)})),r(t,"leavepictureinpicture",(()=>{e.emit("pip",!1)}))}(e):a.webkitSupportsPresentationMode?function(e){const{$video:t}=e.template;t.webkitSetPresentationMode("inline"),(0,o.def)(e,"pip",{get:()=>"picture-in-picture"===t.webkitPresentationMode,set(r){r?(e.normalSize="pip",t.webkitSetPresentationMode("picture-in-picture"),e.emit("pip",!0)):(t.webkitSetPresentationMode("inline"),e.emit("pip",!1))}})}(e):(0,o.def)(e,"pip",{get:()=>!1,set(){r.show=t.get("PIP Not Supported")}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"3N9mP":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{$video:t}=e.template;(0,o.def)(e,"loaded",{get:()=>e.loadedTime/t.duration}),(0,o.def)(e,"loadedTime",{get:()=>t.buffered.length?t.buffered.end(t.buffered.length-1):0})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],et96R:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){(0,o.def)(e,"played",{get:()=>e.currentTime/e.duration})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"9DzzM":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{$video:t}=e.template;(0,o.def)(e,"playing",{get:()=>!!(t.currentTime>0&&!t.paused&&!t.ended&&t.readyState>2)})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],i1LDY:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{$container:t,$player:r,$video:a}=e.template;(0,o.def)(e,"autoSize",{get:()=>(0,o.hasClass)(t,"art-auto-size"),set(i){if(i){const{videoWidth:i,videoHeight:n}=a,{width:s,height:l}=t.getBoundingClientRect(),c=i/n,p=s/l;if((0,o.addClass)(t,"art-auto-size"),p>c){const e=l*c/s*100;(0,o.setStyle)(r,"width",`${e}%`),(0,o.setStyle)(r,"height","100%")}else{const e=s/c/l*100;(0,o.setStyle)(r,"width","100%"),(0,o.setStyle)(r,"height",`${e}%`)}e.emit("autoSize",{width:e.width,height:e.height})}else(0,o.removeClass)(t,"art-auto-size"),(0,o.setStyle)(r,"width",null),(0,o.setStyle)(r,"height",null),e.emit("autoSize")}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],IqARI:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){(0,o.def)(e,"rect",{get:()=>e.template.$player.getBoundingClientRect()});const t=["bottom","height","left","right","top","width"];for(let r=0;r<t.length;r++){const a=t[r];(0,o.def)(e,a,{get:()=>e.rect[a]})}(0,o.def)(e,"x",{get:()=>e.left+window.pageXOffset}),(0,o.def)(e,"y",{get:()=>e.top+window.pageYOffset})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"7E7Vs":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{template:{$player:t},i18n:r,notice:a}=e;(0,o.def)(e,"flip",{get:()=>t.dataset.flip||"normal",set(i){i||(i="normal"),"normal"===i?delete t.dataset.flip:t.dataset.flip=i,a.show=`${r.get("Video Flip")}: ${r.get((0,o.capitalize)(i))}`,e.emit("flip",i)}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],gpugx:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{i18n:t,option:r,storage:a,proxy:i,template:{$player:n,$miniClose:s,$miniTitle:l,$miniHeader:c}}=e;let p=!1,u=0,d=0,f=0,h=0;i(c,"mousedown",(t=>{p=!0,u=t.pageX,d=t.pageY,f=e.left,h=e.top})),i(document,"mousemove",(e=>{if(p){(0,o.addClass)(n,"art-is-dragging");const t=h+e.pageY-d,r=f+e.pageX-u;(0,o.setStyle)(n,"top",`${t}px`),(0,o.setStyle)(n,"left",`${r}px`),a.set("top",t),a.set("left",r)}})),i(document,"mouseup",(()=>{p=!1,(0,o.removeClass)(n,"art-is-dragging")})),i(s,"click",(()=>{e.mini=!1,p=!1,(0,o.removeClass)(n,"art-is-dragging")})),(0,o.append)(l,r.title||t.get("Mini Player")),(0,o.def)(e,"mini",{get:()=>(0,o.hasClass)(n,"art-mini"),set(t){if(t){e.normalSize="mini",e.autoSize=!1,(0,o.addClass)(n,"art-mini");const t=a.get("top"),r=a.get("left");if(t&&r)(0,o.setStyle)(n,"top",`${t}px`),(0,o.setStyle)(n,"left",`${r}px`),(0,o.isInViewport)(c)||(a.del("top"),a.del("left"),e.mini=!0);else{const t=window.innerHeight-e.height-50,r=window.innerWidth-e.width-50;a.set("top",t),a.set("left",r),(0,o.setStyle)(n,"top",`${t}px`),(0,o.setStyle)(n,"left",`${r}px`)}e.aspectRatio=!1,e.playbackRate=!1,e.notice.show="",e.emit("mini",!0)}else(0,o.removeClass)(n,"art-mini"),(0,o.setStyle)(n,"top",null),(0,o.setStyle)(n,"left",null),e.aspectRatio=!1,e.playbackRate=!1,e.autoSize=r.autoSize,e.notice.show="",e.emit("mini",!1)}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],f1hVG:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){let t=[];(0,o.def)(e,"loop",{get:()=>t,set:r=>{if(Array.isArray(r)&&"number"==typeof r[0]&&"number"==typeof r[1]){const a=(0,o.clamp)(r[0],0,Math.min(r[1],e.duration)),i=(0,o.clamp)(r[1],a,e.duration);t=i-a>=1?[a,i]:[]}else t=[]}}),e.on("video:timeupdate",(()=>{t.length&&(e.currentTime<t[0]||e.currentTime>t[1])&&(e.seek=t[0])}))}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"1SuFS":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{option:t,template:{$poster:r}}=e;(0,o.def)(e,"poster",{get:()=>t.poster,set(e){t.poster=e,(0,o.setStyle)(r,"backgroundImage",`url(${e})`)}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"8x4te":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{option:t,template:{$container:r,$video:a}}=e,i=r.style.height;(0,o.def)(e,"autoHeight",{get:()=>(0,o.hasClass)(r,"art-auto-height"),set(n){if(n){const{clientWidth:i}=r,{videoHeight:n,videoWidth:s}=a,l=n*(i/s);(0,o.setStyle)(r,"height",l+"px"),(0,o.addClass)(r,"art-auto-height"),e.autoSize=t.autoSize,e.emit("autoHeight",l)}else(0,o.setStyle)(r,"height",i),(0,o.removeClass)(r,"art-auto-height"),e.autoSize=t.autoSize,e.emit("autoHeight")}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"2FqhO":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{option:t,template:{$player:r}}=e;(0,o.def)(e,"theme",{get:()=>getComputedStyle(r).getPropertyValue("--theme"),set(e){t.theme=e,r.style.setProperty("--theme",e)}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"7Am53":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){(0,o.def)(e,"title",{get:()=>e.option.title,set(t){e.option.title=t}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"1fQQs":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){(0,o.def)(e,"type",{get:()=>e.option.type,set(t){e.option.type=t}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],ePkBr:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const t=["mini","pip","fullscreen","fullscreenWeb"];(0,o.def)(e,"normalSize",{get:()=>t.every((t=>!e[t])),set(r){t.filter((e=>e!==r)).forEach((t=>{e[t]&&(e[t]=!1)}))}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"6vlBV":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{clamp:t}=e.constructor.utils,{notice:r,template:a,i18n:i}=e;let n=0,s=[];e.on("subtitle:switch",(()=>{s=[]})),(0,o.def)(e,"subtitleOffset",{get:()=>n,set(o){if(a.$track&&a.$track.track){const l=Array.from(a.$track.track.cues);n=t(o,-5,5);for(let r=0;r<l.length;r++){const o=l[r];s[r]||(s[r]={startTime:o.startTime,endTime:o.endTime}),o.startTime=t(s[r].startTime+n,0,e.duration),o.endTime=t(s[r].endTime+n,0,e.duration)}e.subtitle.update(),r.show=`${i.get("Subtitle Offset")}: ${o}s`,e.emit("subtitleOffset",o)}else e.emit("subtitleOffset",0)}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],eftqT:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{i18n:t,notice:r,proxy:a,template:{$video:i}}=e;let n=!0;window.WebKitPlaybackTargetAvailabilityEvent&&i.webkitShowPlaybackTargetPicker?a(i,"webkitplaybacktargetavailabilitychanged",(e=>{switch(e.availability){case"available":n=!0;break;case"not-available":n=!1}})):n=!1,(0,o.def)(e,"airplay",{value(){n?(i.webkitShowPlaybackTargetPicker(),e.emit("airplay")):r.show=t.get("AirPlay Not Available")}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],fCWZK:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{option:t,storage:r,template:{$video:a,$poster:i}}=e;Object.keys(t.moreVideoAttr).forEach((r=>{e.attr(r,t.moreVideoAttr[r])})),t.muted&&(e.muted=t.muted),t.volume&&(a.volume=(0,o.clamp)(t.volume,0,1));const n=r.get("volume");"number"==typeof n&&(a.volume=(0,o.clamp)(n,0,1)),t.poster&&(0,o.setStyle)(i,"backgroundImage",`url(${t.poster})`),t.autoplay&&(a.autoplay=t.autoplay),t.playsInline&&(a.playsInline=!0,a["webkit-playsinline"]=!0),t.theme&&(e.theme=t.theme),e.url=t.url}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],f8Lv3:[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("../config"),i=o.interopDefault(a),n=e("../utils");r.default=function(e){const{i18n:t,notice:r,option:o,constructor:a,proxy:s,template:{$player:l,$video:c,$poster:p}}=e;let u=0;for(let t=0;t<i.default.events.length;t++)s(c,i.default.events[t],(t=>{e.emit(`video:${t.type}`,t)}));e.on("video:canplay",(()=>{u=0,e.loading.show=!1})),e.once("video:canplay",(()=>{e.loading.show=!1,e.controls.show=!0,e.mask.show=!0,e.isReady=!0,e.emit("ready")})),e.on("video:ended",(()=>{o.loop?(e.seek=0,e.play(),e.controls.show=!1,e.mask.show=!1):(e.controls.show=!0,e.mask.show=!0)})),e.on("video:error",(async i=>{u<a.RECONNECT_TIME_MAX?(await(0,n.sleep)(a.RECONNECT_SLEEP_TIME),u+=1,e.url=o.url,r.show=`${t.get("Reconnect")}: ${u}`,e.emit("error",i,u)):(e.mask.show=!0,e.loading.show=!1,e.controls.show=!0,(0,n.addClass)(l,"art-error"),await(0,n.sleep)(a.RECONNECT_SLEEP_TIME),r.show=t.get("Video Load Failed"),e.destroy(!1))})),e.on("video:loadedmetadata",(()=>{e.autoSize=o.autoSize,n.isMobile&&(e.loading.show=!1,e.controls.show=!0,e.mask.show=!0)})),e.on("video:loadstart",(()=>{e.loading.show=!0,e.mask.show=!1,e.controls.show=!0})),e.on("video:pause",(()=>{e.controls.show=!0,e.mask.show=!0})),e.on("video:play",(()=>{e.mask.show=!1,(0,n.setStyle)(p,"display","none")})),e.on("video:playing",(()=>{e.mask.show=!1})),e.on("video:seeked",(()=>{e.loading.show=!1})),e.on("video:seeking",(()=>{e.loading.show=!0,e.mask.show=!1})),e.on("video:timeupdate",(()=>{e.mask.show=!1})),e.on("video:waiting",(()=>{e.loading.show=!0,e.mask.show=!1}))}},{"../config":"lyjeQ","../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"8Z0Uf":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("../utils"),i=e("../utils/component"),n=o.interopDefault(i),s=e("./fullscreen"),l=o.interopDefault(s),c=e("./fullscreenWeb"),p=o.interopDefault(c),u=e("./pip"),d=o.interopDefault(u),f=e("./playAndPause"),h=o.interopDefault(f),m=e("./progress"),g=o.interopDefault(m),y=e("./time"),v=o.interopDefault(y),b=e("./volume"),x=o.interopDefault(b),w=e("./setting"),j=o.interopDefault(w),k=e("./thumbnails"),S=o.interopDefault(k),I=e("./screenshot"),C=o.interopDefault(I),$=e("./quality"),E=o.interopDefault($),P=e("./loop"),T=o.interopDefault(P),M=e("./airplay"),F=o.interopDefault(M);class A extends n.default{constructor(e){super(e),this.name="control";const{proxy:t,constructor:r,template:{$player:o}}=e;let i=Date.now();t(o,["click","mousemove","touchstart","touchmove"],(()=>{this.show=!0,(0,a.removeClass)(o,"art-hide-cursor"),(0,a.addClass)(o,"art-hover"),i=Date.now()})),e.on("video:timeupdate",(()=>{!e.isInput&&e.playing&&this.show&&Date.now()-i>=r.CONTROL_HIDE_TIME&&(this.show=!1,(0,a.addClass)(o,"art-hide-cursor"),(0,a.removeClass)(o,"art-hover"))})),this.init()}init(){const{option:e}=this.art;e.isLive||this.add((0,g.default)({name:"progress",position:"top",index:10})),!e.thumbnails.url||e.isLive||a.isMobile||this.add((0,S.default)({name:"thumbnails",position:"top",index:20})),this.add((0,T.default)({name:"loop",position:"top",index:30})),this.add((0,h.default)({name:"playAndPause",position:"left",index:10})),this.add((0,x.default)({name:"volume",position:"left",index:20})),e.isLive||this.add((0,v.default)({name:"time",position:"left",index:30})),e.quality.length&&this.add((0,E.default)({name:"quality",position:"right",index:10})),e.screenshot&&!a.isMobile&&this.add((0,C.default)({name:"screenshot",position:"right",index:20})),e.setting&&this.add((0,j.default)({name:"setting",position:"right",index:30})),e.pip&&this.add((0,d.default)({name:"pip",position:"right",index:40})),e.airplay&&window.WebKitPlaybackTargetAvailabilityEvent&&this.add((0,F.default)({name:"airplay",position:"right",index:50})),e.fullscreenWeb&&this.add((0,p.default)({name:"fullscreenWeb",position:"right",index:60})),e.fullscreen&&this.add((0,l.default)({name:"fullscreen",position:"right",index:70}));for(let t=0;t<e.controls.length;t++)this.add(e.controls[t])}add(e){const t="function"==typeof e?e(this.art):e,{$progress:r,$controlsLeft:o,$controlsRight:i}=this.art.template;switch(t.position){case"top":this.$parent=r;break;case"left":this.$parent=o;break;case"right":this.$parent=i;break;default:(0,a.errorHandle)(!1,"Control option.position must one of \'top\', \'left\', \'right\'")}super.add(t)}}r.default=A},{"../utils":"71aH7","../utils/component":"18nVI","./fullscreen":"c61Lj","./fullscreenWeb":"03jeB","./pip":"u8l8e","./playAndPause":"ebXtb","./progress":"bgoVP","./time":"ikc2j","./volume":"b8NFx","./setting":"03o9l","./thumbnails":"eCVx2","./screenshot":"4KCF5","./quality":"efgTY","./loop":"2hIff","./airplay":"4IS2d","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"18nVI":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("./dom"),i=e("option-validator"),n=o.interopDefault(i),s=e("../scheme"),l=e("./property"),c=e("./error");r.default=class{constructor(e){this.id=0,this.art=e,this.add=this.add.bind(this)}get show(){return(0,a.hasClass)(this.art.template.$player,`art-${this.name}-show`)}set show(e){const{$player:t}=this.art.template,r=`art-${this.name}-show`;e?(0,a.addClass)(t,r):(0,a.removeClass)(t,r),this.art.emit(this.name,e)}set toggle(e){e&&(this.show=!this.show)}add(e){const t="function"==typeof e?e(this.art):e;if(t.html=t.html||"",(0,n.default)(t,s.ComponentOption),!this.$parent||!this.name||t.disable)return;const r=t.name||`${this.name}${this.id}`;(0,c.errorHandle)(!(0,l.has)(this,r),`Cannot add an existing name [${r}] to the [${this.name}]`),this.id+=1;const o=(0,a.createElement)("div");(0,a.addClass)(o,`art-${this.name}`),(0,a.addClass)(o,`art-${this.name}-${r}`);const i=Array.from(this.$parent.children);o.dataset.index=t.index||this.id;const p=i.find((e=>Number(e.dataset.index)>=Number(o.dataset.index)));return p?p.insertAdjacentElement("beforebegin",o):(0,a.append)(this.$parent,o),t.html&&(0,a.append)(o,t.html),t.style&&(0,a.setStyles)(o,t.style),t.tooltip&&(0,a.tooltip)(o,t.tooltip),t.click&&this.art.events.proxy(o,"click",(e=>{e.preventDefault(),t.click.call(this.art,this,e)})),t.selector&&["left","right"].includes(t.position)&&this.selector(t,o),t.mounted&&t.mounted.call(this.art,o),(0,l.def)(this,r,{value:o}),o}selector(e,t){const{hover:r,proxy:o}=this.art.events;(0,a.addClass)(t,"art-control-selector");const i=(0,a.createElement)("div");(0,a.addClass)(i,"art-selector-value"),(0,a.append)(i,e.html),t.innerText="",(0,a.append)(t,i);const n=e.selector.map(((e,t)=>`<div class="art-selector-item ${e.default?"art-current":""}" data-index="${t}">${e.html}</div>`)).join(""),s=(0,a.createElement)("div");(0,a.addClass)(s,"art-selector-list"),(0,a.append)(s,n),(0,a.append)(t,s),this.art.option.backdrop&&(0,a.addClass)(s,"art-backdrop-filter");const l=()=>{const e=(0,a.getStyle)(t,"width")/2-(0,a.getStyle)(s,"width")/2;s.style.left=`${e}px`};r(t,l),o(s,"click",(async t=>{const r=(t.composedPath()||[]).find((e=>(0,a.hasClass)(e,"art-selector-item")));if(!r)return;(0,a.inverseClass)(r,"art-current");const o=Number(r.dataset.index),n=e.selector[o]||{};if(i.innerText=r.innerText,e.onSelect){const o=await e.onSelect.call(this.art,n,r,t);"string"!=typeof o&&"number"!=typeof o||(i.innerHTML=o)}l()}))}}},{"./dom":"bSNiV","option-validator":"bAWi2","../scheme":"AKEiO","./property":"5NSdr","./error":"hwmZz","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],c61Lj:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){return t=>({...e,tooltip:t.i18n.get("Fullscreen"),mounted:e=>{const{proxy:r,icons:a,i18n:i}=t,n=(0,o.append)(e,a.fullscreenOn),s=(0,o.append)(e,a.fullscreenOff);(0,o.setStyle)(s,"display","none"),r(e,"click",(()=>{t.fullscreen=!t.fullscreen})),t.on("fullscreen",(t=>{t?((0,o.tooltip)(e,i.get("Exit Fullscreen")),(0,o.setStyle)(n,"display","none"),(0,o.setStyle)(s,"display","inline-flex")):((0,o.tooltip)(e,i.get("Fullscreen")),(0,o.setStyle)(n,"display","inline-flex"),(0,o.setStyle)(s,"display","none"))}))}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"03jeB":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){return t=>({...e,tooltip:t.i18n.get("Web Fullscreen"),mounted:e=>{const{proxy:r,icons:a,i18n:i}=t,n=(0,o.append)(e,a.fullscreenWebOn),s=(0,o.append)(e,a.fullscreenWebOff);(0,o.setStyle)(s,"display","none"),r(e,"click",(()=>{t.fullscreenWeb=!t.fullscreenWeb})),t.on("fullscreenWeb",(t=>{t?((0,o.tooltip)(e,i.get("Exit Web Fullscreen")),(0,o.setStyle)(n,"display","none"),(0,o.setStyle)(s,"display","inline-flex")):((0,o.tooltip)(e,i.get("Web Fullscreen")),(0,o.setStyle)(n,"display","inline-flex"),(0,o.setStyle)(s,"display","none"))}))}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],u8l8e:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){return t=>({...e,tooltip:t.i18n.get("PIP Mode"),mounted:e=>{const{proxy:r,icons:a,i18n:i}=t;(0,o.append)(e,a.pip),r(e,"click",(()=>{t.pip=!t.pip})),t.on("pip",(t=>{(0,o.tooltip)(e,i.get(t?"Exit PIP Mode":"PIP Mode"))}))}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],ebXtb:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){return t=>({...e,mounted:e=>{const{proxy:r,icons:a,i18n:i}=t,n=(0,o.append)(e,a.play),s=(0,o.append)(e,a.pause);function l(){(0,o.setStyle)(n,"display","flex"),(0,o.setStyle)(s,"display","none")}function c(){(0,o.setStyle)(n,"display","none"),(0,o.setStyle)(s,"display","flex")}(0,o.tooltip)(n,i.get("Play")),(0,o.tooltip)(s,i.get("Pause")),r(n,"click",(()=>{t.play()})),r(s,"click",(()=>{t.pause()})),t.playing?c():l(),t.on("video:playing",(()=>{c()})),t.on("video:pause",(()=>{l()}))}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],bgoVP:[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r),o.export(r,"getPosFromEvent",(()=>i)),o.export(r,"setCurrentTime",(()=>n));var a=e("../utils");function i(e,t){const{$progress:r}=e.template,{left:o}=r.getBoundingClientRect(),i=a.isMobile?t.touches[0].clientX:t.pageX,n=(0,a.clamp)(i-o,0,r.clientWidth),s=n/r.clientWidth*e.duration;return{second:s,time:(0,a.secondToTime)(s),width:n,percentage:(0,a.clamp)(n/r.clientWidth,0,1)}}function n(e,t){if(e.isRotate){const r=t.touches[0].clientY/e.height,o=r*e.duration;e.emit("setBar","played",r),e.seek=o}else{const{second:r,percentage:o}=i(e,t);e.emit("setBar","played",o),e.seek=r}}r.default=function(e){return t=>{const{icons:r,option:o,proxy:s}=t;return{...e,html:\'<div class="art-control-progress-inner"><div class="art-progress-loaded"></div><div class="art-progress-played"></div><div class="art-progress-highlight"></div><div class="art-progress-indicator"></div><div class="art-progress-tip"></div></div>\',mounted:e=>{let l=!1;const c=(0,a.query)(".art-progress-loaded",e),p=(0,a.query)(".art-progress-played",e),u=(0,a.query)(".art-progress-highlight",e),d=(0,a.query)(".art-progress-indicator",e),f=(0,a.query)(".art-progress-tip",e),{PROGRESS_HEIGHT:h,INDICATOR_SIZE:m,INDICATOR_SIZE_ICON:g,INDICATOR_SIZE_MOBILE:y,INDICATOR_SIZE_MOBILE_ICON:v}=t.constructor;(0,a.setStyle)(e,"height",`${h}px`),(0,a.setStyle)(p,"backgroundColor","var(--theme)");let b=m;function x(e,t){"loaded"===e&&(0,a.setStyle)(c,"width",100*t+"%"),"played"===e&&((0,a.setStyle)(p,"width",100*t+"%"),(0,a.setStyle)(d,"left",`calc(${100*t}% - ${b/2}px)`))}r.indicator?(b=g,(0,a.append)(d,r.indicator)):(0,a.setStyles)(d,{backgroundColor:"var(--theme)"}),a.isMobile&&(b=y,r.indicator&&(b=v)),(0,a.setStyles)(d,{left:`-${b/2}px`,width:`${b}px`,height:`${b}px`}),t.on("video:loadedmetadata",(()=>{for(let e=0;e<o.highlight.length;e++){const r=o.highlight[e],i=(0,a.clamp)(r.time,0,t.duration)/t.duration*100;(0,a.append)(u,`<span data-text="${r.text}" data-time="${r.time}" style="left: ${i}%"></span>`)}})),x("loaded",t.loaded),t.on("setBar",((e,t)=>{x(e,t)})),t.on("video:progress",(()=>{x("loaded",t.loaded)})),t.on("video:timeupdate",(()=>{x("played",t.played)})),t.on("video:ended",(()=>{x("played",1)})),a.isMobile||(s(e,"click",(e=>{e.target!==d&&n(t,e)})),s(e,"mousemove",(r=>{(0,a.setStyle)(f,"display","block"),(0,a.includeFromEvent)(r,u)?function(r){const{width:o}=i(t,r),{text:n}=r.target.dataset;f.innerHTML=n;const s=f.clientWidth;o<=s/2?(0,a.setStyle)(f,"left",0):o>e.clientWidth-s/2?(0,a.setStyle)(f,"left",e.clientWidth-s+"px"):(0,a.setStyle)(f,"left",o-s/2+"px")}(r):function(r){const{width:o,time:n}=i(t,r);f.innerHTML=n;const s=f.clientWidth;o<=s/2?(0,a.setStyle)(f,"left",0):o>e.clientWidth-s/2?(0,a.setStyle)(f,"left",e.clientWidth-s+"px"):(0,a.setStyle)(f,"left",o-s/2+"px")}(r)})),s(e,"mouseleave",(()=>{(0,a.setStyle)(f,"display","none")})),s(e,"mousedown",(()=>{l=!0})),s(document,"mousemove",(e=>{if(l){const{second:r,percentage:o}=i(t,e);x("played",o),t.seek=r}})),s(document,"mouseup",(()=>{l&&(l=!1)})))}}}}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],ikc2j:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){return t=>({...e,style:{cursor:"auto",marginLeft:"10px"},mounted:e=>{function r(){const r=`${(0,o.secondToTime)(t.currentTime)} / ${(0,o.secondToTime)(t.duration)}`;r!==e.innerText&&(e.innerText=r)}r();const a=["video:loadedmetadata","video:timeupdate","video:progress"];for(let e=0;e<a.length;e++)t.on(a[e],r)}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],b8NFx:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){return t=>({...e,mounted:e=>{const{proxy:r,icons:a,i18n:i}=t;let n=!1;const s=t.constructor.VOLUME_PANEL_WIDTH,l=t.constructor.VOLUME_HANDLE_WIDTH,c=(0,o.append)(e,a.volume),p=(0,o.append)(e,a.volumeClose),u=(0,o.append)(e,\'<div class="art-volume-panel"></div>\'),d=(0,o.append)(u,\'<div class="art-volume-slider-handle"></div>\');function f(e){const{left:t}=u.getBoundingClientRect();return(0,o.clamp)(e.pageX-t-l/2,0,s-l/2)/(s-l)}function h(e=.7){if(t.muted||0===e)(0,o.setStyle)(c,"display","none"),(0,o.setStyle)(p,"display","flex"),(0,o.setStyle)(d,"left","0");else{const t=(s-l)*e;(0,o.setStyle)(c,"display","flex"),(0,o.setStyle)(p,"display","none"),(0,o.setStyle)(d,"left",`${t}px`)}}(0,o.tooltip)(c,i.get("Mute")),(0,o.setStyle)(p,"display","none"),o.isMobile&&(0,o.setStyle)(u,"display","none"),h(t.volume),t.on("video:volumechange",(()=>{h(t.volume)})),r(c,"click",(()=>{t.muted=!0})),r(p,"click",(()=>{t.muted=!1})),r(u,"click",(e=>{t.muted=!1,t.volume=f(e)})),r(d,"mousedown",(()=>{n=!0})),r(e,"mousemove",(e=>{n&&(t.muted=!1,t.volume=f(e))})),r(document,"mouseup",(()=>{n&&(n=!1)}))}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"03o9l":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){return t=>({...e,tooltip:t.i18n.get("Show Setting"),mounted:e=>{const{proxy:r,icons:a,i18n:i}=t;(0,o.append)(e,a.setting),r(e,"click",(()=>{t.setting.toggle=!0,t.setting.updateStyle()})),t.on("setting",(t=>{(0,o.tooltip)(e,i.get(t?"Hide Setting":"Show Setting"))}))}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],eCVx2:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils"),a=e("./progress");r.default=function(e){return t=>({...e,mounted:e=>{const{option:r,template:{$progress:i,$video:n},events:{proxy:s,loadImg:l}}=t;let c=null,p=!1,u=!1;s(i,"mousemove",(async s=>{if(!p){p=!0;const e=await l(r.thumbnails.url);c=e,u=!0}u&&((0,o.setStyle)(e,"display","block"),function(s){const{width:l}=(0,a.getPosFromEvent)(t,s),{url:p,number:u,column:d,width:f,height:h}=r.thumbnails,m=f||c.naturalWidth/d,g=h||m/(n.videoWidth/n.videoHeight),y=i.clientWidth/u,v=Math.floor(l/y),b=Math.ceil(v/d)-1,x=v%d||d-1;(0,o.setStyle)(e,"backgroundImage",`url(${p})`),(0,o.setStyle)(e,"height",`${g}px`),(0,o.setStyle)(e,"width",`${m}px`),(0,o.setStyle)(e,"backgroundPosition",`-${x*m}px -${b*g}px`),l<=m/2?(0,o.setStyle)(e,"left",0):l>i.clientWidth-m/2?(0,o.setStyle)(e,"left",i.clientWidth-m+"px"):(0,o.setStyle)(e,"left",l-m/2+"px")}(s))})),s(i,"mouseleave",(()=>{(0,o.setStyle)(e,"display","none")})),t.on("hover",(t=>{t||(0,o.setStyle)(e,"display","none")}))}})}},{"../utils":"71aH7","./progress":"bgoVP","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"4KCF5":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){return t=>({...e,tooltip:t.i18n.get("Screenshot"),mounted:e=>{const{proxy:r,icons:a}=t;(0,o.append)(e,a.screenshot),r(e,"click",(()=>{t.screenshot()}))}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],efgTY:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r),r.default=function(e){return t=>{const r=t.option.quality,o=r.find((e=>e.default))||r[0];return{...e,style:{marginRight:"10px"},html:o?o.html:"",selector:r,onSelect(e){t.switchQuality(e.url,e.html)}}}}},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"2hIff":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){return t=>({...e,mounted:e=>{const r=(0,o.append)(e,\'<span class="art-loop-point"></span>\'),a=(0,o.append)(e,\'<span class="art-loop-point"></span>\');t.on("loop",(i=>{i&&i.length?((0,o.setStyle)(e,"display","block"),(0,o.setStyle)(r,"left",`calc(${i[0]/t.duration*100}% - ${r.clientWidth}px)`),(0,o.setStyle)(a,"left",i[1]/t.duration*100+"%")):(0,o.setStyle)(e,"display","none")}))}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"4IS2d":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){return t=>({...e,tooltip:t.i18n.get("AirPlay"),mounted:e=>{const{proxy:r,icons:a}=t;(0,o.append)(e,a.airplay),r(e,"click",(()=>t.airplay()))}})}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"2KYsr":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("../utils"),i=e("../utils/component"),n=o.interopDefault(i),s=e("./playbackRate"),l=o.interopDefault(s),c=e("./aspectRatio"),p=o.interopDefault(c),u=e("./flip"),d=o.interopDefault(u),f=e("./info"),h=o.interopDefault(f),m=e("./version"),g=o.interopDefault(m),y=e("./close"),v=o.interopDefault(y);class b extends n.default{constructor(e){super(e),this.name="contextmenu",this.$parent=e.template.$contextmenu,a.isMobile||this.init()}init(){const{option:e,proxy:t,template:{$player:r,$contextmenu:o}}=this.art;e.playbackRate&&this.add((0,l.default)({name:"playbackRate",index:10})),e.aspectRatio&&this.add((0,p.default)({name:"aspectRatio",index:20})),e.flip&&this.add((0,d.default)({name:"flip",index:30})),this.add((0,h.default)({name:"info",index:40})),this.add((0,g.default)({name:"version",index:50})),this.add((0,v.default)({name:"close",index:60}));for(let t=0;t<e.contextmenu.length;t++)this.add(e.contextmenu[t]);t(r,"contextmenu",(e=>{if(e.preventDefault(),!this.art.constructor.CONTEXTMENU)return;this.show=!0;const t=e.clientX,i=e.clientY,{height:n,width:s,left:l,top:c}=r.getBoundingClientRect(),{height:p,width:u}=o.getBoundingClientRect();let d=t-l,f=i-c;t+u>l+s&&(d=s-u),i+p>c+n&&(f=n-p),(0,a.setStyles)(o,{top:`${f}px`,left:`${d}px`})})),t(r,"click",(e=>{(0,a.includeFromEvent)(e,o)||(this.show=!1)})),this.art.on("blur",(()=>{this.show=!1}))}}r.default=b},{"../utils":"71aH7","../utils/component":"18nVI","./playbackRate":"69eLi","./aspectRatio":"lUefg","./flip":"kysiM","./info":"gqIgJ","./version":"kRU7C","./close":"jQ8Pm","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"69eLi":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){return t=>{const{i18n:r,constructor:{PLAYBACK_RATE:a}}=t;return{...e,html:`${r.get("Play Speed")}:\\n                ${a.map((e=>`<span data-value="${e}">${1===e?r.get("Normal"):e}</span>`)).join("")}\\n            `,click:(e,r)=>{const{value:o}=r.target.dataset;o&&(t.playbackRate=Number(o),e.show=!1)},mounted:e=>{const r=(0,o.query)(\'[data-value="1"]\',e);r&&(0,o.inverseClass)(r,"art-current"),t.on("video:ratechange",(()=>{const r=(0,o.queryAll)("span",e).find((e=>Number(e.dataset.value)===t.playbackRate));r&&(0,o.inverseClass)(r,"art-current")}))}}}}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],lUefg:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){return t=>{const{i18n:r,constructor:{ASPECT_RATIO:a}}=t;return{...e,html:`${r.get("Aspect Ratio")}:\\n                ${a.map((e=>`<span data-value="${e}">${"default"===e?r.get("Default"):e}</span>`)).join("")}\\n            `,click:(e,r)=>{const{value:o}=r.target.dataset;o&&(t.aspectRatio=o,e.show=!1)},mounted:e=>{const r=(0,o.query)(\'[data-value="default"]\',e);r&&(0,o.inverseClass)(r,"art-current"),t.on("aspectRatio",(t=>{const r=(0,o.queryAll)("span",e).find((e=>e.dataset.value===t));r&&(0,o.inverseClass)(r,"art-current")}))}}}}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],kysiM:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){return t=>{const{i18n:r,constructor:{FLIP:a}}=t;return{...e,html:`${r.get("Video Flip")}:\\n                ${a.map((e=>`<span data-value="${e}">${r.get((0,o.capitalize)(e))}</span>`)).join("")}\\n            `,click:(e,r)=>{const{value:o}=r.target.dataset;o&&(t.flip=o.toLowerCase(),e.show=!1)},mounted:e=>{const r=(0,o.query)(\'[data-value="normal"]\',e);r&&(0,o.inverseClass)(r,"art-current"),t.on("flip",(t=>{const r=(0,o.queryAll)("span",e).find((e=>e.dataset.value===t));r&&(0,o.inverseClass)(r,"art-current")}))}}}}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],gqIgJ:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r),r.default=function(e){return t=>({...e,html:t.i18n.get("Video Info"),click:e=>{t.info.show=!0,e.show=!1}})}},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],kRU7C:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r),r.default=function(e){return{...e,html:\'<a href="https://artplayer.org" target="_blank">ArtPlayer 4.6.2</a>\'}}},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],jQ8Pm:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r),r.default=function(e){return t=>({...e,html:t.i18n.get("Close"),click:e=>{e.show=!1}})}},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"02ajl":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("./utils"),i=e("./utils/component"),n=o.interopDefault(i);class s extends n.default{constructor(e){super(e),this.name="info",a.isMobile||this.init()}init(){const{proxy:e,constructor:t,template:{$infoPanel:r,$infoClose:o,$video:i}}=this.art;e(o,"click",(()=>{this.show=!1}));let n=null;const s=(0,a.queryAll)("[data-video]",r)||[];this.art.on("destroy",(()=>{clearTimeout(n)})),function e(){for(let e=0;e<s.length;e++){const t=s[e],r=i[t.dataset.video],o="number"==typeof r?r.toFixed(2):r;t.innerText!==o&&(t.innerText=o)}n=setTimeout(e,t.INFO_LOOP_TIME)}()}}r.default=s},{"./utils":"71aH7","./utils/component":"18nVI","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],eSWto:[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("./utils"),i=e("./utils/component"),n=o.interopDefault(i),s=e("option-validator"),l=o.interopDefault(s),c=e("./scheme"),p=o.interopDefault(c);class u extends n.default{constructor(e){super(e),this.name="subtitle",this.eventDestroy=()=>null,this.init(e.option.subtitle);let t=!1;e.on("video:timeupdate",(()=>{if(!this.url)return;const e=this.art.template.$video.webkitDisplayingFullscreen;"boolean"==typeof e&&e!==t&&(t=e,this.createTrack(e?"subtitles":"metadata",this.url))}))}get url(){return this.art.template.$track.src}set url(e){this.switch(e)}get textTrack(){return this.art.template.$video.textTracks[0]}get activeCue(){return this.textTrack.activeCues[0]}style(e,t){const{$subtitle:r}=this.art.template;return"object"==typeof e?(0,a.setStyles)(r,e):(0,a.setStyle)(r,e,t)}update(){const{$subtitle:e}=this.art.template;e.innerHTML="",this.activeCue&&(this.art.option.subtitle.escape?e.innerHTML=this.activeCue.text.split(/\\r?\\n/).map((e=>`<p>${(0,a.escape)(e)}</p>`)).join(""):e.innerHTML=this.activeCue.text,this.art.emit("subtitleUpdate",this.activeCue.text))}async switch(e,t={}){const{i18n:r,notice:o,option:a}=this.art,i={...a.subtitle,...t,url:e},n=await this.init(i);return t.name&&(o.show=`${r.get("Switch Subtitle")}: ${t.name}`),n}createTrack(e,t){const{template:r,proxy:o}=this.art,{$video:i,$track:n}=r,s=(0,a.createElement)("track");s.default=!0,s.kind=e,s.src=t,s.track.mode="hidden",this.eventDestroy(),(0,a.remove)(n),(0,a.append)(i,s),r.$track=s,this.eventDestroy=o(this.textTrack,"cuechange",(()=>this.update()))}async init(e){const{notice:t,template:{$subtitle:r}}=this.art;if((0,l.default)(e,p.default.subtitle),e.url)return this.style(e.style),fetch(e.url).then((e=>e.arrayBuffer())).then((t=>{const r=new TextDecoder(e.encoding).decode(t);switch(this.art.emit("subtitleLoad",e.url),e.type||(0,a.getExt)(e.url)){case"srt":return(0,a.vttToBlob)((0,a.srtToVtt)(r));case"ass":return(0,a.vttToBlob)((0,a.assToVtt)(r));case"vtt":return(0,a.vttToBlob)(r);default:return e.url}})).then((e=>(r.innerHTML="",this.url===e||(URL.revokeObjectURL(this.url),this.createTrack("metadata",e),this.art.emit("subtitleSwitch",e)),e))).catch((e=>{throw t.show=e,e}))}}r.default=u},{"./utils":"71aH7","./utils/component":"18nVI","option-validator":"bAWi2","./scheme":"AKEiO","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],jo4S1:[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("../utils/error"),i=e("./clickInit"),n=o.interopDefault(i),s=e("./hoverInit"),l=o.interopDefault(s),c=e("./mousemoveInit"),p=o.interopDefault(c),u=e("./resizeInit"),d=o.interopDefault(u),f=e("./gestureInit"),h=o.interopDefault(f),m=e("./viewInit"),g=o.interopDefault(m);r.default=class{constructor(e){this.destroyEvents=[],this.proxy=this.proxy.bind(this),this.hover=this.hover.bind(this),this.loadImg=this.loadImg.bind(this),e.whitelist.state&&((0,n.default)(e,this),(0,l.default)(e,this),(0,p.default)(e,this),(0,d.default)(e,this),(0,h.default)(e,this),(0,g.default)(e,this))}proxy(e,t,r,o={}){if(Array.isArray(t))return t.map((t=>this.proxy(e,t,r,o)));e.addEventListener(t,r,o);const a=()=>e.removeEventListener(t,r,o);return this.destroyEvents.push(a),a}hover(e,t,r){t&&this.proxy(e,"mouseenter",t),r&&this.proxy(e,"mouseleave",r)}loadImg(e){return new Promise(((t,r)=>{let o;if(e instanceof HTMLImageElement)o=e;else{if("string"!=typeof e)return r(new(0,a.ArtPlayerError)("Unable to get Image"));o=new Image,o.src=e}if(o.complete)return t(o);this.proxy(o,"load",(()=>t(o))),this.proxy(o,"error",(()=>r(new(0,a.ArtPlayerError)(`Failed to load Image: ${o.src}`))))}))}destroy(){for(let e=0;e<this.destroyEvents.length;e++)this.destroyEvents[e]()}}},{"../utils/error":"hwmZz","./clickInit":"6UrCm","./hoverInit":"4jWHi","./mousemoveInit":"bMF9b","./resizeInit":"eDXPO","./gestureInit":"95GtS","./viewInit":"InUBx","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"6UrCm":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e,t){const{constructor:r,template:{$player:a,$video:i}}=e;t.proxy(document,["click","contextmenu"],(t=>{(0,o.includeFromEvent)(t,a)?(e.isInput="INPUT"===t.target.tagName,e.isFocus=!0,e.emit("focus")):(e.isInput=!1,e.isFocus=!1,e.emit("blur"))}));let n=0;t.proxy(i,"click",(()=>{const t=Date.now();t-n<=r.DB_CLICE_TIME?(e.emit("dblclick"),o.isMobile?e.isLock||e.toggle():e.fullscreen=!e.fullscreen):(e.emit("click"),o.isMobile||e.toggle()),n=t}))}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"4jWHi":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e,t){const{$player:r}=e.template;t.hover(r,(t=>{(0,o.addClass)(r,"art-hover"),e.emit("hover",!0,t)}),(t=>{(0,o.removeClass)(r,"art-hover"),e.emit("hover",!1,t)}))}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],bMF9b:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r),r.default=function(e,t){const{$player:r}=e.template;t.proxy(r,"mousemove",(t=>{e.emit("mousemove",t)}))}},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],eDXPO:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e,t){const{option:r}=e,a=(0,o.throttle)((()=>{e.normalSize&&(e.autoSize=r.autoSize),e.aspectRatioReset=!0,e.notice.show="",e.emit("resize")}),e.constructor.RESIZE_TIME);t.proxy(window,["orientationchange","resize"],(()=>{a()})),screen&&screen.orientation&&screen.orientation.onchange&&t.proxy(screen.orientation,"change",(()=>{a()}))}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"95GtS":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils"),a=e("../control/progress");r.default=function(e,t){if(o.isMobile&&!e.option.isLive){const{$video:r,$progress:i}=e.template;let n=null,s=!1,l=0,c=0,p=0;const u=t=>{if(1===t.touches.length&&!e.isLock){n===i&&(0,a.setCurrentTime)(e,t),s=!0;const{clientX:r,clientY:o}=t.touches[0];l=r,c=o,p=e.currentTime}},d=t=>{if(1===t.touches.length&&s&&e.duration){const{clientX:a,clientY:i}=t.touches[0],s=(0,o.clamp)((a-l)/e.width,-1,1),u=(0,o.clamp)((i-c)/e.height,-1,1),d=e.isRotate?u:s,f=n===r?e.constructor.TOUCH_MOVE_RATIO:1,h=(0,o.clamp)(p+e.duration*d*f,0,e.duration);e.seek=h,e.emit("setBar","played",(0,o.clamp)(h/e.duration,0,1)),e.notice.show=`${(0,o.secondToTime)(h)} / ${(0,o.secondToTime)(e.duration)}`}},f=()=>{s&&(l=0,c=0,p=0,s=!1,n=null)};t.proxy(i,"touchstart",(e=>{n=i,u(e)})),t.proxy(r,"touchstart",(e=>{n=r,u(e)})),t.proxy(r,"touchmove",d),t.proxy(i,"touchmove",d),t.proxy(document,"touchend",f)}}},{"../utils":"71aH7","../control/progress":"bgoVP","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],InUBx:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e,t){const{option:r,constructor:a,template:{$container:i}}=e,n=(0,o.throttle)((()=>{e.emit("view",(0,o.isInViewport)(i,a.SCROLL_GAP))}),a.SCROLL_TIME);t.proxy(window,"scroll",(()=>{n()})),e.on("view",(t=>{r.autoMini&&(e.mini=!t)}))}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"6NoFy":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("./utils");r.default=class{constructor(e){this.art=e,this.keys={},e.option.hotkey&&!o.isMobile&&this.init()}init(){const{proxy:e,constructor:t}=this.art;this.add(27,(()=>{this.art.fullscreenWeb&&(this.art.fullscreenWeb=!1)})),this.add(32,(()=>{this.art.toggle()})),this.add(37,(()=>{this.art.backward=t.SEEK_STEP})),this.add(38,(()=>{this.art.volume+=t.VOLUME_STEP})),this.add(39,(()=>{this.art.forward=t.SEEK_STEP})),this.add(40,(()=>{this.art.volume-=t.VOLUME_STEP})),e(window,"keydown",(e=>{if(this.art.isFocus){const t=document.activeElement.tagName.toUpperCase(),r=document.activeElement.getAttribute("contenteditable");if("INPUT"!==t&&"TEXTAREA"!==t&&""!==r&&"true"!==r){const t=this.keys[e.keyCode];if(t){e.preventDefault();for(let r=0;r<t.length;r++)t[r].call(this.art,e);this.art.emit("hotkey",e)}}}}))}add(e,t){return this.keys[e]?this.keys[e].push(t):this.keys[e]=[t],this}remove(e,t){if(this.keys[e]){const r=this.keys[e].indexOf(t);-1!==r&&this.keys[e].splice(r,1)}return this}}},{"./utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"6G6hZ":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("./utils/component"),i=o.interopDefault(a);class n extends i.default{constructor(e){super(e);const{option:t,template:{$layer:r}}=e;this.name="layer",this.$parent=r;for(let e=0;e<t.layers.length;e++)this.add(t.layers[e])}}r.default=n},{"./utils/component":"18nVI","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"3dsEe":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("./utils"),i=e("./utils/component"),n=o.interopDefault(i);class s extends n.default{constructor(e){super(e),this.name="loading",(0,a.append)(e.template.$loading,e.icons.loading)}}r.default=s},{"./utils":"71aH7","./utils/component":"18nVI","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],dWGTw:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("./utils");r.default=class{constructor(e){this.art=e,this.timer=null}set show(e){const{constructor:t,template:{$player:r,$noticeInner:a}}=this.art;e?(a.innerText=e instanceof Error?e.message.trim():e,(0,o.addClass)(r,"art-notice-show"),clearTimeout(this.timer),this.timer=setTimeout((()=>{a.innerText="",(0,o.removeClass)(r,"art-notice-show")}),t.NOTICE_TIME)):(0,o.removeClass)(r,"art-notice-show")}}},{"./utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"5POkG":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("./utils"),i=e("./utils/component"),n=o.interopDefault(i);class s extends n.default{constructor(e){super(e),this.name="mask";const{template:t,icons:r,events:o}=e,i=(0,a.append)(t.$state,r.state),n=(0,a.append)(t.$state,r.error);(0,a.setStyle)(n,"display","none"),e.on("destroy",(()=>{(0,a.setStyle)(i,"display","none"),(0,a.setStyle)(n,"display",null)})),o.proxy(t.$state,"click",(()=>e.play()))}}r.default=s},{"./utils":"71aH7","./utils/component":"18nVI","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"6OeNg":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("../utils"),i=e("bundle-text:./loading.svg"),n=o.interopDefault(i),s=e("bundle-text:./state.svg"),l=o.interopDefault(s),c=e("bundle-text:./check.svg"),p=o.interopDefault(c),u=e("bundle-text:./play.svg"),d=o.interopDefault(u),f=e("bundle-text:./pause.svg"),h=o.interopDefault(f),m=e("bundle-text:./volume.svg"),g=o.interopDefault(m),y=e("bundle-text:./volume-close.svg"),v=o.interopDefault(y),b=e("bundle-text:./screenshot.svg"),x=o.interopDefault(b),w=e("bundle-text:./setting.svg"),j=o.interopDefault(w),k=e("bundle-text:./arrow-left.svg"),S=o.interopDefault(k),I=e("bundle-text:./arrow-right.svg"),C=o.interopDefault(I),$=e("bundle-text:./playback-rate.svg"),E=o.interopDefault($),P=e("bundle-text:./aspect-ratio.svg"),T=o.interopDefault(P),M=e("bundle-text:./config.svg"),F=o.interopDefault(M),A=e("bundle-text:./pip.svg"),z=o.interopDefault(A),H=e("bundle-text:./lock.svg"),D=o.interopDefault(H),O=e("bundle-text:./unlock.svg"),R=o.interopDefault(O),L=e("bundle-text:./fullscreen-off.svg"),N=o.interopDefault(L),V=e("bundle-text:./fullscreen-on.svg"),Y=o.interopDefault(V),_=e("bundle-text:./fullscreen-web-off.svg"),W=o.interopDefault(_),B=e("bundle-text:./fullscreen-web-on.svg"),q=o.interopDefault(B),U=e("bundle-text:./switch-on.svg"),Z=o.interopDefault(U),G=e("bundle-text:./switch-off.svg"),K=o.interopDefault(G),X=e("bundle-text:./flip.svg"),J=o.interopDefault(X),Q=e("bundle-text:./error.svg"),ee=o.interopDefault(Q),te=e("bundle-text:./close.svg"),re=o.interopDefault(te),oe=e("bundle-text:./airplay.svg"),ae=o.interopDefault(oe);r.default=class{constructor(e){const t={loading:n.default,state:l.default,play:d.default,pause:h.default,check:p.default,volume:g.default,volumeClose:v.default,screenshot:x.default,setting:j.default,pip:z.default,arrowLeft:S.default,arrowRight:C.default,playbackRate:E.default,aspectRatio:T.default,config:F.default,lock:D.default,flip:J.default,unlock:R.default,fullscreenOff:N.default,fullscreenOn:Y.default,fullscreenWebOff:W.default,fullscreenWebOn:q.default,switchOn:Z.default,switchOff:K.default,error:ee.default,close:re.default,airplay:ae.default,...e.option.icons};Object.keys(t).forEach((e=>{(0,a.def)(this,e,{get:()=>{const r=(0,a.createElement)("i");return(0,a.addClass)(r,"art-icon"),(0,a.addClass)(r,`art-icon-${e}`),(0,a.append)(r,t[e]),r}})}))}}},{"../utils":"71aH7","bundle-text:./loading.svg":"7tDub","bundle-text:./state.svg":"1ElZc","bundle-text:./check.svg":"lmgoP","bundle-text:./play.svg":"lVWoQ","bundle-text:./pause.svg":"5Mnax","bundle-text:./volume.svg":"w3eIa","bundle-text:./volume-close.svg":"rHjo1","bundle-text:./screenshot.svg":"2KcqM","bundle-text:./setting.svg":"8rQMV","bundle-text:./arrow-left.svg":"kqGBE","bundle-text:./arrow-right.svg":"aFjpC","bundle-text:./playback-rate.svg":"lx7ZM","bundle-text:./aspect-ratio.svg":"2sEjf","bundle-text:./config.svg":"fQTgE","bundle-text:./pip.svg":"2CaxO","bundle-text:./lock.svg":"aCGnW","bundle-text:./unlock.svg":"bTrAV","bundle-text:./fullscreen-off.svg":"bA3p0","bundle-text:./fullscreen-on.svg":"fTuY8","bundle-text:./fullscreen-web-off.svg":"tvKf4","bundle-text:./fullscreen-web-on.svg":"1F1oB","bundle-text:./switch-on.svg":"7qNHs","bundle-text:./switch-off.svg":"28aV8","bundle-text:./flip.svg":"1uXI6","bundle-text:./error.svg":"9f4dh","bundle-text:./close.svg":"4nTtS","bundle-text:./airplay.svg":"cDPXC","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"7tDub":[function(e,t,r){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" width="50" height="50" viewBox="0 0 100 100" preserveAspectRatio="xMidYMid" class="uil-default"><path fill="none" class="bk" d="M0 0h100v100H0z"/><rect x="47" y="40" width="6" height="20" rx="5" ry="5" fill="#fff" transform="translate(0 -30)"><animate attributeName="opacity" from="1" to="0" dur="1s" begin="-1s" repeatCount="indefinite"/></rect><rect x="47" y="40" width="6" height="20" rx="5" ry="5" fill="#fff" transform="rotate(30 105.98 65)"><animate attributeName="opacity" from="1" to="0" dur="1s" begin="-0.9166666666666666s" repeatCount="indefinite"/></rect><rect x="47" y="40" width="6" height="20" rx="5" ry="5" fill="#fff" transform="rotate(60 75.98 65)"><animate attributeName="opacity" from="1" to="0" dur="1s" begin="-0.8333333333333334s" repeatCount="indefinite"/></rect><rect x="47" y="40" width="6" height="20" rx="5" ry="5" fill="#fff" transform="rotate(90 65 65)"><animate attributeName="opacity" from="1" to="0" dur="1s" begin="-0.75s" repeatCount="indefinite"/></rect><rect x="47" y="40" width="6" height="20" rx="5" ry="5" fill="#fff" transform="rotate(120 58.66 65)"><animate attributeName="opacity" from="1" to="0" dur="1s" begin="-0.6666666666666666s" repeatCount="indefinite"/></rect><rect x="47" y="40" width="6" height="20" rx="5" ry="5" fill="#fff" transform="rotate(150 54.02 65)"><animate attributeName="opacity" from="1" to="0" dur="1s" begin="-0.5833333333333334s" repeatCount="indefinite"/></rect><rect x="47" y="40" width="6" height="20" rx="5" ry="5" fill="#fff" transform="rotate(180 50 65)"><animate attributeName="opacity" from="1" to="0" dur="1s" begin="-0.5s" repeatCount="indefinite"/></rect><rect x="47" y="40" width="6" height="20" rx="5" ry="5" fill="#fff" transform="rotate(-150 45.98 65)"><animate attributeName="opacity" from="1" to="0" dur="1s" begin="-0.4166666666666667s" repeatCount="indefinite"/></rect><rect x="47" y="40" width="6" height="20" rx="5" ry="5" fill="#fff" transform="rotate(-120 41.34 65)"><animate attributeName="opacity" from="1" to="0" dur="1s" begin="-0.3333333333333333s" repeatCount="indefinite"/></rect><rect x="47" y="40" width="6" height="20" rx="5" ry="5" fill="#fff" transform="rotate(-90 35 65)"><animate attributeName="opacity" from="1" to="0" dur="1s" begin="-0.25s" repeatCount="indefinite"/></rect><rect x="47" y="40" width="6" height="20" rx="5" ry="5" fill="#fff" transform="rotate(-60 24.02 65)"><animate attributeName="opacity" from="1" to="0" dur="1s" begin="-0.16666666666666666s" repeatCount="indefinite"/></rect><rect x="47" y="40" width="6" height="20" rx="5" ry="5" fill="#fff" transform="rotate(-30 -5.98 65)"><animate attributeName="opacity" from="1" to="0" dur="1s" begin="-0.08333333333333333s" repeatCount="indefinite"/></rect></svg>\'},{}],"1ElZc":[function(e,t,r){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" height="60" width="60" style="filter:drop-shadow(0 1px 1px #000)" viewBox="0 0 24 24"><path d="M20 2H4C1.8 2 0 3.8 0 6v12c0 2.2 1.8 4 4 4h16c2.2 0 4-1.8 4-4V6c0-2.2-1.8-4-4-4zm-4.4 10.8L10.5 16c-.6.5-1.5 0-1.5-.8V8.8c0-.8.9-1.3 1.5-.8l5.1 3.2c.7.3.7 1.3 0 1.6z"/></svg>\'},{}],lmgoP:[function(e,t,r){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" style="width:100%;height:100%"><path d="M9 16.2 4.8 12l-1.4 1.4L9 19 21 7l-1.4-1.4L9 16.2z" fill="#fff"/></svg>\'},{}],lVWoQ:[function(e,t,r){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" height="22" width="22"><path d="M17.982 9.275 8.06 3.27A2.013 2.013 0 0 0 5 4.994v12.011a2.017 2.017 0 0 0 3.06 1.725l9.922-6.005a2.017 2.017 0 0 0 0-3.45z"/></svg>\'},{}],"5Mnax":[function(e,t,r){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" height="22" width="22"><path d="M7 3a2 2 0 0 0-2 2v12a2 2 0 1 0 4 0V5a2 2 0 0 0-2-2zm8 0a2 2 0 0 0-2 2v12a2 2 0 1 0 4 0V5a2 2 0 0 0-2-2z"/></svg>\'},{}],w3eIa:[function(e,t,r){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" height="22" width="22"><path d="M10.188 4.65 6 8H5a2 2 0 0 0-2 2v2a2 2 0 0 0 2 2h1l4.188 3.35a.5.5 0 0 0 .812-.39V5.04a.498.498 0 0 0-.812-.39zm4.258-.872a1 1 0 0 0-.862 1.804 6.002 6.002 0 0 1-.007 10.838 1 1 0 0 0 .86 1.806A8.001 8.001 0 0 0 19 11a8.001 8.001 0 0 0-4.554-7.222z"/><path d="M15 11a3.998 3.998 0 0 0-2-3.465v6.93A3.998 3.998 0 0 0 15 11z"/></svg>\'},{}],rHjo1:[function(e,t,r){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" height="22" width="22"><path d="M15 11a3.998 3.998 0 0 0-2-3.465v2.636l1.865 1.865A4.02 4.02 0 0 0 15 11z"/><path d="M13.583 5.583A5.998 5.998 0 0 1 17 11a6 6 0 0 1-.585 2.587l1.477 1.477a8.001 8.001 0 0 0-3.446-11.286 1 1 0 0 0-.863 1.805zm5.195 13.195-2.121-2.121-1.414-1.414-1.415-1.415L13 13l-2-2-3.889-3.889-3.889-3.889a.999.999 0 1 0-1.414 1.414L5.172 8H5a2 2 0 0 0-2 2v2a2 2 0 0 0 2 2h1l4.188 3.35a.5.5 0 0 0 .812-.39v-3.131l2.587 2.587-.01.005a1 1 0 0 0 .86 1.806c.215-.102.424-.214.627-.333l2.3 2.3a1.001 1.001 0 0 0 1.414-1.416zM11 5.04a.5.5 0 0 0-.813-.39L8.682 5.854 11 8.172V5.04z"/></svg>\'},{}],"2KcqM":[function(e,t,r){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" height="22" width="22" viewBox="0 0 50 50"><path d="M19.402 6a5 5 0 0 0-4.902 4.012L14.098 12H9a5 5 0 0 0-5 5v21a5 5 0 0 0 5 5h32a5 5 0 0 0 5-5V17a5 5 0 0 0-5-5h-5.098l-.402-1.988A5 5 0 0 0 30.598 6ZM25 17c5.52 0 10 4.48 10 10s-4.48 10-10 10-10-4.48-10-10 4.48-10 10-10Zm0 2c-4.41 0-8 3.59-8 8s3.59 8 8 8 8-3.59 8-8-3.59-8-8-8Z"/></svg>\'},{}],"8rQMV":[function(e,t,r){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" height="22" width="22"><circle cx="11" cy="11" r="2"/><path d="M19.164 8.861 17.6 8.6a6.978 6.978 0 0 0-1.186-2.099l.574-1.533a1 1 0 0 0-.436-1.217l-1.997-1.153a1.001 1.001 0 0 0-1.272.23l-1.008 1.225a7.04 7.04 0 0 0-2.55.001L8.716 2.829a1 1 0 0 0-1.272-.23L5.447 3.751a1 1 0 0 0-.436 1.217l.574 1.533A6.997 6.997 0 0 0 4.4 8.6l-1.564.261A.999.999 0 0 0 2 9.847v2.306c0 .489.353.906.836.986l1.613.269a7 7 0 0 0 1.228 2.075l-.558 1.487a1 1 0 0 0 .436 1.217l1.997 1.153c.423.244.961.147 1.272-.23l1.04-1.263a7.089 7.089 0 0 0 2.272 0l1.04 1.263a1 1 0 0 0 1.272.23l1.997-1.153a1 1 0 0 0 .436-1.217l-.557-1.487c.521-.61.94-1.31 1.228-2.075l1.613-.269a.999.999 0 0 0 .835-.986V9.847a.999.999 0 0 0-.836-.986zM11 15a4 4 0 1 1 0-8 4 4 0 0 1 0 8z"/></svg>\'},{}],kqGBE:[function(e,t,r){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" height="32" width="32"><path d="m19.41 20.09-4.58-4.59 4.58-4.59L18 9.5l-6 6 6 6z" fill="#fff"/></svg>\'},{}],aFjpC:[function(e,t,r){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" height="32" width="32"><path d="m12.59 20.34 4.58-4.59-4.58-4.59L14 9.75l6 6-6 6z" fill="#fff"/></svg>\'},{}],lx7ZM:[function(e,t,r){t.exports=\'<svg height="24" width="24"><path d="M10 8v8l6-4-6-4zM6.3 5l-.6-.8C7.2 3 9 2.2 11 2l.1 1c-1.8.2-3.4.9-4.8 2zM5 6.3l-.8-.6C3 7.2 2.2 9 2 11l1 .1c.2-1.8.9-3.4 2-4.8zm0 11.4c-1.1-1.4-1.8-3.1-2-4.8L2 13c.2 2 1 3.8 2.2 5.4l.8-.7zm6.1 3.3c-1.8-.2-3.4-.9-4.8-2l-.6.8C7.2 21 9 21.8 11 22l.1-1zM22 12c0-5.2-3.9-9.4-9-10l-.1 1c4.6.5 8.1 4.3 8.1 9s-3.5 8.5-8.1 9l.1 1c5.2-.5 9-4.8 9-10z" fill="#fff" style="--darkreader-inline-fill:#a8a6a4"/></svg>\'},{}],"2sEjf":[function(e,t,r){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 88 88" style="width:100%;height:100%;transform:translate(0,0)"><defs><clipPath id="__lottie_element_216"><path d="M0 0h88v88H0z"/></clipPath></defs><g style="display:block" clip-path="url(\\\'#__lottie_element_216\\\')"><path fill="#FFF" d="m12.438-12.702-2.82 2.82c-.79.79-.79 2.05 0 2.83l7.07 7.07-7.07 7.07c-.79.79-.79 2.05 0 2.83l2.82 2.83c.79.78 2.05.78 2.83 0l11.32-11.31c.78-.78.78-2.05 0-2.83l-11.32-11.31c-.78-.79-2.04-.79-2.83 0zm-24.88 0c-.74-.74-1.92-.78-2.7-.12l-.13.12-11.31 11.31a2 2 0 0 0-.12 2.7l.12.13 11.31 11.31a2 2 0 0 0 2.7.12l.13-.12 2.83-2.83c.74-.74.78-1.91.11-2.7l-.11-.13-7.07-7.07 7.07-7.07c.74-.74.78-1.91.11-2.7l-.11-.13-2.83-2.82zM28-28c4.42 0 8 3.58 8 8v40c0 4.42-3.58 8-8 8h-56c-4.42 0-8-3.58-8-8v-40c0-4.42 3.58-8 8-8h56z" style="--darkreader-inline-fill:#a8a6a4" transform="translate(44 44)"/></g></svg>\'},{}],fQTgE:[function(e,t,r){t.exports=\'<svg height="24" width="24"><path d="M15 17h6v1h-6v-1zm-4 0H3v1h8v2h1v-5h-1v2zm3-9h1V3h-1v2H3v1h11v2zm4-3v1h3V5h-3zM6 14h1V9H6v2H3v1h3v2zm4-2h11v-1H10v1z" fill="#fff" style="--darkreader-inline-fill:#a8a6a4"/></svg>\'},{}],"2CaxO":[function(e,t,r){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 36 36" height="32" width="32"><path d="M25 17h-8v6h8v-6Zm4 8V10.98C29 9.88 28.1 9 27 9H9c-1.1 0-2 .88-2 1.98V25c0 1.1.9 2 2 2h18c1.1 0 2-.9 2-2Zm-2 .02H9V10.97h18v14.05Z"/></svg>\'},{}],aCGnW:[function(e,t,r){t.exports=\'<svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="20" height="20"><path d="M298.667 426.667v-85.334a213.333 213.333 0 1 1 426.666 0v85.334H768A85.333 85.333 0 0 1 853.333 512v256A85.333 85.333 0 0 1 768 853.333H256A85.333 85.333 0 0 1 170.667 768V512A85.333 85.333 0 0 1 256 426.667h42.667zM512 213.333a128 128 0 0 0-128 128v85.334h256v-85.334a128 128 0 0 0-128-128z" fill="#fff"/></svg>\'},{}],bTrAV:[function(e,t,r){t.exports=\'<svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="20" height="20"><path d="m666.752 194.517-49.365 74.112A128 128 0 0 0 384 341.333l.043 85.334h384A85.333 85.333 0 0 1 853.376 512v256a85.333 85.333 0 0 1-85.333 85.333H256A85.333 85.333 0 0 1 170.667 768V512A85.333 85.333 0 0 1 256 426.667h42.667v-85.334a213.333 213.333 0 0 1 368.085-146.816z" fill="#fff"/></svg>\'},{}],bA3p0:[function(e,t,r){t.exports=\'<svg class="icon" width="22" height="22" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path fill="#fff" d="M768 298.667h170.667V384h-256V128H768v170.667zM341.333 384h-256v-85.333H256V128h85.333v256zM768 725.333V896h-85.333V640h256v85.333H768zM341.333 640v256H256V725.333H85.333V640h256z"/></svg>\'},{}],fTuY8:[function(e,t,r){t.exports=\'<svg class="icon" width="22" height="22" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg"><path fill="#fff" d="M625.778 256H768v142.222h113.778v-256h-256V256zM256 398.222V256h142.222V142.222h-256v256H256zm512 227.556V768H625.778v113.778h256v-256H768zM398.222 768H256V625.778H142.222v256h256V768z"/></svg>\'},{}],tvKf4:[function(e,t,r){t.exports=\'<svg class="icon" width="18" height="18" viewBox="0 0 1152 1024" xmlns="http://www.w3.org/2000/svg"><path fill="#fff" d="M1075.2 0H76.8A76.8 76.8 0 0 0 0 76.8v870.4a76.8 76.8 0 0 0 76.8 76.8h998.4a76.8 76.8 0 0 0 76.8-76.8V76.8A76.8 76.8 0 0 0 1075.2 0zM1024 128v768H128V128h896zM896 512a64 64 0 0 1 7.488 127.552L896 640H768v128a64 64 0 0 1-56.512 63.552L704 832a64 64 0 0 1-63.552-56.512L640 768V582.592c0-34.496 25.024-66.112 61.632-70.208l8-.384H896zm-640 0a64 64 0 0 1-7.488-127.552L256 384h128V256a64 64 0 0 1 56.512-63.552L448 192a64 64 0 0 1 63.552 56.512L512 256v185.408c0 34.432-25.024 66.112-61.632 70.144l-8 .448H256z"/></svg>\'},{}],"1F1oB":[function(e,t,r){t.exports=\'<svg class="icon" width="18" height="18" viewBox="0 0 1152 1024" xmlns="http://www.w3.org/2000/svg"><path fill="#fff" d="M1075.2 0H76.8A76.8 76.8 0 0 0 0 76.8v870.4a76.8 76.8 0 0 0 76.8 76.8h998.4a76.8 76.8 0 0 0 76.8-76.8V76.8A76.8 76.8 0 0 0 1075.2 0zM1024 128v768H128V128h896zm-576 64a64 64 0 0 1 7.488 127.552L448 320H320v128a64 64 0 0 1-56.512 63.552L256 512a64 64 0 0 1-63.552-56.512L192 448V262.592c0-34.432 25.024-66.112 61.632-70.144l8-.448H448zm256 640a64 64 0 0 1-7.488-127.552L704 704h128V576a64 64 0 0 1 56.512-63.552L896 512a64 64 0 0 1 63.552 56.512L960 576v185.408c0 34.496-25.024 66.112-61.632 70.208l-8 .384H704z"/></svg>\'},{}],"7qNHs":[function(e,t,r){t.exports=\'<svg class="icon" width="26" height="26" viewBox="0 0 1664 1024" xmlns="http://www.w3.org/2000/svg"><path fill="#648FFC" d="M1152 0H512a512 512 0 0 0 0 1024h640a512 512 0 0 0 0-1024zm0 960a448 448 0 1 1 448-448 448 448 0 0 1-448 448z"/></svg>\'},{}],"28aV8":[function(e,t,r){t.exports=\'<svg class="icon" width="26" height="26" viewBox="0 0 1740 1024" xmlns="http://www.w3.org/2000/svg"><path fill="#fff" d="M511.898 1024h670.515c282.419-.41 511.18-229.478 511.18-511.898 0-282.419-228.761-511.488-511.18-511.897H511.898C229.478.615.717 229.683.717 512.102c0 282.42 228.761 511.488 511.18 511.898zm-.564-975.36A464.589 464.589 0 1 1 48.026 513.024 463.872 463.872 0 0 1 511.334 48.435v.205z"/></svg>\'},{}],"1uXI6":[function(e,t,r){t.exports=\'<svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="24" height="24"><path d="M554.667 810.667V896h-85.334v-85.333h85.334zm-384-632.662a42.667 42.667 0 0 1 34.986 18.219l203.904 291.328a42.667 42.667 0 0 1 0 48.896L205.611 827.776A42.667 42.667 0 0 1 128 803.328V220.672a42.667 42.667 0 0 1 42.667-42.667zm682.666 0a42.667 42.667 0 0 1 42.368 37.718l.299 4.949v582.656a42.667 42.667 0 0 1-74.24 28.63l-3.413-4.182-203.904-291.328a42.667 42.667 0 0 1-3.03-43.861l3.03-5.035 203.946-291.328a42.667 42.667 0 0 1 34.944-18.219zM554.667 640v85.333h-85.334V640h85.334zm-358.4-320.896V716.8L335.957 512 196.31 319.104zm358.4 150.23v85.333h-85.334v-85.334h85.334zm0-170.667V384h-85.334v-85.333h85.334zm0-170.667v85.333h-85.334V128h85.334z" fill="#fff"/></svg>\'},{}],"9f4dh":[function(e,t,r){t.exports=\'<svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="50" height="50"><path d="M593.818 168.55 949.82 763.76c26.153 43.746 10.732 99.738-34.447 125.052-14.397 8.069-30.72 12.308-47.37 12.308H155.976c-52.224 0-94.536-40.96-94.536-91.505 0-16.097 4.383-31.928 12.718-45.875l356.004-595.19c26.173-43.724 84.009-58.654 129.208-33.341a93.082 93.082 0 0 1 34.448 33.341zM512 819.2a61.44 61.44 0 1 0 0-122.88 61.44 61.44 0 0 0 0 122.88zm0-512a72.315 72.315 0 0 0-71.762 81.306l25.723 205.721a46.408 46.408 0 0 0 92.078 0l25.723-205.742A72.315 72.315 0 0 0 512 307.2z"/></svg>\'},{}],"4nTtS":[function(e,t,r){t.exports=\'<svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="22" height="22"><path d="m571.733 512 268.8-268.8c17.067-17.067 17.067-42.667 0-59.733-17.066-17.067-42.666-17.067-59.733 0L512 452.267l-268.8-268.8c-17.067-17.067-42.667-17.067-59.733 0-17.067 17.066-17.067 42.666 0 59.733l268.8 268.8-268.8 268.8c-17.067 17.067-17.067 42.667 0 59.733 8.533 8.534 19.2 12.8 29.866 12.8s21.334-4.266 29.867-12.8l268.8-268.8 268.8 268.8c8.533 8.534 19.2 12.8 29.867 12.8s21.333-4.266 29.866-12.8c17.067-17.066 17.067-42.666 0-59.733L571.733 512z"/></svg>\'},{}],cDPXC:[function(e,t,r){t.exports=\'<svg width="18" height="18" xmlns="http://www.w3.org/2000/svg"><g fill="#fff"><path d="M16 1H2a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h3v-2H3V3h12v8h-2v2h3a1 1 0 0 0 1-1V2a1 1 0 0 0-1-1Z"/><path d="M4 17h10l-5-6z"/></g></svg>\'},{}],"3eYNH":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("./flip"),i=o.interopDefault(a),n=e("./aspectRatio"),s=o.interopDefault(n),l=e("./playbackRate"),c=o.interopDefault(l),p=e("./subtitleOffset"),u=o.interopDefault(p),d=e("../utils/component"),f=o.interopDefault(d),h=e("../utils");class m extends f.default{constructor(e){super(e);const{option:t,proxy:r,template:{$setting:o,$player:a}}=e;if(this.name="setting",this.$parent=o,this.option=[],this.events=[],this.cache=new Map,t.setting){t.playbackRate&&this.option.push((0,c.default)(e)),t.aspectRatio&&this.option.push((0,s.default)(e)),t.flip&&this.option.push((0,i.default)(e)),t.subtitleOffset&&this.option.push((0,u.default)(e));for(let e=0;e<t.settings.length;e++)this.option.push(t.settings[e]);this.update(),e.on("blur",(()=>{this.show&&(this.show=!1,this.init(this.option))})),r(a,"click",(t=>{!this.show||(0,h.includeFromEvent)(t,e.controls.setting)||(0,h.includeFromEvent)(t,this.$parent)||(this.show=!1,this.init(this.option))}))}}static makeRecursion(e,t,r){for(let o=0;o<e.length;o++){const a=e[o];a.$parentItem=t,a.$parentList=r,a.selector&&m.makeRecursion(a.selector,a,e)}return e}update(){return this.cache=new Map,this.events.forEach((e=>e())),this.events=[],this.$parent.innerHTML="",this.option=m.makeRecursion(this.option),this.init(this.option),this.option}add(e){return this.option.push(e),this.update(),e}creatHeader(e){const{icons:t,proxy:r}=this.art,o=(0,h.createElement)("div");(0,h.addClass)(o,"art-setting-item"),(0,h.addClass)(o,"art-setting-item-back");const a=(0,h.append)(o,\'<div class="art-setting-item-left"></div>\'),i=(0,h.createElement)("div");(0,h.addClass)(i,"art-setting-item-left-icon"),(0,h.append)(i,t.arrowLeft),(0,h.append)(a,i),(0,h.append)(a,e.$parentItem.html);const n=r(o,"click",(()=>this.init(e.$parentList)));return this.events.push(n),o}creatItem(e,t){const{icons:r,proxy:o}=this.art,a=(0,h.createElement)("div");(0,h.addClass)(a,"art-setting-item"),(0,h.isStringOrNumber)(t.name)&&(a.dataset.name=t.name),(0,h.isStringOrNumber)(t.value)&&(a.dataset.value=t.value);const i=(0,h.append)(a,\'<div class="art-setting-item-left"></div>\'),n=(0,h.append)(a,\'<div class="art-setting-item-right"></div>\'),s=(0,h.createElement)("div");switch((0,h.addClass)(s,"art-setting-item-left-icon"),e){case"switch":case"range":(0,h.append)(s,(0,h.isStringOrNumber)(t.icon)||t.icon instanceof Element?t.icon:r.config);break;case"selector":t.selector&&t.selector.length?(0,h.append)(s,(0,h.isStringOrNumber)(t.icon)||t.icon instanceof Element?t.icon:r.config):(0,h.append)(s,r.check)}(0,h.append)(i,s),t.$icon=s,(0,h.def)(t,"icon",{configurable:!0,get:()=>s.innerHTML,set(e){(0,h.isStringOrNumber)(e)&&(s.innerHTML=e)}});const l=(0,h.createElement)("div");(0,h.addClass)(l,"art-setting-item-left-text"),(0,h.append)(l,t.html||""),(0,h.append)(i,l),t.$html=l,(0,h.def)(t,"html",{configurable:!0,get:()=>l.innerHTML,set(e){(0,h.isStringOrNumber)(e)&&(l.innerHTML=e)}});const c=(0,h.createElement)("div");switch((0,h.addClass)(c,"art-setting-item-right-tooltip"),(0,h.append)(c,t.tooltip||""),(0,h.append)(n,c),t.$tooltip=c,(0,h.def)(t,"tooltip",{configurable:!0,get:()=>c.innerHTML,set(e){(0,h.isStringOrNumber)(e)&&(c.innerHTML=e)}}),e){case"switch":{const e=(0,h.createElement)("div");(0,h.addClass)(e,"art-setting-item-right-icon");const o=(0,h.append)(e,r.switchOn),a=(0,h.append)(e,r.switchOff);(0,h.setStyle)(t.switch?a:o,"display","none"),(0,h.append)(n,e),t.$switch=t.switch,(0,h.def)(t,"switch",{configurable:!0,get:()=>t.$switch,set(e){t.$switch=e,e?((0,h.setStyle)(a,"display","none"),(0,h.setStyle)(o,"display",null)):((0,h.setStyle)(a,"display",null),(0,h.setStyle)(o,"display","none"))}});break}case"range":{const e=(0,h.createElement)("div");(0,h.addClass)(e,"art-setting-item-right-icon");const r=(0,h.append)(e,\'<input type="range">\');r.value=t.range[0]||0,r.min=t.range[1]||0,r.max=t.range[2]||10,r.step=t.range[3]||1,(0,h.addClass)(r,"art-setting-range"),(0,h.append)(n,e),t.$range=r,(0,h.def)(t,"range",{configurable:!0,get:()=>r.valueAsNumber,set(e){r.value=Number(e)}})}break;case"selector":if(t.selector&&t.selector.length){const e=(0,h.createElement)("div");(0,h.addClass)(e,"art-setting-item-right-icon"),(0,h.append)(e,r.arrowRight),(0,h.append)(n,e)}}switch(e){case"switch":if(t.onSwitch){const e=o(a,"click",(async e=>{t.switch=await t.onSwitch.call(this.art,t,a,e)}));this.events.push(e)}break;case"range":if(t.$range){if(t.onRange){const e=o(t.$range,"change",(async e=>{t.tooltip=await t.onRange.call(this.art,t,a,e)}));this.events.push(e)}if(t.onChange){const e=o(t.$range,"input",(async e=>{t.tooltip=await t.onChange.call(this.art,t,a,e)}));this.events.push(e)}}break;case"selector":{const e=o(a,"click",(async e=>{if(t.selector&&t.selector.length)this.init(t.selector,t.width);else{(0,h.inverseClass)(a,"art-current");for(let e=0;e<t.$parentItem.selector.length;e++){const r=t.$parentItem.selector[e];r.default=r===t}if(t.$parentList&&this.init(t.$parentList),t.$parentItem&&t.$parentItem.onSelect){const r=await t.$parentItem.onSelect.call(this.art,t,a,e);t.$parentItem.$tooltip&&(0,h.isStringOrNumber)(r)&&(t.$parentItem.$tooltip.innerHTML=r)}}}));this.events.push(e),t.default&&(0,h.addClass)(a,"art-current")}}return a}updateStyle(e){const{controls:t,constructor:r,template:{$player:o,$setting:a}}=this.art;if(t.setting){const i=e||r.SETTING_WIDTH,{left:n,width:s}=t.setting.getBoundingClientRect(),{left:l,width:c}=o.getBoundingClientRect(),p=n-l+s/2-i/2;p+i>c?((0,h.setStyle)(a,"left","auto"),(0,h.setStyle)(a,"right","10px")):((0,h.setStyle)(a,"left",`${p}px`),(0,h.setStyle)(a,"right","auto"))}else(0,h.setStyle)(a,"left","auto"),(0,h.setStyle)(a,"right","10px")}init(e,t){const{constructor:r}=this.art;if(this.cache.has(e)){const t=this.cache.get(e);(0,h.inverseClass)(t,"art-current"),(0,h.setStyle)(this.$parent,"width",`${t.dataset.width}px`),(0,h.setStyle)(this.$parent,"height",`${t.dataset.height}px`),this.updateStyle(Number(t.dataset.width))}else{const o=(0,h.createElement)("div");(0,h.addClass)(o,"art-setting-panel"),o.dataset.width=t||r.SETTING_WIDTH,o.dataset.height=e.length*r.SETTING_ITEM_HEIGHT,e[0]&&e[0].$parentItem&&((0,h.append)(o,this.creatHeader(e[0])),o.dataset.height=Number(o.dataset.height)+r.SETTING_ITEM_HEIGHT);for(let t=0;t<e.length;t++){const r=e[t];(0,h.has)(r,"switch")?(0,h.append)(o,this.creatItem("switch",r)):(0,h.has)(r,"range")?(0,h.append)(o,this.creatItem("range",r)):(0,h.append)(o,this.creatItem("selector",r))}(0,h.append)(this.$parent,o),this.cache.set(e,o),(0,h.inverseClass)(o,"art-current"),(0,h.setStyle)(this.$parent,"width",`${o.dataset.width}px`),(0,h.setStyle)(this.$parent,"height",`${o.dataset.height}px`),this.updateStyle(Number(o.dataset.width)),e[0]&&e[0].$parentItem&&e[0].$parentItem.mounted&&e[0].$parentItem.mounted.call(this.art,o,e[0].$parentItem)}}}r.default=m},{"./flip":"kONUB","./aspectRatio":"84NBV","./playbackRate":"aetWt","./subtitleOffset":"fIBkO","../utils/component":"18nVI","../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],kONUB:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{i18n:t,icons:r,constructor:{SETTING_ITEM_WIDTH:a,FLIP:i}}=e;function n(e,r,a){r&&(r.innerText=t.get((0,o.capitalize)(a)));const i=(0,o.queryAll)(".art-setting-item",e).find((e=>e.dataset.value===a));i&&(0,o.inverseClass)(i,"art-current")}return{width:a,html:t.get("Video Flip"),tooltip:t.get((0,o.capitalize)(e.flip)),icon:r.flip,selector:i.map((r=>({value:r,default:r===e.flip,html:t.get((0,o.capitalize)(r))}))),onSelect:t=>(e.flip=t.value,t.value),mounted:(t,r)=>{n(t,r.$tooltip,e.flip),e.on("flip",(()=>{n(t,r.$tooltip,e.flip)}))}}}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"84NBV":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{i18n:t,icons:r,constructor:{SETTING_ITEM_WIDTH:a,ASPECT_RATIO:i}}=e;function n(e){return"default"===e?t.get("Default"):e}function s(e,t,r){t&&(t.innerText=n(r));const a=(0,o.queryAll)(".art-setting-item",e).find((e=>e.dataset.value===r));a&&(0,o.inverseClass)(a,"art-current")}return{width:a,html:t.get("Aspect Ratio"),icon:r.aspectRatio,tooltip:n(e.aspectRatio),selector:i.map((t=>({value:t,default:t===e.aspectRatio,html:n(t)}))),onSelect:t=>(e.aspectRatio=t.value,t.value),mounted:(t,r)=>{s(t,r.$tooltip,e.aspectRatio),e.on("aspectRatio",(()=>{s(t,r.$tooltip,e.aspectRatio)}))}}}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],aetWt:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{i18n:t,icons:r,constructor:{SETTING_ITEM_WIDTH:a,PLAYBACK_RATE:i}}=e;function n(e){return 1===e?t.get("Normal"):e}function s(e,t,r){t&&(t.innerText=n(r));const a=(0,o.queryAll)(".art-setting-item",e).find((e=>Number(e.dataset.value)===r));a&&(0,o.inverseClass)(a,"art-current")}return{width:a,html:t.get("Play Speed"),tooltip:n(e.playbackRate),icon:r.playbackRate,selector:i.map((t=>({value:t,default:t===e.playbackRate,html:n(t)}))),onSelect:t=>(e.playbackRate=t.value,t.value),mounted:(t,r)=>{s(t,r.$tooltip,e.playbackRate),e.on("video:ratechange",(()=>{s(t,r.$tooltip,e.playbackRate)}))}}}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],fIBkO:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r),r.default=function(e){const{i18n:t,icons:r,constructor:o}=e;return{width:o.SETTING_ITEM_WIDTH,html:t.get("Subtitle Offset"),icon:r.subtitle,tooltip:"0s",range:[0,-5,5,.1],onChange:t=>(e.subtitleOffset=t.range,t.range+"s")}}},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"2aaJe":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);r.default=class{constructor(){this.name="artplayer_settings",this.settings={}}get(e){try{const t=JSON.parse(window.localStorage.getItem(this.name))||{};return e?t[e]:t}catch(t){return e?this.settings[e]:this.settings}}set(e,t){try{const r=Object.assign({},this.get(),{[e]:t});window.localStorage.setItem(this.name,JSON.stringify(r))}catch(r){this.settings[e]=t}}del(e){try{const t=this.get();delete t[e],window.localStorage.setItem(this.name,JSON.stringify(t))}catch(t){delete this.settings[e]}}clear(){try{window.localStorage.removeItem(this.name)}catch(e){this.settings={}}}}},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"8MTUM":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("../utils"),i=e("./miniProgressBar"),n=o.interopDefault(i),s=e("./autoOrientation"),l=o.interopDefault(s),c=e("./autoPlayback"),p=o.interopDefault(c),u=e("./fastForward"),d=o.interopDefault(u),f=e("./lock"),h=o.interopDefault(f);r.default=class{constructor(e){this.art=e,this.id=0;const{option:t}=e;t.miniProgressBar&&!t.isLive&&this.add(n.default),t.lock&&a.isMobile&&this.add(h.default),t.autoPlayback&&!t.isLive&&this.add(p.default),t.autoOrientation&&a.isMobile&&this.add(l.default),t.fastForward&&a.isMobile&&!t.isLive&&this.add(d.default);for(let e=0;e<t.plugins.length;e++)this.add(t.plugins[e])}add(e){this.id+=1;const t=e.call(this.art,this.art),r=t&&t.name||e.name||`plugin${this.id}`;return(0,a.errorHandle)(!(0,a.has)(this,r),`Cannot add a plugin that already has the same name: ${r}`),(0,a.def)(this,r,{value:t}),this}}},{"../utils":"71aH7","./miniProgressBar":"87pSL","./autoOrientation":"ePEg5","./autoPlayback":"cVO99","./fastForward":"hFDwt","./lock":"1hsTH","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"87pSL":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r),r.default=function(e){return e.on("ready",(()=>{e.layers.add({name:"miniProgressBar",mounted(t){e.on("destroy",(()=>{t.style.display="none"})),e.on("video:timeupdate",(()=>{t.style.width=100*e.played+"%"})),e.on("setBar",((e,r)=>{"played"===e&&(t.style.width=100*r+"%")}))}})})),{name:"miniProgressBar"}}},{"@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],ePEg5:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{option:t,constructor:r,template:{$player:a,$video:i}}=e;return e.on("fullscreenWeb",(n=>{if(n){const{videoWidth:t,videoHeight:n}=i,{clientWidth:s,clientHeight:l}=document.documentElement;(t>n&&s<l||t<n&&s>l)&&setTimeout((()=>{(0,o.setStyle)(a,"width",`${l}px`),(0,o.setStyle)(a,"height",`${s}px`),(0,o.setStyle)(a,"transform-origin","0 0"),(0,o.setStyle)(a,"transform",`rotate(90deg) translate(0, -${s}px)`),(0,o.addClass)(a,"art-auto-orientation"),e.isRotate=!0,e.emit("resize")}),r.MOBILE_AUTO_ORIENTATION_TIME)}else(0,o.hasClass)(a,"art-auto-orientation")&&((0,o.setStyle)(a,"width",null),(0,o.setStyle)(a,"height",null),(0,o.setStyle)(a,"transform",null),(0,o.setStyle)(a,"transform-origin",null),(0,o.removeClass)(a,"art-auto-orientation"),e.isRotate=!1,e.aspectRatioReset=!0,e.autoSize=t.autoSize,e.notice.show="",e.emit("resize"))})),e.on("fullscreen",(async e=>{const t=screen.orientation.type;if(e){const{videoWidth:e,videoHeight:r}=i,{clientWidth:n,clientHeight:s}=document.documentElement;if(e>r&&n<s||e<r&&n>s){const e=t.startsWith("portrait")?"landscape":"portrait";await screen.orientation.lock(e),(0,o.addClass)(a,"art-auto-orientation-fullscreen")}}else(0,o.hasClass)(a,"art-auto-orientation-fullscreen")&&(await screen.orientation.lock(t),(0,o.removeClass)(a,"art-auto-orientation-fullscreen"))})),{name:"autoOrientation",get state(){return(0,o.hasClass)(a,"art-auto-orientation")}}}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],cVO99:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{i18n:t,icons:r,storage:a,constructor:i,proxy:n,template:{$poster:s}}=e,l=e.layers.add({name:"autoPlayback",html:\'<div class="art-autoPlayback-close"></div><div class="art-autoPlayback-last"></div><div class="art-autoPlayback-jump"></div>\'}),c=(0,o.query)(".art-autoPlayback-last",l),p=(0,o.query)(".art-autoPlayback-jump",l),u=(0,o.query)(".art-autoPlayback-close",l);return e.on("video:timeupdate",(()=>{const t=a.get("times")||{},r=Object.keys(t);r.length>i.AUTO_PLAYBACK_MAX&&delete t[r[0]],t[e.option.id||e.option.url]=e.currentTime,a.set("times",t)})),e.on("ready",(()=>{const d=(a.get("times")||{})[e.option.id||e.option.url];d&&d>=i.AUTO_PLAYBACK_MIN&&((0,o.append)(u,r.close),(0,o.setStyle)(l,"display","flex"),c.innerText=`${t.get("Last Seen")} ${(0,o.secondToTime)(d)}`,p.innerText=t.get("Jump Play"),n(u,"click",(()=>{(0,o.setStyle)(l,"display","none")})),n(p,"click",(()=>{e.seek=d,e.play(),(0,o.setStyle)(s,"display","none"),(0,o.setStyle)(l,"display","none")})),e.once("video:timeupdate",(()=>{setTimeout((()=>{(0,o.setStyle)(l,"display","none")}),i.AUTO_PLAYBACK_TIMEOUT)})))})),{name:"autoPlayback",get times(){return a.get("times")||{}},clear:()=>a.del("times"),delete(e){const t=a.get("times")||{};return delete t[e],a.set("times",t),t}}}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],hFDwt:[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{constructor:t,proxy:r,template:{$player:a,$video:i}}=e;let n=null,s=!1,l=1;const c=()=>{clearTimeout(n),s&&(s=!1,e.playbackRate=l,(0,o.removeClass)(a,"art-fast-forward"))};return r(i,"touchstart",(r=>{1===r.touches.length&&e.playing&&!e.isLock&&(n=setTimeout((()=>{s=!0,l=e.playbackRate,e.playbackRate=t.FAST_FORWARD_VALUE,(0,o.addClass)(a,"art-fast-forward")}),t.FAST_FORWARD_TIME))})),r(document,"touchmove",c),r(document,"touchend",c),{name:"fastForward",get state(){return(0,o.hasClass)(a,"art-fast-forward")}}}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"1hsTH":[function(e,t,r){e("@parcel/transformer-js/src/esmodule-helpers.js").defineInteropFlag(r);var o=e("../utils");r.default=function(e){const{layers:t,icons:r,template:{$player:a}}=e;return t.add({name:"lock",mounted(t){const a=(0,o.append)(t,r.lock),i=(0,o.append)(t,r.unlock);(0,o.setStyle)(a,"display","none"),e.on("lock",(e=>{e?((0,o.setStyle)(a,"display","inline-flex"),(0,o.setStyle)(i,"display","none")):((0,o.setStyle)(a,"display","none"),(0,o.setStyle)(i,"display","inline-flex"))}))},click(){(0,o.hasClass)(a,"art-lock")?((0,o.removeClass)(a,"art-lock"),this.isLock=!1):((0,o.addClass)(a,"art-lock"),this.isLock=!0)}}),{name:"lock",get state(){return(0,o.hasClass)(a,"art-lock")}}}},{"../utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}],"7mil2":[function(e,t,r){var o=e("@parcel/transformer-js/src/esmodule-helpers.js");o.defineInteropFlag(r);var a=e("./config"),i=o.interopDefault(a),n=e("./utils");r.default=class{constructor(e){const{option:t,proxy:r,template:{$video:o}}=e;for(let t=0;t<i.default.events.length;t++)r(o,i.default.events[t],(t=>{e.emit(`video:${t.type}`,t)}));Object.keys(t.moreVideoAttr).forEach((e=>{o[e]=t.moreVideoAttr[e]})),o.controls=!0,t.muted&&(o.muted=t.muted),t.volume&&(o.volume=(0,n.clamp)(t.volume,0,1)),t.poster&&(o.poster=t.poster),t.autoplay&&(o.autoplay=t.autoplay),t.playsInline&&(o.playsInline=!0,o["webkit-playsinline"]=!0);const a=t.type||(0,n.getExt)(t.url),s=t.customType[a];a&&s?s(o,t.url,e):(o.src=t.url,e.emit("url",o.src))}}},{"./config":"lyjeQ","./utils":"71aH7","@parcel/transformer-js/src/esmodule-helpers.js":"9pCYc"}]},["5lTcX"],"5lTcX","parcelRequire4dc0");\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/artplayer@4.6.2/node_modules/artplayer/dist/artplayer.js?')},"./node_modules/.pnpm/content-type@1.0.5/node_modules/content-type/index.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/.pnpm/content-type@1.0.5/node_modules/content-type/index.js ***!
  \**********************************************************************************/function(__unused_webpack_module,exports){"use strict";eval("/*!\n * content-type\n * Copyright(c) 2015 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n\n\n/**\n * RegExp to match *( \";\" parameter ) in RFC 7231 sec 3.1.1.1\n *\n * parameter     = token \"=\" ( token / quoted-string )\n * token         = 1*tchar\n * tchar         = \"!\" / \"#\" / \"$\" / \"%\" / \"&\" / \"'\" / \"*\"\n *               / \"+\" / \"-\" / \".\" / \"^\" / \"_\" / \"`\" / \"|\" / \"~\"\n *               / DIGIT / ALPHA\n *               ; any VCHAR, except delimiters\n * quoted-string = DQUOTE *( qdtext / quoted-pair ) DQUOTE\n * qdtext        = HTAB / SP / %x21 / %x23-5B / %x5D-7E / obs-text\n * obs-text      = %x80-FF\n * quoted-pair   = \"\\\" ( HTAB / SP / VCHAR / obs-text )\n */\nvar PARAM_REGEXP = /; *([!#$%&'*+.^_`|~0-9A-Za-z-]+) *= *(\"(?:[\\u000b\\u0020\\u0021\\u0023-\\u005b\\u005d-\\u007e\\u0080-\\u00ff]|\\\\[\\u000b\\u0020-\\u00ff])*\"|[!#$%&'*+.^_`|~0-9A-Za-z-]+) */g // eslint-disable-line no-control-regex\nvar TEXT_REGEXP = /^[\\u000b\\u0020-\\u007e\\u0080-\\u00ff]+$/ // eslint-disable-line no-control-regex\nvar TOKEN_REGEXP = /^[!#$%&'*+.^_`|~0-9A-Za-z-]+$/\n\n/**\n * RegExp to match quoted-pair in RFC 7230 sec 3.2.6\n *\n * quoted-pair = \"\\\" ( HTAB / SP / VCHAR / obs-text )\n * obs-text    = %x80-FF\n */\nvar QESC_REGEXP = /\\\\([\\u000b\\u0020-\\u00ff])/g // eslint-disable-line no-control-regex\n\n/**\n * RegExp to match chars that must be quoted-pair in RFC 7230 sec 3.2.6\n */\nvar QUOTE_REGEXP = /([\\\\\"])/g\n\n/**\n * RegExp to match type in RFC 7231 sec 3.1.1.1\n *\n * media-type = type \"/\" subtype\n * type       = token\n * subtype    = token\n */\nvar TYPE_REGEXP = /^[!#$%&'*+.^_`|~0-9A-Za-z-]+\\/[!#$%&'*+.^_`|~0-9A-Za-z-]+$/\n\n/**\n * Module exports.\n * @public\n */\n\nexports.format = format\nexports.parse = parse\n\n/**\n * Format object to media type.\n *\n * @param {object} obj\n * @return {string}\n * @public\n */\n\nfunction format (obj) {\n  if (!obj || typeof obj !== 'object') {\n    throw new TypeError('argument obj is required')\n  }\n\n  var parameters = obj.parameters\n  var type = obj.type\n\n  if (!type || !TYPE_REGEXP.test(type)) {\n    throw new TypeError('invalid type')\n  }\n\n  var string = type\n\n  // append parameters\n  if (parameters && typeof parameters === 'object') {\n    var param\n    var params = Object.keys(parameters).sort()\n\n    for (var i = 0; i < params.length; i++) {\n      param = params[i]\n\n      if (!TOKEN_REGEXP.test(param)) {\n        throw new TypeError('invalid parameter name')\n      }\n\n      string += '; ' + param + '=' + qstring(parameters[param])\n    }\n  }\n\n  return string\n}\n\n/**\n * Parse media type to object.\n *\n * @param {string|object} string\n * @return {Object}\n * @public\n */\n\nfunction parse (string) {\n  if (!string) {\n    throw new TypeError('argument string is required')\n  }\n\n  // support req/res-like objects as argument\n  var header = typeof string === 'object'\n    ? getcontenttype(string)\n    : string\n\n  if (typeof header !== 'string') {\n    throw new TypeError('argument string is required to be a string')\n  }\n\n  var index = header.indexOf(';')\n  var type = index !== -1\n    ? header.slice(0, index).trim()\n    : header.trim()\n\n  if (!TYPE_REGEXP.test(type)) {\n    throw new TypeError('invalid media type')\n  }\n\n  var obj = new ContentType(type.toLowerCase())\n\n  // parse parameters\n  if (index !== -1) {\n    var key\n    var match\n    var value\n\n    PARAM_REGEXP.lastIndex = index\n\n    while ((match = PARAM_REGEXP.exec(header))) {\n      if (match.index !== index) {\n        throw new TypeError('invalid parameter format')\n      }\n\n      index += match[0].length\n      key = match[1].toLowerCase()\n      value = match[2]\n\n      if (value.charCodeAt(0) === 0x22 /* \" */) {\n        // remove quotes\n        value = value.slice(1, -1)\n\n        // remove escapes\n        if (value.indexOf('\\\\') !== -1) {\n          value = value.replace(QESC_REGEXP, '$1')\n        }\n      }\n\n      obj.parameters[key] = value\n    }\n\n    if (index !== header.length) {\n      throw new TypeError('invalid parameter format')\n    }\n  }\n\n  return obj\n}\n\n/**\n * Get content-type from req/res objects.\n *\n * @param {object}\n * @return {Object}\n * @private\n */\n\nfunction getcontenttype (obj) {\n  var header\n\n  if (typeof obj.getHeader === 'function') {\n    // res-like\n    header = obj.getHeader('content-type')\n  } else if (typeof obj.headers === 'object') {\n    // req-like\n    header = obj.headers && obj.headers['content-type']\n  }\n\n  if (typeof header !== 'string') {\n    throw new TypeError('content-type header is missing from object')\n  }\n\n  return header\n}\n\n/**\n * Quote a string if necessary.\n *\n * @param {string} val\n * @return {string}\n * @private\n */\n\nfunction qstring (val) {\n  var str = String(val)\n\n  // no need to quote tokens\n  if (TOKEN_REGEXP.test(str)) {\n    return str\n  }\n\n  if (str.length > 0 && !TEXT_REGEXP.test(str)) {\n    throw new TypeError('invalid parameter value')\n  }\n\n  return '\"' + str.replace(QUOTE_REGEXP, '\\\\$1') + '\"'\n}\n\n/**\n * Class to represent a content type.\n * @private\n */\nfunction ContentType (type) {\n  this.parameters = Object.create(null)\n  this.type = type\n}\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/content-type@1.0.5/node_modules/content-type/index.js?")},"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js":
/*!**************************************************************************!*\
  !*** ./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js ***!
  \**************************************************************************/function(module,exports,__webpack_require__){eval('/* eslint-env browser */\n\n/**\n * This is the web browser implementation of `debug()`.\n */\n\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\nexports.storage = localstorage();\nexports.destroy = (() => {\n\tlet warned = false;\n\n\treturn () => {\n\t\tif (!warned) {\n\t\t\twarned = true;\n\t\t\tconsole.warn(\'Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.\');\n\t\t}\n\t};\n})();\n\n/**\n * Colors.\n */\n\nexports.colors = [\n\t\'#0000CC\',\n\t\'#0000FF\',\n\t\'#0033CC\',\n\t\'#0033FF\',\n\t\'#0066CC\',\n\t\'#0066FF\',\n\t\'#0099CC\',\n\t\'#0099FF\',\n\t\'#00CC00\',\n\t\'#00CC33\',\n\t\'#00CC66\',\n\t\'#00CC99\',\n\t\'#00CCCC\',\n\t\'#00CCFF\',\n\t\'#3300CC\',\n\t\'#3300FF\',\n\t\'#3333CC\',\n\t\'#3333FF\',\n\t\'#3366CC\',\n\t\'#3366FF\',\n\t\'#3399CC\',\n\t\'#3399FF\',\n\t\'#33CC00\',\n\t\'#33CC33\',\n\t\'#33CC66\',\n\t\'#33CC99\',\n\t\'#33CCCC\',\n\t\'#33CCFF\',\n\t\'#6600CC\',\n\t\'#6600FF\',\n\t\'#6633CC\',\n\t\'#6633FF\',\n\t\'#66CC00\',\n\t\'#66CC33\',\n\t\'#9900CC\',\n\t\'#9900FF\',\n\t\'#9933CC\',\n\t\'#9933FF\',\n\t\'#99CC00\',\n\t\'#99CC33\',\n\t\'#CC0000\',\n\t\'#CC0033\',\n\t\'#CC0066\',\n\t\'#CC0099\',\n\t\'#CC00CC\',\n\t\'#CC00FF\',\n\t\'#CC3300\',\n\t\'#CC3333\',\n\t\'#CC3366\',\n\t\'#CC3399\',\n\t\'#CC33CC\',\n\t\'#CC33FF\',\n\t\'#CC6600\',\n\t\'#CC6633\',\n\t\'#CC9900\',\n\t\'#CC9933\',\n\t\'#CCCC00\',\n\t\'#CCCC33\',\n\t\'#FF0000\',\n\t\'#FF0033\',\n\t\'#FF0066\',\n\t\'#FF0099\',\n\t\'#FF00CC\',\n\t\'#FF00FF\',\n\t\'#FF3300\',\n\t\'#FF3333\',\n\t\'#FF3366\',\n\t\'#FF3399\',\n\t\'#FF33CC\',\n\t\'#FF33FF\',\n\t\'#FF6600\',\n\t\'#FF6633\',\n\t\'#FF9900\',\n\t\'#FF9933\',\n\t\'#FFCC00\',\n\t\'#FFCC33\'\n];\n\n/**\n * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n * and the Firebug extension (any Firefox version) are known\n * to support "%c" CSS customizations.\n *\n * TODO: add a `localStorage` variable to explicitly enable/disable colors\n */\n\n// eslint-disable-next-line complexity\nfunction useColors() {\n\t// NB: In an Electron preload script, document will be defined but not fully\n\t// initialized. Since we know we\'re in Chrome, we\'ll just detect this case\n\t// explicitly\n\tif (typeof window !== \'undefined\' && window.process && (window.process.type === \'renderer\' || window.process.__nwjs)) {\n\t\treturn true;\n\t}\n\n\t// Internet Explorer and Edge do not support colors.\n\tif (typeof navigator !== \'undefined\' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\\/(\\d+)/)) {\n\t\treturn false;\n\t}\n\n\tlet m;\n\n\t// Is webkit? http://stackoverflow.com/a/16459606/376773\n\t// document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n\treturn (typeof document !== \'undefined\' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||\n\t\t// Is firebug? http://stackoverflow.com/a/398120/376773\n\t\t(typeof window !== \'undefined\' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||\n\t\t// Is firefox >= v31?\n\t\t// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n\t\t(typeof navigator !== \'undefined\' && navigator.userAgent && (m = navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/)) && parseInt(m[1], 10) >= 31) ||\n\t\t// Double check webkit in userAgent just in case we are in a worker\n\t\t(typeof navigator !== \'undefined\' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n}\n\n/**\n * Colorize log arguments if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n\targs[0] = (this.useColors ? \'%c\' : \'\') +\n\t\tthis.namespace +\n\t\t(this.useColors ? \' %c\' : \' \') +\n\t\targs[0] +\n\t\t(this.useColors ? \'%c \' : \' \') +\n\t\t\'+\' + module.exports.humanize(this.diff);\n\n\tif (!this.useColors) {\n\t\treturn;\n\t}\n\n\tconst c = \'color: \' + this.color;\n\targs.splice(1, 0, c, \'color: inherit\');\n\n\t// The final "%c" is somewhat tricky, because there could be other\n\t// arguments passed either before or after the %c, so we need to\n\t// figure out the correct index to insert the CSS into\n\tlet index = 0;\n\tlet lastC = 0;\n\targs[0].replace(/%[a-zA-Z%]/g, match => {\n\t\tif (match === \'%%\') {\n\t\t\treturn;\n\t\t}\n\t\tindex++;\n\t\tif (match === \'%c\') {\n\t\t\t// We only are interested in the *last* %c\n\t\t\t// (the user may have provided their own)\n\t\t\tlastC = index;\n\t\t}\n\t});\n\n\targs.splice(lastC, 0, c);\n}\n\n/**\n * Invokes `console.debug()` when available.\n * No-op when `console.debug` is not a "function".\n * If `console.debug` is not available, falls back\n * to `console.log`.\n *\n * @api public\n */\nexports.log = console.debug || console.log || (() => {});\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\nfunction save(namespaces) {\n\ttry {\n\t\tif (namespaces) {\n\t\t\texports.storage.setItem(\'debug\', namespaces);\n\t\t} else {\n\t\t\texports.storage.removeItem(\'debug\');\n\t\t}\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\nfunction load() {\n\tlet r;\n\ttry {\n\t\tr = exports.storage.getItem(\'debug\');\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n\n\t// If debug isn\'t set in LS, and we\'re in Electron, try to load $DEBUG\n\tif (!r && typeof process !== \'undefined\' && \'env\' in process) {\n\t\tr = {"GITHUB_STATE":"/home/runner/work/_temp/_runner_file_commands/save_state_8e046db2-ff2e-45f9-aaac-c46abcc07265","npm_package_dependencies_tiptap_markdown":"^0.6.1","npm_package_dependencies_viewerjs":"^1.11.7","STATS_TRP":"true","DEPLOYMENT_BASEPATH":"/opt/runner","DOTNET_NOLOGO":"1","npm_package_dependencies_bulma":"0.9.4","USER":"runner","npm_package_devDependencies__vue_cli_service":"5.0.8","npm_package_devDependencies_webpack_cli":"^5.1.4","npm_config_user_agent":"pnpm/9.12.2 npm/? node/v18.20.5 linux x64","CI":"true","npm_package_dependencies_vue":"2.7.16","npm_package_dependencies_vue_apexcharts":"^1.7.0","npm_package_dependencies_vue_fullscreen":"^2.6.2","RUNNER_ENVIRONMENT":"github-hosted","GITHUB_ENV":"/home/runner/work/_temp/_runner_file_commands/set_env_8e046db2-ff2e-45f9-aaac-c46abcc07265","PIPX_HOME":"/opt/pipx","npm_package_dependencies__tiptap_core":"^2.0.4","npm_package_dependencies_codemirror":"^5.41.0","npm_package_dependencies_xterm_addon_attach":"^0.6.0","npm_package_devDependencies_compression_webpack_plugin":"5.0.2","npm_node_execpath":"/opt/hostedtoolcache/node/18.20.5/x64/bin/node","JAVA_HOME_8_X64":"/usr/lib/jvm/temurin-8-jdk-amd64","SHLVL":"1","npm_package_packageManager":"pnpm@9.0.6","HOME":"/home/runner","npm_package_dependencies_csslint":"^1.0.5","npm_package_dependencies_vue_codemirror":"^4.0.6","npm_package_dependencies_vue_demi":"0.14.6","npm_package_dependencies_vue_popperjs":"^2.3.0","npm_package_dependencies_vuex":"^3.6.2","npm_package_devDependencies_patch_package":"^7.0.2","npm_package_devDependencies_sass":"1.44.0","RUNNER_TEMP":"/home/runner/work/_temp","GITHUB_EVENT_PATH":"/home/runner/work/_temp/_github_workflow/event.json","npm_package_devDependencies_eslint_config_prettier":"^9.1.0","JAVA_HOME_11_X64":"/usr/lib/jvm/temurin-11-jdk-amd64","PIPX_BIN_DIR":"/opt/pipx_bin","GITHUB_REPOSITORY_OWNER":"IceWhaleTech","npm_package_dependencies_vue2_touch_events":"^3.2.2","GRADLE_HOME":"/usr/share/gradle-8.11.1","ANDROID_NDK_LATEST_HOME":"/usr/local/lib/android/sdk/ndk/27.2.12479018","JAVA_HOME_21_X64":"/usr/lib/jvm/temurin-21-jdk-amd64","STATS_RDCL":"true","GITHUB_RETENTION_DAYS":"90","npm_package_dependencies_composerize":"^1.2.0","npm_package_dependencies_remove":"^0.1.5","npm_package_dependencies_ua_parser_js":"^1.0.35","npm_package_dependencies_validator":"^13.9.0","npm_package_devDependencies__vue_cli_plugin_router":"5.0.8","npm_package_devDependencies_terser_webpack_plugin":"5.3.10","GITHUB_REPOSITORY_OWNER_ID":"91336243","POWERSHELL_DISTRIBUTION_CHANNEL":"GitHub-Actions-ubuntu22","AZURE_EXTENSION_DIR":"/opt/az/azcliextensions","GITHUB_HEAD_REF":"","npm_package_dependencies__icewhale_casaos_appmanagement_openapi":"latest","npm_package_dependencies_iconfonts_casaos":"^1.0.4","npm_package_dependencies_xterm_addon_fit":"^0.5.0","SYSTEMD_EXEC_PID":"603","npm_package_dependencies_buefy":"^0.9.29","npm_package_dependencies_dayjs":"^1.11.9","npm_package_dependencies_jshint":"^2.13.6","npm_package_dependencies_yamljs":"^0.3.0","npm_package_devDependencies_css_minimizer_webpack_plugin":"^7.0.0","GITHUB_GRAPHQL_URL":"https://api.github.com/graphql","npm_package_dependencies__vue_office_docx":"^1.6.0","npm_package_dependencies_qs":"^6.11.2","npm_package_devDependencies_tailwindcss":"^3.4.15","npm_package_devDependencies_typescript":"^5.7.2","NVM_DIR":"/home/runner/.nvm","npm_package_dependencies__vue_office_pdf":"^1.6.0","npm_package_dependencies_hitbox_js":"^1.0.2","npm_package_dependencies_mime":"^3.0.0","npm_package_dependencies_vue_awesome_swiper":"^4.1.1","npm_package_dependencies_vue_socket_io_extended":"^4.2.0","DOTNET_SKIP_FIRST_TIME_EXPERIENCE":"1","GOROOT_1_21_X64":"/opt/hostedtoolcache/go/1.21.13/x64","JAVA_HOME_17_X64":"/usr/lib/jvm/temurin-17-jdk-amd64","ImageVersion":"20241201.1.0","npm_package_scripts_dev":"vue-cli-service serve --mode dev","npm_package_devDependencies_prettier":"^3.4.1","RUNNER_OS":"Linux","GITHUB_API_URL":"https://api.github.com","GOROOT_1_22_X64":"/opt/hostedtoolcache/go/1.22.9/x64","SWIFT_PATH":"/usr/share/swift/usr/bin","npm_package_dependencies__fontsource_roboto":"^5.0.5","npm_package_dependencies__vueuse_core":"^10.2.1","npm_package_devDependencies__babel_preset_typescript":"^7.22.5","npm_package_devDependencies_vue_template_compiler":"^2.7.14","RUNNER_USER":"runner","STATS_V3PS":"true","CHROMEWEBDRIVER":"/usr/local/share/chromedriver-linux64","GOROOT_1_23_X64":"/opt/hostedtoolcache/go/1.23.3/x64","JOURNAL_STREAM":"8:19609","GITHUB_WORKFLOW":"alpha prerelease CI","_":"/home/runner/setup-pnpm/node_modules/.bin/pnpm","npm_package_private":"true","npm_package_installConfig_hoistingLimits":"workspaces","npm_package_dependencies__kangc_v_md_editor":"^1.7.11","npm_package_dependencies__tiptap_extension_highlight":"^2.0.4","npm_package_dependencies_gsap":"^3.12.2","npm_package_dependencies_vue_social_sharing":"^3.0.9","npm_package_scripts_lint":"vue-cli-service lint","npm_package_devDependencies_postcss_import":"^16.1.0","npm_config_registry":"https://registry.npmjs.org/","ACTIONS_RUNNER_ACTION_ARCHIVE_CACHE":"/opt/actionarchivecache","STATS_D":"false","GITHUB_RUN_ID":"12253718243","STATS_VMFE":"true","npm_package_dependencies_clipboard_copy":"^4.0.1","npm_package_dependencies_core_js":"^3.39.0","npm_package_dependencies_music_metadata_browser":"^2.5.10","npm_package_devDependencies__babel_core":"^7.22.9","npm_package_devDependencies_postinstall_postinstall":"^2.1.0","GITHUB_REF_TYPE":"tag","BOOTSTRAP_HASKELL_NONINTERACTIVE":"1","GITHUB_WORKFLOW_SHA":"df89812945b2d6935de1043d2fbadaef43485f0e","GITHUB_BASE_REF":"","ImageOS":"ubuntu22","npm_package_dependencies__tiptap_extension_typography":"^2.0.4","npm_package_dependencies_vue_breakpoint_mixin":"^1.5.0","GITHUB_WORKFLOW_REF":"IceWhaleTech/CasaOS-UI/.github/workflows/node-prerelease.js.yml@refs/tags/v0.4.15","PERFLOG_LOCATION_SETTING":"RUNNER_PERFLOG","GITHUB_ACTION_REPOSITORY":"","npm_package_dependencies_axios":"^0.28.1","npm_package_devDependencies_md5_es":"^1.8.2","npm_package_devDependencies_postcss_loader":"^4.3.0","npm_package_devDependencies_prettier_plugin_tailwindcss":"^0.6.9","npm_config_node_gyp":"/home/runner/setup-pnpm/node_modules/.pnpm/pnpm@9.12.2/node_modules/pnpm/dist/node_modules/node-gyp/bin/node-gyp.js","PATH":"/home/runner/work/CasaOS-UI/CasaOS-UI/node_modules/.bin:/home/runner/setup-pnpm/node_modules/.pnpm/pnpm@9.12.2/node_modules/pnpm/dist/node-gyp-bin:/home/runner/setup-pnpm/node_modules/.bin:/opt/hostedtoolcache/node/18.20.5/x64/bin:/snap/bin:/home/runner/.local/bin:/opt/pipx_bin:/home/runner/.cargo/bin:/home/runner/.config/composer/vendor/bin:/usr/local/.ghcup/bin:/home/runner/.dotnet/tools:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin","ANT_HOME":"/usr/share/ant","DOTNET_MULTILEVEL_LOOKUP":"0","RUNNER_TRACKING_ID":"github_8c1ffee4-43cb-4316-a4fa-671b0ee2c50c","INVOCATION_ID":"f368e18df6e34d78b3735e368fb7c4c9","RUNNER_TOOL_CACHE":"/opt/hostedtoolcache","npm_package_name":"casaos-main","npm_package_dependencies__tiptap_vue_2":"^2.0.4","npm_package_dependencies__vueuse_components":"^10.2.1","npm_package_dependencies_file_saver":"^2.0.5","npm_package_dependencies_vue_slider_component":"^3.2.24","npm_package_devDependencies__babel_eslint_parser":"^7.25.9","NODE":"/opt/hostedtoolcache/node/18.20.5/x64/bin/node","GITHUB_ACTION":"__run_4","GITHUB_RUN_NUMBER":"156","GITHUB_TRIGGERING_ACTOR":"jerrykuku","RUNNER_ARCH":"X64","XDG_RUNTIME_DIR":"/run/user/1001","AGENT_TOOLSDIRECTORY":"/opt/hostedtoolcache","npm_package_dependencies_marked":"^4.3.0","npm_package_dependencies_vue_dompurify_html":"2.6.0","npm_package_devDependencies_style_resources_loader":"^1.5.0","npm_config_frozen_lockfile":"","npm_package_dependencies__icewhale_casaos_openapi":"latest","npm_package_dependencies_artplayer":"^4.6.2","npm_package_dependencies_vue_advanced_cropper":"1.11.6","npm_package_devDependencies_glob":"^10.4.5","LANG":"C.UTF-8","VCPKG_INSTALLATION_ROOT":"/usr/local/share/vcpkg","npm_package_scripts_build_messagebus":"node message_bus.build.js","npm_package_devDependencies_eslint":"8.57.1","CONDA":"/usr/share/miniconda","RUNNER_NAME":"GitHub Actions 18","XDG_CONFIG_HOME":"/home/runner/.config","STATS_VMD":"true","GITHUB_REF_NAME":"v0.4.15","GITHUB_REPOSITORY":"IceWhaleTech/CasaOS-UI","STATS_D_D":"false","npm_package_dependencies__mdi_font":"^6.9.96","npm_package_dependencies_is_valid_hostname":"^1.0.2","npm_package_dependencies_v_animate_css":"^0.0.6","npm_package_devDependencies_dotenv":"^16.4.5","npm_package_browserslist_0":"> 1%","npm_lifecycle_script":"node message_bus.build.js && vue-cli-service build --dest ./build/sysroot/var/lib/casaos/www/ --mode production","STATS_UE":"true","ANDROID_NDK_ROOT":"/usr/local/lib/android/sdk/ndk/27.2.12479018","GITHUB_ACTION_REF":"","DEBIAN_FRONTEND":"noninteractive","npm_package_scripts_test":"vitest","npm_package_dependencies_browser_info":"^1.3.0","npm_package_dependencies_docx_preview":"^0.3.0","npm_package_dependencies_intersection_observer":"^0.12.2","npm_package_devDependencies__trivago_prettier_plugin_sort_imports":"^4.3.0","npm_package_devDependencies__vue_cli_plugin_vuex":"5.0.8","npm_package_devDependencies_prettier_plugin_organize_attributes":"^1.0.0","npm_package_devDependencies_webpack_dev_server":"^5.1.0","npm_package_browserslist_1":"last 2 versions","GITHUB_REPOSITORY_ID":"410528678","GITHUB_ACTIONS":"true","STATS_PIP":"false","NODE_PATH":"/home/runner/work/CasaOS-UI/CasaOS-UI/node_modules/.pnpm/@vue+cli-service@5.0.8_@vue+compiler-sfc@3.5.13_ejs@3.1.10_lodash@4.17.21_prettier@3.4.1_sass_pumtanxjijhthirvtxntgrvmmi/node_modules/@vue/cli-service/bin/node_modules:/home/runner/work/CasaOS-UI/CasaOS-UI/node_modules/.pnpm/@vue+cli-service@5.0.8_@vue+compiler-sfc@3.5.13_ejs@3.1.10_lodash@4.17.21_prettier@3.4.1_sass_pumtanxjijhthirvtxntgrvmmi/node_modules/@vue/cli-service/node_modules:/home/runner/work/CasaOS-UI/CasaOS-UI/node_modules/.pnpm/@vue+cli-service@5.0.8_@vue+compiler-sfc@3.5.13_ejs@3.1.10_lodash@4.17.21_prettier@3.4.1_sass_pumtanxjijhthirvtxntgrvmmi/node_modules/@vue/node_modules:/home/runner/work/CasaOS-UI/CasaOS-UI/node_modules/.pnpm/@vue+cli-service@5.0.8_@vue+compiler-sfc@3.5.13_ejs@3.1.10_lodash@4.17.21_prettier@3.4.1_sass_pumtanxjijhthirvtxntgrvmmi/node_modules:/home/runner/work/CasaOS-UI/CasaOS-UI/node_modules/.pnpm/node_modules:/home/runner/setup-pnpm/node_modules/.pnpm/pnpm@9.12.2/node_modules/pnpm/bin/node_modules:/home/runner/setup-pnpm/node_modules/.pnpm/pnpm@9.12.2/node_modules/pnpm/node_modules:/home/runner/setup-pnpm/node_modules/.pnpm/pnpm@9.12.2/node_modules:/home/runner/setup-pnpm/node_modules/.pnpm/node_modules","npm_package_version":"v0.4.5","npm_package_dependencies_jsonlint_mod":"^1.7.6","npm_package_dependencies_nanoid":"^4.0.2","npm_package_dependencies_vee_validate":"^3.4.15","npm_package_dependencies_vuedraggable":"^2.24.3","npm_package_devDependencies_jwt_decode":"^3.1.2","npm_package_browserslist_2":"not dead","npm_lifecycle_event":"build","GITHUB_REF_PROTECTED":"false","npm_package_scripts_build":"node message_bus.build.js && vue-cli-service build --dest ./build/sysroot/var/lib/casaos/www/ --mode production","npm_package_dependencies_dateformat":"^5.0.3","npm_package_dependencies_ejs":"^3.1.5","npm_package_dependencies_js_yaml":"^4.1.0","npm_package_dependencies_simple_uploader_js":"^0.6.0","npm_package_dependencies_vue_i18n":"8.28.2","GITHUB_WORKSPACE":"/home/runner/work/CasaOS-UI/CasaOS-UI","ACCEPT_EULA":"Y","GITHUB_JOB":"release","RUNNER_PERFLOG":"/home/runner/perflog","npm_package_dependencies_lodash":"^4.17.21","npm_package_dependencies_uuid_validate":"^0.0.3","npm_package_dependencies_vue_aplayer":"^1.6.1","npm_package_dependencies_yargs_parser":"^21.1.1","GITHUB_SHA":"df89812945b2d6935de1043d2fbadaef43485f0e","GITHUB_RUN_ATTEMPT":"1","STATS_D_TC":"true","npm_package_dependencies__icewhale_icewhale_files_openapi":"latest","npm_package_dependencies_vue_custom_scrollbar":"^1.4.4","npm_package_dependencies_vue_router":"^3.6.5","npm_package_devDependencies__vue_cli_plugin_eslint":"5.0.8","npm_package_devDependencies_sass_loader":"10.4.1","GITHUB_REF":"refs/tags/v0.4.15","GITHUB_ACTOR":"jerrykuku","ANDROID_SDK_ROOT":"/usr/local/lib/android/sdk","npm_package_dependencies_markdown_it":"^13.0.1","npm_package_dependencies_v_viewer":"^1.7.1","LEIN_HOME":"/usr/local/lib/lein","npm_package_dependencies_htmlhint":"^1.1.4","npm_package_dependencies_vue_smooth_reflow":"^0.1.12","npm_package_dependencies_xterm":"^4.19.0","npm_package_devDependencies_eslint_plugin_prettier":"^5.2.1","npm_package_devDependencies_rss_parser":"^3.13.0","GITHUB_PATH":"/home/runner/work/_temp/_runner_file_commands/add_path_8e046db2-ff2e-45f9-aaac-c46abcc07265","JAVA_HOME":"/usr/lib/jvm/temurin-11-jdk-amd64","PWD":"/home/runner/work/CasaOS-UI/CasaOS-UI","GITHUB_ACTOR_ID":"9485680","RUNNER_WORKSPACE":"/home/runner/work/CasaOS-UI","npm_package_dependencies__vue_office_excel":"^1.6.0","npm_package_devDependencies__vue_cli_plugin_babel":"5.0.8","npm_execpath":"/home/runner/setup-pnpm/node_modules/.pnpm/pnpm@9.12.2/node_modules/pnpm/bin/pnpm.cjs","HOMEBREW_CLEANUP_PERIODIC_FULL_DAYS":"3650","STATS_TIS":"mining","GITHUB_EVENT_NAME":"push","HOMEBREW_NO_AUTO_UPDATE":"1","ANDROID_HOME":"/usr/local/lib/android/sdk","GITHUB_SERVER_URL":"https://github.com","GECKOWEBDRIVER":"/usr/local/share/gecko_driver","LEIN_JAR":"/usr/local/lib/lein/self-installs/leiningen-2.11.2-standalone.jar","GHCUP_INSTALL_BASE_PREFIX":"/usr/local","GITHUB_OUTPUT":"/home/runner/work/_temp/_runner_file_commands/set_output_8e046db2-ff2e-45f9-aaac-c46abcc07265","npm_package_dependencies__tiptap_pm":"^2.0.4","npm_package_dependencies__tiptap_starter_kit":"^2.0.4","npm_package_dependencies_dompurify":"^3.0.6","npm_package_dependencies_vue_ellipse_progress":"^1.3.1","EDGEWEBDRIVER":"/usr/local/share/edge_driver","STATS_EXT":"true","npm_package_dependencies_socket_io_client":"^2.5.0","npm_package_devDependencies_eslint_plugin_vue":"^8.7.1","npm_package_devDependencies_postcss":"^8.4.38","npm_package_devDependencies_swiper":"^5.4.5","npm_command":"run-script","PNPM_SCRIPT_SRC_DIR":"/home/runner/work/CasaOS-UI/CasaOS-UI","ANDROID_NDK":"/usr/local/lib/android/sdk/ndk/27.2.12479018","SGX_AESM_ADDR":"1","CHROME_BIN":"/usr/bin/google-chrome","npm_package_devDependencies_babel_eslint":"^10.1.0","SELENIUM_JAR_PATH":"/usr/share/java/selenium-server.jar","PNPM_HOME":"/home/runner/setup-pnpm/node_modules/.bin","STATS_EXTP":"https://provjobdprod.z13.web.core.windows.net/settings/provjobdsettings-latest/provjobd.data","npm_package_dependencies_hls_js":"^1.4.14","npm_package_dependencies_lottie_web_vue":"1.2.1","npm_package_devDependencies_browserslist":"^4.21.9","ANDROID_NDK_HOME":"/usr/local/lib/android/sdk/ndk/27.2.12479018","GITHUB_STEP_SUMMARY":"/home/runner/work/_temp/_runner_file_commands/step_summary_8e046db2-ff2e-45f9-aaac-c46abcc07265","npm_package_dependencies_highlight_js":"^11.10.0","npm_package_devDependencies__antfu_eslint_config":"^2.27.3","npm_package_devDependencies_node_polyfill_webpack_plugin":"^4.0.0","npm_package_devDependencies_yaml":"^1.10.2","INIT_CWD":"/home/runner/work/CasaOS-UI/CasaOS-UI","NODE_ENV":"prod","BABEL_ENV":"production","VUE_CLI_TRANSPILE_BABEL_RUNTIME":"true","VUE_CLI_BUILD_TARGET":"app"}.DEBUG;\n\t}\n\n\treturn r;\n}\n\n/**\n * Localstorage attempts to return the localstorage.\n *\n * This is necessary because safari throws\n * when a user disables cookies/localstorage\n * and you attempt to access it.\n *\n * @return {LocalStorage}\n * @api private\n */\n\nfunction localstorage() {\n\ttry {\n\t\t// TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context\n\t\t// The Browser also has localStorage in the global context.\n\t\treturn localStorage;\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n}\n\nmodule.exports = __webpack_require__(/*! ./common */ "./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/common.js")(exports);\n\nconst {formatters} = module.exports;\n\n/**\n * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n */\n\nformatters.j = function (v) {\n\ttry {\n\t\treturn JSON.stringify(v);\n\t} catch (error) {\n\t\treturn \'[UnexpectedJSONParseError]: \' + error.message;\n\t}\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js?')},"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/common.js":
/*!*************************************************************************!*\
  !*** ./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/common.js ***!
  \*************************************************************************/function(module,__unused_webpack_exports,__webpack_require__){eval("\n/**\n * This is the common logic for both the Node.js and web browser\n * implementations of `debug()`.\n */\n\nfunction setup(env) {\n\tcreateDebug.debug = createDebug;\n\tcreateDebug.default = createDebug;\n\tcreateDebug.coerce = coerce;\n\tcreateDebug.disable = disable;\n\tcreateDebug.enable = enable;\n\tcreateDebug.enabled = enabled;\n\tcreateDebug.humanize = __webpack_require__(/*! ms */ \"./node_modules/.pnpm/ms@2.1.3/node_modules/ms/index.js\");\n\tcreateDebug.destroy = destroy;\n\n\tObject.keys(env).forEach(key => {\n\t\tcreateDebug[key] = env[key];\n\t});\n\n\t/**\n\t* The currently active debug mode names, and names to skip.\n\t*/\n\n\tcreateDebug.names = [];\n\tcreateDebug.skips = [];\n\n\t/**\n\t* Map of special \"%n\" handling functions, for the debug \"format\" argument.\n\t*\n\t* Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n\t*/\n\tcreateDebug.formatters = {};\n\n\t/**\n\t* Selects a color for a debug namespace\n\t* @param {String} namespace The namespace string for the debug instance to be colored\n\t* @return {Number|String} An ANSI color code for the given namespace\n\t* @api private\n\t*/\n\tfunction selectColor(namespace) {\n\t\tlet hash = 0;\n\n\t\tfor (let i = 0; i < namespace.length; i++) {\n\t\t\thash = ((hash << 5) - hash) + namespace.charCodeAt(i);\n\t\t\thash |= 0; // Convert to 32bit integer\n\t\t}\n\n\t\treturn createDebug.colors[Math.abs(hash) % createDebug.colors.length];\n\t}\n\tcreateDebug.selectColor = selectColor;\n\n\t/**\n\t* Create a debugger with the given `namespace`.\n\t*\n\t* @param {String} namespace\n\t* @return {Function}\n\t* @api public\n\t*/\n\tfunction createDebug(namespace) {\n\t\tlet prevTime;\n\t\tlet enableOverride = null;\n\t\tlet namespacesCache;\n\t\tlet enabledCache;\n\n\t\tfunction debug(...args) {\n\t\t\t// Disabled?\n\t\t\tif (!debug.enabled) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tconst self = debug;\n\n\t\t\t// Set `diff` timestamp\n\t\t\tconst curr = Number(new Date());\n\t\t\tconst ms = curr - (prevTime || curr);\n\t\t\tself.diff = ms;\n\t\t\tself.prev = prevTime;\n\t\t\tself.curr = curr;\n\t\t\tprevTime = curr;\n\n\t\t\targs[0] = createDebug.coerce(args[0]);\n\n\t\t\tif (typeof args[0] !== 'string') {\n\t\t\t\t// Anything else let's inspect with %O\n\t\t\t\targs.unshift('%O');\n\t\t\t}\n\n\t\t\t// Apply any `formatters` transformations\n\t\t\tlet index = 0;\n\t\t\targs[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {\n\t\t\t\t// If we encounter an escaped % then don't increase the array index\n\t\t\t\tif (match === '%%') {\n\t\t\t\t\treturn '%';\n\t\t\t\t}\n\t\t\t\tindex++;\n\t\t\t\tconst formatter = createDebug.formatters[format];\n\t\t\t\tif (typeof formatter === 'function') {\n\t\t\t\t\tconst val = args[index];\n\t\t\t\t\tmatch = formatter.call(self, val);\n\n\t\t\t\t\t// Now we need to remove `args[index]` since it's inlined in the `format`\n\t\t\t\t\targs.splice(index, 1);\n\t\t\t\t\tindex--;\n\t\t\t\t}\n\t\t\t\treturn match;\n\t\t\t});\n\n\t\t\t// Apply env-specific formatting (colors, etc.)\n\t\t\tcreateDebug.formatArgs.call(self, args);\n\n\t\t\tconst logFn = self.log || createDebug.log;\n\t\t\tlogFn.apply(self, args);\n\t\t}\n\n\t\tdebug.namespace = namespace;\n\t\tdebug.useColors = createDebug.useColors();\n\t\tdebug.color = createDebug.selectColor(namespace);\n\t\tdebug.extend = extend;\n\t\tdebug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.\n\n\t\tObject.defineProperty(debug, 'enabled', {\n\t\t\tenumerable: true,\n\t\t\tconfigurable: false,\n\t\t\tget: () => {\n\t\t\t\tif (enableOverride !== null) {\n\t\t\t\t\treturn enableOverride;\n\t\t\t\t}\n\t\t\t\tif (namespacesCache !== createDebug.namespaces) {\n\t\t\t\t\tnamespacesCache = createDebug.namespaces;\n\t\t\t\t\tenabledCache = createDebug.enabled(namespace);\n\t\t\t\t}\n\n\t\t\t\treturn enabledCache;\n\t\t\t},\n\t\t\tset: v => {\n\t\t\t\tenableOverride = v;\n\t\t\t}\n\t\t});\n\n\t\t// Env-specific initialization logic for debug instances\n\t\tif (typeof createDebug.init === 'function') {\n\t\t\tcreateDebug.init(debug);\n\t\t}\n\n\t\treturn debug;\n\t}\n\n\tfunction extend(namespace, delimiter) {\n\t\tconst newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);\n\t\tnewDebug.log = this.log;\n\t\treturn newDebug;\n\t}\n\n\t/**\n\t* Enables a debug mode by namespaces. This can include modes\n\t* separated by a colon and wildcards.\n\t*\n\t* @param {String} namespaces\n\t* @api public\n\t*/\n\tfunction enable(namespaces) {\n\t\tcreateDebug.save(namespaces);\n\t\tcreateDebug.namespaces = namespaces;\n\n\t\tcreateDebug.names = [];\n\t\tcreateDebug.skips = [];\n\n\t\tlet i;\n\t\tconst split = (typeof namespaces === 'string' ? namespaces : '').split(/[\\s,]+/);\n\t\tconst len = split.length;\n\n\t\tfor (i = 0; i < len; i++) {\n\t\t\tif (!split[i]) {\n\t\t\t\t// ignore empty strings\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tnamespaces = split[i].replace(/\\*/g, '.*?');\n\n\t\t\tif (namespaces[0] === '-') {\n\t\t\t\tcreateDebug.skips.push(new RegExp('^' + namespaces.slice(1) + '$'));\n\t\t\t} else {\n\t\t\t\tcreateDebug.names.push(new RegExp('^' + namespaces + '$'));\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t* Disable debug output.\n\t*\n\t* @return {String} namespaces\n\t* @api public\n\t*/\n\tfunction disable() {\n\t\tconst namespaces = [\n\t\t\t...createDebug.names.map(toNamespace),\n\t\t\t...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)\n\t\t].join(',');\n\t\tcreateDebug.enable('');\n\t\treturn namespaces;\n\t}\n\n\t/**\n\t* Returns true if the given mode name is enabled, false otherwise.\n\t*\n\t* @param {String} name\n\t* @return {Boolean}\n\t* @api public\n\t*/\n\tfunction enabled(name) {\n\t\tif (name[name.length - 1] === '*') {\n\t\t\treturn true;\n\t\t}\n\n\t\tlet i;\n\t\tlet len;\n\n\t\tfor (i = 0, len = createDebug.skips.length; i < len; i++) {\n\t\t\tif (createDebug.skips[i].test(name)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\tfor (i = 0, len = createDebug.names.length; i < len; i++) {\n\t\t\tif (createDebug.names[i].test(name)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\n\t\treturn false;\n\t}\n\n\t/**\n\t* Convert regexp to namespace\n\t*\n\t* @param {RegExp} regxep\n\t* @return {String} namespace\n\t* @api private\n\t*/\n\tfunction toNamespace(regexp) {\n\t\treturn regexp.toString()\n\t\t\t.substring(2, regexp.toString().length - 2)\n\t\t\t.replace(/\\.\\*\\?$/, '*');\n\t}\n\n\t/**\n\t* Coerce `val`.\n\t*\n\t* @param {Mixed} val\n\t* @return {Mixed}\n\t* @api private\n\t*/\n\tfunction coerce(val) {\n\t\tif (val instanceof Error) {\n\t\t\treturn val.stack || val.message;\n\t\t}\n\t\treturn val;\n\t}\n\n\t/**\n\t* XXX DO NOT USE. This is a temporary stub function.\n\t* XXX It WILL be removed in the next major release.\n\t*/\n\tfunction destroy() {\n\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t}\n\n\tcreateDebug.enable(createDebug.load());\n\n\treturn createDebug;\n}\n\nmodule.exports = setup;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/common.js?")},"./node_modules/.pnpm/file-type@16.5.4/node_modules/file-type/core.js":
/*!****************************************************************************!*\
  !*** ./node_modules/.pnpm/file-type@16.5.4/node_modules/file-type/core.js ***!
  \****************************************************************************/function(module,__unused_webpack_exports,__webpack_require__){"use strict";eval("/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ \"./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js\")[\"Buffer\"];\n\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst strtok3 = __webpack_require__(/*! strtok3/lib/core */ \"./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/core.js\");\nconst {\n\tstringToBytes,\n\ttarHeaderChecksumMatches,\n\tuint32SyncSafeToken\n} = __webpack_require__(/*! ./util */ \"./node_modules/.pnpm/file-type@16.5.4/node_modules/file-type/util.js\");\nconst supported = __webpack_require__(/*! ./supported */ \"./node_modules/.pnpm/file-type@16.5.4/node_modules/file-type/supported.js\");\n\nconst minimumBytes = 4100; // A fair amount of file-types are detectable within this range\n\nasync function fromStream(stream) {\n\tconst tokenizer = await strtok3.fromStream(stream);\n\ttry {\n\t\treturn await fromTokenizer(tokenizer);\n\t} finally {\n\t\tawait tokenizer.close();\n\t}\n}\n\nasync function fromBuffer(input) {\n\tif (!(input instanceof Uint8Array || input instanceof ArrayBuffer || Buffer.isBuffer(input))) {\n\t\tthrow new TypeError(`Expected the \\`input\\` argument to be of type \\`Uint8Array\\` or \\`Buffer\\` or \\`ArrayBuffer\\`, got \\`${typeof input}\\``);\n\t}\n\n\tconst buffer = input instanceof Buffer ? input : Buffer.from(input);\n\n\tif (!(buffer && buffer.length > 1)) {\n\t\treturn;\n\t}\n\n\tconst tokenizer = strtok3.fromBuffer(buffer);\n\treturn fromTokenizer(tokenizer);\n}\n\nfunction _check(buffer, headers, options) {\n\toptions = {\n\t\toffset: 0,\n\t\t...options\n\t};\n\n\tfor (const [index, header] of headers.entries()) {\n\t\t// If a bitmask is set\n\t\tif (options.mask) {\n\t\t\t// If header doesn't equal `buf` with bits masked off\n\t\t\tif (header !== (options.mask[index] & buffer[index + options.offset])) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t} else if (header !== buffer[index + options.offset]) {\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}\n\nasync function fromTokenizer(tokenizer) {\n\ttry {\n\t\treturn _fromTokenizer(tokenizer);\n\t} catch (error) {\n\t\tif (!(error instanceof strtok3.EndOfStreamError)) {\n\t\t\tthrow error;\n\t\t}\n\t}\n}\n\nasync function _fromTokenizer(tokenizer) {\n\tlet buffer = Buffer.alloc(minimumBytes);\n\tconst bytesRead = 12;\n\tconst check = (header, options) => _check(buffer, header, options);\n\tconst checkString = (header, options) => check(stringToBytes(header), options);\n\n\t// Keep reading until EOF if the file size is unknown.\n\tif (!tokenizer.fileInfo.size) {\n\t\ttokenizer.fileInfo.size = Number.MAX_SAFE_INTEGER;\n\t}\n\n\tawait tokenizer.peekBuffer(buffer, {length: bytesRead, mayBeLess: true});\n\n\t// -- 2-byte signatures --\n\n\tif (check([0x42, 0x4D])) {\n\t\treturn {\n\t\t\text: 'bmp',\n\t\t\tmime: 'image/bmp'\n\t\t};\n\t}\n\n\tif (check([0x0B, 0x77])) {\n\t\treturn {\n\t\t\text: 'ac3',\n\t\t\tmime: 'audio/vnd.dolby.dd-raw'\n\t\t};\n\t}\n\n\tif (check([0x78, 0x01])) {\n\t\treturn {\n\t\t\text: 'dmg',\n\t\t\tmime: 'application/x-apple-diskimage'\n\t\t};\n\t}\n\n\tif (check([0x4D, 0x5A])) {\n\t\treturn {\n\t\t\text: 'exe',\n\t\t\tmime: 'application/x-msdownload'\n\t\t};\n\t}\n\n\tif (check([0x25, 0x21])) {\n\t\tawait tokenizer.peekBuffer(buffer, {length: 24, mayBeLess: true});\n\n\t\tif (checkString('PS-Adobe-', {offset: 2}) &&\n\t\t\tcheckString(' EPSF-', {offset: 14})) {\n\t\t\treturn {\n\t\t\t\text: 'eps',\n\t\t\t\tmime: 'application/eps'\n\t\t\t};\n\t\t}\n\n\t\treturn {\n\t\t\text: 'ps',\n\t\t\tmime: 'application/postscript'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x1F, 0xA0]) ||\n\t\tcheck([0x1F, 0x9D])\n\t) {\n\t\treturn {\n\t\t\text: 'Z',\n\t\t\tmime: 'application/x-compress'\n\t\t};\n\t}\n\n\t// -- 3-byte signatures --\n\n\tif (check([0xFF, 0xD8, 0xFF])) {\n\t\treturn {\n\t\t\text: 'jpg',\n\t\t\tmime: 'image/jpeg'\n\t\t};\n\t}\n\n\tif (check([0x49, 0x49, 0xBC])) {\n\t\treturn {\n\t\t\text: 'jxr',\n\t\t\tmime: 'image/vnd.ms-photo'\n\t\t};\n\t}\n\n\tif (check([0x1F, 0x8B, 0x8])) {\n\t\treturn {\n\t\t\text: 'gz',\n\t\t\tmime: 'application/gzip'\n\t\t};\n\t}\n\n\tif (check([0x42, 0x5A, 0x68])) {\n\t\treturn {\n\t\t\text: 'bz2',\n\t\t\tmime: 'application/x-bzip2'\n\t\t};\n\t}\n\n\tif (checkString('ID3')) {\n\t\tawait tokenizer.ignore(6); // Skip ID3 header until the header size\n\t\tconst id3HeaderLen = await tokenizer.readToken(uint32SyncSafeToken);\n\t\tif (tokenizer.position + id3HeaderLen > tokenizer.fileInfo.size) {\n\t\t\t// Guess file type based on ID3 header for backward compatibility\n\t\t\treturn {\n\t\t\t\text: 'mp3',\n\t\t\t\tmime: 'audio/mpeg'\n\t\t\t};\n\t\t}\n\n\t\tawait tokenizer.ignore(id3HeaderLen);\n\t\treturn fromTokenizer(tokenizer); // Skip ID3 header, recursion\n\t}\n\n\t// Musepack, SV7\n\tif (checkString('MP+')) {\n\t\treturn {\n\t\t\text: 'mpc',\n\t\t\tmime: 'audio/x-musepack'\n\t\t};\n\t}\n\n\tif (\n\t\t(buffer[0] === 0x43 || buffer[0] === 0x46) &&\n\t\tcheck([0x57, 0x53], {offset: 1})\n\t) {\n\t\treturn {\n\t\t\text: 'swf',\n\t\t\tmime: 'application/x-shockwave-flash'\n\t\t};\n\t}\n\n\t// -- 4-byte signatures --\n\n\tif (check([0x47, 0x49, 0x46])) {\n\t\treturn {\n\t\t\text: 'gif',\n\t\t\tmime: 'image/gif'\n\t\t};\n\t}\n\n\tif (checkString('FLIF')) {\n\t\treturn {\n\t\t\text: 'flif',\n\t\t\tmime: 'image/flif'\n\t\t};\n\t}\n\n\tif (checkString('8BPS')) {\n\t\treturn {\n\t\t\text: 'psd',\n\t\t\tmime: 'image/vnd.adobe.photoshop'\n\t\t};\n\t}\n\n\tif (checkString('WEBP', {offset: 8})) {\n\t\treturn {\n\t\t\text: 'webp',\n\t\t\tmime: 'image/webp'\n\t\t};\n\t}\n\n\t// Musepack, SV8\n\tif (checkString('MPCK')) {\n\t\treturn {\n\t\t\text: 'mpc',\n\t\t\tmime: 'audio/x-musepack'\n\t\t};\n\t}\n\n\tif (checkString('FORM')) {\n\t\treturn {\n\t\t\text: 'aif',\n\t\t\tmime: 'audio/aiff'\n\t\t};\n\t}\n\n\tif (checkString('icns', {offset: 0})) {\n\t\treturn {\n\t\t\text: 'icns',\n\t\t\tmime: 'image/icns'\n\t\t};\n\t}\n\n\t// Zip-based file formats\n\t// Need to be before the `zip` check\n\tif (check([0x50, 0x4B, 0x3, 0x4])) { // Local file header signature\n\t\ttry {\n\t\t\twhile (tokenizer.position + 30 < tokenizer.fileInfo.size) {\n\t\t\t\tawait tokenizer.readBuffer(buffer, {length: 30});\n\n\t\t\t\t// https://en.wikipedia.org/wiki/Zip_(file_format)#File_headers\n\t\t\t\tconst zipHeader = {\n\t\t\t\t\tcompressedSize: buffer.readUInt32LE(18),\n\t\t\t\t\tuncompressedSize: buffer.readUInt32LE(22),\n\t\t\t\t\tfilenameLength: buffer.readUInt16LE(26),\n\t\t\t\t\textraFieldLength: buffer.readUInt16LE(28)\n\t\t\t\t};\n\n\t\t\t\tzipHeader.filename = await tokenizer.readToken(new Token.StringType(zipHeader.filenameLength, 'utf-8'));\n\t\t\t\tawait tokenizer.ignore(zipHeader.extraFieldLength);\n\n\t\t\t\t// Assumes signed `.xpi` from addons.mozilla.org\n\t\t\t\tif (zipHeader.filename === 'META-INF/mozilla.rsa') {\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'xpi',\n\t\t\t\t\t\tmime: 'application/x-xpinstall'\n\t\t\t\t\t};\n\t\t\t\t}\n\n\t\t\t\tif (zipHeader.filename.endsWith('.rels') || zipHeader.filename.endsWith('.xml')) {\n\t\t\t\t\tconst type = zipHeader.filename.split('/')[0];\n\t\t\t\t\tswitch (type) {\n\t\t\t\t\t\tcase '_rels':\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tcase 'word':\n\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\text: 'docx',\n\t\t\t\t\t\t\t\tmime: 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'\n\t\t\t\t\t\t\t};\n\t\t\t\t\t\tcase 'ppt':\n\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\text: 'pptx',\n\t\t\t\t\t\t\t\tmime: 'application/vnd.openxmlformats-officedocument.presentationml.presentation'\n\t\t\t\t\t\t\t};\n\t\t\t\t\t\tcase 'xl':\n\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\text: 'xlsx',\n\t\t\t\t\t\t\t\tmime: 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n\t\t\t\t\t\t\t};\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif (zipHeader.filename.startsWith('xl/')) {\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'xlsx',\n\t\t\t\t\t\tmime: 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n\t\t\t\t\t};\n\t\t\t\t}\n\n\t\t\t\tif (zipHeader.filename.startsWith('3D/') && zipHeader.filename.endsWith('.model')) {\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: '3mf',\n\t\t\t\t\t\tmime: 'model/3mf'\n\t\t\t\t\t};\n\t\t\t\t}\n\n\t\t\t\t// The docx, xlsx and pptx file types extend the Office Open XML file format:\n\t\t\t\t// https://en.wikipedia.org/wiki/Office_Open_XML_file_formats\n\t\t\t\t// We look for:\n\t\t\t\t// - one entry named '[Content_Types].xml' or '_rels/.rels',\n\t\t\t\t// - one entry indicating specific type of file.\n\t\t\t\t// MS Office, OpenOffice and LibreOffice may put the parts in different order, so the check should not rely on it.\n\t\t\t\tif (zipHeader.filename === 'mimetype' && zipHeader.compressedSize === zipHeader.uncompressedSize) {\n\t\t\t\t\tconst mimeType = await tokenizer.readToken(new Token.StringType(zipHeader.compressedSize, 'utf-8'));\n\n\t\t\t\t\tswitch (mimeType) {\n\t\t\t\t\t\tcase 'application/epub+zip':\n\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\text: 'epub',\n\t\t\t\t\t\t\t\tmime: 'application/epub+zip'\n\t\t\t\t\t\t\t};\n\t\t\t\t\t\tcase 'application/vnd.oasis.opendocument.text':\n\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\text: 'odt',\n\t\t\t\t\t\t\t\tmime: 'application/vnd.oasis.opendocument.text'\n\t\t\t\t\t\t\t};\n\t\t\t\t\t\tcase 'application/vnd.oasis.opendocument.spreadsheet':\n\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\text: 'ods',\n\t\t\t\t\t\t\t\tmime: 'application/vnd.oasis.opendocument.spreadsheet'\n\t\t\t\t\t\t\t};\n\t\t\t\t\t\tcase 'application/vnd.oasis.opendocument.presentation':\n\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\text: 'odp',\n\t\t\t\t\t\t\t\tmime: 'application/vnd.oasis.opendocument.presentation'\n\t\t\t\t\t\t\t};\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// Try to find next header manually when current one is corrupted\n\t\t\t\tif (zipHeader.compressedSize === 0) {\n\t\t\t\t\tlet nextHeaderIndex = -1;\n\n\t\t\t\t\twhile (nextHeaderIndex < 0 && (tokenizer.position < tokenizer.fileInfo.size)) {\n\t\t\t\t\t\tawait tokenizer.peekBuffer(buffer, {mayBeLess: true});\n\n\t\t\t\t\t\tnextHeaderIndex = buffer.indexOf('504B0304', 0, 'hex');\n\t\t\t\t\t\t// Move position to the next header if found, skip the whole buffer otherwise\n\t\t\t\t\t\tawait tokenizer.ignore(nextHeaderIndex >= 0 ? nextHeaderIndex : buffer.length);\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tawait tokenizer.ignore(zipHeader.compressedSize);\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (error) {\n\t\t\tif (!(error instanceof strtok3.EndOfStreamError)) {\n\t\t\t\tthrow error;\n\t\t\t}\n\t\t}\n\n\t\treturn {\n\t\t\text: 'zip',\n\t\t\tmime: 'application/zip'\n\t\t};\n\t}\n\n\tif (checkString('OggS')) {\n\t\t// This is an OGG container\n\t\tawait tokenizer.ignore(28);\n\t\tconst type = Buffer.alloc(8);\n\t\tawait tokenizer.readBuffer(type);\n\n\t\t// Needs to be before `ogg` check\n\t\tif (_check(type, [0x4F, 0x70, 0x75, 0x73, 0x48, 0x65, 0x61, 0x64])) {\n\t\t\treturn {\n\t\t\t\text: 'opus',\n\t\t\t\tmime: 'audio/opus'\n\t\t\t};\n\t\t}\n\n\t\t// If ' theora' in header.\n\t\tif (_check(type, [0x80, 0x74, 0x68, 0x65, 0x6F, 0x72, 0x61])) {\n\t\t\treturn {\n\t\t\t\text: 'ogv',\n\t\t\t\tmime: 'video/ogg'\n\t\t\t};\n\t\t}\n\n\t\t// If '\\x01video' in header.\n\t\tif (_check(type, [0x01, 0x76, 0x69, 0x64, 0x65, 0x6F, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'ogm',\n\t\t\t\tmime: 'video/ogg'\n\t\t\t};\n\t\t}\n\n\t\t// If ' FLAC' in header  https://xiph.org/flac/faq.html\n\t\tif (_check(type, [0x7F, 0x46, 0x4C, 0x41, 0x43])) {\n\t\t\treturn {\n\t\t\t\text: 'oga',\n\t\t\t\tmime: 'audio/ogg'\n\t\t\t};\n\t\t}\n\n\t\t// 'Speex  ' in header https://en.wikipedia.org/wiki/Speex\n\t\tif (_check(type, [0x53, 0x70, 0x65, 0x65, 0x78, 0x20, 0x20])) {\n\t\t\treturn {\n\t\t\t\text: 'spx',\n\t\t\t\tmime: 'audio/ogg'\n\t\t\t};\n\t\t}\n\n\t\t// If '\\x01vorbis' in header\n\t\tif (_check(type, [0x01, 0x76, 0x6F, 0x72, 0x62, 0x69, 0x73])) {\n\t\t\treturn {\n\t\t\t\text: 'ogg',\n\t\t\t\tmime: 'audio/ogg'\n\t\t\t};\n\t\t}\n\n\t\t// Default OGG container https://www.iana.org/assignments/media-types/application/ogg\n\t\treturn {\n\t\t\text: 'ogx',\n\t\t\tmime: 'application/ogg'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x50, 0x4B]) &&\n\t\t(buffer[2] === 0x3 || buffer[2] === 0x5 || buffer[2] === 0x7) &&\n\t\t(buffer[3] === 0x4 || buffer[3] === 0x6 || buffer[3] === 0x8)\n\t) {\n\t\treturn {\n\t\t\text: 'zip',\n\t\t\tmime: 'application/zip'\n\t\t};\n\t}\n\n\t//\n\n\t// File Type Box (https://en.wikipedia.org/wiki/ISO_base_media_file_format)\n\t// It's not required to be first, but it's recommended to be. Almost all ISO base media files start with `ftyp` box.\n\t// `ftyp` box must contain a brand major identifier, which must consist of ISO 8859-1 printable characters.\n\t// Here we check for 8859-1 printable characters (for simplicity, it's a mask which also catches one non-printable character).\n\tif (\n\t\tcheckString('ftyp', {offset: 4}) &&\n\t\t(buffer[8] & 0x60) !== 0x00 // Brand major, first character ASCII?\n\t) {\n\t\t// They all can have MIME `video/mp4` except `application/mp4` special-case which is hard to detect.\n\t\t// For some cases, we're specific, everything else falls to `video/mp4` with `mp4` extension.\n\t\tconst brandMajor = buffer.toString('binary', 8, 12).replace('\\0', ' ').trim();\n\t\tswitch (brandMajor) {\n\t\t\tcase 'avif':\n\t\t\t\treturn {ext: 'avif', mime: 'image/avif'};\n\t\t\tcase 'mif1':\n\t\t\t\treturn {ext: 'heic', mime: 'image/heif'};\n\t\t\tcase 'msf1':\n\t\t\t\treturn {ext: 'heic', mime: 'image/heif-sequence'};\n\t\t\tcase 'heic':\n\t\t\tcase 'heix':\n\t\t\t\treturn {ext: 'heic', mime: 'image/heic'};\n\t\t\tcase 'hevc':\n\t\t\tcase 'hevx':\n\t\t\t\treturn {ext: 'heic', mime: 'image/heic-sequence'};\n\t\t\tcase 'qt':\n\t\t\t\treturn {ext: 'mov', mime: 'video/quicktime'};\n\t\t\tcase 'M4V':\n\t\t\tcase 'M4VH':\n\t\t\tcase 'M4VP':\n\t\t\t\treturn {ext: 'm4v', mime: 'video/x-m4v'};\n\t\t\tcase 'M4P':\n\t\t\t\treturn {ext: 'm4p', mime: 'video/mp4'};\n\t\t\tcase 'M4B':\n\t\t\t\treturn {ext: 'm4b', mime: 'audio/mp4'};\n\t\t\tcase 'M4A':\n\t\t\t\treturn {ext: 'm4a', mime: 'audio/x-m4a'};\n\t\t\tcase 'F4V':\n\t\t\t\treturn {ext: 'f4v', mime: 'video/mp4'};\n\t\t\tcase 'F4P':\n\t\t\t\treturn {ext: 'f4p', mime: 'video/mp4'};\n\t\t\tcase 'F4A':\n\t\t\t\treturn {ext: 'f4a', mime: 'audio/mp4'};\n\t\t\tcase 'F4B':\n\t\t\t\treturn {ext: 'f4b', mime: 'audio/mp4'};\n\t\t\tcase 'crx':\n\t\t\t\treturn {ext: 'cr3', mime: 'image/x-canon-cr3'};\n\t\t\tdefault:\n\t\t\t\tif (brandMajor.startsWith('3g')) {\n\t\t\t\t\tif (brandMajor.startsWith('3g2')) {\n\t\t\t\t\t\treturn {ext: '3g2', mime: 'video/3gpp2'};\n\t\t\t\t\t}\n\n\t\t\t\t\treturn {ext: '3gp', mime: 'video/3gpp'};\n\t\t\t\t}\n\n\t\t\t\treturn {ext: 'mp4', mime: 'video/mp4'};\n\t\t}\n\t}\n\n\tif (checkString('MThd')) {\n\t\treturn {\n\t\t\text: 'mid',\n\t\t\tmime: 'audio/midi'\n\t\t};\n\t}\n\n\tif (\n\t\tcheckString('wOFF') &&\n\t\t(\n\t\t\tcheck([0x00, 0x01, 0x00, 0x00], {offset: 4}) ||\n\t\t\tcheckString('OTTO', {offset: 4})\n\t\t)\n\t) {\n\t\treturn {\n\t\t\text: 'woff',\n\t\t\tmime: 'font/woff'\n\t\t};\n\t}\n\n\tif (\n\t\tcheckString('wOF2') &&\n\t\t(\n\t\t\tcheck([0x00, 0x01, 0x00, 0x00], {offset: 4}) ||\n\t\t\tcheckString('OTTO', {offset: 4})\n\t\t)\n\t) {\n\t\treturn {\n\t\t\text: 'woff2',\n\t\t\tmime: 'font/woff2'\n\t\t};\n\t}\n\n\tif (check([0xD4, 0xC3, 0xB2, 0xA1]) || check([0xA1, 0xB2, 0xC3, 0xD4])) {\n\t\treturn {\n\t\t\text: 'pcap',\n\t\t\tmime: 'application/vnd.tcpdump.pcap'\n\t\t};\n\t}\n\n\t// Sony DSD Stream File (DSF)\n\tif (checkString('DSD ')) {\n\t\treturn {\n\t\t\text: 'dsf',\n\t\t\tmime: 'audio/x-dsf' // Non-standard\n\t\t};\n\t}\n\n\tif (checkString('LZIP')) {\n\t\treturn {\n\t\t\text: 'lz',\n\t\t\tmime: 'application/x-lzip'\n\t\t};\n\t}\n\n\tif (checkString('fLaC')) {\n\t\treturn {\n\t\t\text: 'flac',\n\t\t\tmime: 'audio/x-flac'\n\t\t};\n\t}\n\n\tif (check([0x42, 0x50, 0x47, 0xFB])) {\n\t\treturn {\n\t\t\text: 'bpg',\n\t\t\tmime: 'image/bpg'\n\t\t};\n\t}\n\n\tif (checkString('wvpk')) {\n\t\treturn {\n\t\t\text: 'wv',\n\t\t\tmime: 'audio/wavpack'\n\t\t};\n\t}\n\n\tif (checkString('%PDF')) {\n\t\tawait tokenizer.ignore(1350);\n\t\tconst maxBufferSize = 10 * 1024 * 1024;\n\t\tconst buffer = Buffer.alloc(Math.min(maxBufferSize, tokenizer.fileInfo.size));\n\t\tawait tokenizer.readBuffer(buffer, {mayBeLess: true});\n\n\t\t// Check if this is an Adobe Illustrator file\n\t\tif (buffer.includes(Buffer.from('AIPrivateData'))) {\n\t\t\treturn {\n\t\t\t\text: 'ai',\n\t\t\t\tmime: 'application/postscript'\n\t\t\t};\n\t\t}\n\n\t\t// Assume this is just a normal PDF\n\t\treturn {\n\t\t\text: 'pdf',\n\t\t\tmime: 'application/pdf'\n\t\t};\n\t}\n\n\tif (check([0x00, 0x61, 0x73, 0x6D])) {\n\t\treturn {\n\t\t\text: 'wasm',\n\t\t\tmime: 'application/wasm'\n\t\t};\n\t}\n\n\t// TIFF, little-endian type\n\tif (check([0x49, 0x49, 0x2A, 0x0])) {\n\t\tif (checkString('CR', {offset: 8})) {\n\t\t\treturn {\n\t\t\t\text: 'cr2',\n\t\t\t\tmime: 'image/x-canon-cr2'\n\t\t\t};\n\t\t}\n\n\t\tif (check([0x1C, 0x00, 0xFE, 0x00], {offset: 8}) || check([0x1F, 0x00, 0x0B, 0x00], {offset: 8})) {\n\t\t\treturn {\n\t\t\t\text: 'nef',\n\t\t\t\tmime: 'image/x-nikon-nef'\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tcheck([0x08, 0x00, 0x00, 0x00], {offset: 4}) &&\n\t\t\t(check([0x2D, 0x00, 0xFE, 0x00], {offset: 8}) ||\n\t\t\t\tcheck([0x27, 0x00, 0xFE, 0x00], {offset: 8}))\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'dng',\n\t\t\t\tmime: 'image/x-adobe-dng'\n\t\t\t};\n\t\t}\n\n\t\tbuffer = Buffer.alloc(24);\n\t\tawait tokenizer.peekBuffer(buffer);\n\t\tif (\n\t\t\t(check([0x10, 0xFB, 0x86, 0x01], {offset: 4}) || check([0x08, 0x00, 0x00, 0x00], {offset: 4})) &&\n\t\t\t// This pattern differentiates ARW from other TIFF-ish file types:\n\t\t\tcheck([0x00, 0xFE, 0x00, 0x04, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x03, 0x01], {offset: 9})\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'arw',\n\t\t\t\tmime: 'image/x-sony-arw'\n\t\t\t};\n\t\t}\n\n\t\treturn {\n\t\t\text: 'tif',\n\t\t\tmime: 'image/tiff'\n\t\t};\n\t}\n\n\t// TIFF, big-endian type\n\tif (check([0x4D, 0x4D, 0x0, 0x2A])) {\n\t\treturn {\n\t\t\text: 'tif',\n\t\t\tmime: 'image/tiff'\n\t\t};\n\t}\n\n\tif (checkString('MAC ')) {\n\t\treturn {\n\t\t\text: 'ape',\n\t\t\tmime: 'audio/ape'\n\t\t};\n\t}\n\n\t// https://github.com/threatstack/libmagic/blob/master/magic/Magdir/matroska\n\tif (check([0x1A, 0x45, 0xDF, 0xA3])) { // Root element: EBML\n\t\tasync function readField() {\n\t\t\tconst msb = await tokenizer.peekNumber(Token.UINT8);\n\t\t\tlet mask = 0x80;\n\t\t\tlet ic = 0; // 0 = A, 1 = B, 2 = C, 3 = D\n\n\t\t\twhile ((msb & mask) === 0 && mask !== 0) {\n\t\t\t\t++ic;\n\t\t\t\tmask >>= 1;\n\t\t\t}\n\n\t\t\tconst id = Buffer.alloc(ic + 1);\n\t\t\tawait tokenizer.readBuffer(id);\n\t\t\treturn id;\n\t\t}\n\n\t\tasync function readElement() {\n\t\t\tconst id = await readField();\n\t\t\tconst lenField = await readField();\n\t\t\tlenField[0] ^= 0x80 >> (lenField.length - 1);\n\t\t\tconst nrLen = Math.min(6, lenField.length); // JavaScript can max read 6 bytes integer\n\t\t\treturn {\n\t\t\t\tid: id.readUIntBE(0, id.length),\n\t\t\t\tlen: lenField.readUIntBE(lenField.length - nrLen, nrLen)\n\t\t\t};\n\t\t}\n\n\t\tasync function readChildren(level, children) {\n\t\t\twhile (children > 0) {\n\t\t\t\tconst e = await readElement();\n\t\t\t\tif (e.id === 0x4282) {\n\t\t\t\t\treturn tokenizer.readToken(new Token.StringType(e.len, 'utf-8')); // Return DocType\n\t\t\t\t}\n\n\t\t\t\tawait tokenizer.ignore(e.len); // ignore payload\n\t\t\t\t--children;\n\t\t\t}\n\t\t}\n\n\t\tconst re = await readElement();\n\t\tconst docType = await readChildren(1, re.len);\n\n\t\tswitch (docType) {\n\t\t\tcase 'webm':\n\t\t\t\treturn {\n\t\t\t\t\text: 'webm',\n\t\t\t\t\tmime: 'video/webm'\n\t\t\t\t};\n\n\t\t\tcase 'matroska':\n\t\t\t\treturn {\n\t\t\t\t\text: 'mkv',\n\t\t\t\t\tmime: 'video/x-matroska'\n\t\t\t\t};\n\n\t\t\tdefault:\n\t\t\t\treturn;\n\t\t}\n\t}\n\n\t// RIFF file format which might be AVI, WAV, QCP, etc\n\tif (check([0x52, 0x49, 0x46, 0x46])) {\n\t\tif (check([0x41, 0x56, 0x49], {offset: 8})) {\n\t\t\treturn {\n\t\t\t\text: 'avi',\n\t\t\t\tmime: 'video/vnd.avi'\n\t\t\t};\n\t\t}\n\n\t\tif (check([0x57, 0x41, 0x56, 0x45], {offset: 8})) {\n\t\t\treturn {\n\t\t\t\text: 'wav',\n\t\t\t\tmime: 'audio/vnd.wave'\n\t\t\t};\n\t\t}\n\n\t\t// QLCM, QCP file\n\t\tif (check([0x51, 0x4C, 0x43, 0x4D], {offset: 8})) {\n\t\t\treturn {\n\t\t\t\text: 'qcp',\n\t\t\t\tmime: 'audio/qcelp'\n\t\t\t};\n\t\t}\n\t}\n\n\tif (checkString('SQLi')) {\n\t\treturn {\n\t\t\text: 'sqlite',\n\t\t\tmime: 'application/x-sqlite3'\n\t\t};\n\t}\n\n\tif (check([0x4E, 0x45, 0x53, 0x1A])) {\n\t\treturn {\n\t\t\text: 'nes',\n\t\t\tmime: 'application/x-nintendo-nes-rom'\n\t\t};\n\t}\n\n\tif (checkString('Cr24')) {\n\t\treturn {\n\t\t\text: 'crx',\n\t\t\tmime: 'application/x-google-chrome-extension'\n\t\t};\n\t}\n\n\tif (\n\t\tcheckString('MSCF') ||\n\t\tcheckString('ISc(')\n\t) {\n\t\treturn {\n\t\t\text: 'cab',\n\t\t\tmime: 'application/vnd.ms-cab-compressed'\n\t\t};\n\t}\n\n\tif (check([0xED, 0xAB, 0xEE, 0xDB])) {\n\t\treturn {\n\t\t\text: 'rpm',\n\t\t\tmime: 'application/x-rpm'\n\t\t};\n\t}\n\n\tif (check([0xC5, 0xD0, 0xD3, 0xC6])) {\n\t\treturn {\n\t\t\text: 'eps',\n\t\t\tmime: 'application/eps'\n\t\t};\n\t}\n\n\tif (check([0x28, 0xB5, 0x2F, 0xFD])) {\n\t\treturn {\n\t\t\text: 'zst',\n\t\t\tmime: 'application/zstd'\n\t\t};\n\t}\n\n\t// -- 5-byte signatures --\n\n\tif (check([0x4F, 0x54, 0x54, 0x4F, 0x00])) {\n\t\treturn {\n\t\t\text: 'otf',\n\t\t\tmime: 'font/otf'\n\t\t};\n\t}\n\n\tif (checkString('#!AMR')) {\n\t\treturn {\n\t\t\text: 'amr',\n\t\t\tmime: 'audio/amr'\n\t\t};\n\t}\n\n\tif (checkString('{\\\\rtf')) {\n\t\treturn {\n\t\t\text: 'rtf',\n\t\t\tmime: 'application/rtf'\n\t\t};\n\t}\n\n\tif (check([0x46, 0x4C, 0x56, 0x01])) {\n\t\treturn {\n\t\t\text: 'flv',\n\t\t\tmime: 'video/x-flv'\n\t\t};\n\t}\n\n\tif (checkString('IMPM')) {\n\t\treturn {\n\t\t\text: 'it',\n\t\t\tmime: 'audio/x-it'\n\t\t};\n\t}\n\n\tif (\n\t\tcheckString('-lh0-', {offset: 2}) ||\n\t\tcheckString('-lh1-', {offset: 2}) ||\n\t\tcheckString('-lh2-', {offset: 2}) ||\n\t\tcheckString('-lh3-', {offset: 2}) ||\n\t\tcheckString('-lh4-', {offset: 2}) ||\n\t\tcheckString('-lh5-', {offset: 2}) ||\n\t\tcheckString('-lh6-', {offset: 2}) ||\n\t\tcheckString('-lh7-', {offset: 2}) ||\n\t\tcheckString('-lzs-', {offset: 2}) ||\n\t\tcheckString('-lz4-', {offset: 2}) ||\n\t\tcheckString('-lz5-', {offset: 2}) ||\n\t\tcheckString('-lhd-', {offset: 2})\n\t) {\n\t\treturn {\n\t\t\text: 'lzh',\n\t\t\tmime: 'application/x-lzh-compressed'\n\t\t};\n\t}\n\n\t// MPEG program stream (PS or MPEG-PS)\n\tif (check([0x00, 0x00, 0x01, 0xBA])) {\n\t\t//  MPEG-PS, MPEG-1 Part 1\n\t\tif (check([0x21], {offset: 4, mask: [0xF1]})) {\n\t\t\treturn {\n\t\t\t\text: 'mpg', // May also be .ps, .mpeg\n\t\t\t\tmime: 'video/MP1S'\n\t\t\t};\n\t\t}\n\n\t\t// MPEG-PS, MPEG-2 Part 1\n\t\tif (check([0x44], {offset: 4, mask: [0xC4]})) {\n\t\t\treturn {\n\t\t\t\text: 'mpg', // May also be .mpg, .m2p, .vob or .sub\n\t\t\t\tmime: 'video/MP2P'\n\t\t\t};\n\t\t}\n\t}\n\n\tif (checkString('ITSF')) {\n\t\treturn {\n\t\t\text: 'chm',\n\t\t\tmime: 'application/vnd.ms-htmlhelp'\n\t\t};\n\t}\n\n\t// -- 6-byte signatures --\n\n\tif (check([0xFD, 0x37, 0x7A, 0x58, 0x5A, 0x00])) {\n\t\treturn {\n\t\t\text: 'xz',\n\t\t\tmime: 'application/x-xz'\n\t\t};\n\t}\n\n\tif (checkString('<?xml ')) {\n\t\treturn {\n\t\t\text: 'xml',\n\t\t\tmime: 'application/xml'\n\t\t};\n\t}\n\n\tif (check([0x37, 0x7A, 0xBC, 0xAF, 0x27, 0x1C])) {\n\t\treturn {\n\t\t\text: '7z',\n\t\t\tmime: 'application/x-7z-compressed'\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x52, 0x61, 0x72, 0x21, 0x1A, 0x7]) &&\n\t\t(buffer[6] === 0x0 || buffer[6] === 0x1)\n\t) {\n\t\treturn {\n\t\t\text: 'rar',\n\t\t\tmime: 'application/x-rar-compressed'\n\t\t};\n\t}\n\n\tif (checkString('solid ')) {\n\t\treturn {\n\t\t\text: 'stl',\n\t\t\tmime: 'model/stl'\n\t\t};\n\t}\n\n\t// -- 7-byte signatures --\n\n\tif (checkString('BLENDER')) {\n\t\treturn {\n\t\t\text: 'blend',\n\t\t\tmime: 'application/x-blender'\n\t\t};\n\t}\n\n\tif (checkString('!<arch>')) {\n\t\tawait tokenizer.ignore(8);\n\t\tconst str = await tokenizer.readToken(new Token.StringType(13, 'ascii'));\n\t\tif (str === 'debian-binary') {\n\t\t\treturn {\n\t\t\t\text: 'deb',\n\t\t\t\tmime: 'application/x-deb'\n\t\t\t};\n\t\t}\n\n\t\treturn {\n\t\t\text: 'ar',\n\t\t\tmime: 'application/x-unix-archive'\n\t\t};\n\t}\n\n\t// -- 8-byte signatures --\n\n\tif (check([0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A])) {\n\t\t// APNG format (https://wiki.mozilla.org/APNG_Specification)\n\t\t// 1. Find the first IDAT (image data) chunk (49 44 41 54)\n\t\t// 2. Check if there is an \"acTL\" chunk before the IDAT one (61 63 54 4C)\n\n\t\t// Offset calculated as follows:\n\t\t// - 8 bytes: PNG signature\n\t\t// - 4 (length) + 4 (chunk type) + 13 (chunk data) + 4 (CRC): IHDR chunk\n\n\t\tawait tokenizer.ignore(8); // ignore PNG signature\n\n\t\tasync function readChunkHeader() {\n\t\t\treturn {\n\t\t\t\tlength: await tokenizer.readToken(Token.INT32_BE),\n\t\t\t\ttype: await tokenizer.readToken(new Token.StringType(4, 'binary'))\n\t\t\t};\n\t\t}\n\n\t\tdo {\n\t\t\tconst chunk = await readChunkHeader();\n\t\t\tif (chunk.length < 0) {\n\t\t\t\treturn; // Invalid chunk length\n\t\t\t}\n\n\t\t\tswitch (chunk.type) {\n\t\t\t\tcase 'IDAT':\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'png',\n\t\t\t\t\t\tmime: 'image/png'\n\t\t\t\t\t};\n\t\t\t\tcase 'acTL':\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'apng',\n\t\t\t\t\t\tmime: 'image/apng'\n\t\t\t\t\t};\n\t\t\t\tdefault:\n\t\t\t\t\tawait tokenizer.ignore(chunk.length + 4); // Ignore chunk-data + CRC\n\t\t\t}\n\t\t} while (tokenizer.position + 8 < tokenizer.fileInfo.size);\n\n\t\treturn {\n\t\t\text: 'png',\n\t\t\tmime: 'image/png'\n\t\t};\n\t}\n\n\tif (check([0x41, 0x52, 0x52, 0x4F, 0x57, 0x31, 0x00, 0x00])) {\n\t\treturn {\n\t\t\text: 'arrow',\n\t\t\tmime: 'application/x-apache-arrow'\n\t\t};\n\t}\n\n\tif (check([0x67, 0x6C, 0x54, 0x46, 0x02, 0x00, 0x00, 0x00])) {\n\t\treturn {\n\t\t\text: 'glb',\n\t\t\tmime: 'model/gltf-binary'\n\t\t};\n\t}\n\n\t// `mov` format variants\n\tif (\n\t\tcheck([0x66, 0x72, 0x65, 0x65], {offset: 4}) || // `free`\n\t\tcheck([0x6D, 0x64, 0x61, 0x74], {offset: 4}) || // `mdat` MJPEG\n\t\tcheck([0x6D, 0x6F, 0x6F, 0x76], {offset: 4}) || // `moov`\n\t\tcheck([0x77, 0x69, 0x64, 0x65], {offset: 4}) // `wide`\n\t) {\n\t\treturn {\n\t\t\text: 'mov',\n\t\t\tmime: 'video/quicktime'\n\t\t};\n\t}\n\n\t// -- 9-byte signatures --\n\n\tif (check([0x49, 0x49, 0x52, 0x4F, 0x08, 0x00, 0x00, 0x00, 0x18])) {\n\t\treturn {\n\t\t\text: 'orf',\n\t\t\tmime: 'image/x-olympus-orf'\n\t\t};\n\t}\n\n\tif (checkString('gimp xcf ')) {\n\t\treturn {\n\t\t\text: 'xcf',\n\t\t\tmime: 'image/x-xcf'\n\t\t};\n\t}\n\n\t// -- 12-byte signatures --\n\n\tif (check([0x49, 0x49, 0x55, 0x00, 0x18, 0x00, 0x00, 0x00, 0x88, 0xE7, 0x74, 0xD8])) {\n\t\treturn {\n\t\t\text: 'rw2',\n\t\t\tmime: 'image/x-panasonic-rw2'\n\t\t};\n\t}\n\n\t// ASF_Header_Object first 80 bytes\n\tif (check([0x30, 0x26, 0xB2, 0x75, 0x8E, 0x66, 0xCF, 0x11, 0xA6, 0xD9])) {\n\t\tasync function readHeader() {\n\t\t\tconst guid = Buffer.alloc(16);\n\t\t\tawait tokenizer.readBuffer(guid);\n\t\t\treturn {\n\t\t\t\tid: guid,\n\t\t\t\tsize: Number(await tokenizer.readToken(Token.UINT64_LE))\n\t\t\t};\n\t\t}\n\n\t\tawait tokenizer.ignore(30);\n\t\t// Search for header should be in first 1KB of file.\n\t\twhile (tokenizer.position + 24 < tokenizer.fileInfo.size) {\n\t\t\tconst header = await readHeader();\n\t\t\tlet payload = header.size - 24;\n\t\t\tif (_check(header.id, [0x91, 0x07, 0xDC, 0xB7, 0xB7, 0xA9, 0xCF, 0x11, 0x8E, 0xE6, 0x00, 0xC0, 0x0C, 0x20, 0x53, 0x65])) {\n\t\t\t\t// Sync on Stream-Properties-Object (B7DC0791-A9B7-11CF-8EE6-00C00C205365)\n\t\t\t\tconst typeId = Buffer.alloc(16);\n\t\t\t\tpayload -= await tokenizer.readBuffer(typeId);\n\n\t\t\t\tif (_check(typeId, [0x40, 0x9E, 0x69, 0xF8, 0x4D, 0x5B, 0xCF, 0x11, 0xA8, 0xFD, 0x00, 0x80, 0x5F, 0x5C, 0x44, 0x2B])) {\n\t\t\t\t\t// Found audio:\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'asf',\n\t\t\t\t\t\tmime: 'audio/x-ms-asf'\n\t\t\t\t\t};\n\t\t\t\t}\n\n\t\t\t\tif (_check(typeId, [0xC0, 0xEF, 0x19, 0xBC, 0x4D, 0x5B, 0xCF, 0x11, 0xA8, 0xFD, 0x00, 0x80, 0x5F, 0x5C, 0x44, 0x2B])) {\n\t\t\t\t\t// Found video:\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'asf',\n\t\t\t\t\t\tmime: 'video/x-ms-asf'\n\t\t\t\t\t};\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tawait tokenizer.ignore(payload);\n\t\t}\n\n\t\t// Default to ASF generic extension\n\t\treturn {\n\t\t\text: 'asf',\n\t\t\tmime: 'application/vnd.ms-asf'\n\t\t};\n\t}\n\n\tif (check([0xAB, 0x4B, 0x54, 0x58, 0x20, 0x31, 0x31, 0xBB, 0x0D, 0x0A, 0x1A, 0x0A])) {\n\t\treturn {\n\t\t\text: 'ktx',\n\t\t\tmime: 'image/ktx'\n\t\t};\n\t}\n\n\tif ((check([0x7E, 0x10, 0x04]) || check([0x7E, 0x18, 0x04])) && check([0x30, 0x4D, 0x49, 0x45], {offset: 4})) {\n\t\treturn {\n\t\t\text: 'mie',\n\t\t\tmime: 'application/x-mie'\n\t\t};\n\t}\n\n\tif (check([0x27, 0x0A, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00], {offset: 2})) {\n\t\treturn {\n\t\t\text: 'shp',\n\t\t\tmime: 'application/x-esri-shape'\n\t\t};\n\t}\n\n\tif (check([0x00, 0x00, 0x00, 0x0C, 0x6A, 0x50, 0x20, 0x20, 0x0D, 0x0A, 0x87, 0x0A])) {\n\t\t// JPEG-2000 family\n\n\t\tawait tokenizer.ignore(20);\n\t\tconst type = await tokenizer.readToken(new Token.StringType(4, 'ascii'));\n\t\tswitch (type) {\n\t\t\tcase 'jp2 ':\n\t\t\t\treturn {\n\t\t\t\t\text: 'jp2',\n\t\t\t\t\tmime: 'image/jp2'\n\t\t\t\t};\n\t\t\tcase 'jpx ':\n\t\t\t\treturn {\n\t\t\t\t\text: 'jpx',\n\t\t\t\t\tmime: 'image/jpx'\n\t\t\t\t};\n\t\t\tcase 'jpm ':\n\t\t\t\treturn {\n\t\t\t\t\text: 'jpm',\n\t\t\t\t\tmime: 'image/jpm'\n\t\t\t\t};\n\t\t\tcase 'mjp2':\n\t\t\t\treturn {\n\t\t\t\t\text: 'mj2',\n\t\t\t\t\tmime: 'image/mj2'\n\t\t\t\t};\n\t\t\tdefault:\n\t\t\t\treturn;\n\t\t}\n\t}\n\n\tif (\n\t\tcheck([0xFF, 0x0A]) ||\n\t\tcheck([0x00, 0x00, 0x00, 0x0C, 0x4A, 0x58, 0x4C, 0x20, 0x0D, 0x0A, 0x87, 0x0A])\n\t) {\n\t\treturn {\n\t\t\text: 'jxl',\n\t\t\tmime: 'image/jxl'\n\t\t};\n\t}\n\n\t// -- Unsafe signatures --\n\n\tif (\n\t\tcheck([0x0, 0x0, 0x1, 0xBA]) ||\n\t\tcheck([0x0, 0x0, 0x1, 0xB3])\n\t) {\n\t\treturn {\n\t\t\text: 'mpg',\n\t\t\tmime: 'video/mpeg'\n\t\t};\n\t}\n\n\tif (check([0x00, 0x01, 0x00, 0x00, 0x00])) {\n\t\treturn {\n\t\t\text: 'ttf',\n\t\t\tmime: 'font/ttf'\n\t\t};\n\t}\n\n\tif (check([0x00, 0x00, 0x01, 0x00])) {\n\t\treturn {\n\t\t\text: 'ico',\n\t\t\tmime: 'image/x-icon'\n\t\t};\n\t}\n\n\tif (check([0x00, 0x00, 0x02, 0x00])) {\n\t\treturn {\n\t\t\text: 'cur',\n\t\t\tmime: 'image/x-icon'\n\t\t};\n\t}\n\n\tif (check([0xD0, 0xCF, 0x11, 0xE0, 0xA1, 0xB1, 0x1A, 0xE1])) {\n\t\t// Detected Microsoft Compound File Binary File (MS-CFB) Format.\n\t\treturn {\n\t\t\text: 'cfb',\n\t\t\tmime: 'application/x-cfb'\n\t\t};\n\t}\n\n\t// Increase sample size from 12 to 256.\n\tawait tokenizer.peekBuffer(buffer, {length: Math.min(256, tokenizer.fileInfo.size), mayBeLess: true});\n\n\t// -- 15-byte signatures --\n\n\tif (checkString('BEGIN:')) {\n\t\tif (checkString('VCARD', {offset: 6})) {\n\t\t\treturn {\n\t\t\t\text: 'vcf',\n\t\t\t\tmime: 'text/vcard'\n\t\t\t};\n\t\t}\n\n\t\tif (checkString('VCALENDAR', {offset: 6})) {\n\t\t\treturn {\n\t\t\t\text: 'ics',\n\t\t\t\tmime: 'text/calendar'\n\t\t\t};\n\t\t}\n\t}\n\n\t// `raf` is here just to keep all the raw image detectors together.\n\tif (checkString('FUJIFILMCCD-RAW')) {\n\t\treturn {\n\t\t\text: 'raf',\n\t\t\tmime: 'image/x-fujifilm-raf'\n\t\t};\n\t}\n\n\tif (checkString('Extended Module:')) {\n\t\treturn {\n\t\t\text: 'xm',\n\t\t\tmime: 'audio/x-xm'\n\t\t};\n\t}\n\n\tif (checkString('Creative Voice File')) {\n\t\treturn {\n\t\t\text: 'voc',\n\t\t\tmime: 'audio/x-voc'\n\t\t};\n\t}\n\n\tif (check([0x04, 0x00, 0x00, 0x00]) && buffer.length >= 16) { // Rough & quick check Pickle/ASAR\n\t\tconst jsonSize = buffer.readUInt32LE(12);\n\t\tif (jsonSize > 12 && buffer.length >= jsonSize + 16) {\n\t\t\ttry {\n\t\t\t\tconst header = buffer.slice(16, jsonSize + 16).toString();\n\t\t\t\tconst json = JSON.parse(header);\n\t\t\t\t// Check if Pickle is ASAR\n\t\t\t\tif (json.files) { // Final check, assuring Pickle/ASAR format\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'asar',\n\t\t\t\t\t\tmime: 'application/x-asar'\n\t\t\t\t\t};\n\t\t\t\t}\n\t\t\t} catch (_) {\n\t\t\t}\n\t\t}\n\t}\n\n\tif (check([0x06, 0x0E, 0x2B, 0x34, 0x02, 0x05, 0x01, 0x01, 0x0D, 0x01, 0x02, 0x01, 0x01, 0x02])) {\n\t\treturn {\n\t\t\text: 'mxf',\n\t\t\tmime: 'application/mxf'\n\t\t};\n\t}\n\n\tif (checkString('SCRM', {offset: 44})) {\n\t\treturn {\n\t\t\text: 's3m',\n\t\t\tmime: 'audio/x-s3m'\n\t\t};\n\t}\n\n\tif (check([0x47], {offset: 4}) && (check([0x47], {offset: 192}) || check([0x47], {offset: 196}))) {\n\t\treturn {\n\t\t\text: 'mts',\n\t\t\tmime: 'video/mp2t'\n\t\t};\n\t}\n\n\tif (check([0x42, 0x4F, 0x4F, 0x4B, 0x4D, 0x4F, 0x42, 0x49], {offset: 60})) {\n\t\treturn {\n\t\t\text: 'mobi',\n\t\t\tmime: 'application/x-mobipocket-ebook'\n\t\t};\n\t}\n\n\tif (check([0x44, 0x49, 0x43, 0x4D], {offset: 128})) {\n\t\treturn {\n\t\t\text: 'dcm',\n\t\t\tmime: 'application/dicom'\n\t\t};\n\t}\n\n\tif (check([0x4C, 0x00, 0x00, 0x00, 0x01, 0x14, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0xC0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x46])) {\n\t\treturn {\n\t\t\text: 'lnk',\n\t\t\tmime: 'application/x.ms.shortcut' // Invented by us\n\t\t};\n\t}\n\n\tif (check([0x62, 0x6F, 0x6F, 0x6B, 0x00, 0x00, 0x00, 0x00, 0x6D, 0x61, 0x72, 0x6B, 0x00, 0x00, 0x00, 0x00])) {\n\t\treturn {\n\t\t\text: 'alias',\n\t\t\tmime: 'application/x.apple.alias' // Invented by us\n\t\t};\n\t}\n\n\tif (\n\t\tcheck([0x4C, 0x50], {offset: 34}) &&\n\t\t(\n\t\t\tcheck([0x00, 0x00, 0x01], {offset: 8}) ||\n\t\t\tcheck([0x01, 0x00, 0x02], {offset: 8}) ||\n\t\t\tcheck([0x02, 0x00, 0x02], {offset: 8})\n\t\t)\n\t) {\n\t\treturn {\n\t\t\text: 'eot',\n\t\t\tmime: 'application/vnd.ms-fontobject'\n\t\t};\n\t}\n\n\tif (check([0x06, 0x06, 0xED, 0xF5, 0xD8, 0x1D, 0x46, 0xE5, 0xBD, 0x31, 0xEF, 0xE7, 0xFE, 0x74, 0xB7, 0x1D])) {\n\t\treturn {\n\t\t\text: 'indd',\n\t\t\tmime: 'application/x-indesign'\n\t\t};\n\t}\n\n\t// Increase sample size from 256 to 512\n\tawait tokenizer.peekBuffer(buffer, {length: Math.min(512, tokenizer.fileInfo.size), mayBeLess: true});\n\n\t// Requires a buffer size of 512 bytes\n\tif (tarHeaderChecksumMatches(buffer)) {\n\t\treturn {\n\t\t\text: 'tar',\n\t\t\tmime: 'application/x-tar'\n\t\t};\n\t}\n\n\tif (check([0xFF, 0xFE, 0xFF, 0x0E, 0x53, 0x00, 0x6B, 0x00, 0x65, 0x00, 0x74, 0x00, 0x63, 0x00, 0x68, 0x00, 0x55, 0x00, 0x70, 0x00, 0x20, 0x00, 0x4D, 0x00, 0x6F, 0x00, 0x64, 0x00, 0x65, 0x00, 0x6C, 0x00])) {\n\t\treturn {\n\t\t\text: 'skp',\n\t\t\tmime: 'application/vnd.sketchup.skp'\n\t\t};\n\t}\n\n\tif (checkString('-----BEGIN PGP MESSAGE-----')) {\n\t\treturn {\n\t\t\text: 'pgp',\n\t\t\tmime: 'application/pgp-encrypted'\n\t\t};\n\t}\n\n\t// Check MPEG 1 or 2 Layer 3 header, or 'layer 0' for ADTS (MPEG sync-word 0xFFE)\n\tif (buffer.length >= 2 && check([0xFF, 0xE0], {offset: 0, mask: [0xFF, 0xE0]})) {\n\t\tif (check([0x10], {offset: 1, mask: [0x16]})) {\n\t\t\t// Check for (ADTS) MPEG-2\n\t\t\tif (check([0x08], {offset: 1, mask: [0x08]})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'aac',\n\t\t\t\t\tmime: 'audio/aac'\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// Must be (ADTS) MPEG-4\n\t\t\treturn {\n\t\t\t\text: 'aac',\n\t\t\t\tmime: 'audio/aac'\n\t\t\t};\n\t\t}\n\n\t\t// MPEG 1 or 2 Layer 3 header\n\t\t// Check for MPEG layer 3\n\t\tif (check([0x02], {offset: 1, mask: [0x06]})) {\n\t\t\treturn {\n\t\t\t\text: 'mp3',\n\t\t\t\tmime: 'audio/mpeg'\n\t\t\t};\n\t\t}\n\n\t\t// Check for MPEG layer 2\n\t\tif (check([0x04], {offset: 1, mask: [0x06]})) {\n\t\t\treturn {\n\t\t\t\text: 'mp2',\n\t\t\t\tmime: 'audio/mpeg'\n\t\t\t};\n\t\t}\n\n\t\t// Check for MPEG layer 1\n\t\tif (check([0x06], {offset: 1, mask: [0x06]})) {\n\t\t\treturn {\n\t\t\t\text: 'mp1',\n\t\t\t\tmime: 'audio/mpeg'\n\t\t\t};\n\t\t}\n\t}\n}\n\nconst stream = readableStream => new Promise((resolve, reject) => {\n\t// Using `eval` to work around issues when bundling with Webpack\n\tconst stream = eval('require')('stream'); // eslint-disable-line no-eval\n\n\treadableStream.on('error', reject);\n\treadableStream.once('readable', async () => {\n\t\t// Set up output stream\n\t\tconst pass = new stream.PassThrough();\n\t\tlet outputStream;\n\t\tif (stream.pipeline) {\n\t\t\toutputStream = stream.pipeline(readableStream, pass, () => {\n\t\t\t});\n\t\t} else {\n\t\t\toutputStream = readableStream.pipe(pass);\n\t\t}\n\n\t\t// Read the input stream and detect the filetype\n\t\tconst chunk = readableStream.read(minimumBytes) || readableStream.read() || Buffer.alloc(0);\n\t\ttry {\n\t\t\tconst fileType = await fromBuffer(chunk);\n\t\t\tpass.fileType = fileType;\n\t\t} catch (error) {\n\t\t\treject(error);\n\t\t}\n\n\t\tresolve(outputStream);\n\t});\n});\n\nconst fileType = {\n\tfromStream,\n\tfromTokenizer,\n\tfromBuffer,\n\tstream\n};\n\nObject.defineProperty(fileType, 'extensions', {\n\tget() {\n\t\treturn new Set(supported.extensions);\n\t}\n});\n\nObject.defineProperty(fileType, 'mimeTypes', {\n\tget() {\n\t\treturn new Set(supported.mimeTypes);\n\t}\n});\n\nmodule.exports = fileType;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/file-type@16.5.4/node_modules/file-type/core.js?")},"./node_modules/.pnpm/file-type@16.5.4/node_modules/file-type/supported.js":
/*!*********************************************************************************!*\
  !*** ./node_modules/.pnpm/file-type@16.5.4/node_modules/file-type/supported.js ***!
  \*********************************************************************************/function(module){"use strict";eval("\n\nmodule.exports = {\n\textensions: [\n\t\t'jpg',\n\t\t'png',\n\t\t'apng',\n\t\t'gif',\n\t\t'webp',\n\t\t'flif',\n\t\t'xcf',\n\t\t'cr2',\n\t\t'cr3',\n\t\t'orf',\n\t\t'arw',\n\t\t'dng',\n\t\t'nef',\n\t\t'rw2',\n\t\t'raf',\n\t\t'tif',\n\t\t'bmp',\n\t\t'icns',\n\t\t'jxr',\n\t\t'psd',\n\t\t'indd',\n\t\t'zip',\n\t\t'tar',\n\t\t'rar',\n\t\t'gz',\n\t\t'bz2',\n\t\t'7z',\n\t\t'dmg',\n\t\t'mp4',\n\t\t'mid',\n\t\t'mkv',\n\t\t'webm',\n\t\t'mov',\n\t\t'avi',\n\t\t'mpg',\n\t\t'mp2',\n\t\t'mp3',\n\t\t'm4a',\n\t\t'oga',\n\t\t'ogg',\n\t\t'ogv',\n\t\t'opus',\n\t\t'flac',\n\t\t'wav',\n\t\t'spx',\n\t\t'amr',\n\t\t'pdf',\n\t\t'epub',\n\t\t'exe',\n\t\t'swf',\n\t\t'rtf',\n\t\t'wasm',\n\t\t'woff',\n\t\t'woff2',\n\t\t'eot',\n\t\t'ttf',\n\t\t'otf',\n\t\t'ico',\n\t\t'flv',\n\t\t'ps',\n\t\t'xz',\n\t\t'sqlite',\n\t\t'nes',\n\t\t'crx',\n\t\t'xpi',\n\t\t'cab',\n\t\t'deb',\n\t\t'ar',\n\t\t'rpm',\n\t\t'Z',\n\t\t'lz',\n\t\t'cfb',\n\t\t'mxf',\n\t\t'mts',\n\t\t'blend',\n\t\t'bpg',\n\t\t'docx',\n\t\t'pptx',\n\t\t'xlsx',\n\t\t'3gp',\n\t\t'3g2',\n\t\t'jp2',\n\t\t'jpm',\n\t\t'jpx',\n\t\t'mj2',\n\t\t'aif',\n\t\t'qcp',\n\t\t'odt',\n\t\t'ods',\n\t\t'odp',\n\t\t'xml',\n\t\t'mobi',\n\t\t'heic',\n\t\t'cur',\n\t\t'ktx',\n\t\t'ape',\n\t\t'wv',\n\t\t'dcm',\n\t\t'ics',\n\t\t'glb',\n\t\t'pcap',\n\t\t'dsf',\n\t\t'lnk',\n\t\t'alias',\n\t\t'voc',\n\t\t'ac3',\n\t\t'm4v',\n\t\t'm4p',\n\t\t'm4b',\n\t\t'f4v',\n\t\t'f4p',\n\t\t'f4b',\n\t\t'f4a',\n\t\t'mie',\n\t\t'asf',\n\t\t'ogm',\n\t\t'ogx',\n\t\t'mpc',\n\t\t'arrow',\n\t\t'shp',\n\t\t'aac',\n\t\t'mp1',\n\t\t'it',\n\t\t's3m',\n\t\t'xm',\n\t\t'ai',\n\t\t'skp',\n\t\t'avif',\n\t\t'eps',\n\t\t'lzh',\n\t\t'pgp',\n\t\t'asar',\n\t\t'stl',\n\t\t'chm',\n\t\t'3mf',\n\t\t'zst',\n\t\t'jxl',\n\t\t'vcf'\n\t],\n\tmimeTypes: [\n\t\t'image/jpeg',\n\t\t'image/png',\n\t\t'image/gif',\n\t\t'image/webp',\n\t\t'image/flif',\n\t\t'image/x-xcf',\n\t\t'image/x-canon-cr2',\n\t\t'image/x-canon-cr3',\n\t\t'image/tiff',\n\t\t'image/bmp',\n\t\t'image/vnd.ms-photo',\n\t\t'image/vnd.adobe.photoshop',\n\t\t'application/x-indesign',\n\t\t'application/epub+zip',\n\t\t'application/x-xpinstall',\n\t\t'application/vnd.oasis.opendocument.text',\n\t\t'application/vnd.oasis.opendocument.spreadsheet',\n\t\t'application/vnd.oasis.opendocument.presentation',\n\t\t'application/vnd.openxmlformats-officedocument.wordprocessingml.document',\n\t\t'application/vnd.openxmlformats-officedocument.presentationml.presentation',\n\t\t'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n\t\t'application/zip',\n\t\t'application/x-tar',\n\t\t'application/x-rar-compressed',\n\t\t'application/gzip',\n\t\t'application/x-bzip2',\n\t\t'application/x-7z-compressed',\n\t\t'application/x-apple-diskimage',\n\t\t'application/x-apache-arrow',\n\t\t'video/mp4',\n\t\t'audio/midi',\n\t\t'video/x-matroska',\n\t\t'video/webm',\n\t\t'video/quicktime',\n\t\t'video/vnd.avi',\n\t\t'audio/vnd.wave',\n\t\t'audio/qcelp',\n\t\t'audio/x-ms-asf',\n\t\t'video/x-ms-asf',\n\t\t'application/vnd.ms-asf',\n\t\t'video/mpeg',\n\t\t'video/3gpp',\n\t\t'audio/mpeg',\n\t\t'audio/mp4', // RFC 4337\n\t\t'audio/opus',\n\t\t'video/ogg',\n\t\t'audio/ogg',\n\t\t'application/ogg',\n\t\t'audio/x-flac',\n\t\t'audio/ape',\n\t\t'audio/wavpack',\n\t\t'audio/amr',\n\t\t'application/pdf',\n\t\t'application/x-msdownload',\n\t\t'application/x-shockwave-flash',\n\t\t'application/rtf',\n\t\t'application/wasm',\n\t\t'font/woff',\n\t\t'font/woff2',\n\t\t'application/vnd.ms-fontobject',\n\t\t'font/ttf',\n\t\t'font/otf',\n\t\t'image/x-icon',\n\t\t'video/x-flv',\n\t\t'application/postscript',\n\t\t'application/eps',\n\t\t'application/x-xz',\n\t\t'application/x-sqlite3',\n\t\t'application/x-nintendo-nes-rom',\n\t\t'application/x-google-chrome-extension',\n\t\t'application/vnd.ms-cab-compressed',\n\t\t'application/x-deb',\n\t\t'application/x-unix-archive',\n\t\t'application/x-rpm',\n\t\t'application/x-compress',\n\t\t'application/x-lzip',\n\t\t'application/x-cfb',\n\t\t'application/x-mie',\n\t\t'application/mxf',\n\t\t'video/mp2t',\n\t\t'application/x-blender',\n\t\t'image/bpg',\n\t\t'image/jp2',\n\t\t'image/jpx',\n\t\t'image/jpm',\n\t\t'image/mj2',\n\t\t'audio/aiff',\n\t\t'application/xml',\n\t\t'application/x-mobipocket-ebook',\n\t\t'image/heif',\n\t\t'image/heif-sequence',\n\t\t'image/heic',\n\t\t'image/heic-sequence',\n\t\t'image/icns',\n\t\t'image/ktx',\n\t\t'application/dicom',\n\t\t'audio/x-musepack',\n\t\t'text/calendar',\n\t\t'text/vcard',\n\t\t'model/gltf-binary',\n\t\t'application/vnd.tcpdump.pcap',\n\t\t'audio/x-dsf', // Non-standard\n\t\t'application/x.ms.shortcut', // Invented by us\n\t\t'application/x.apple.alias', // Invented by us\n\t\t'audio/x-voc',\n\t\t'audio/vnd.dolby.dd-raw',\n\t\t'audio/x-m4a',\n\t\t'image/apng',\n\t\t'image/x-olympus-orf',\n\t\t'image/x-sony-arw',\n\t\t'image/x-adobe-dng',\n\t\t'image/x-nikon-nef',\n\t\t'image/x-panasonic-rw2',\n\t\t'image/x-fujifilm-raf',\n\t\t'video/x-m4v',\n\t\t'video/3gpp2',\n\t\t'application/x-esri-shape',\n\t\t'audio/aac',\n\t\t'audio/x-it',\n\t\t'audio/x-s3m',\n\t\t'audio/x-xm',\n\t\t'video/MP1S',\n\t\t'video/MP2P',\n\t\t'application/vnd.sketchup.skp',\n\t\t'image/avif',\n\t\t'application/x-lzh-compressed',\n\t\t'application/pgp-encrypted',\n\t\t'application/x-asar',\n\t\t'model/stl',\n\t\t'application/vnd.ms-htmlhelp',\n\t\t'model/3mf',\n\t\t'image/jxl',\n\t\t'application/zstd'\n\t]\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/file-type@16.5.4/node_modules/file-type/supported.js?")},"./node_modules/.pnpm/file-type@16.5.4/node_modules/file-type/util.js":
/*!****************************************************************************!*\
  !*** ./node_modules/.pnpm/file-type@16.5.4/node_modules/file-type/util.js ***!
  \****************************************************************************/function(__unused_webpack_module,exports){"use strict";eval("\n\nexports.stringToBytes = string => [...string].map(character => character.charCodeAt(0));\n\n/**\nChecks whether the TAR checksum is valid.\n\n@param {Buffer} buffer - The TAR header `[offset ... offset + 512]`.\n@param {number} offset - TAR header offset.\n@returns {boolean} `true` if the TAR checksum is valid, otherwise `false`.\n*/\nexports.tarHeaderChecksumMatches = (buffer, offset = 0) => {\n\tconst readSum = parseInt(buffer.toString('utf8', 148, 154).replace(/\\0.*$/, '').trim(), 8); // Read sum in header\n\tif (isNaN(readSum)) {\n\t\treturn false;\n\t}\n\n\tlet sum = 8 * 0x20; // Initialize signed bit sum\n\n\tfor (let i = offset; i < offset + 148; i++) {\n\t\tsum += buffer[i];\n\t}\n\n\tfor (let i = offset + 156; i < offset + 512; i++) {\n\t\tsum += buffer[i];\n\t}\n\n\treturn readSum === sum;\n};\n\n/**\nID3 UINT32 sync-safe tokenizer token.\n28 bits (representing up to 256MB) integer, the msb is 0 to avoid \"false syncsignals\".\n*/\nexports.uint32SyncSafeToken = {\n\tget: (buffer, offset) => {\n\t\treturn (buffer[offset + 3] & 0x7F) | ((buffer[offset + 2]) << 7) | ((buffer[offset + 1]) << 14) | ((buffer[offset]) << 21);\n\t},\n\tlen: 4\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/file-type@16.5.4/node_modules/file-type/util.js?")},"./node_modules/.pnpm/hls.js@1.5.17/node_modules/hls.js/dist/hls.js":
/*!**************************************************************************!*\
  !*** ./node_modules/.pnpm/hls.js@1.5.17/node_modules/hls.js/dist/hls.js ***!
  \**************************************************************************/function(module){eval("(function __HLS_WORKER_BUNDLE__(__IN_WORKER__){\n(function (global, factory) {\n   true ? module.exports = factory() :\n  0;\n})(this, (function () { 'use strict';\n\n  function ownKeys(e, r) {\n    var t = Object.keys(e);\n    if (Object.getOwnPropertySymbols) {\n      var o = Object.getOwnPropertySymbols(e);\n      r && (o = o.filter(function (r) {\n        return Object.getOwnPropertyDescriptor(e, r).enumerable;\n      })), t.push.apply(t, o);\n    }\n    return t;\n  }\n  function _objectSpread2(e) {\n    for (var r = 1; r < arguments.length; r++) {\n      var t = null != arguments[r] ? arguments[r] : {};\n      r % 2 ? ownKeys(Object(t), !0).forEach(function (r) {\n        _defineProperty(e, r, t[r]);\n      }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(e, Object.getOwnPropertyDescriptors(t)) : ownKeys(Object(t)).forEach(function (r) {\n        Object.defineProperty(e, r, Object.getOwnPropertyDescriptor(t, r));\n      });\n    }\n    return e;\n  }\n  function _toPrimitive(t, r) {\n    if (\"object\" != typeof t || !t) return t;\n    var e = t[Symbol.toPrimitive];\n    if (void 0 !== e) {\n      var i = e.call(t, r || \"default\");\n      if (\"object\" != typeof i) return i;\n      throw new TypeError(\"@@toPrimitive must return a primitive value.\");\n    }\n    return (\"string\" === r ? String : Number)(t);\n  }\n  function _toPropertyKey(t) {\n    var i = _toPrimitive(t, \"string\");\n    return \"symbol\" == typeof i ? i : String(i);\n  }\n  function _defineProperties(target, props) {\n    for (var i = 0; i < props.length; i++) {\n      var descriptor = props[i];\n      descriptor.enumerable = descriptor.enumerable || false;\n      descriptor.configurable = true;\n      if (\"value\" in descriptor) descriptor.writable = true;\n      Object.defineProperty(target, _toPropertyKey(descriptor.key), descriptor);\n    }\n  }\n  function _createClass(Constructor, protoProps, staticProps) {\n    if (protoProps) _defineProperties(Constructor.prototype, protoProps);\n    if (staticProps) _defineProperties(Constructor, staticProps);\n    Object.defineProperty(Constructor, \"prototype\", {\n      writable: false\n    });\n    return Constructor;\n  }\n  function _defineProperty(obj, key, value) {\n    key = _toPropertyKey(key);\n    if (key in obj) {\n      Object.defineProperty(obj, key, {\n        value: value,\n        enumerable: true,\n        configurable: true,\n        writable: true\n      });\n    } else {\n      obj[key] = value;\n    }\n    return obj;\n  }\n  function _extends() {\n    _extends = Object.assign ? Object.assign.bind() : function (target) {\n      for (var i = 1; i < arguments.length; i++) {\n        var source = arguments[i];\n        for (var key in source) {\n          if (Object.prototype.hasOwnProperty.call(source, key)) {\n            target[key] = source[key];\n          }\n        }\n      }\n      return target;\n    };\n    return _extends.apply(this, arguments);\n  }\n  function _inheritsLoose(subClass, superClass) {\n    subClass.prototype = Object.create(superClass.prototype);\n    subClass.prototype.constructor = subClass;\n    _setPrototypeOf(subClass, superClass);\n  }\n  function _getPrototypeOf(o) {\n    _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf.bind() : function _getPrototypeOf(o) {\n      return o.__proto__ || Object.getPrototypeOf(o);\n    };\n    return _getPrototypeOf(o);\n  }\n  function _setPrototypeOf(o, p) {\n    _setPrototypeOf = Object.setPrototypeOf ? Object.setPrototypeOf.bind() : function _setPrototypeOf(o, p) {\n      o.__proto__ = p;\n      return o;\n    };\n    return _setPrototypeOf(o, p);\n  }\n  function _isNativeReflectConstruct() {\n    if (typeof Reflect === \"undefined\" || !Reflect.construct) return false;\n    if (Reflect.construct.sham) return false;\n    if (typeof Proxy === \"function\") return true;\n    try {\n      Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {}));\n      return true;\n    } catch (e) {\n      return false;\n    }\n  }\n  function _construct(Parent, args, Class) {\n    if (_isNativeReflectConstruct()) {\n      _construct = Reflect.construct.bind();\n    } else {\n      _construct = function _construct(Parent, args, Class) {\n        var a = [null];\n        a.push.apply(a, args);\n        var Constructor = Function.bind.apply(Parent, a);\n        var instance = new Constructor();\n        if (Class) _setPrototypeOf(instance, Class.prototype);\n        return instance;\n      };\n    }\n    return _construct.apply(null, arguments);\n  }\n  function _isNativeFunction(fn) {\n    try {\n      return Function.toString.call(fn).indexOf(\"[native code]\") !== -1;\n    } catch (e) {\n      return typeof fn === \"function\";\n    }\n  }\n  function _wrapNativeSuper(Class) {\n    var _cache = typeof Map === \"function\" ? new Map() : undefined;\n    _wrapNativeSuper = function _wrapNativeSuper(Class) {\n      if (Class === null || !_isNativeFunction(Class)) return Class;\n      if (typeof Class !== \"function\") {\n        throw new TypeError(\"Super expression must either be null or a function\");\n      }\n      if (typeof _cache !== \"undefined\") {\n        if (_cache.has(Class)) return _cache.get(Class);\n        _cache.set(Class, Wrapper);\n      }\n      function Wrapper() {\n        return _construct(Class, arguments, _getPrototypeOf(this).constructor);\n      }\n      Wrapper.prototype = Object.create(Class.prototype, {\n        constructor: {\n          value: Wrapper,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      });\n      return _setPrototypeOf(Wrapper, Class);\n    };\n    return _wrapNativeSuper(Class);\n  }\n  function _assertThisInitialized(self) {\n    if (self === void 0) {\n      throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");\n    }\n    return self;\n  }\n  function _unsupportedIterableToArray(o, minLen) {\n    if (!o) return;\n    if (typeof o === \"string\") return _arrayLikeToArray(o, minLen);\n    var n = Object.prototype.toString.call(o).slice(8, -1);\n    if (n === \"Object\" && o.constructor) n = o.constructor.name;\n    if (n === \"Map\" || n === \"Set\") return Array.from(o);\n    if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen);\n  }\n  function _arrayLikeToArray(arr, len) {\n    if (len == null || len > arr.length) len = arr.length;\n    for (var i = 0, arr2 = new Array(len); i < len; i++) arr2[i] = arr[i];\n    return arr2;\n  }\n  function _createForOfIteratorHelperLoose(o, allowArrayLike) {\n    var it = typeof Symbol !== \"undefined\" && o[Symbol.iterator] || o[\"@@iterator\"];\n    if (it) return (it = it.call(o)).next.bind(it);\n    if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") {\n      if (it) o = it;\n      var i = 0;\n      return function () {\n        if (i >= o.length) return {\n          done: true\n        };\n        return {\n          done: false,\n          value: o[i++]\n        };\n      };\n    }\n    throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n  }\n\n  function getDefaultExportFromCjs (x) {\n  \treturn x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;\n  }\n\n  var urlToolkit = {exports: {}};\n\n  (function (module, exports) {\n  \t// see https://tools.ietf.org/html/rfc1808\n\n  \t(function (root) {\n  \t  var URL_REGEX =\n  \t    /^(?=((?:[a-zA-Z0-9+\\-.]+:)?))\\1(?=((?:\\/\\/[^\\/?#]*)?))\\2(?=((?:(?:[^?#\\/]*\\/)*[^;?#\\/]*)?))\\3((?:;[^?#]*)?)(\\?[^#]*)?(#[^]*)?$/;\n  \t  var FIRST_SEGMENT_REGEX = /^(?=([^\\/?#]*))\\1([^]*)$/;\n  \t  var SLASH_DOT_REGEX = /(?:\\/|^)\\.(?=\\/)/g;\n  \t  var SLASH_DOT_DOT_REGEX = /(?:\\/|^)\\.\\.\\/(?!\\.\\.\\/)[^\\/]*(?=\\/)/g;\n\n  \t  var URLToolkit = {\n  \t    // If opts.alwaysNormalize is true then the path will always be normalized even when it starts with / or //\n  \t    // E.g\n  \t    // With opts.alwaysNormalize = false (default, spec compliant)\n  \t    // http://a.com/b/cd + /e/f/../g => http://a.com/e/f/../g\n  \t    // With opts.alwaysNormalize = true (not spec compliant)\n  \t    // http://a.com/b/cd + /e/f/../g => http://a.com/e/g\n  \t    buildAbsoluteURL: function (baseURL, relativeURL, opts) {\n  \t      opts = opts || {};\n  \t      // remove any remaining space and CRLF\n  \t      baseURL = baseURL.trim();\n  \t      relativeURL = relativeURL.trim();\n  \t      if (!relativeURL) {\n  \t        // 2a) If the embedded URL is entirely empty, it inherits the\n  \t        // entire base URL (i.e., is set equal to the base URL)\n  \t        // and we are done.\n  \t        if (!opts.alwaysNormalize) {\n  \t          return baseURL;\n  \t        }\n  \t        var basePartsForNormalise = URLToolkit.parseURL(baseURL);\n  \t        if (!basePartsForNormalise) {\n  \t          throw new Error('Error trying to parse base URL.');\n  \t        }\n  \t        basePartsForNormalise.path = URLToolkit.normalizePath(\n  \t          basePartsForNormalise.path\n  \t        );\n  \t        return URLToolkit.buildURLFromParts(basePartsForNormalise);\n  \t      }\n  \t      var relativeParts = URLToolkit.parseURL(relativeURL);\n  \t      if (!relativeParts) {\n  \t        throw new Error('Error trying to parse relative URL.');\n  \t      }\n  \t      if (relativeParts.scheme) {\n  \t        // 2b) If the embedded URL starts with a scheme name, it is\n  \t        // interpreted as an absolute URL and we are done.\n  \t        if (!opts.alwaysNormalize) {\n  \t          return relativeURL;\n  \t        }\n  \t        relativeParts.path = URLToolkit.normalizePath(relativeParts.path);\n  \t        return URLToolkit.buildURLFromParts(relativeParts);\n  \t      }\n  \t      var baseParts = URLToolkit.parseURL(baseURL);\n  \t      if (!baseParts) {\n  \t        throw new Error('Error trying to parse base URL.');\n  \t      }\n  \t      if (!baseParts.netLoc && baseParts.path && baseParts.path[0] !== '/') {\n  \t        // If netLoc missing and path doesn't start with '/', assume everthing before the first '/' is the netLoc\n  \t        // This causes 'example.com/a' to be handled as '//example.com/a' instead of '/example.com/a'\n  \t        var pathParts = FIRST_SEGMENT_REGEX.exec(baseParts.path);\n  \t        baseParts.netLoc = pathParts[1];\n  \t        baseParts.path = pathParts[2];\n  \t      }\n  \t      if (baseParts.netLoc && !baseParts.path) {\n  \t        baseParts.path = '/';\n  \t      }\n  \t      var builtParts = {\n  \t        // 2c) Otherwise, the embedded URL inherits the scheme of\n  \t        // the base URL.\n  \t        scheme: baseParts.scheme,\n  \t        netLoc: relativeParts.netLoc,\n  \t        path: null,\n  \t        params: relativeParts.params,\n  \t        query: relativeParts.query,\n  \t        fragment: relativeParts.fragment,\n  \t      };\n  \t      if (!relativeParts.netLoc) {\n  \t        // 3) If the embedded URL's <net_loc> is non-empty, we skip to\n  \t        // Step 7.  Otherwise, the embedded URL inherits the <net_loc>\n  \t        // (if any) of the base URL.\n  \t        builtParts.netLoc = baseParts.netLoc;\n  \t        // 4) If the embedded URL path is preceded by a slash \"/\", the\n  \t        // path is not relative and we skip to Step 7.\n  \t        if (relativeParts.path[0] !== '/') {\n  \t          if (!relativeParts.path) {\n  \t            // 5) If the embedded URL path is empty (and not preceded by a\n  \t            // slash), then the embedded URL inherits the base URL path\n  \t            builtParts.path = baseParts.path;\n  \t            // 5a) if the embedded URL's <params> is non-empty, we skip to\n  \t            // step 7; otherwise, it inherits the <params> of the base\n  \t            // URL (if any) and\n  \t            if (!relativeParts.params) {\n  \t              builtParts.params = baseParts.params;\n  \t              // 5b) if the embedded URL's <query> is non-empty, we skip to\n  \t              // step 7; otherwise, it inherits the <query> of the base\n  \t              // URL (if any) and we skip to step 7.\n  \t              if (!relativeParts.query) {\n  \t                builtParts.query = baseParts.query;\n  \t              }\n  \t            }\n  \t          } else {\n  \t            // 6) The last segment of the base URL's path (anything\n  \t            // following the rightmost slash \"/\", or the entire path if no\n  \t            // slash is present) is removed and the embedded URL's path is\n  \t            // appended in its place.\n  \t            var baseURLPath = baseParts.path;\n  \t            var newPath =\n  \t              baseURLPath.substring(0, baseURLPath.lastIndexOf('/') + 1) +\n  \t              relativeParts.path;\n  \t            builtParts.path = URLToolkit.normalizePath(newPath);\n  \t          }\n  \t        }\n  \t      }\n  \t      if (builtParts.path === null) {\n  \t        builtParts.path = opts.alwaysNormalize\n  \t          ? URLToolkit.normalizePath(relativeParts.path)\n  \t          : relativeParts.path;\n  \t      }\n  \t      return URLToolkit.buildURLFromParts(builtParts);\n  \t    },\n  \t    parseURL: function (url) {\n  \t      var parts = URL_REGEX.exec(url);\n  \t      if (!parts) {\n  \t        return null;\n  \t      }\n  \t      return {\n  \t        scheme: parts[1] || '',\n  \t        netLoc: parts[2] || '',\n  \t        path: parts[3] || '',\n  \t        params: parts[4] || '',\n  \t        query: parts[5] || '',\n  \t        fragment: parts[6] || '',\n  \t      };\n  \t    },\n  \t    normalizePath: function (path) {\n  \t      // The following operations are\n  \t      // then applied, in order, to the new path:\n  \t      // 6a) All occurrences of \"./\", where \".\" is a complete path\n  \t      // segment, are removed.\n  \t      // 6b) If the path ends with \".\" as a complete path segment,\n  \t      // that \".\" is removed.\n  \t      path = path.split('').reverse().join('').replace(SLASH_DOT_REGEX, '');\n  \t      // 6c) All occurrences of \"<segment>/../\", where <segment> is a\n  \t      // complete path segment not equal to \"..\", are removed.\n  \t      // Removal of these path segments is performed iteratively,\n  \t      // removing the leftmost matching pattern on each iteration,\n  \t      // until no matching pattern remains.\n  \t      // 6d) If the path ends with \"<segment>/..\", where <segment> is a\n  \t      // complete path segment not equal to \"..\", that\n  \t      // \"<segment>/..\" is removed.\n  \t      while (\n  \t        path.length !== (path = path.replace(SLASH_DOT_DOT_REGEX, '')).length\n  \t      ) {}\n  \t      return path.split('').reverse().join('');\n  \t    },\n  \t    buildURLFromParts: function (parts) {\n  \t      return (\n  \t        parts.scheme +\n  \t        parts.netLoc +\n  \t        parts.path +\n  \t        parts.params +\n  \t        parts.query +\n  \t        parts.fragment\n  \t      );\n  \t    },\n  \t  };\n\n  \t  module.exports = URLToolkit;\n  \t})(); \n  } (urlToolkit));\n\n  var urlToolkitExports = urlToolkit.exports;\n\n  // https://caniuse.com/mdn-javascript_builtins_number_isfinite\n  var isFiniteNumber = Number.isFinite || function (value) {\n    return typeof value === 'number' && isFinite(value);\n  };\n\n  // https://caniuse.com/mdn-javascript_builtins_number_issafeinteger\n  var isSafeInteger = Number.isSafeInteger || function (value) {\n    return typeof value === 'number' && Math.abs(value) <= MAX_SAFE_INTEGER;\n  };\n  var MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER || 9007199254740991;\n\n  var Events = /*#__PURE__*/function (Events) {\n    Events[\"MEDIA_ATTACHING\"] = \"hlsMediaAttaching\";\n    Events[\"MEDIA_ATTACHED\"] = \"hlsMediaAttached\";\n    Events[\"MEDIA_DETACHING\"] = \"hlsMediaDetaching\";\n    Events[\"MEDIA_DETACHED\"] = \"hlsMediaDetached\";\n    Events[\"BUFFER_RESET\"] = \"hlsBufferReset\";\n    Events[\"BUFFER_CODECS\"] = \"hlsBufferCodecs\";\n    Events[\"BUFFER_CREATED\"] = \"hlsBufferCreated\";\n    Events[\"BUFFER_APPENDING\"] = \"hlsBufferAppending\";\n    Events[\"BUFFER_APPENDED\"] = \"hlsBufferAppended\";\n    Events[\"BUFFER_EOS\"] = \"hlsBufferEos\";\n    Events[\"BUFFER_FLUSHING\"] = \"hlsBufferFlushing\";\n    Events[\"BUFFER_FLUSHED\"] = \"hlsBufferFlushed\";\n    Events[\"MANIFEST_LOADING\"] = \"hlsManifestLoading\";\n    Events[\"MANIFEST_LOADED\"] = \"hlsManifestLoaded\";\n    Events[\"MANIFEST_PARSED\"] = \"hlsManifestParsed\";\n    Events[\"LEVEL_SWITCHING\"] = \"hlsLevelSwitching\";\n    Events[\"LEVEL_SWITCHED\"] = \"hlsLevelSwitched\";\n    Events[\"LEVEL_LOADING\"] = \"hlsLevelLoading\";\n    Events[\"LEVEL_LOADED\"] = \"hlsLevelLoaded\";\n    Events[\"LEVEL_UPDATED\"] = \"hlsLevelUpdated\";\n    Events[\"LEVEL_PTS_UPDATED\"] = \"hlsLevelPtsUpdated\";\n    Events[\"LEVELS_UPDATED\"] = \"hlsLevelsUpdated\";\n    Events[\"AUDIO_TRACKS_UPDATED\"] = \"hlsAudioTracksUpdated\";\n    Events[\"AUDIO_TRACK_SWITCHING\"] = \"hlsAudioTrackSwitching\";\n    Events[\"AUDIO_TRACK_SWITCHED\"] = \"hlsAudioTrackSwitched\";\n    Events[\"AUDIO_TRACK_LOADING\"] = \"hlsAudioTrackLoading\";\n    Events[\"AUDIO_TRACK_LOADED\"] = \"hlsAudioTrackLoaded\";\n    Events[\"SUBTITLE_TRACKS_UPDATED\"] = \"hlsSubtitleTracksUpdated\";\n    Events[\"SUBTITLE_TRACKS_CLEARED\"] = \"hlsSubtitleTracksCleared\";\n    Events[\"SUBTITLE_TRACK_SWITCH\"] = \"hlsSubtitleTrackSwitch\";\n    Events[\"SUBTITLE_TRACK_LOADING\"] = \"hlsSubtitleTrackLoading\";\n    Events[\"SUBTITLE_TRACK_LOADED\"] = \"hlsSubtitleTrackLoaded\";\n    Events[\"SUBTITLE_FRAG_PROCESSED\"] = \"hlsSubtitleFragProcessed\";\n    Events[\"CUES_PARSED\"] = \"hlsCuesParsed\";\n    Events[\"NON_NATIVE_TEXT_TRACKS_FOUND\"] = \"hlsNonNativeTextTracksFound\";\n    Events[\"INIT_PTS_FOUND\"] = \"hlsInitPtsFound\";\n    Events[\"FRAG_LOADING\"] = \"hlsFragLoading\";\n    Events[\"FRAG_LOAD_EMERGENCY_ABORTED\"] = \"hlsFragLoadEmergencyAborted\";\n    Events[\"FRAG_LOADED\"] = \"hlsFragLoaded\";\n    Events[\"FRAG_DECRYPTED\"] = \"hlsFragDecrypted\";\n    Events[\"FRAG_PARSING_INIT_SEGMENT\"] = \"hlsFragParsingInitSegment\";\n    Events[\"FRAG_PARSING_USERDATA\"] = \"hlsFragParsingUserdata\";\n    Events[\"FRAG_PARSING_METADATA\"] = \"hlsFragParsingMetadata\";\n    Events[\"FRAG_PARSED\"] = \"hlsFragParsed\";\n    Events[\"FRAG_BUFFERED\"] = \"hlsFragBuffered\";\n    Events[\"FRAG_CHANGED\"] = \"hlsFragChanged\";\n    Events[\"FPS_DROP\"] = \"hlsFpsDrop\";\n    Events[\"FPS_DROP_LEVEL_CAPPING\"] = \"hlsFpsDropLevelCapping\";\n    Events[\"MAX_AUTO_LEVEL_UPDATED\"] = \"hlsMaxAutoLevelUpdated\";\n    Events[\"ERROR\"] = \"hlsError\";\n    Events[\"DESTROYING\"] = \"hlsDestroying\";\n    Events[\"KEY_LOADING\"] = \"hlsKeyLoading\";\n    Events[\"KEY_LOADED\"] = \"hlsKeyLoaded\";\n    Events[\"LIVE_BACK_BUFFER_REACHED\"] = \"hlsLiveBackBufferReached\";\n    Events[\"BACK_BUFFER_REACHED\"] = \"hlsBackBufferReached\";\n    Events[\"STEERING_MANIFEST_LOADED\"] = \"hlsSteeringManifestLoaded\";\n    return Events;\n  }({});\n\n  /**\n   * Defines each Event type and payload by Event name. Used in {@link hls.js#HlsEventEmitter} to strongly type the event listener API.\n   */\n\n  var ErrorTypes = /*#__PURE__*/function (ErrorTypes) {\n    ErrorTypes[\"NETWORK_ERROR\"] = \"networkError\";\n    ErrorTypes[\"MEDIA_ERROR\"] = \"mediaError\";\n    ErrorTypes[\"KEY_SYSTEM_ERROR\"] = \"keySystemError\";\n    ErrorTypes[\"MUX_ERROR\"] = \"muxError\";\n    ErrorTypes[\"OTHER_ERROR\"] = \"otherError\";\n    return ErrorTypes;\n  }({});\n  var ErrorDetails = /*#__PURE__*/function (ErrorDetails) {\n    ErrorDetails[\"KEY_SYSTEM_NO_KEYS\"] = \"keySystemNoKeys\";\n    ErrorDetails[\"KEY_SYSTEM_NO_ACCESS\"] = \"keySystemNoAccess\";\n    ErrorDetails[\"KEY_SYSTEM_NO_SESSION\"] = \"keySystemNoSession\";\n    ErrorDetails[\"KEY_SYSTEM_NO_CONFIGURED_LICENSE\"] = \"keySystemNoConfiguredLicense\";\n    ErrorDetails[\"KEY_SYSTEM_LICENSE_REQUEST_FAILED\"] = \"keySystemLicenseRequestFailed\";\n    ErrorDetails[\"KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED\"] = \"keySystemServerCertificateRequestFailed\";\n    ErrorDetails[\"KEY_SYSTEM_SERVER_CERTIFICATE_UPDATE_FAILED\"] = \"keySystemServerCertificateUpdateFailed\";\n    ErrorDetails[\"KEY_SYSTEM_SESSION_UPDATE_FAILED\"] = \"keySystemSessionUpdateFailed\";\n    ErrorDetails[\"KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED\"] = \"keySystemStatusOutputRestricted\";\n    ErrorDetails[\"KEY_SYSTEM_STATUS_INTERNAL_ERROR\"] = \"keySystemStatusInternalError\";\n    ErrorDetails[\"MANIFEST_LOAD_ERROR\"] = \"manifestLoadError\";\n    ErrorDetails[\"MANIFEST_LOAD_TIMEOUT\"] = \"manifestLoadTimeOut\";\n    ErrorDetails[\"MANIFEST_PARSING_ERROR\"] = \"manifestParsingError\";\n    ErrorDetails[\"MANIFEST_INCOMPATIBLE_CODECS_ERROR\"] = \"manifestIncompatibleCodecsError\";\n    ErrorDetails[\"LEVEL_EMPTY_ERROR\"] = \"levelEmptyError\";\n    ErrorDetails[\"LEVEL_LOAD_ERROR\"] = \"levelLoadError\";\n    ErrorDetails[\"LEVEL_LOAD_TIMEOUT\"] = \"levelLoadTimeOut\";\n    ErrorDetails[\"LEVEL_PARSING_ERROR\"] = \"levelParsingError\";\n    ErrorDetails[\"LEVEL_SWITCH_ERROR\"] = \"levelSwitchError\";\n    ErrorDetails[\"AUDIO_TRACK_LOAD_ERROR\"] = \"audioTrackLoadError\";\n    ErrorDetails[\"AUDIO_TRACK_LOAD_TIMEOUT\"] = \"audioTrackLoadTimeOut\";\n    ErrorDetails[\"SUBTITLE_LOAD_ERROR\"] = \"subtitleTrackLoadError\";\n    ErrorDetails[\"SUBTITLE_TRACK_LOAD_TIMEOUT\"] = \"subtitleTrackLoadTimeOut\";\n    ErrorDetails[\"FRAG_LOAD_ERROR\"] = \"fragLoadError\";\n    ErrorDetails[\"FRAG_LOAD_TIMEOUT\"] = \"fragLoadTimeOut\";\n    ErrorDetails[\"FRAG_DECRYPT_ERROR\"] = \"fragDecryptError\";\n    ErrorDetails[\"FRAG_PARSING_ERROR\"] = \"fragParsingError\";\n    ErrorDetails[\"FRAG_GAP\"] = \"fragGap\";\n    ErrorDetails[\"REMUX_ALLOC_ERROR\"] = \"remuxAllocError\";\n    ErrorDetails[\"KEY_LOAD_ERROR\"] = \"keyLoadError\";\n    ErrorDetails[\"KEY_LOAD_TIMEOUT\"] = \"keyLoadTimeOut\";\n    ErrorDetails[\"BUFFER_ADD_CODEC_ERROR\"] = \"bufferAddCodecError\";\n    ErrorDetails[\"BUFFER_INCOMPATIBLE_CODECS_ERROR\"] = \"bufferIncompatibleCodecsError\";\n    ErrorDetails[\"BUFFER_APPEND_ERROR\"] = \"bufferAppendError\";\n    ErrorDetails[\"BUFFER_APPENDING_ERROR\"] = \"bufferAppendingError\";\n    ErrorDetails[\"BUFFER_STALLED_ERROR\"] = \"bufferStalledError\";\n    ErrorDetails[\"BUFFER_FULL_ERROR\"] = \"bufferFullError\";\n    ErrorDetails[\"BUFFER_SEEK_OVER_HOLE\"] = \"bufferSeekOverHole\";\n    ErrorDetails[\"BUFFER_NUDGE_ON_STALL\"] = \"bufferNudgeOnStall\";\n    ErrorDetails[\"INTERNAL_EXCEPTION\"] = \"internalException\";\n    ErrorDetails[\"INTERNAL_ABORTED\"] = \"aborted\";\n    ErrorDetails[\"UNKNOWN\"] = \"unknown\";\n    return ErrorDetails;\n  }({});\n\n  var noop = function noop() {};\n  var fakeLogger = {\n    trace: noop,\n    debug: noop,\n    log: noop,\n    warn: noop,\n    info: noop,\n    error: noop\n  };\n  var exportedLogger = fakeLogger;\n\n  // let lastCallTime;\n  // function formatMsgWithTimeInfo(type, msg) {\n  //   const now = Date.now();\n  //   const diff = lastCallTime ? '+' + (now - lastCallTime) : '0';\n  //   lastCallTime = now;\n  //   msg = (new Date(now)).toISOString() + ' | [' +  type + '] > ' + msg + ' ( ' + diff + ' ms )';\n  //   return msg;\n  // }\n\n  function consolePrintFn(type) {\n    var func = self.console[type];\n    if (func) {\n      return func.bind(self.console, \"[\" + type + \"] >\");\n    }\n    return noop;\n  }\n  function exportLoggerFunctions(debugConfig) {\n    for (var _len = arguments.length, functions = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n      functions[_key - 1] = arguments[_key];\n    }\n    functions.forEach(function (type) {\n      exportedLogger[type] = debugConfig[type] ? debugConfig[type].bind(debugConfig) : consolePrintFn(type);\n    });\n  }\n  function enableLogs(debugConfig, id) {\n    // check that console is available\n    if (typeof console === 'object' && debugConfig === true || typeof debugConfig === 'object') {\n      exportLoggerFunctions(debugConfig,\n      // Remove out from list here to hard-disable a log-level\n      // 'trace',\n      'debug', 'log', 'info', 'warn', 'error');\n      // Some browsers don't allow to use bind on console object anyway\n      // fallback to default if needed\n      try {\n        exportedLogger.log(\"Debug logs enabled for \\\"\" + id + \"\\\" in hls.js version \" + \"1.5.17\");\n      } catch (e) {\n        exportedLogger = fakeLogger;\n      }\n    } else {\n      exportedLogger = fakeLogger;\n    }\n  }\n  var logger = exportedLogger;\n\n  var DECIMAL_RESOLUTION_REGEX = /^(\\d+)x(\\d+)$/;\n  var ATTR_LIST_REGEX = /(.+?)=(\".*?\"|.*?)(?:,|$)/g;\n\n  // adapted from https://github.com/kanongil/node-m3u8parse/blob/master/attrlist.js\n  var AttrList = /*#__PURE__*/function () {\n    function AttrList(attrs) {\n      if (typeof attrs === 'string') {\n        attrs = AttrList.parseAttrList(attrs);\n      }\n      _extends(this, attrs);\n    }\n    var _proto = AttrList.prototype;\n    _proto.decimalInteger = function decimalInteger(attrName) {\n      var intValue = parseInt(this[attrName], 10);\n      if (intValue > Number.MAX_SAFE_INTEGER) {\n        return Infinity;\n      }\n      return intValue;\n    };\n    _proto.hexadecimalInteger = function hexadecimalInteger(attrName) {\n      if (this[attrName]) {\n        var stringValue = (this[attrName] || '0x').slice(2);\n        stringValue = (stringValue.length & 1 ? '0' : '') + stringValue;\n        var value = new Uint8Array(stringValue.length / 2);\n        for (var i = 0; i < stringValue.length / 2; i++) {\n          value[i] = parseInt(stringValue.slice(i * 2, i * 2 + 2), 16);\n        }\n        return value;\n      } else {\n        return null;\n      }\n    };\n    _proto.hexadecimalIntegerAsNumber = function hexadecimalIntegerAsNumber(attrName) {\n      var intValue = parseInt(this[attrName], 16);\n      if (intValue > Number.MAX_SAFE_INTEGER) {\n        return Infinity;\n      }\n      return intValue;\n    };\n    _proto.decimalFloatingPoint = function decimalFloatingPoint(attrName) {\n      return parseFloat(this[attrName]);\n    };\n    _proto.optionalFloat = function optionalFloat(attrName, defaultValue) {\n      var value = this[attrName];\n      return value ? parseFloat(value) : defaultValue;\n    };\n    _proto.enumeratedString = function enumeratedString(attrName) {\n      return this[attrName];\n    };\n    _proto.bool = function bool(attrName) {\n      return this[attrName] === 'YES';\n    };\n    _proto.decimalResolution = function decimalResolution(attrName) {\n      var res = DECIMAL_RESOLUTION_REGEX.exec(this[attrName]);\n      if (res === null) {\n        return undefined;\n      }\n      return {\n        width: parseInt(res[1], 10),\n        height: parseInt(res[2], 10)\n      };\n    };\n    AttrList.parseAttrList = function parseAttrList(input) {\n      var match;\n      var attrs = {};\n      var quote = '\"';\n      ATTR_LIST_REGEX.lastIndex = 0;\n      while ((match = ATTR_LIST_REGEX.exec(input)) !== null) {\n        var value = match[2];\n        if (value.indexOf(quote) === 0 && value.lastIndexOf(quote) === value.length - 1) {\n          value = value.slice(1, -1);\n        }\n        var name = match[1].trim();\n        attrs[name] = value;\n      }\n      return attrs;\n    };\n    _createClass(AttrList, [{\n      key: \"clientAttrs\",\n      get: function get() {\n        return Object.keys(this).filter(function (attr) {\n          return attr.substring(0, 2) === 'X-';\n        });\n      }\n    }]);\n    return AttrList;\n  }();\n\n  // Avoid exporting const enum so that these values can be inlined\n\n  function isDateRangeCueAttribute(attrName) {\n    return attrName !== \"ID\" && attrName !== \"CLASS\" && attrName !== \"START-DATE\" && attrName !== \"DURATION\" && attrName !== \"END-DATE\" && attrName !== \"END-ON-NEXT\";\n  }\n  function isSCTE35Attribute(attrName) {\n    return attrName === \"SCTE35-OUT\" || attrName === \"SCTE35-IN\";\n  }\n  var DateRange = /*#__PURE__*/function () {\n    function DateRange(dateRangeAttr, dateRangeWithSameId) {\n      this.attr = void 0;\n      this._startDate = void 0;\n      this._endDate = void 0;\n      this._badValueForSameId = void 0;\n      if (dateRangeWithSameId) {\n        var previousAttr = dateRangeWithSameId.attr;\n        for (var key in previousAttr) {\n          if (Object.prototype.hasOwnProperty.call(dateRangeAttr, key) && dateRangeAttr[key] !== previousAttr[key]) {\n            logger.warn(\"DATERANGE tag attribute: \\\"\" + key + \"\\\" does not match for tags with ID: \\\"\" + dateRangeAttr.ID + \"\\\"\");\n            this._badValueForSameId = key;\n            break;\n          }\n        }\n        // Merge DateRange tags with the same ID\n        dateRangeAttr = _extends(new AttrList({}), previousAttr, dateRangeAttr);\n      }\n      this.attr = dateRangeAttr;\n      this._startDate = new Date(dateRangeAttr[\"START-DATE\"]);\n      if (\"END-DATE\" in this.attr) {\n        var endDate = new Date(this.attr[\"END-DATE\"]);\n        if (isFiniteNumber(endDate.getTime())) {\n          this._endDate = endDate;\n        }\n      }\n    }\n    _createClass(DateRange, [{\n      key: \"id\",\n      get: function get() {\n        return this.attr.ID;\n      }\n    }, {\n      key: \"class\",\n      get: function get() {\n        return this.attr.CLASS;\n      }\n    }, {\n      key: \"startDate\",\n      get: function get() {\n        return this._startDate;\n      }\n    }, {\n      key: \"endDate\",\n      get: function get() {\n        if (this._endDate) {\n          return this._endDate;\n        }\n        var duration = this.duration;\n        if (duration !== null) {\n          return new Date(this._startDate.getTime() + duration * 1000);\n        }\n        return null;\n      }\n    }, {\n      key: \"duration\",\n      get: function get() {\n        if (\"DURATION\" in this.attr) {\n          var duration = this.attr.decimalFloatingPoint(\"DURATION\");\n          if (isFiniteNumber(duration)) {\n            return duration;\n          }\n        } else if (this._endDate) {\n          return (this._endDate.getTime() - this._startDate.getTime()) / 1000;\n        }\n        return null;\n      }\n    }, {\n      key: \"plannedDuration\",\n      get: function get() {\n        if (\"PLANNED-DURATION\" in this.attr) {\n          return this.attr.decimalFloatingPoint(\"PLANNED-DURATION\");\n        }\n        return null;\n      }\n    }, {\n      key: \"endOnNext\",\n      get: function get() {\n        return this.attr.bool(\"END-ON-NEXT\");\n      }\n    }, {\n      key: \"isValid\",\n      get: function get() {\n        return !!this.id && !this._badValueForSameId && isFiniteNumber(this.startDate.getTime()) && (this.duration === null || this.duration >= 0) && (!this.endOnNext || !!this.class);\n      }\n    }]);\n    return DateRange;\n  }();\n\n  var LoadStats = function LoadStats() {\n    this.aborted = false;\n    this.loaded = 0;\n    this.retry = 0;\n    this.total = 0;\n    this.chunkCount = 0;\n    this.bwEstimate = 0;\n    this.loading = {\n      start: 0,\n      first: 0,\n      end: 0\n    };\n    this.parsing = {\n      start: 0,\n      end: 0\n    };\n    this.buffering = {\n      start: 0,\n      first: 0,\n      end: 0\n    };\n  };\n\n  var ElementaryStreamTypes = {\n    AUDIO: \"audio\",\n    VIDEO: \"video\",\n    AUDIOVIDEO: \"audiovideo\"\n  };\n  var BaseSegment = /*#__PURE__*/function () {\n    function BaseSegment(baseurl) {\n      var _this$elementaryStrea;\n      this._byteRange = null;\n      this._url = null;\n      // baseurl is the URL to the playlist\n      this.baseurl = void 0;\n      // relurl is the portion of the URL that comes from inside the playlist.\n      this.relurl = void 0;\n      // Holds the types of data this fragment supports\n      this.elementaryStreams = (_this$elementaryStrea = {}, _this$elementaryStrea[ElementaryStreamTypes.AUDIO] = null, _this$elementaryStrea[ElementaryStreamTypes.VIDEO] = null, _this$elementaryStrea[ElementaryStreamTypes.AUDIOVIDEO] = null, _this$elementaryStrea);\n      this.baseurl = baseurl;\n    }\n\n    // setByteRange converts a EXT-X-BYTERANGE attribute into a two element array\n    var _proto = BaseSegment.prototype;\n    _proto.setByteRange = function setByteRange(value, previous) {\n      var params = value.split('@', 2);\n      var start;\n      if (params.length === 1) {\n        start = (previous == null ? void 0 : previous.byteRangeEndOffset) || 0;\n      } else {\n        start = parseInt(params[1]);\n      }\n      this._byteRange = [start, parseInt(params[0]) + start];\n    };\n    _createClass(BaseSegment, [{\n      key: \"byteRange\",\n      get: function get() {\n        if (!this._byteRange) {\n          return [];\n        }\n        return this._byteRange;\n      }\n    }, {\n      key: \"byteRangeStartOffset\",\n      get: function get() {\n        return this.byteRange[0];\n      }\n    }, {\n      key: \"byteRangeEndOffset\",\n      get: function get() {\n        return this.byteRange[1];\n      }\n    }, {\n      key: \"url\",\n      get: function get() {\n        if (!this._url && this.baseurl && this.relurl) {\n          this._url = urlToolkitExports.buildAbsoluteURL(this.baseurl, this.relurl, {\n            alwaysNormalize: true\n          });\n        }\n        return this._url || '';\n      },\n      set: function set(value) {\n        this._url = value;\n      }\n    }]);\n    return BaseSegment;\n  }();\n\n  /**\n   * Object representing parsed data from an HLS Segment. Found in {@link hls.js#LevelDetails.fragments}.\n   */\n  var Fragment = /*#__PURE__*/function (_BaseSegment) {\n    _inheritsLoose(Fragment, _BaseSegment);\n    function Fragment(type, baseurl) {\n      var _this;\n      _this = _BaseSegment.call(this, baseurl) || this;\n      _this._decryptdata = null;\n      _this.rawProgramDateTime = null;\n      _this.programDateTime = null;\n      _this.tagList = [];\n      // EXTINF has to be present for a m3u8 to be considered valid\n      _this.duration = 0;\n      // sn notates the sequence number for a segment, and if set to a string can be 'initSegment'\n      _this.sn = 0;\n      // levelkeys are the EXT-X-KEY tags that apply to this segment for decryption\n      // core difference from the private field _decryptdata is the lack of the initialized IV\n      // _decryptdata will set the IV for this segment based on the segment number in the fragment\n      _this.levelkeys = void 0;\n      // A string representing the fragment type\n      _this.type = void 0;\n      // A reference to the loader. Set while the fragment is loading, and removed afterwards. Used to abort fragment loading\n      _this.loader = null;\n      // A reference to the key loader. Set while the key is loading, and removed afterwards. Used to abort key loading\n      _this.keyLoader = null;\n      // The level/track index to which the fragment belongs\n      _this.level = -1;\n      // The continuity counter of the fragment\n      _this.cc = 0;\n      // The starting Presentation Time Stamp (PTS) of the fragment. Set after transmux complete.\n      _this.startPTS = void 0;\n      // The ending Presentation Time Stamp (PTS) of the fragment. Set after transmux complete.\n      _this.endPTS = void 0;\n      // The starting Decode Time Stamp (DTS) of the fragment. Set after transmux complete.\n      _this.startDTS = void 0;\n      // The ending Decode Time Stamp (DTS) of the fragment. Set after transmux complete.\n      _this.endDTS = void 0;\n      // The start time of the fragment, as listed in the manifest. Updated after transmux complete.\n      _this.start = 0;\n      // Set by `updateFragPTSDTS` in level-helper\n      _this.deltaPTS = void 0;\n      // The maximum starting Presentation Time Stamp (audio/video PTS) of the fragment. Set after transmux complete.\n      _this.maxStartPTS = void 0;\n      // The minimum ending Presentation Time Stamp (audio/video PTS) of the fragment. Set after transmux complete.\n      _this.minEndPTS = void 0;\n      // Load/parse timing information\n      _this.stats = new LoadStats();\n      // Init Segment bytes (unset for media segments)\n      _this.data = void 0;\n      // A flag indicating whether the segment was downloaded in order to test bitrate, and was not buffered\n      _this.bitrateTest = false;\n      // #EXTINF  segment title\n      _this.title = null;\n      // The Media Initialization Section for this segment\n      _this.initSegment = null;\n      // Fragment is the last fragment in the media playlist\n      _this.endList = void 0;\n      // Fragment is marked by an EXT-X-GAP tag indicating that it does not contain media data and should not be loaded\n      _this.gap = void 0;\n      // Deprecated\n      _this.urlId = 0;\n      _this.type = type;\n      return _this;\n    }\n    var _proto2 = Fragment.prototype;\n    _proto2.setKeyFormat = function setKeyFormat(keyFormat) {\n      if (this.levelkeys) {\n        var _key = this.levelkeys[keyFormat];\n        if (_key && !this._decryptdata) {\n          this._decryptdata = _key.getDecryptData(this.sn);\n        }\n      }\n    };\n    _proto2.abortRequests = function abortRequests() {\n      var _this$loader, _this$keyLoader;\n      (_this$loader = this.loader) == null ? void 0 : _this$loader.abort();\n      (_this$keyLoader = this.keyLoader) == null ? void 0 : _this$keyLoader.abort();\n    };\n    _proto2.setElementaryStreamInfo = function setElementaryStreamInfo(type, startPTS, endPTS, startDTS, endDTS, partial) {\n      if (partial === void 0) {\n        partial = false;\n      }\n      var elementaryStreams = this.elementaryStreams;\n      var info = elementaryStreams[type];\n      if (!info) {\n        elementaryStreams[type] = {\n          startPTS: startPTS,\n          endPTS: endPTS,\n          startDTS: startDTS,\n          endDTS: endDTS,\n          partial: partial\n        };\n        return;\n      }\n      info.startPTS = Math.min(info.startPTS, startPTS);\n      info.endPTS = Math.max(info.endPTS, endPTS);\n      info.startDTS = Math.min(info.startDTS, startDTS);\n      info.endDTS = Math.max(info.endDTS, endDTS);\n    };\n    _proto2.clearElementaryStreamInfo = function clearElementaryStreamInfo() {\n      var elementaryStreams = this.elementaryStreams;\n      elementaryStreams[ElementaryStreamTypes.AUDIO] = null;\n      elementaryStreams[ElementaryStreamTypes.VIDEO] = null;\n      elementaryStreams[ElementaryStreamTypes.AUDIOVIDEO] = null;\n    };\n    _createClass(Fragment, [{\n      key: \"decryptdata\",\n      get: function get() {\n        var levelkeys = this.levelkeys;\n        if (!levelkeys && !this._decryptdata) {\n          return null;\n        }\n        if (!this._decryptdata && this.levelkeys && !this.levelkeys.NONE) {\n          var _key2 = this.levelkeys.identity;\n          if (_key2) {\n            this._decryptdata = _key2.getDecryptData(this.sn);\n          } else {\n            var keyFormats = Object.keys(this.levelkeys);\n            if (keyFormats.length === 1) {\n              return this._decryptdata = this.levelkeys[keyFormats[0]].getDecryptData(this.sn);\n            }\n          }\n        }\n        return this._decryptdata;\n      }\n    }, {\n      key: \"end\",\n      get: function get() {\n        return this.start + this.duration;\n      }\n    }, {\n      key: \"endProgramDateTime\",\n      get: function get() {\n        if (this.programDateTime === null) {\n          return null;\n        }\n        if (!isFiniteNumber(this.programDateTime)) {\n          return null;\n        }\n        var duration = !isFiniteNumber(this.duration) ? 0 : this.duration;\n        return this.programDateTime + duration * 1000;\n      }\n    }, {\n      key: \"encrypted\",\n      get: function get() {\n        var _this$_decryptdata;\n        // At the m3u8-parser level we need to add support for manifest signalled keyformats\n        // when we want the fragment to start reporting that it is encrypted.\n        // Currently, keyFormat will only be set for identity keys\n        if ((_this$_decryptdata = this._decryptdata) != null && _this$_decryptdata.encrypted) {\n          return true;\n        } else if (this.levelkeys) {\n          var keyFormats = Object.keys(this.levelkeys);\n          var len = keyFormats.length;\n          if (len > 1 || len === 1 && this.levelkeys[keyFormats[0]].encrypted) {\n            return true;\n          }\n        }\n        return false;\n      }\n    }]);\n    return Fragment;\n  }(BaseSegment);\n\n  /**\n   * Object representing parsed data from an HLS Partial Segment. Found in {@link hls.js#LevelDetails.partList}.\n   */\n  var Part = /*#__PURE__*/function (_BaseSegment2) {\n    _inheritsLoose(Part, _BaseSegment2);\n    function Part(partAttrs, frag, baseurl, index, previous) {\n      var _this2;\n      _this2 = _BaseSegment2.call(this, baseurl) || this;\n      _this2.fragOffset = 0;\n      _this2.duration = 0;\n      _this2.gap = false;\n      _this2.independent = false;\n      _this2.relurl = void 0;\n      _this2.fragment = void 0;\n      _this2.index = void 0;\n      _this2.stats = new LoadStats();\n      _this2.duration = partAttrs.decimalFloatingPoint('DURATION');\n      _this2.gap = partAttrs.bool('GAP');\n      _this2.independent = partAttrs.bool('INDEPENDENT');\n      _this2.relurl = partAttrs.enumeratedString('URI');\n      _this2.fragment = frag;\n      _this2.index = index;\n      var byteRange = partAttrs.enumeratedString('BYTERANGE');\n      if (byteRange) {\n        _this2.setByteRange(byteRange, previous);\n      }\n      if (previous) {\n        _this2.fragOffset = previous.fragOffset + previous.duration;\n      }\n      return _this2;\n    }\n    _createClass(Part, [{\n      key: \"start\",\n      get: function get() {\n        return this.fragment.start + this.fragOffset;\n      }\n    }, {\n      key: \"end\",\n      get: function get() {\n        return this.start + this.duration;\n      }\n    }, {\n      key: \"loaded\",\n      get: function get() {\n        var elementaryStreams = this.elementaryStreams;\n        return !!(elementaryStreams.audio || elementaryStreams.video || elementaryStreams.audiovideo);\n      }\n    }]);\n    return Part;\n  }(BaseSegment);\n\n  var DEFAULT_TARGET_DURATION = 10;\n\n  /**\n   * Object representing parsed data from an HLS Media Playlist. Found in {@link hls.js#Level.details}.\n   */\n  var LevelDetails = /*#__PURE__*/function () {\n    function LevelDetails(baseUrl) {\n      this.PTSKnown = false;\n      this.alignedSliding = false;\n      this.averagetargetduration = void 0;\n      this.endCC = 0;\n      this.endSN = 0;\n      this.fragments = void 0;\n      this.fragmentHint = void 0;\n      this.partList = null;\n      this.dateRanges = void 0;\n      this.live = true;\n      this.ageHeader = 0;\n      this.advancedDateTime = void 0;\n      this.updated = true;\n      this.advanced = true;\n      this.availabilityDelay = void 0;\n      // Manifest reload synchronization\n      this.misses = 0;\n      this.startCC = 0;\n      this.startSN = 0;\n      this.startTimeOffset = null;\n      this.targetduration = 0;\n      this.totalduration = 0;\n      this.type = null;\n      this.url = void 0;\n      this.m3u8 = '';\n      this.version = null;\n      this.canBlockReload = false;\n      this.canSkipUntil = 0;\n      this.canSkipDateRanges = false;\n      this.skippedSegments = 0;\n      this.recentlyRemovedDateranges = void 0;\n      this.partHoldBack = 0;\n      this.holdBack = 0;\n      this.partTarget = 0;\n      this.preloadHint = void 0;\n      this.renditionReports = void 0;\n      this.tuneInGoal = 0;\n      this.deltaUpdateFailed = void 0;\n      this.driftStartTime = 0;\n      this.driftEndTime = 0;\n      this.driftStart = 0;\n      this.driftEnd = 0;\n      this.encryptedFragments = void 0;\n      this.playlistParsingError = null;\n      this.variableList = null;\n      this.hasVariableRefs = false;\n      this.fragments = [];\n      this.encryptedFragments = [];\n      this.dateRanges = {};\n      this.url = baseUrl;\n    }\n    var _proto = LevelDetails.prototype;\n    _proto.reloaded = function reloaded(previous) {\n      if (!previous) {\n        this.advanced = true;\n        this.updated = true;\n        return;\n      }\n      var partSnDiff = this.lastPartSn - previous.lastPartSn;\n      var partIndexDiff = this.lastPartIndex - previous.lastPartIndex;\n      this.updated = this.endSN !== previous.endSN || !!partIndexDiff || !!partSnDiff || !this.live;\n      this.advanced = this.endSN > previous.endSN || partSnDiff > 0 || partSnDiff === 0 && partIndexDiff > 0;\n      if (this.updated || this.advanced) {\n        this.misses = Math.floor(previous.misses * 0.6);\n      } else {\n        this.misses = previous.misses + 1;\n      }\n      this.availabilityDelay = previous.availabilityDelay;\n    };\n    _createClass(LevelDetails, [{\n      key: \"hasProgramDateTime\",\n      get: function get() {\n        if (this.fragments.length) {\n          return isFiniteNumber(this.fragments[this.fragments.length - 1].programDateTime);\n        }\n        return false;\n      }\n    }, {\n      key: \"levelTargetDuration\",\n      get: function get() {\n        return this.averagetargetduration || this.targetduration || DEFAULT_TARGET_DURATION;\n      }\n    }, {\n      key: \"drift\",\n      get: function get() {\n        var runTime = this.driftEndTime - this.driftStartTime;\n        if (runTime > 0) {\n          var runDuration = this.driftEnd - this.driftStart;\n          return runDuration * 1000 / runTime;\n        }\n        return 1;\n      }\n    }, {\n      key: \"edge\",\n      get: function get() {\n        return this.partEnd || this.fragmentEnd;\n      }\n    }, {\n      key: \"partEnd\",\n      get: function get() {\n        var _this$partList;\n        if ((_this$partList = this.partList) != null && _this$partList.length) {\n          return this.partList[this.partList.length - 1].end;\n        }\n        return this.fragmentEnd;\n      }\n    }, {\n      key: \"fragmentEnd\",\n      get: function get() {\n        var _this$fragments;\n        if ((_this$fragments = this.fragments) != null && _this$fragments.length) {\n          return this.fragments[this.fragments.length - 1].end;\n        }\n        return 0;\n      }\n    }, {\n      key: \"age\",\n      get: function get() {\n        if (this.advancedDateTime) {\n          return Math.max(Date.now() - this.advancedDateTime, 0) / 1000;\n        }\n        return 0;\n      }\n    }, {\n      key: \"lastPartIndex\",\n      get: function get() {\n        var _this$partList2;\n        if ((_this$partList2 = this.partList) != null && _this$partList2.length) {\n          return this.partList[this.partList.length - 1].index;\n        }\n        return -1;\n      }\n    }, {\n      key: \"lastPartSn\",\n      get: function get() {\n        var _this$partList3;\n        if ((_this$partList3 = this.partList) != null && _this$partList3.length) {\n          return this.partList[this.partList.length - 1].fragment.sn;\n        }\n        return this.endSN;\n      }\n    }]);\n    return LevelDetails;\n  }();\n\n  function base64Decode(base64encodedStr) {\n    return Uint8Array.from(atob(base64encodedStr), function (c) {\n      return c.charCodeAt(0);\n    });\n  }\n\n  function getKeyIdBytes(str) {\n    var keyIdbytes = strToUtf8array(str).subarray(0, 16);\n    var paddedkeyIdbytes = new Uint8Array(16);\n    paddedkeyIdbytes.set(keyIdbytes, 16 - keyIdbytes.length);\n    return paddedkeyIdbytes;\n  }\n  function changeEndianness(keyId) {\n    var swap = function swap(array, from, to) {\n      var cur = array[from];\n      array[from] = array[to];\n      array[to] = cur;\n    };\n    swap(keyId, 0, 3);\n    swap(keyId, 1, 2);\n    swap(keyId, 4, 5);\n    swap(keyId, 6, 7);\n  }\n  function convertDataUriToArrayBytes(uri) {\n    // data:[<media type][;attribute=value][;base64],<data>\n    var colonsplit = uri.split(':');\n    var keydata = null;\n    if (colonsplit[0] === 'data' && colonsplit.length === 2) {\n      var semicolonsplit = colonsplit[1].split(';');\n      var commasplit = semicolonsplit[semicolonsplit.length - 1].split(',');\n      if (commasplit.length === 2) {\n        var isbase64 = commasplit[0] === 'base64';\n        var data = commasplit[1];\n        if (isbase64) {\n          semicolonsplit.splice(-1, 1); // remove from processing\n          keydata = base64Decode(data);\n        } else {\n          keydata = getKeyIdBytes(data);\n        }\n      }\n    }\n    return keydata;\n  }\n  function strToUtf8array(str) {\n    return Uint8Array.from(unescape(encodeURIComponent(str)), function (c) {\n      return c.charCodeAt(0);\n    });\n  }\n\n  /** returns `undefined` is `self` is missing, e.g. in node */\n  var optionalSelf = typeof self !== 'undefined' ? self : undefined;\n\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/API/Navigator/requestMediaKeySystemAccess\n   */\n  var KeySystems = {\n    CLEARKEY: \"org.w3.clearkey\",\n    FAIRPLAY: \"com.apple.fps\",\n    PLAYREADY: \"com.microsoft.playready\",\n    WIDEVINE: \"com.widevine.alpha\"\n  };\n\n  // Playlist #EXT-X-KEY KEYFORMAT values\n  var KeySystemFormats = {\n    CLEARKEY: \"org.w3.clearkey\",\n    FAIRPLAY: \"com.apple.streamingkeydelivery\",\n    PLAYREADY: \"com.microsoft.playready\",\n    WIDEVINE: \"urn:uuid:edef8ba9-79d6-4ace-a3c8-27dcd51d21ed\"\n  };\n  function keySystemFormatToKeySystemDomain(format) {\n    switch (format) {\n      case KeySystemFormats.FAIRPLAY:\n        return KeySystems.FAIRPLAY;\n      case KeySystemFormats.PLAYREADY:\n        return KeySystems.PLAYREADY;\n      case KeySystemFormats.WIDEVINE:\n        return KeySystems.WIDEVINE;\n      case KeySystemFormats.CLEARKEY:\n        return KeySystems.CLEARKEY;\n    }\n  }\n\n  // System IDs for which we can extract a key ID from \"encrypted\" event PSSH\n  var KeySystemIds = {\n    CENC: \"1077efecc0b24d02ace33c1e52e2fb4b\",\n    CLEARKEY: \"e2719d58a985b3c9781ab030af78d30e\",\n    FAIRPLAY: \"94ce86fb07ff4f43adb893d2fa968ca2\",\n    PLAYREADY: \"9a04f07998404286ab92e65be0885f95\",\n    WIDEVINE: \"edef8ba979d64acea3c827dcd51d21ed\"\n  };\n  function keySystemIdToKeySystemDomain(systemId) {\n    if (systemId === KeySystemIds.WIDEVINE) {\n      return KeySystems.WIDEVINE;\n    } else if (systemId === KeySystemIds.PLAYREADY) {\n      return KeySystems.PLAYREADY;\n    } else if (systemId === KeySystemIds.CENC || systemId === KeySystemIds.CLEARKEY) {\n      return KeySystems.CLEARKEY;\n    }\n  }\n  function keySystemDomainToKeySystemFormat(keySystem) {\n    switch (keySystem) {\n      case KeySystems.FAIRPLAY:\n        return KeySystemFormats.FAIRPLAY;\n      case KeySystems.PLAYREADY:\n        return KeySystemFormats.PLAYREADY;\n      case KeySystems.WIDEVINE:\n        return KeySystemFormats.WIDEVINE;\n      case KeySystems.CLEARKEY:\n        return KeySystemFormats.CLEARKEY;\n    }\n  }\n  function getKeySystemsForConfig(config) {\n    var drmSystems = config.drmSystems,\n      widevineLicenseUrl = config.widevineLicenseUrl;\n    var keySystemsToAttempt = drmSystems ? [KeySystems.FAIRPLAY, KeySystems.WIDEVINE, KeySystems.PLAYREADY, KeySystems.CLEARKEY].filter(function (keySystem) {\n      return !!drmSystems[keySystem];\n    }) : [];\n    if (!keySystemsToAttempt[KeySystems.WIDEVINE] && widevineLicenseUrl) {\n      keySystemsToAttempt.push(KeySystems.WIDEVINE);\n    }\n    return keySystemsToAttempt;\n  }\n  var requestMediaKeySystemAccess = function (_optionalSelf$navigat) {\n    if (optionalSelf != null && (_optionalSelf$navigat = optionalSelf.navigator) != null && _optionalSelf$navigat.requestMediaKeySystemAccess) {\n      return self.navigator.requestMediaKeySystemAccess.bind(self.navigator);\n    } else {\n      return null;\n    }\n  }();\n\n  /**\n   * @see https://developer.mozilla.org/en-US/docs/Web/API/MediaKeySystemConfiguration\n   */\n  function getSupportedMediaKeySystemConfigurations(keySystem, audioCodecs, videoCodecs, drmSystemOptions) {\n    var initDataTypes;\n    switch (keySystem) {\n      case KeySystems.FAIRPLAY:\n        initDataTypes = ['cenc', 'sinf'];\n        break;\n      case KeySystems.WIDEVINE:\n      case KeySystems.PLAYREADY:\n        initDataTypes = ['cenc'];\n        break;\n      case KeySystems.CLEARKEY:\n        initDataTypes = ['cenc', 'keyids'];\n        break;\n      default:\n        throw new Error(\"Unknown key-system: \" + keySystem);\n    }\n    return createMediaKeySystemConfigurations(initDataTypes, audioCodecs, videoCodecs, drmSystemOptions);\n  }\n  function createMediaKeySystemConfigurations(initDataTypes, audioCodecs, videoCodecs, drmSystemOptions) {\n    var baseConfig = {\n      initDataTypes: initDataTypes,\n      persistentState: drmSystemOptions.persistentState || 'optional',\n      distinctiveIdentifier: drmSystemOptions.distinctiveIdentifier || 'optional',\n      sessionTypes: drmSystemOptions.sessionTypes || [drmSystemOptions.sessionType || 'temporary'],\n      audioCapabilities: audioCodecs.map(function (codec) {\n        return {\n          contentType: \"audio/mp4; codecs=\\\"\" + codec + \"\\\"\",\n          robustness: drmSystemOptions.audioRobustness || '',\n          encryptionScheme: drmSystemOptions.audioEncryptionScheme || null\n        };\n      }),\n      videoCapabilities: videoCodecs.map(function (codec) {\n        return {\n          contentType: \"video/mp4; codecs=\\\"\" + codec + \"\\\"\",\n          robustness: drmSystemOptions.videoRobustness || '',\n          encryptionScheme: drmSystemOptions.videoEncryptionScheme || null\n        };\n      })\n    };\n    return [baseConfig];\n  }\n\n  function sliceUint8(array, start, end) {\n    // @ts-expect-error This polyfills IE11 usage of Uint8Array slice.\n    // It always exists in the TypeScript definition so fails, but it fails at runtime on IE11.\n    return Uint8Array.prototype.slice ? array.slice(start, end) : new Uint8Array(Array.prototype.slice.call(array, start, end));\n  }\n\n  // breaking up those two types in order to clarify what is happening in the decoding path.\n\n  /**\n   * Returns true if an ID3 header can be found at offset in data\n   * @param data - The data to search\n   * @param offset - The offset at which to start searching\n   */\n  var isHeader$2 = function isHeader(data, offset) {\n    /*\n     * http://id3.org/id3v2.3.0\n     * [0]     = 'I'\n     * [1]     = 'D'\n     * [2]     = '3'\n     * [3,4]   = {Version}\n     * [5]     = {Flags}\n     * [6-9]   = {ID3 Size}\n     *\n     * An ID3v2 tag can be detected with the following pattern:\n     *  $49 44 33 yy yy xx zz zz zz zz\n     * Where yy is less than $FF, xx is the 'flags' byte and zz is less than $80\n     */\n    if (offset + 10 <= data.length) {\n      // look for 'ID3' identifier\n      if (data[offset] === 0x49 && data[offset + 1] === 0x44 && data[offset + 2] === 0x33) {\n        // check version is within range\n        if (data[offset + 3] < 0xff && data[offset + 4] < 0xff) {\n          // check size is within range\n          if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) {\n            return true;\n          }\n        }\n      }\n    }\n    return false;\n  };\n\n  /**\n   * Returns true if an ID3 footer can be found at offset in data\n   * @param data - The data to search\n   * @param offset - The offset at which to start searching\n   */\n  var isFooter = function isFooter(data, offset) {\n    /*\n     * The footer is a copy of the header, but with a different identifier\n     */\n    if (offset + 10 <= data.length) {\n      // look for '3DI' identifier\n      if (data[offset] === 0x33 && data[offset + 1] === 0x44 && data[offset + 2] === 0x49) {\n        // check version is within range\n        if (data[offset + 3] < 0xff && data[offset + 4] < 0xff) {\n          // check size is within range\n          if (data[offset + 6] < 0x80 && data[offset + 7] < 0x80 && data[offset + 8] < 0x80 && data[offset + 9] < 0x80) {\n            return true;\n          }\n        }\n      }\n    }\n    return false;\n  };\n\n  /**\n   * Returns any adjacent ID3 tags found in data starting at offset, as one block of data\n   * @param data - The data to search in\n   * @param offset - The offset at which to start searching\n   * @returns the block of data containing any ID3 tags found\n   * or *undefined* if no header is found at the starting offset\n   */\n  var getID3Data = function getID3Data(data, offset) {\n    var front = offset;\n    var length = 0;\n    while (isHeader$2(data, offset)) {\n      // ID3 header is 10 bytes\n      length += 10;\n      var size = readSize(data, offset + 6);\n      length += size;\n      if (isFooter(data, offset + 10)) {\n        // ID3 footer is 10 bytes\n        length += 10;\n      }\n      offset += length;\n    }\n    if (length > 0) {\n      return data.subarray(front, front + length);\n    }\n    return undefined;\n  };\n  var readSize = function readSize(data, offset) {\n    var size = 0;\n    size = (data[offset] & 0x7f) << 21;\n    size |= (data[offset + 1] & 0x7f) << 14;\n    size |= (data[offset + 2] & 0x7f) << 7;\n    size |= data[offset + 3] & 0x7f;\n    return size;\n  };\n  var canParse$2 = function canParse(data, offset) {\n    return isHeader$2(data, offset) && readSize(data, offset + 6) + 10 <= data.length - offset;\n  };\n\n  /**\n   * Searches for the Elementary Stream timestamp found in the ID3 data chunk\n   * @param data - Block of data containing one or more ID3 tags\n   */\n  var getTimeStamp = function getTimeStamp(data) {\n    var frames = getID3Frames(data);\n    for (var i = 0; i < frames.length; i++) {\n      var frame = frames[i];\n      if (isTimeStampFrame(frame)) {\n        return readTimeStamp(frame);\n      }\n    }\n    return undefined;\n  };\n\n  /**\n   * Returns true if the ID3 frame is an Elementary Stream timestamp frame\n   */\n  var isTimeStampFrame = function isTimeStampFrame(frame) {\n    return frame && frame.key === 'PRIV' && frame.info === 'com.apple.streaming.transportStreamTimestamp';\n  };\n  var getFrameData = function getFrameData(data) {\n    /*\n    Frame ID       $xx xx xx xx (four characters)\n    Size           $xx xx xx xx\n    Flags          $xx xx\n    */\n    var type = String.fromCharCode(data[0], data[1], data[2], data[3]);\n    var size = readSize(data, 4);\n\n    // skip frame id, size, and flags\n    var offset = 10;\n    return {\n      type: type,\n      size: size,\n      data: data.subarray(offset, offset + size)\n    };\n  };\n\n  /**\n   * Returns an array of ID3 frames found in all the ID3 tags in the id3Data\n   * @param id3Data - The ID3 data containing one or more ID3 tags\n   */\n  var getID3Frames = function getID3Frames(id3Data) {\n    var offset = 0;\n    var frames = [];\n    while (isHeader$2(id3Data, offset)) {\n      var size = readSize(id3Data, offset + 6);\n      // skip past ID3 header\n      offset += 10;\n      var end = offset + size;\n      // loop through frames in the ID3 tag\n      while (offset + 8 < end) {\n        var frameData = getFrameData(id3Data.subarray(offset));\n        var frame = decodeFrame(frameData);\n        if (frame) {\n          frames.push(frame);\n        }\n\n        // skip frame header and frame data\n        offset += frameData.size + 10;\n      }\n      if (isFooter(id3Data, offset)) {\n        offset += 10;\n      }\n    }\n    return frames;\n  };\n  var decodeFrame = function decodeFrame(frame) {\n    if (frame.type === 'PRIV') {\n      return decodePrivFrame(frame);\n    } else if (frame.type[0] === 'W') {\n      return decodeURLFrame(frame);\n    }\n    return decodeTextFrame(frame);\n  };\n  var decodePrivFrame = function decodePrivFrame(frame) {\n    /*\n    Format: <text string>\\0<binary data>\n    */\n    if (frame.size < 2) {\n      return undefined;\n    }\n    var owner = utf8ArrayToStr(frame.data, true);\n    var privateData = new Uint8Array(frame.data.subarray(owner.length + 1));\n    return {\n      key: frame.type,\n      info: owner,\n      data: privateData.buffer\n    };\n  };\n  var decodeTextFrame = function decodeTextFrame(frame) {\n    if (frame.size < 2) {\n      return undefined;\n    }\n    if (frame.type === 'TXXX') {\n      /*\n      Format:\n      [0]   = {Text Encoding}\n      [1-?] = {Description}\\0{Value}\n      */\n      var index = 1;\n      var description = utf8ArrayToStr(frame.data.subarray(index), true);\n      index += description.length + 1;\n      var value = utf8ArrayToStr(frame.data.subarray(index));\n      return {\n        key: frame.type,\n        info: description,\n        data: value\n      };\n    }\n    /*\n    Format:\n    [0]   = {Text Encoding}\n    [1-?] = {Value}\n    */\n    var text = utf8ArrayToStr(frame.data.subarray(1));\n    return {\n      key: frame.type,\n      data: text\n    };\n  };\n  var decodeURLFrame = function decodeURLFrame(frame) {\n    if (frame.type === 'WXXX') {\n      /*\n      Format:\n      [0]   = {Text Encoding}\n      [1-?] = {Description}\\0{URL}\n      */\n      if (frame.size < 2) {\n        return undefined;\n      }\n      var index = 1;\n      var description = utf8ArrayToStr(frame.data.subarray(index), true);\n      index += description.length + 1;\n      var value = utf8ArrayToStr(frame.data.subarray(index));\n      return {\n        key: frame.type,\n        info: description,\n        data: value\n      };\n    }\n    /*\n    Format:\n    [0-?] = {URL}\n    */\n    var url = utf8ArrayToStr(frame.data);\n    return {\n      key: frame.type,\n      data: url\n    };\n  };\n  var readTimeStamp = function readTimeStamp(timeStampFrame) {\n    if (timeStampFrame.data.byteLength === 8) {\n      var data = new Uint8Array(timeStampFrame.data);\n      // timestamp is 33 bit expressed as a big-endian eight-octet number,\n      // with the upper 31 bits set to zero.\n      var pts33Bit = data[3] & 0x1;\n      var timestamp = (data[4] << 23) + (data[5] << 15) + (data[6] << 7) + data[7];\n      timestamp /= 45;\n      if (pts33Bit) {\n        timestamp += 47721858.84;\n      } // 2^32 / 90\n\n      return Math.round(timestamp);\n    }\n    return undefined;\n  };\n\n  // http://stackoverflow.com/questions/8936984/uint8array-to-string-in-javascript/22373197\n  // http://www.onicos.com/staff/iz/amuse/javascript/expert/utf.txt\n  /* utf.js - UTF-8 <=> UTF-16 convertion\n   *\n   * Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>\n   * Version: 1.0\n   * LastModified: Dec 25 1999\n   * This library is free.  You can redistribute it and/or modify it.\n   */\n  var utf8ArrayToStr = function utf8ArrayToStr(array, exitOnNull) {\n    if (exitOnNull === void 0) {\n      exitOnNull = false;\n    }\n    var decoder = getTextDecoder();\n    if (decoder) {\n      var decoded = decoder.decode(array);\n      if (exitOnNull) {\n        // grab up to the first null\n        var idx = decoded.indexOf('\\0');\n        return idx !== -1 ? decoded.substring(0, idx) : decoded;\n      }\n\n      // remove any null characters\n      return decoded.replace(/\\0/g, '');\n    }\n    var len = array.length;\n    var c;\n    var char2;\n    var char3;\n    var out = '';\n    var i = 0;\n    while (i < len) {\n      c = array[i++];\n      if (c === 0x00 && exitOnNull) {\n        return out;\n      } else if (c === 0x00 || c === 0x03) {\n        // If the character is 3 (END_OF_TEXT) or 0 (NULL) then skip it\n        continue;\n      }\n      switch (c >> 4) {\n        case 0:\n        case 1:\n        case 2:\n        case 3:\n        case 4:\n        case 5:\n        case 6:\n        case 7:\n          // 0xxxxxxx\n          out += String.fromCharCode(c);\n          break;\n        case 12:\n        case 13:\n          // 110x xxxx   10xx xxxx\n          char2 = array[i++];\n          out += String.fromCharCode((c & 0x1f) << 6 | char2 & 0x3f);\n          break;\n        case 14:\n          // 1110 xxxx  10xx xxxx  10xx xxxx\n          char2 = array[i++];\n          char3 = array[i++];\n          out += String.fromCharCode((c & 0x0f) << 12 | (char2 & 0x3f) << 6 | (char3 & 0x3f) << 0);\n          break;\n      }\n    }\n    return out;\n  };\n  var decoder;\n  function getTextDecoder() {\n    // On Play Station 4, TextDecoder is defined but partially implemented.\n    // Manual decoding option is preferable\n    if (navigator.userAgent.includes('PlayStation 4')) {\n      return;\n    }\n    if (!decoder && typeof self.TextDecoder !== 'undefined') {\n      decoder = new self.TextDecoder('utf-8');\n    }\n    return decoder;\n  }\n\n  /**\n   *  hex dump helper class\n   */\n\n  var Hex = {\n    hexDump: function hexDump(array) {\n      var str = '';\n      for (var i = 0; i < array.length; i++) {\n        var h = array[i].toString(16);\n        if (h.length < 2) {\n          h = '0' + h;\n        }\n        str += h;\n      }\n      return str;\n    }\n  };\n\n  var UINT32_MAX$1 = Math.pow(2, 32) - 1;\n  var push = [].push;\n\n  // We are using fixed track IDs for driving the MP4 remuxer\n  // instead of following the TS PIDs.\n  // There is no reason not to do this and some browsers/SourceBuffer-demuxers\n  // may not like if there are TrackID \"switches\"\n  // See https://github.com/video-dev/hls.js/issues/1331\n  // Here we are mapping our internal track types to constant MP4 track IDs\n  // With MSE currently one can only have one track of each, and we are muxing\n  // whatever video/audio rendition in them.\n  var RemuxerTrackIdConfig = {\n    video: 1,\n    audio: 2,\n    id3: 3,\n    text: 4\n  };\n  function bin2str(data) {\n    return String.fromCharCode.apply(null, data);\n  }\n  function readUint16(buffer, offset) {\n    var val = buffer[offset] << 8 | buffer[offset + 1];\n    return val < 0 ? 65536 + val : val;\n  }\n  function readUint32(buffer, offset) {\n    var val = readSint32(buffer, offset);\n    return val < 0 ? 4294967296 + val : val;\n  }\n  function readUint64(buffer, offset) {\n    var result = readUint32(buffer, offset);\n    result *= Math.pow(2, 32);\n    result += readUint32(buffer, offset + 4);\n    return result;\n  }\n  function readSint32(buffer, offset) {\n    return buffer[offset] << 24 | buffer[offset + 1] << 16 | buffer[offset + 2] << 8 | buffer[offset + 3];\n  }\n  function writeUint32(buffer, offset, value) {\n    buffer[offset] = value >> 24;\n    buffer[offset + 1] = value >> 16 & 0xff;\n    buffer[offset + 2] = value >> 8 & 0xff;\n    buffer[offset + 3] = value & 0xff;\n  }\n\n  // Find \"moof\" box\n  function hasMoofData(data) {\n    var end = data.byteLength;\n    for (var i = 0; i < end;) {\n      var size = readUint32(data, i);\n      if (size > 8 && data[i + 4] === 0x6d && data[i + 5] === 0x6f && data[i + 6] === 0x6f && data[i + 7] === 0x66) {\n        return true;\n      }\n      i = size > 1 ? i + size : end;\n    }\n    return false;\n  }\n\n  // Find the data for a box specified by its path\n  function findBox(data, path) {\n    var results = [];\n    if (!path.length) {\n      // short-circuit the search for empty paths\n      return results;\n    }\n    var end = data.byteLength;\n    for (var i = 0; i < end;) {\n      var size = readUint32(data, i);\n      var type = bin2str(data.subarray(i + 4, i + 8));\n      var endbox = size > 1 ? i + size : end;\n      if (type === path[0]) {\n        if (path.length === 1) {\n          // this is the end of the path and we've found the box we were\n          // looking for\n          results.push(data.subarray(i + 8, endbox));\n        } else {\n          // recursively search for the next box along the path\n          var subresults = findBox(data.subarray(i + 8, endbox), path.slice(1));\n          if (subresults.length) {\n            push.apply(results, subresults);\n          }\n        }\n      }\n      i = endbox;\n    }\n\n    // we've finished searching all of data\n    return results;\n  }\n  function parseSegmentIndex(sidx) {\n    var references = [];\n    var version = sidx[0];\n\n    // set initial offset, we skip the reference ID (not needed)\n    var index = 8;\n    var timescale = readUint32(sidx, index);\n    index += 4;\n    var earliestPresentationTime = 0;\n    var firstOffset = 0;\n    if (version === 0) {\n      earliestPresentationTime = readUint32(sidx, index);\n      firstOffset = readUint32(sidx, index + 4);\n      index += 8;\n    } else {\n      earliestPresentationTime = readUint64(sidx, index);\n      firstOffset = readUint64(sidx, index + 8);\n      index += 16;\n    }\n\n    // skip reserved\n    index += 2;\n    var startByte = sidx.length + firstOffset;\n    var referencesCount = readUint16(sidx, index);\n    index += 2;\n    for (var i = 0; i < referencesCount; i++) {\n      var referenceIndex = index;\n      var referenceInfo = readUint32(sidx, referenceIndex);\n      referenceIndex += 4;\n      var referenceSize = referenceInfo & 0x7fffffff;\n      var referenceType = (referenceInfo & 0x80000000) >>> 31;\n      if (referenceType === 1) {\n        logger.warn('SIDX has hierarchical references (not supported)');\n        return null;\n      }\n      var subsegmentDuration = readUint32(sidx, referenceIndex);\n      referenceIndex += 4;\n      references.push({\n        referenceSize: referenceSize,\n        subsegmentDuration: subsegmentDuration,\n        // unscaled\n        info: {\n          duration: subsegmentDuration / timescale,\n          start: startByte,\n          end: startByte + referenceSize - 1\n        }\n      });\n      startByte += referenceSize;\n\n      // Skipping 1 bit for |startsWithSap|, 3 bits for |sapType|, and 28 bits\n      // for |sapDelta|.\n      referenceIndex += 4;\n\n      // skip to next ref\n      index = referenceIndex;\n    }\n    return {\n      earliestPresentationTime: earliestPresentationTime,\n      timescale: timescale,\n      version: version,\n      referencesCount: referencesCount,\n      references: references\n    };\n  }\n\n  /**\n   * Parses an MP4 initialization segment and extracts stream type and\n   * timescale values for any declared tracks. Timescale values indicate the\n   * number of clock ticks per second to assume for time-based values\n   * elsewhere in the MP4.\n   *\n   * To determine the start time of an MP4, you need two pieces of\n   * information: the timescale unit and the earliest base media decode\n   * time. Multiple timescales can be specified within an MP4 but the\n   * base media decode time is always expressed in the timescale from\n   * the media header box for the track:\n   * ```\n   * moov > trak > mdia > mdhd.timescale\n   * moov > trak > mdia > hdlr\n   * ```\n   * @param initSegment the bytes of the init segment\n   * @returns a hash of track type to timescale values or null if\n   * the init segment is malformed.\n   */\n\n  function parseInitSegment(initSegment) {\n    var result = [];\n    var traks = findBox(initSegment, ['moov', 'trak']);\n    for (var i = 0; i < traks.length; i++) {\n      var trak = traks[i];\n      var tkhd = findBox(trak, ['tkhd'])[0];\n      if (tkhd) {\n        var version = tkhd[0];\n        var trackId = readUint32(tkhd, version === 0 ? 12 : 20);\n        var mdhd = findBox(trak, ['mdia', 'mdhd'])[0];\n        if (mdhd) {\n          version = mdhd[0];\n          var timescale = readUint32(mdhd, version === 0 ? 12 : 20);\n          var hdlr = findBox(trak, ['mdia', 'hdlr'])[0];\n          if (hdlr) {\n            var hdlrType = bin2str(hdlr.subarray(8, 12));\n            var type = {\n              soun: ElementaryStreamTypes.AUDIO,\n              vide: ElementaryStreamTypes.VIDEO\n            }[hdlrType];\n            if (type) {\n              // Parse codec details\n              var stsd = findBox(trak, ['mdia', 'minf', 'stbl', 'stsd'])[0];\n              var stsdData = parseStsd(stsd);\n              result[trackId] = {\n                timescale: timescale,\n                type: type\n              };\n              result[type] = _objectSpread2({\n                timescale: timescale,\n                id: trackId\n              }, stsdData);\n            }\n          }\n        }\n      }\n    }\n    var trex = findBox(initSegment, ['moov', 'mvex', 'trex']);\n    trex.forEach(function (trex) {\n      var trackId = readUint32(trex, 4);\n      var track = result[trackId];\n      if (track) {\n        track.default = {\n          duration: readUint32(trex, 12),\n          flags: readUint32(trex, 20)\n        };\n      }\n    });\n    return result;\n  }\n  function parseStsd(stsd) {\n    var sampleEntries = stsd.subarray(8);\n    var sampleEntriesEnd = sampleEntries.subarray(8 + 78);\n    var fourCC = bin2str(sampleEntries.subarray(4, 8));\n    var codec = fourCC;\n    var encrypted = fourCC === 'enca' || fourCC === 'encv';\n    if (encrypted) {\n      var encBox = findBox(sampleEntries, [fourCC])[0];\n      var encBoxChildren = encBox.subarray(fourCC === 'enca' ? 28 : 78);\n      var sinfs = findBox(encBoxChildren, ['sinf']);\n      sinfs.forEach(function (sinf) {\n        var schm = findBox(sinf, ['schm'])[0];\n        if (schm) {\n          var scheme = bin2str(schm.subarray(4, 8));\n          if (scheme === 'cbcs' || scheme === 'cenc') {\n            var frma = findBox(sinf, ['frma'])[0];\n            if (frma) {\n              // for encrypted content codec fourCC will be in frma\n              codec = bin2str(frma);\n            }\n          }\n        }\n      });\n    }\n    switch (codec) {\n      case 'avc1':\n      case 'avc2':\n      case 'avc3':\n      case 'avc4':\n        {\n          // extract profile + compatibility + level out of avcC box\n          var avcCBox = findBox(sampleEntriesEnd, ['avcC'])[0];\n          codec += '.' + toHex(avcCBox[1]) + toHex(avcCBox[2]) + toHex(avcCBox[3]);\n          break;\n        }\n      case 'mp4a':\n        {\n          var codecBox = findBox(sampleEntries, [fourCC])[0];\n          var esdsBox = findBox(codecBox.subarray(28), ['esds'])[0];\n          if (esdsBox && esdsBox.length > 12) {\n            var i = 4;\n            // ES Descriptor tag\n            if (esdsBox[i++] !== 0x03) {\n              break;\n            }\n            i = skipBERInteger(esdsBox, i);\n            i += 2; // skip es_id;\n            var flags = esdsBox[i++];\n            if (flags & 0x80) {\n              i += 2; // skip dependency es_id\n            }\n            if (flags & 0x40) {\n              i += esdsBox[i++]; // skip URL\n            }\n            // Decoder config descriptor\n            if (esdsBox[i++] !== 0x04) {\n              break;\n            }\n            i = skipBERInteger(esdsBox, i);\n            var objectType = esdsBox[i++];\n            if (objectType === 0x40) {\n              codec += '.' + toHex(objectType);\n            } else {\n              break;\n            }\n            i += 12;\n            // Decoder specific info\n            if (esdsBox[i++] !== 0x05) {\n              break;\n            }\n            i = skipBERInteger(esdsBox, i);\n            var firstByte = esdsBox[i++];\n            var audioObjectType = (firstByte & 0xf8) >> 3;\n            if (audioObjectType === 31) {\n              audioObjectType += 1 + ((firstByte & 0x7) << 3) + ((esdsBox[i] & 0xe0) >> 5);\n            }\n            codec += '.' + audioObjectType;\n          }\n          break;\n        }\n      case 'hvc1':\n      case 'hev1':\n        {\n          var hvcCBox = findBox(sampleEntriesEnd, ['hvcC'])[0];\n          var profileByte = hvcCBox[1];\n          var profileSpace = ['', 'A', 'B', 'C'][profileByte >> 6];\n          var generalProfileIdc = profileByte & 0x1f;\n          var profileCompat = readUint32(hvcCBox, 2);\n          var tierFlag = (profileByte & 0x20) >> 5 ? 'H' : 'L';\n          var levelIDC = hvcCBox[12];\n          var constraintIndicator = hvcCBox.subarray(6, 12);\n          codec += '.' + profileSpace + generalProfileIdc;\n          codec += '.' + profileCompat.toString(16).toUpperCase();\n          codec += '.' + tierFlag + levelIDC;\n          var constraintString = '';\n          for (var _i = constraintIndicator.length; _i--;) {\n            var _byte = constraintIndicator[_i];\n            if (_byte || constraintString) {\n              var encodedByte = _byte.toString(16).toUpperCase();\n              constraintString = '.' + encodedByte + constraintString;\n            }\n          }\n          codec += constraintString;\n          break;\n        }\n      case 'dvh1':\n      case 'dvhe':\n        {\n          var dvcCBox = findBox(sampleEntriesEnd, ['dvcC'])[0];\n          var profile = dvcCBox[2] >> 1 & 0x7f;\n          var level = dvcCBox[2] << 5 & 0x20 | dvcCBox[3] >> 3 & 0x1f;\n          codec += '.' + addLeadingZero(profile) + '.' + addLeadingZero(level);\n          break;\n        }\n      case 'vp09':\n        {\n          var vpcCBox = findBox(sampleEntriesEnd, ['vpcC'])[0];\n          var _profile = vpcCBox[4];\n          var _level = vpcCBox[5];\n          var bitDepth = vpcCBox[6] >> 4 & 0x0f;\n          codec += '.' + addLeadingZero(_profile) + '.' + addLeadingZero(_level) + '.' + addLeadingZero(bitDepth);\n          break;\n        }\n      case 'av01':\n        {\n          var av1CBox = findBox(sampleEntriesEnd, ['av1C'])[0];\n          var _profile2 = av1CBox[1] >>> 5;\n          var _level2 = av1CBox[1] & 0x1f;\n          var _tierFlag = av1CBox[2] >>> 7 ? 'H' : 'M';\n          var highBitDepth = (av1CBox[2] & 0x40) >> 6;\n          var twelveBit = (av1CBox[2] & 0x20) >> 5;\n          var _bitDepth = _profile2 === 2 && highBitDepth ? twelveBit ? 12 : 10 : highBitDepth ? 10 : 8;\n          var monochrome = (av1CBox[2] & 0x10) >> 4;\n          var chromaSubsamplingX = (av1CBox[2] & 0x08) >> 3;\n          var chromaSubsamplingY = (av1CBox[2] & 0x04) >> 2;\n          var chromaSamplePosition = av1CBox[2] & 0x03;\n          // TODO: parse color_description_present_flag\n          // default it to BT.709/limited range for now\n          // more info https://aomediacodec.github.io/av1-isobmff/#av1codecconfigurationbox-syntax\n          var colorPrimaries = 1;\n          var transferCharacteristics = 1;\n          var matrixCoefficients = 1;\n          var videoFullRangeFlag = 0;\n          codec += '.' + _profile2 + '.' + addLeadingZero(_level2) + _tierFlag + '.' + addLeadingZero(_bitDepth) + '.' + monochrome + '.' + chromaSubsamplingX + chromaSubsamplingY + chromaSamplePosition + '.' + addLeadingZero(colorPrimaries) + '.' + addLeadingZero(transferCharacteristics) + '.' + addLeadingZero(matrixCoefficients) + '.' + videoFullRangeFlag;\n          break;\n        }\n    }\n    return {\n      codec: codec,\n      encrypted: encrypted\n    };\n  }\n  function skipBERInteger(bytes, i) {\n    var limit = i + 5;\n    while (bytes[i++] & 0x80 && i < limit) {}\n    return i;\n  }\n  function toHex(x) {\n    return ('0' + x.toString(16).toUpperCase()).slice(-2);\n  }\n  function addLeadingZero(num) {\n    return (num < 10 ? '0' : '') + num;\n  }\n  function patchEncyptionData(initSegment, decryptdata) {\n    if (!initSegment || !decryptdata) {\n      return initSegment;\n    }\n    var keyId = decryptdata.keyId;\n    if (keyId && decryptdata.isCommonEncryption) {\n      var traks = findBox(initSegment, ['moov', 'trak']);\n      traks.forEach(function (trak) {\n        var stsd = findBox(trak, ['mdia', 'minf', 'stbl', 'stsd'])[0];\n\n        // skip the sample entry count\n        var sampleEntries = stsd.subarray(8);\n        var encBoxes = findBox(sampleEntries, ['enca']);\n        var isAudio = encBoxes.length > 0;\n        if (!isAudio) {\n          encBoxes = findBox(sampleEntries, ['encv']);\n        }\n        encBoxes.forEach(function (enc) {\n          var encBoxChildren = isAudio ? enc.subarray(28) : enc.subarray(78);\n          var sinfBoxes = findBox(encBoxChildren, ['sinf']);\n          sinfBoxes.forEach(function (sinf) {\n            var tenc = parseSinf(sinf);\n            if (tenc) {\n              // Look for default key id (keyID offset is always 8 within the tenc box):\n              var tencKeyId = tenc.subarray(8, 24);\n              if (!tencKeyId.some(function (b) {\n                return b !== 0;\n              })) {\n                logger.log(\"[eme] Patching keyId in 'enc\" + (isAudio ? 'a' : 'v') + \">sinf>>tenc' box: \" + Hex.hexDump(tencKeyId) + \" -> \" + Hex.hexDump(keyId));\n                tenc.set(keyId, 8);\n              }\n            }\n          });\n        });\n      });\n    }\n    return initSegment;\n  }\n  function parseSinf(sinf) {\n    var schm = findBox(sinf, ['schm'])[0];\n    if (schm) {\n      var scheme = bin2str(schm.subarray(4, 8));\n      if (scheme === 'cbcs' || scheme === 'cenc') {\n        return findBox(sinf, ['schi', 'tenc'])[0];\n      }\n    }\n    return null;\n  }\n\n  /**\n   * Determine the base media decode start time, in seconds, for an MP4\n   * fragment. If multiple fragments are specified, the earliest time is\n   * returned.\n   *\n   * The base media decode time can be parsed from track fragment\n   * metadata:\n   * ```\n   * moof > traf > tfdt.baseMediaDecodeTime\n   * ```\n   * It requires the timescale value from the mdhd to interpret.\n   *\n   * @param initData - a hash of track type to timescale values\n   * @param fmp4 - the bytes of the mp4 fragment\n   * @returns the earliest base media decode start time for the\n   * fragment, in seconds\n   */\n  function getStartDTS(initData, fmp4) {\n    // we need info from two children of each track fragment box\n    return findBox(fmp4, ['moof', 'traf']).reduce(function (result, traf) {\n      var tfdt = findBox(traf, ['tfdt'])[0];\n      var version = tfdt[0];\n      var start = findBox(traf, ['tfhd']).reduce(function (result, tfhd) {\n        // get the track id from the tfhd\n        var id = readUint32(tfhd, 4);\n        var track = initData[id];\n        if (track) {\n          var baseTime = readUint32(tfdt, 4);\n          if (version === 1) {\n            // If value is too large, assume signed 64-bit. Negative track fragment decode times are invalid, but they exist in the wild.\n            // This prevents large values from being used for initPTS, which can cause playlist sync issues.\n            // https://github.com/video-dev/hls.js/issues/5303\n            if (baseTime === UINT32_MAX$1) {\n              logger.warn(\"[mp4-demuxer]: Ignoring assumed invalid signed 64-bit track fragment decode time\");\n              return result;\n            }\n            baseTime *= UINT32_MAX$1 + 1;\n            baseTime += readUint32(tfdt, 8);\n          }\n          // assume a 90kHz clock if no timescale was specified\n          var scale = track.timescale || 90e3;\n          // convert base time to seconds\n          var startTime = baseTime / scale;\n          if (isFiniteNumber(startTime) && (result === null || startTime < result)) {\n            return startTime;\n          }\n        }\n        return result;\n      }, null);\n      if (start !== null && isFiniteNumber(start) && (result === null || start < result)) {\n        return start;\n      }\n      return result;\n    }, null);\n  }\n\n  /*\n    For Reference:\n    aligned(8) class TrackFragmentHeaderBox\n             extends FullBox(tfhd, 0, tf_flags){\n       unsigned int(32)  track_ID;\n       // all the following are optional fields\n       unsigned int(64)  base_data_offset;\n       unsigned int(32)  sample_description_index;\n       unsigned int(32)  default_sample_duration;\n       unsigned int(32)  default_sample_size;\n       unsigned int(32)  default_sample_flags\n    }\n   */\n  function getDuration(data, initData) {\n    var rawDuration = 0;\n    var videoDuration = 0;\n    var audioDuration = 0;\n    var trafs = findBox(data, ['moof', 'traf']);\n    for (var i = 0; i < trafs.length; i++) {\n      var traf = trafs[i];\n      // There is only one tfhd & trun per traf\n      // This is true for CMAF style content, and we should perhaps check the ftyp\n      // and only look for a single trun then, but for ISOBMFF we should check\n      // for multiple track runs.\n      var tfhd = findBox(traf, ['tfhd'])[0];\n      // get the track id from the tfhd\n      var id = readUint32(tfhd, 4);\n      var track = initData[id];\n      if (!track) {\n        continue;\n      }\n      var trackDefault = track.default;\n      var tfhdFlags = readUint32(tfhd, 0) | (trackDefault == null ? void 0 : trackDefault.flags);\n      var sampleDuration = trackDefault == null ? void 0 : trackDefault.duration;\n      if (tfhdFlags & 0x000008) {\n        // 0x000008 indicates the presence of the default_sample_duration field\n        if (tfhdFlags & 0x000002) {\n          // 0x000002 indicates the presence of the sample_description_index field, which precedes default_sample_duration\n          // If present, the default_sample_duration exists at byte offset 12\n          sampleDuration = readUint32(tfhd, 12);\n        } else {\n          // Otherwise, the duration is at byte offset 8\n          sampleDuration = readUint32(tfhd, 8);\n        }\n      }\n      // assume a 90kHz clock if no timescale was specified\n      var timescale = track.timescale || 90e3;\n      var truns = findBox(traf, ['trun']);\n      for (var j = 0; j < truns.length; j++) {\n        rawDuration = computeRawDurationFromSamples(truns[j]);\n        if (!rawDuration && sampleDuration) {\n          var sampleCount = readUint32(truns[j], 4);\n          rawDuration = sampleDuration * sampleCount;\n        }\n        if (track.type === ElementaryStreamTypes.VIDEO) {\n          videoDuration += rawDuration / timescale;\n        } else if (track.type === ElementaryStreamTypes.AUDIO) {\n          audioDuration += rawDuration / timescale;\n        }\n      }\n    }\n    if (videoDuration === 0 && audioDuration === 0) {\n      // If duration samples are not available in the traf use sidx subsegment_duration\n      var sidxMinStart = Infinity;\n      var sidxMaxEnd = 0;\n      var sidxDuration = 0;\n      var sidxs = findBox(data, ['sidx']);\n      for (var _i2 = 0; _i2 < sidxs.length; _i2++) {\n        var sidx = parseSegmentIndex(sidxs[_i2]);\n        if (sidx != null && sidx.references) {\n          sidxMinStart = Math.min(sidxMinStart, sidx.earliestPresentationTime / sidx.timescale);\n          var subSegmentDuration = sidx.references.reduce(function (dur, ref) {\n            return dur + ref.info.duration || 0;\n          }, 0);\n          sidxMaxEnd = Math.max(sidxMaxEnd, subSegmentDuration + sidx.earliestPresentationTime / sidx.timescale);\n          sidxDuration = sidxMaxEnd - sidxMinStart;\n        }\n      }\n      if (sidxDuration && isFiniteNumber(sidxDuration)) {\n        return sidxDuration;\n      }\n    }\n    if (videoDuration) {\n      return videoDuration;\n    }\n    return audioDuration;\n  }\n\n  /*\n    For Reference:\n    aligned(8) class TrackRunBox\n             extends FullBox(trun, version, tr_flags) {\n       unsigned int(32)  sample_count;\n       // the following are optional fields\n       signed int(32) data_offset;\n       unsigned int(32)  first_sample_flags;\n       // all fields in the following array are optional\n       {\n          unsigned int(32)  sample_duration;\n          unsigned int(32)  sample_size;\n          unsigned int(32)  sample_flags\n          if (version == 0)\n             { unsigned int(32)\n          else\n             { signed int(32)\n       }[ sample_count ]\n    }\n   */\n  function computeRawDurationFromSamples(trun) {\n    var flags = readUint32(trun, 0);\n    // Flags are at offset 0, non-optional sample_count is at offset 4. Therefore we start 8 bytes in.\n    // Each field is an int32, which is 4 bytes\n    var offset = 8;\n    // data-offset-present flag\n    if (flags & 0x000001) {\n      offset += 4;\n    }\n    // first-sample-flags-present flag\n    if (flags & 0x000004) {\n      offset += 4;\n    }\n    var duration = 0;\n    var sampleCount = readUint32(trun, 4);\n    for (var i = 0; i < sampleCount; i++) {\n      // sample-duration-present flag\n      if (flags & 0x000100) {\n        var sampleDuration = readUint32(trun, offset);\n        duration += sampleDuration;\n        offset += 4;\n      }\n      // sample-size-present flag\n      if (flags & 0x000200) {\n        offset += 4;\n      }\n      // sample-flags-present flag\n      if (flags & 0x000400) {\n        offset += 4;\n      }\n      // sample-composition-time-offsets-present flag\n      if (flags & 0x000800) {\n        offset += 4;\n      }\n    }\n    return duration;\n  }\n  function offsetStartDTS(initData, fmp4, timeOffset) {\n    findBox(fmp4, ['moof', 'traf']).forEach(function (traf) {\n      findBox(traf, ['tfhd']).forEach(function (tfhd) {\n        // get the track id from the tfhd\n        var id = readUint32(tfhd, 4);\n        var track = initData[id];\n        if (!track) {\n          return;\n        }\n        // assume a 90kHz clock if no timescale was specified\n        var timescale = track.timescale || 90e3;\n        // get the base media decode time from the tfdt\n        findBox(traf, ['tfdt']).forEach(function (tfdt) {\n          var version = tfdt[0];\n          var offset = timeOffset * timescale;\n          if (offset) {\n            var baseMediaDecodeTime = readUint32(tfdt, 4);\n            if (version === 0) {\n              baseMediaDecodeTime -= offset;\n              baseMediaDecodeTime = Math.max(baseMediaDecodeTime, 0);\n              writeUint32(tfdt, 4, baseMediaDecodeTime);\n            } else {\n              baseMediaDecodeTime *= Math.pow(2, 32);\n              baseMediaDecodeTime += readUint32(tfdt, 8);\n              baseMediaDecodeTime -= offset;\n              baseMediaDecodeTime = Math.max(baseMediaDecodeTime, 0);\n              var upper = Math.floor(baseMediaDecodeTime / (UINT32_MAX$1 + 1));\n              var lower = Math.floor(baseMediaDecodeTime % (UINT32_MAX$1 + 1));\n              writeUint32(tfdt, 4, upper);\n              writeUint32(tfdt, 8, lower);\n            }\n          }\n        });\n      });\n    });\n  }\n\n  // TODO: Check if the last moof+mdat pair is part of the valid range\n  function segmentValidRange(data) {\n    var segmentedRange = {\n      valid: null,\n      remainder: null\n    };\n    var moofs = findBox(data, ['moof']);\n    if (moofs.length < 2) {\n      segmentedRange.remainder = data;\n      return segmentedRange;\n    }\n    var last = moofs[moofs.length - 1];\n    // Offset by 8 bytes; findBox offsets the start by as much\n    segmentedRange.valid = sliceUint8(data, 0, last.byteOffset - 8);\n    segmentedRange.remainder = sliceUint8(data, last.byteOffset - 8);\n    return segmentedRange;\n  }\n  function appendUint8Array(data1, data2) {\n    var temp = new Uint8Array(data1.length + data2.length);\n    temp.set(data1);\n    temp.set(data2, data1.length);\n    return temp;\n  }\n  function parseSamples(timeOffset, track) {\n    var seiSamples = [];\n    var videoData = track.samples;\n    var timescale = track.timescale;\n    var trackId = track.id;\n    var isHEVCFlavor = false;\n    var moofs = findBox(videoData, ['moof']);\n    moofs.map(function (moof) {\n      var moofOffset = moof.byteOffset - 8;\n      var trafs = findBox(moof, ['traf']);\n      trafs.map(function (traf) {\n        // get the base media decode time from the tfdt\n        var baseTime = findBox(traf, ['tfdt']).map(function (tfdt) {\n          var version = tfdt[0];\n          var result = readUint32(tfdt, 4);\n          if (version === 1) {\n            result *= Math.pow(2, 32);\n            result += readUint32(tfdt, 8);\n          }\n          return result / timescale;\n        })[0];\n        if (baseTime !== undefined) {\n          timeOffset = baseTime;\n        }\n        return findBox(traf, ['tfhd']).map(function (tfhd) {\n          var id = readUint32(tfhd, 4);\n          var tfhdFlags = readUint32(tfhd, 0) & 0xffffff;\n          var baseDataOffsetPresent = (tfhdFlags & 0x000001) !== 0;\n          var sampleDescriptionIndexPresent = (tfhdFlags & 0x000002) !== 0;\n          var defaultSampleDurationPresent = (tfhdFlags & 0x000008) !== 0;\n          var defaultSampleDuration = 0;\n          var defaultSampleSizePresent = (tfhdFlags & 0x000010) !== 0;\n          var defaultSampleSize = 0;\n          var defaultSampleFlagsPresent = (tfhdFlags & 0x000020) !== 0;\n          var tfhdOffset = 8;\n          if (id === trackId) {\n            if (baseDataOffsetPresent) {\n              tfhdOffset += 8;\n            }\n            if (sampleDescriptionIndexPresent) {\n              tfhdOffset += 4;\n            }\n            if (defaultSampleDurationPresent) {\n              defaultSampleDuration = readUint32(tfhd, tfhdOffset);\n              tfhdOffset += 4;\n            }\n            if (defaultSampleSizePresent) {\n              defaultSampleSize = readUint32(tfhd, tfhdOffset);\n              tfhdOffset += 4;\n            }\n            if (defaultSampleFlagsPresent) {\n              tfhdOffset += 4;\n            }\n            if (track.type === 'video') {\n              isHEVCFlavor = isHEVC(track.codec);\n            }\n            findBox(traf, ['trun']).map(function (trun) {\n              var version = trun[0];\n              var flags = readUint32(trun, 0) & 0xffffff;\n              var dataOffsetPresent = (flags & 0x000001) !== 0;\n              var dataOffset = 0;\n              var firstSampleFlagsPresent = (flags & 0x000004) !== 0;\n              var sampleDurationPresent = (flags & 0x000100) !== 0;\n              var sampleDuration = 0;\n              var sampleSizePresent = (flags & 0x000200) !== 0;\n              var sampleSize = 0;\n              var sampleFlagsPresent = (flags & 0x000400) !== 0;\n              var sampleCompositionOffsetsPresent = (flags & 0x000800) !== 0;\n              var compositionOffset = 0;\n              var sampleCount = readUint32(trun, 4);\n              var trunOffset = 8; // past version, flags, and sample count\n\n              if (dataOffsetPresent) {\n                dataOffset = readUint32(trun, trunOffset);\n                trunOffset += 4;\n              }\n              if (firstSampleFlagsPresent) {\n                trunOffset += 4;\n              }\n              var sampleOffset = dataOffset + moofOffset;\n              for (var ix = 0; ix < sampleCount; ix++) {\n                if (sampleDurationPresent) {\n                  sampleDuration = readUint32(trun, trunOffset);\n                  trunOffset += 4;\n                } else {\n                  sampleDuration = defaultSampleDuration;\n                }\n                if (sampleSizePresent) {\n                  sampleSize = readUint32(trun, trunOffset);\n                  trunOffset += 4;\n                } else {\n                  sampleSize = defaultSampleSize;\n                }\n                if (sampleFlagsPresent) {\n                  trunOffset += 4;\n                }\n                if (sampleCompositionOffsetsPresent) {\n                  if (version === 0) {\n                    compositionOffset = readUint32(trun, trunOffset);\n                  } else {\n                    compositionOffset = readSint32(trun, trunOffset);\n                  }\n                  trunOffset += 4;\n                }\n                if (track.type === ElementaryStreamTypes.VIDEO) {\n                  var naluTotalSize = 0;\n                  while (naluTotalSize < sampleSize) {\n                    var naluSize = readUint32(videoData, sampleOffset);\n                    sampleOffset += 4;\n                    if (isSEIMessage(isHEVCFlavor, videoData[sampleOffset])) {\n                      var data = videoData.subarray(sampleOffset, sampleOffset + naluSize);\n                      parseSEIMessageFromNALu(data, isHEVCFlavor ? 2 : 1, timeOffset + compositionOffset / timescale, seiSamples);\n                    }\n                    sampleOffset += naluSize;\n                    naluTotalSize += naluSize + 4;\n                  }\n                }\n                timeOffset += sampleDuration / timescale;\n              }\n            });\n          }\n        });\n      });\n    });\n    return seiSamples;\n  }\n  function isHEVC(codec) {\n    if (!codec) {\n      return false;\n    }\n    var delimit = codec.indexOf('.');\n    var baseCodec = delimit < 0 ? codec : codec.substring(0, delimit);\n    return baseCodec === 'hvc1' || baseCodec === 'hev1' ||\n    // Dolby Vision\n    baseCodec === 'dvh1' || baseCodec === 'dvhe';\n  }\n  function isSEIMessage(isHEVCFlavor, naluHeader) {\n    if (isHEVCFlavor) {\n      var naluType = naluHeader >> 1 & 0x3f;\n      return naluType === 39 || naluType === 40;\n    } else {\n      var _naluType = naluHeader & 0x1f;\n      return _naluType === 6;\n    }\n  }\n  function parseSEIMessageFromNALu(unescapedData, headerSize, pts, samples) {\n    var data = discardEPB(unescapedData);\n    var seiPtr = 0;\n    // skip nal header\n    seiPtr += headerSize;\n    var payloadType = 0;\n    var payloadSize = 0;\n    var b = 0;\n    while (seiPtr < data.length) {\n      payloadType = 0;\n      do {\n        if (seiPtr >= data.length) {\n          break;\n        }\n        b = data[seiPtr++];\n        payloadType += b;\n      } while (b === 0xff);\n\n      // Parse payload size.\n      payloadSize = 0;\n      do {\n        if (seiPtr >= data.length) {\n          break;\n        }\n        b = data[seiPtr++];\n        payloadSize += b;\n      } while (b === 0xff);\n      var leftOver = data.length - seiPtr;\n      // Create a variable to process the payload\n      var payPtr = seiPtr;\n\n      // Increment the seiPtr to the end of the payload\n      if (payloadSize < leftOver) {\n        seiPtr += payloadSize;\n      } else if (payloadSize > leftOver) {\n        // Some type of corruption has happened?\n        logger.error(\"Malformed SEI payload. \" + payloadSize + \" is too small, only \" + leftOver + \" bytes left to parse.\");\n        // We might be able to parse some data, but let's be safe and ignore it.\n        break;\n      }\n      if (payloadType === 4) {\n        var countryCode = data[payPtr++];\n        if (countryCode === 181) {\n          var providerCode = readUint16(data, payPtr);\n          payPtr += 2;\n          if (providerCode === 49) {\n            var userStructure = readUint32(data, payPtr);\n            payPtr += 4;\n            if (userStructure === 0x47413934) {\n              var userDataType = data[payPtr++];\n\n              // Raw CEA-608 bytes wrapped in CEA-708 packet\n              if (userDataType === 3) {\n                var firstByte = data[payPtr++];\n                var totalCCs = 0x1f & firstByte;\n                var enabled = 0x40 & firstByte;\n                var totalBytes = enabled ? 2 + totalCCs * 3 : 0;\n                var byteArray = new Uint8Array(totalBytes);\n                if (enabled) {\n                  byteArray[0] = firstByte;\n                  for (var i = 1; i < totalBytes; i++) {\n                    byteArray[i] = data[payPtr++];\n                  }\n                }\n                samples.push({\n                  type: userDataType,\n                  payloadType: payloadType,\n                  pts: pts,\n                  bytes: byteArray\n                });\n              }\n            }\n          }\n        }\n      } else if (payloadType === 5) {\n        if (payloadSize > 16) {\n          var uuidStrArray = [];\n          for (var _i3 = 0; _i3 < 16; _i3++) {\n            var _b = data[payPtr++].toString(16);\n            uuidStrArray.push(_b.length == 1 ? '0' + _b : _b);\n            if (_i3 === 3 || _i3 === 5 || _i3 === 7 || _i3 === 9) {\n              uuidStrArray.push('-');\n            }\n          }\n          var length = payloadSize - 16;\n          var userDataBytes = new Uint8Array(length);\n          for (var _i4 = 0; _i4 < length; _i4++) {\n            userDataBytes[_i4] = data[payPtr++];\n          }\n          samples.push({\n            payloadType: payloadType,\n            pts: pts,\n            uuid: uuidStrArray.join(''),\n            userData: utf8ArrayToStr(userDataBytes),\n            userDataBytes: userDataBytes\n          });\n        }\n      }\n    }\n  }\n\n  /**\n   * remove Emulation Prevention bytes from a RBSP\n   */\n  function discardEPB(data) {\n    var length = data.byteLength;\n    var EPBPositions = [];\n    var i = 1;\n\n    // Find all `Emulation Prevention Bytes`\n    while (i < length - 2) {\n      if (data[i] === 0 && data[i + 1] === 0 && data[i + 2] === 0x03) {\n        EPBPositions.push(i + 2);\n        i += 2;\n      } else {\n        i++;\n      }\n    }\n\n    // If no Emulation Prevention Bytes were found just return the original\n    // array\n    if (EPBPositions.length === 0) {\n      return data;\n    }\n\n    // Create a new array to hold the NAL unit data\n    var newLength = length - EPBPositions.length;\n    var newData = new Uint8Array(newLength);\n    var sourceIndex = 0;\n    for (i = 0; i < newLength; sourceIndex++, i++) {\n      if (sourceIndex === EPBPositions[0]) {\n        // Skip this byte\n        sourceIndex++;\n        // Remove this position index\n        EPBPositions.shift();\n      }\n      newData[i] = data[sourceIndex];\n    }\n    return newData;\n  }\n  function parseEmsg(data) {\n    var version = data[0];\n    var schemeIdUri = '';\n    var value = '';\n    var timeScale = 0;\n    var presentationTimeDelta = 0;\n    var presentationTime = 0;\n    var eventDuration = 0;\n    var id = 0;\n    var offset = 0;\n    if (version === 0) {\n      while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n        schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n        offset += 1;\n      }\n      schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n      while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n        value += bin2str(data.subarray(offset, offset + 1));\n        offset += 1;\n      }\n      value += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n      timeScale = readUint32(data, 12);\n      presentationTimeDelta = readUint32(data, 16);\n      eventDuration = readUint32(data, 20);\n      id = readUint32(data, 24);\n      offset = 28;\n    } else if (version === 1) {\n      offset += 4;\n      timeScale = readUint32(data, offset);\n      offset += 4;\n      var leftPresentationTime = readUint32(data, offset);\n      offset += 4;\n      var rightPresentationTime = readUint32(data, offset);\n      offset += 4;\n      presentationTime = Math.pow(2, 32) * leftPresentationTime + rightPresentationTime;\n      if (!isSafeInteger(presentationTime)) {\n        presentationTime = Number.MAX_SAFE_INTEGER;\n        logger.warn('Presentation time exceeds safe integer limit and wrapped to max safe integer in parsing emsg box');\n      }\n      eventDuration = readUint32(data, offset);\n      offset += 4;\n      id = readUint32(data, offset);\n      offset += 4;\n      while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n        schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n        offset += 1;\n      }\n      schemeIdUri += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n      while (bin2str(data.subarray(offset, offset + 1)) !== '\\0') {\n        value += bin2str(data.subarray(offset, offset + 1));\n        offset += 1;\n      }\n      value += bin2str(data.subarray(offset, offset + 1));\n      offset += 1;\n    }\n    var payload = data.subarray(offset, data.byteLength);\n    return {\n      schemeIdUri: schemeIdUri,\n      value: value,\n      timeScale: timeScale,\n      presentationTime: presentationTime,\n      presentationTimeDelta: presentationTimeDelta,\n      eventDuration: eventDuration,\n      id: id,\n      payload: payload\n    };\n  }\n  function mp4Box(type) {\n    for (var _len = arguments.length, payload = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n      payload[_key - 1] = arguments[_key];\n    }\n    var len = payload.length;\n    var size = 8;\n    var i = len;\n    while (i--) {\n      size += payload[i].byteLength;\n    }\n    var result = new Uint8Array(size);\n    result[0] = size >> 24 & 0xff;\n    result[1] = size >> 16 & 0xff;\n    result[2] = size >> 8 & 0xff;\n    result[3] = size & 0xff;\n    result.set(type, 4);\n    for (i = 0, size = 8; i < len; i++) {\n      result.set(payload[i], size);\n      size += payload[i].byteLength;\n    }\n    return result;\n  }\n  function mp4pssh(systemId, keyids, data) {\n    if (systemId.byteLength !== 16) {\n      throw new RangeError('Invalid system id');\n    }\n    var version;\n    var kids;\n    if (keyids) {\n      version = 1;\n      kids = new Uint8Array(keyids.length * 16);\n      for (var ix = 0; ix < keyids.length; ix++) {\n        var k = keyids[ix]; // uint8array\n        if (k.byteLength !== 16) {\n          throw new RangeError('Invalid key');\n        }\n        kids.set(k, ix * 16);\n      }\n    } else {\n      version = 0;\n      kids = new Uint8Array();\n    }\n    var kidCount;\n    if (version > 0) {\n      kidCount = new Uint8Array(4);\n      if (keyids.length > 0) {\n        new DataView(kidCount.buffer).setUint32(0, keyids.length, false);\n      }\n    } else {\n      kidCount = new Uint8Array();\n    }\n    var dataSize = new Uint8Array(4);\n    if (data && data.byteLength > 0) {\n      new DataView(dataSize.buffer).setUint32(0, data.byteLength, false);\n    }\n    return mp4Box([112, 115, 115, 104], new Uint8Array([version, 0x00, 0x00, 0x00 // Flags\n    ]), systemId,\n    // 16 bytes\n    kidCount, kids, dataSize, data || new Uint8Array());\n  }\n  function parseMultiPssh(initData) {\n    var results = [];\n    if (initData instanceof ArrayBuffer) {\n      var length = initData.byteLength;\n      var offset = 0;\n      while (offset + 32 < length) {\n        var view = new DataView(initData, offset);\n        var pssh = parsePssh(view);\n        results.push(pssh);\n        offset += pssh.size;\n      }\n    }\n    return results;\n  }\n  function parsePssh(view) {\n    var size = view.getUint32(0);\n    var offset = view.byteOffset;\n    var length = view.byteLength;\n    if (length < size) {\n      return {\n        offset: offset,\n        size: length\n      };\n    }\n    var type = view.getUint32(4);\n    if (type !== 0x70737368) {\n      return {\n        offset: offset,\n        size: size\n      };\n    }\n    var version = view.getUint32(8) >>> 24;\n    if (version !== 0 && version !== 1) {\n      return {\n        offset: offset,\n        size: size\n      };\n    }\n    var buffer = view.buffer;\n    var systemId = Hex.hexDump(new Uint8Array(buffer, offset + 12, 16));\n    var dataSizeOrKidCount = view.getUint32(28);\n    var kids = null;\n    var data = null;\n    if (version === 0) {\n      if (size - 32 < dataSizeOrKidCount || dataSizeOrKidCount < 22) {\n        return {\n          offset: offset,\n          size: size\n        };\n      }\n      data = new Uint8Array(buffer, offset + 32, dataSizeOrKidCount);\n    } else if (version === 1) {\n      if (!dataSizeOrKidCount || length < offset + 32 + dataSizeOrKidCount * 16 + 16) {\n        return {\n          offset: offset,\n          size: size\n        };\n      }\n      kids = [];\n      for (var i = 0; i < dataSizeOrKidCount; i++) {\n        kids.push(new Uint8Array(buffer, offset + 32 + i * 16, 16));\n      }\n    }\n    return {\n      version: version,\n      systemId: systemId,\n      kids: kids,\n      data: data,\n      offset: offset,\n      size: size\n    };\n  }\n\n  var keyUriToKeyIdMap = {};\n  var LevelKey = /*#__PURE__*/function () {\n    LevelKey.clearKeyUriToKeyIdMap = function clearKeyUriToKeyIdMap() {\n      keyUriToKeyIdMap = {};\n    };\n    function LevelKey(method, uri, format, formatversions, iv) {\n      if (formatversions === void 0) {\n        formatversions = [1];\n      }\n      if (iv === void 0) {\n        iv = null;\n      }\n      this.uri = void 0;\n      this.method = void 0;\n      this.keyFormat = void 0;\n      this.keyFormatVersions = void 0;\n      this.encrypted = void 0;\n      this.isCommonEncryption = void 0;\n      this.iv = null;\n      this.key = null;\n      this.keyId = null;\n      this.pssh = null;\n      this.method = method;\n      this.uri = uri;\n      this.keyFormat = format;\n      this.keyFormatVersions = formatversions;\n      this.iv = iv;\n      this.encrypted = method ? method !== 'NONE' : false;\n      this.isCommonEncryption = this.encrypted && method !== 'AES-128';\n    }\n    var _proto = LevelKey.prototype;\n    _proto.isSupported = function isSupported() {\n      // If it's Segment encryption or No encryption, just select that key system\n      if (this.method) {\n        if (this.method === 'AES-128' || this.method === 'NONE') {\n          return true;\n        }\n        if (this.keyFormat === 'identity') {\n          // Maintain support for clear SAMPLE-AES with MPEG-3 TS\n          return this.method === 'SAMPLE-AES';\n        } else {\n          switch (this.keyFormat) {\n            case KeySystemFormats.FAIRPLAY:\n            case KeySystemFormats.WIDEVINE:\n            case KeySystemFormats.PLAYREADY:\n            case KeySystemFormats.CLEARKEY:\n              return ['ISO-23001-7', 'SAMPLE-AES', 'SAMPLE-AES-CENC', 'SAMPLE-AES-CTR'].indexOf(this.method) !== -1;\n          }\n        }\n      }\n      return false;\n    };\n    _proto.getDecryptData = function getDecryptData(sn) {\n      if (!this.encrypted || !this.uri) {\n        return null;\n      }\n      if (this.method === 'AES-128' && this.uri && !this.iv) {\n        if (typeof sn !== 'number') {\n          // We are fetching decryption data for a initialization segment\n          // If the segment was encrypted with AES-128\n          // It must have an IV defined. We cannot substitute the Segment Number in.\n          if (this.method === 'AES-128' && !this.iv) {\n            logger.warn(\"missing IV for initialization segment with method=\\\"\" + this.method + \"\\\" - compliance issue\");\n          }\n          // Explicitly set sn to resulting value from implicit conversions 'initSegment' values for IV generation.\n          sn = 0;\n        }\n        var iv = createInitializationVector(sn);\n        var decryptdata = new LevelKey(this.method, this.uri, 'identity', this.keyFormatVersions, iv);\n        return decryptdata;\n      }\n\n      // Initialize keyId if possible\n      var keyBytes = convertDataUriToArrayBytes(this.uri);\n      if (keyBytes) {\n        switch (this.keyFormat) {\n          case KeySystemFormats.WIDEVINE:\n            this.pssh = keyBytes;\n            // In case of widevine keyID is embedded in PSSH box. Read Key ID.\n            if (keyBytes.length >= 22) {\n              this.keyId = keyBytes.subarray(keyBytes.length - 22, keyBytes.length - 6);\n            }\n            break;\n          case KeySystemFormats.PLAYREADY:\n            {\n              var PlayReadyKeySystemUUID = new Uint8Array([0x9a, 0x04, 0xf0, 0x79, 0x98, 0x40, 0x42, 0x86, 0xab, 0x92, 0xe6, 0x5b, 0xe0, 0x88, 0x5f, 0x95]);\n              this.pssh = mp4pssh(PlayReadyKeySystemUUID, null, keyBytes);\n              var keyBytesUtf16 = new Uint16Array(keyBytes.buffer, keyBytes.byteOffset, keyBytes.byteLength / 2);\n              var keyByteStr = String.fromCharCode.apply(null, Array.from(keyBytesUtf16));\n\n              // Parse Playready WRMHeader XML\n              var xmlKeyBytes = keyByteStr.substring(keyByteStr.indexOf('<'), keyByteStr.length);\n              var parser = new DOMParser();\n              var xmlDoc = parser.parseFromString(xmlKeyBytes, 'text/xml');\n              var keyData = xmlDoc.getElementsByTagName('KID')[0];\n              if (keyData) {\n                var keyId = keyData.childNodes[0] ? keyData.childNodes[0].nodeValue : keyData.getAttribute('VALUE');\n                if (keyId) {\n                  var keyIdArray = base64Decode(keyId).subarray(0, 16);\n                  // KID value in PRO is a base64-encoded little endian GUID interpretation of UUID\n                  // KID value in tenc is a big endian UUID GUID interpretation of UUID\n                  changeEndianness(keyIdArray);\n                  this.keyId = keyIdArray;\n                }\n              }\n              break;\n            }\n          default:\n            {\n              var keydata = keyBytes.subarray(0, 16);\n              if (keydata.length !== 16) {\n                var padded = new Uint8Array(16);\n                padded.set(keydata, 16 - keydata.length);\n                keydata = padded;\n              }\n              this.keyId = keydata;\n              break;\n            }\n        }\n      }\n\n      // Default behavior: assign a new keyId for each uri\n      if (!this.keyId || this.keyId.byteLength !== 16) {\n        var _keyId = keyUriToKeyIdMap[this.uri];\n        if (!_keyId) {\n          var val = Object.keys(keyUriToKeyIdMap).length % Number.MAX_SAFE_INTEGER;\n          _keyId = new Uint8Array(16);\n          var dv = new DataView(_keyId.buffer, 12, 4); // Just set the last 4 bytes\n          dv.setUint32(0, val);\n          keyUriToKeyIdMap[this.uri] = _keyId;\n        }\n        this.keyId = _keyId;\n      }\n      return this;\n    };\n    return LevelKey;\n  }();\n  function createInitializationVector(segmentNumber) {\n    var uint8View = new Uint8Array(16);\n    for (var i = 12; i < 16; i++) {\n      uint8View[i] = segmentNumber >> 8 * (15 - i) & 0xff;\n    }\n    return uint8View;\n  }\n\n  var VARIABLE_REPLACEMENT_REGEX = /\\{\\$([a-zA-Z0-9-_]+)\\}/g;\n  function hasVariableReferences(str) {\n    return VARIABLE_REPLACEMENT_REGEX.test(str);\n  }\n  function substituteVariablesInAttributes(parsed, attr, attributeNames) {\n    if (parsed.variableList !== null || parsed.hasVariableRefs) {\n      for (var i = attributeNames.length; i--;) {\n        var name = attributeNames[i];\n        var value = attr[name];\n        if (value) {\n          attr[name] = substituteVariables(parsed, value);\n        }\n      }\n    }\n  }\n  function substituteVariables(parsed, value) {\n    if (parsed.variableList !== null || parsed.hasVariableRefs) {\n      var variableList = parsed.variableList;\n      return value.replace(VARIABLE_REPLACEMENT_REGEX, function (variableReference) {\n        var variableName = variableReference.substring(2, variableReference.length - 1);\n        var variableValue = variableList == null ? void 0 : variableList[variableName];\n        if (variableValue === undefined) {\n          parsed.playlistParsingError || (parsed.playlistParsingError = new Error(\"Missing preceding EXT-X-DEFINE tag for Variable Reference: \\\"\" + variableName + \"\\\"\"));\n          return variableReference;\n        }\n        return variableValue;\n      });\n    }\n    return value;\n  }\n  function addVariableDefinition(parsed, attr, parentUrl) {\n    var variableList = parsed.variableList;\n    if (!variableList) {\n      parsed.variableList = variableList = {};\n    }\n    var NAME;\n    var VALUE;\n    if ('QUERYPARAM' in attr) {\n      NAME = attr.QUERYPARAM;\n      try {\n        var searchParams = new self.URL(parentUrl).searchParams;\n        if (searchParams.has(NAME)) {\n          VALUE = searchParams.get(NAME);\n        } else {\n          throw new Error(\"\\\"\" + NAME + \"\\\" does not match any query parameter in URI: \\\"\" + parentUrl + \"\\\"\");\n        }\n      } catch (error) {\n        parsed.playlistParsingError || (parsed.playlistParsingError = new Error(\"EXT-X-DEFINE QUERYPARAM: \" + error.message));\n      }\n    } else {\n      NAME = attr.NAME;\n      VALUE = attr.VALUE;\n    }\n    if (NAME in variableList) {\n      parsed.playlistParsingError || (parsed.playlistParsingError = new Error(\"EXT-X-DEFINE duplicate Variable Name declarations: \\\"\" + NAME + \"\\\"\"));\n    } else {\n      variableList[NAME] = VALUE || '';\n    }\n  }\n  function importVariableDefinition(parsed, attr, sourceVariableList) {\n    var IMPORT = attr.IMPORT;\n    if (sourceVariableList && IMPORT in sourceVariableList) {\n      var variableList = parsed.variableList;\n      if (!variableList) {\n        parsed.variableList = variableList = {};\n      }\n      variableList[IMPORT] = sourceVariableList[IMPORT];\n    } else {\n      parsed.playlistParsingError || (parsed.playlistParsingError = new Error(\"EXT-X-DEFINE IMPORT attribute not found in Multivariant Playlist: \\\"\" + IMPORT + \"\\\"\"));\n    }\n  }\n\n  /**\n   * MediaSource helper\n   */\n\n  function getMediaSource(preferManagedMediaSource) {\n    if (preferManagedMediaSource === void 0) {\n      preferManagedMediaSource = true;\n    }\n    if (typeof self === 'undefined') return undefined;\n    var mms = (preferManagedMediaSource || !self.MediaSource) && self.ManagedMediaSource;\n    return mms || self.MediaSource || self.WebKitMediaSource;\n  }\n  function isManagedMediaSource(source) {\n    return typeof self !== 'undefined' && source === self.ManagedMediaSource;\n  }\n\n  // from http://mp4ra.org/codecs.html\n  // values indicate codec selection preference (lower is higher priority)\n  var sampleEntryCodesISO = {\n    audio: {\n      a3ds: 1,\n      'ac-3': 0.95,\n      'ac-4': 1,\n      alac: 0.9,\n      alaw: 1,\n      dra1: 1,\n      'dts+': 1,\n      'dts-': 1,\n      dtsc: 1,\n      dtse: 1,\n      dtsh: 1,\n      'ec-3': 0.9,\n      enca: 1,\n      fLaC: 0.9,\n      // MP4-RA listed codec entry for FLAC\n      flac: 0.9,\n      // legacy browser codec name for FLAC\n      FLAC: 0.9,\n      // some manifests may list \"FLAC\" with Apple's tools\n      g719: 1,\n      g726: 1,\n      m4ae: 1,\n      mha1: 1,\n      mha2: 1,\n      mhm1: 1,\n      mhm2: 1,\n      mlpa: 1,\n      mp4a: 1,\n      'raw ': 1,\n      Opus: 1,\n      opus: 1,\n      // browsers expect this to be lowercase despite MP4RA says 'Opus'\n      samr: 1,\n      sawb: 1,\n      sawp: 1,\n      sevc: 1,\n      sqcp: 1,\n      ssmv: 1,\n      twos: 1,\n      ulaw: 1\n    },\n    video: {\n      avc1: 1,\n      avc2: 1,\n      avc3: 1,\n      avc4: 1,\n      avcp: 1,\n      av01: 0.8,\n      drac: 1,\n      dva1: 1,\n      dvav: 1,\n      dvh1: 0.7,\n      dvhe: 0.7,\n      encv: 1,\n      hev1: 0.75,\n      hvc1: 0.75,\n      mjp2: 1,\n      mp4v: 1,\n      mvc1: 1,\n      mvc2: 1,\n      mvc3: 1,\n      mvc4: 1,\n      resv: 1,\n      rv60: 1,\n      s263: 1,\n      svc1: 1,\n      svc2: 1,\n      'vc-1': 1,\n      vp08: 1,\n      vp09: 0.9\n    },\n    text: {\n      stpp: 1,\n      wvtt: 1\n    }\n  };\n  function isCodecType(codec, type) {\n    var typeCodes = sampleEntryCodesISO[type];\n    return !!typeCodes && !!typeCodes[codec.slice(0, 4)];\n  }\n  function areCodecsMediaSourceSupported(codecs, type, preferManagedMediaSource) {\n    if (preferManagedMediaSource === void 0) {\n      preferManagedMediaSource = true;\n    }\n    return !codecs.split(',').some(function (codec) {\n      return !isCodecMediaSourceSupported(codec, type, preferManagedMediaSource);\n    });\n  }\n  function isCodecMediaSourceSupported(codec, type, preferManagedMediaSource) {\n    var _MediaSource$isTypeSu;\n    if (preferManagedMediaSource === void 0) {\n      preferManagedMediaSource = true;\n    }\n    var MediaSource = getMediaSource(preferManagedMediaSource);\n    return (_MediaSource$isTypeSu = MediaSource == null ? void 0 : MediaSource.isTypeSupported(mimeTypeForCodec(codec, type))) != null ? _MediaSource$isTypeSu : false;\n  }\n  function mimeTypeForCodec(codec, type) {\n    return type + \"/mp4;codecs=\\\"\" + codec + \"\\\"\";\n  }\n  function videoCodecPreferenceValue(videoCodec) {\n    if (videoCodec) {\n      var fourCC = videoCodec.substring(0, 4);\n      return sampleEntryCodesISO.video[fourCC];\n    }\n    return 2;\n  }\n  function codecsSetSelectionPreferenceValue(codecSet) {\n    return codecSet.split(',').reduce(function (num, fourCC) {\n      var preferenceValue = sampleEntryCodesISO.video[fourCC];\n      if (preferenceValue) {\n        return (preferenceValue * 2 + num) / (num ? 3 : 2);\n      }\n      return (sampleEntryCodesISO.audio[fourCC] + num) / (num ? 2 : 1);\n    }, 0);\n  }\n  var CODEC_COMPATIBLE_NAMES = {};\n  function getCodecCompatibleNameLower(lowerCaseCodec, preferManagedMediaSource) {\n    if (preferManagedMediaSource === void 0) {\n      preferManagedMediaSource = true;\n    }\n    if (CODEC_COMPATIBLE_NAMES[lowerCaseCodec]) {\n      return CODEC_COMPATIBLE_NAMES[lowerCaseCodec];\n    }\n\n    // Idealy fLaC and Opus would be first (spec-compliant) but\n    // some browsers will report that fLaC is supported then fail.\n    // see: https://bugs.chromium.org/p/chromium/issues/detail?id=1422728\n    var codecsToCheck = {\n      flac: ['flac', 'fLaC', 'FLAC'],\n      opus: ['opus', 'Opus']\n    }[lowerCaseCodec];\n    for (var i = 0; i < codecsToCheck.length; i++) {\n      if (isCodecMediaSourceSupported(codecsToCheck[i], 'audio', preferManagedMediaSource)) {\n        CODEC_COMPATIBLE_NAMES[lowerCaseCodec] = codecsToCheck[i];\n        return codecsToCheck[i];\n      }\n    }\n    return lowerCaseCodec;\n  }\n  var AUDIO_CODEC_REGEXP = /flac|opus/i;\n  function getCodecCompatibleName(codec, preferManagedMediaSource) {\n    if (preferManagedMediaSource === void 0) {\n      preferManagedMediaSource = true;\n    }\n    return codec.replace(AUDIO_CODEC_REGEXP, function (m) {\n      return getCodecCompatibleNameLower(m.toLowerCase(), preferManagedMediaSource);\n    });\n  }\n  function pickMostCompleteCodecName(parsedCodec, levelCodec) {\n    // Parsing of mp4a codecs strings in mp4-tools from media is incomplete as of d8c6c7a\n    // so use level codec is parsed codec is unavailable or incomplete\n    if (parsedCodec && parsedCodec !== 'mp4a') {\n      return parsedCodec;\n    }\n    return levelCodec ? levelCodec.split(',')[0] : levelCodec;\n  }\n  function convertAVC1ToAVCOTI(codec) {\n    // Convert avc1 codec string from RFC-4281 to RFC-6381 for MediaSource.isTypeSupported\n    // Examples: avc1.66.30 to avc1.42001e and avc1.77.30,avc1.66.30 to avc1.4d001e,avc1.42001e.\n    var codecs = codec.split(',');\n    for (var i = 0; i < codecs.length; i++) {\n      var avcdata = codecs[i].split('.');\n      if (avcdata.length > 2) {\n        var result = avcdata.shift() + '.';\n        result += parseInt(avcdata.shift()).toString(16);\n        result += ('000' + parseInt(avcdata.shift()).toString(16)).slice(-4);\n        codecs[i] = result;\n      }\n    }\n    return codecs.join(',');\n  }\n\n  var MASTER_PLAYLIST_REGEX = /#EXT-X-STREAM-INF:([^\\r\\n]*)(?:[\\r\\n](?:#[^\\r\\n]*)?)*([^\\r\\n]+)|#EXT-X-(SESSION-DATA|SESSION-KEY|DEFINE|CONTENT-STEERING|START):([^\\r\\n]*)[\\r\\n]+/g;\n  var MASTER_PLAYLIST_MEDIA_REGEX = /#EXT-X-MEDIA:(.*)/g;\n  var IS_MEDIA_PLAYLIST = /^#EXT(?:INF|-X-TARGETDURATION):/m; // Handle empty Media Playlist (first EXTINF not signaled, but TARGETDURATION present)\n\n  var LEVEL_PLAYLIST_REGEX_FAST = new RegExp([/#EXTINF:\\s*(\\d*(?:\\.\\d+)?)(?:,(.*)\\s+)?/.source,\n  // duration (#EXTINF:<duration>,<title>), group 1 => duration, group 2 => title\n  /(?!#) *(\\S[^\\r\\n]*)/.source,\n  // segment URI, group 3 => the URI (note newline is not eaten)\n  /#EXT-X-BYTERANGE:*(.+)/.source,\n  // next segment's byterange, group 4 => range spec (x@y)\n  /#EXT-X-PROGRAM-DATE-TIME:(.+)/.source,\n  // next segment's program date/time group 5 => the datetime spec\n  /#.*/.source // All other non-segment oriented tags will match with all groups empty\n  ].join('|'), 'g');\n  var LEVEL_PLAYLIST_REGEX_SLOW = new RegExp([/#(EXTM3U)/.source, /#EXT-X-(DATERANGE|DEFINE|KEY|MAP|PART|PART-INF|PLAYLIST-TYPE|PRELOAD-HINT|RENDITION-REPORT|SERVER-CONTROL|SKIP|START):(.+)/.source, /#EXT-X-(BITRATE|DISCONTINUITY-SEQUENCE|MEDIA-SEQUENCE|TARGETDURATION|VERSION): *(\\d+)/.source, /#EXT-X-(DISCONTINUITY|ENDLIST|GAP|INDEPENDENT-SEGMENTS)/.source, /(#)([^:]*):(.*)/.source, /(#)(.*)(?:.*)\\r?\\n?/.source].join('|'));\n  var M3U8Parser = /*#__PURE__*/function () {\n    function M3U8Parser() {}\n    M3U8Parser.findGroup = function findGroup(groups, mediaGroupId) {\n      for (var i = 0; i < groups.length; i++) {\n        var group = groups[i];\n        if (group.id === mediaGroupId) {\n          return group;\n        }\n      }\n    };\n    M3U8Parser.resolve = function resolve(url, baseUrl) {\n      return urlToolkitExports.buildAbsoluteURL(baseUrl, url, {\n        alwaysNormalize: true\n      });\n    };\n    M3U8Parser.isMediaPlaylist = function isMediaPlaylist(str) {\n      return IS_MEDIA_PLAYLIST.test(str);\n    };\n    M3U8Parser.parseMasterPlaylist = function parseMasterPlaylist(string, baseurl) {\n      var hasVariableRefs = hasVariableReferences(string) ;\n      var parsed = {\n        contentSteering: null,\n        levels: [],\n        playlistParsingError: null,\n        sessionData: null,\n        sessionKeys: null,\n        startTimeOffset: null,\n        variableList: null,\n        hasVariableRefs: hasVariableRefs\n      };\n      var levelsWithKnownCodecs = [];\n      MASTER_PLAYLIST_REGEX.lastIndex = 0;\n      var result;\n      while ((result = MASTER_PLAYLIST_REGEX.exec(string)) != null) {\n        if (result[1]) {\n          var _level$unknownCodecs;\n          // '#EXT-X-STREAM-INF' is found, parse level tag  in group 1\n          var attrs = new AttrList(result[1]);\n          {\n            substituteVariablesInAttributes(parsed, attrs, ['CODECS', 'SUPPLEMENTAL-CODECS', 'ALLOWED-CPC', 'PATHWAY-ID', 'STABLE-VARIANT-ID', 'AUDIO', 'VIDEO', 'SUBTITLES', 'CLOSED-CAPTIONS', 'NAME']);\n          }\n          var uri = substituteVariables(parsed, result[2]) ;\n          var level = {\n            attrs: attrs,\n            bitrate: attrs.decimalInteger('BANDWIDTH') || attrs.decimalInteger('AVERAGE-BANDWIDTH'),\n            name: attrs.NAME,\n            url: M3U8Parser.resolve(uri, baseurl)\n          };\n          var resolution = attrs.decimalResolution('RESOLUTION');\n          if (resolution) {\n            level.width = resolution.width;\n            level.height = resolution.height;\n          }\n          setCodecs(attrs.CODECS, level);\n          if (!((_level$unknownCodecs = level.unknownCodecs) != null && _level$unknownCodecs.length)) {\n            levelsWithKnownCodecs.push(level);\n          }\n          parsed.levels.push(level);\n        } else if (result[3]) {\n          var tag = result[3];\n          var attributes = result[4];\n          switch (tag) {\n            case 'SESSION-DATA':\n              {\n                // #EXT-X-SESSION-DATA\n                var sessionAttrs = new AttrList(attributes);\n                {\n                  substituteVariablesInAttributes(parsed, sessionAttrs, ['DATA-ID', 'LANGUAGE', 'VALUE', 'URI']);\n                }\n                var dataId = sessionAttrs['DATA-ID'];\n                if (dataId) {\n                  if (parsed.sessionData === null) {\n                    parsed.sessionData = {};\n                  }\n                  parsed.sessionData[dataId] = sessionAttrs;\n                }\n                break;\n              }\n            case 'SESSION-KEY':\n              {\n                // #EXT-X-SESSION-KEY\n                var sessionKey = parseKey(attributes, baseurl, parsed);\n                if (sessionKey.encrypted && sessionKey.isSupported()) {\n                  if (parsed.sessionKeys === null) {\n                    parsed.sessionKeys = [];\n                  }\n                  parsed.sessionKeys.push(sessionKey);\n                } else {\n                  logger.warn(\"[Keys] Ignoring invalid EXT-X-SESSION-KEY tag: \\\"\" + attributes + \"\\\"\");\n                }\n                break;\n              }\n            case 'DEFINE':\n              {\n                // #EXT-X-DEFINE\n                {\n                  var variableAttributes = new AttrList(attributes);\n                  substituteVariablesInAttributes(parsed, variableAttributes, ['NAME', 'VALUE', 'QUERYPARAM']);\n                  addVariableDefinition(parsed, variableAttributes, baseurl);\n                }\n                break;\n              }\n            case 'CONTENT-STEERING':\n              {\n                // #EXT-X-CONTENT-STEERING\n                var contentSteeringAttributes = new AttrList(attributes);\n                {\n                  substituteVariablesInAttributes(parsed, contentSteeringAttributes, ['SERVER-URI', 'PATHWAY-ID']);\n                }\n                parsed.contentSteering = {\n                  uri: M3U8Parser.resolve(contentSteeringAttributes['SERVER-URI'], baseurl),\n                  pathwayId: contentSteeringAttributes['PATHWAY-ID'] || '.'\n                };\n                break;\n              }\n            case 'START':\n              {\n                // #EXT-X-START\n                parsed.startTimeOffset = parseStartTimeOffset(attributes);\n                break;\n              }\n          }\n        }\n      }\n      // Filter out levels with unknown codecs if it does not remove all levels\n      var stripUnknownCodecLevels = levelsWithKnownCodecs.length > 0 && levelsWithKnownCodecs.length < parsed.levels.length;\n      parsed.levels = stripUnknownCodecLevels ? levelsWithKnownCodecs : parsed.levels;\n      if (parsed.levels.length === 0) {\n        parsed.playlistParsingError = new Error('no levels found in manifest');\n      }\n      return parsed;\n    };\n    M3U8Parser.parseMasterPlaylistMedia = function parseMasterPlaylistMedia(string, baseurl, parsed) {\n      var result;\n      var results = {};\n      var levels = parsed.levels;\n      var groupsByType = {\n        AUDIO: levels.map(function (level) {\n          return {\n            id: level.attrs.AUDIO,\n            audioCodec: level.audioCodec\n          };\n        }),\n        SUBTITLES: levels.map(function (level) {\n          return {\n            id: level.attrs.SUBTITLES,\n            textCodec: level.textCodec\n          };\n        }),\n        'CLOSED-CAPTIONS': []\n      };\n      var id = 0;\n      MASTER_PLAYLIST_MEDIA_REGEX.lastIndex = 0;\n      while ((result = MASTER_PLAYLIST_MEDIA_REGEX.exec(string)) !== null) {\n        var attrs = new AttrList(result[1]);\n        var type = attrs.TYPE;\n        if (type) {\n          var groups = groupsByType[type];\n          var medias = results[type] || [];\n          results[type] = medias;\n          {\n            substituteVariablesInAttributes(parsed, attrs, ['URI', 'GROUP-ID', 'LANGUAGE', 'ASSOC-LANGUAGE', 'STABLE-RENDITION-ID', 'NAME', 'INSTREAM-ID', 'CHARACTERISTICS', 'CHANNELS']);\n          }\n          var lang = attrs.LANGUAGE;\n          var assocLang = attrs['ASSOC-LANGUAGE'];\n          var channels = attrs.CHANNELS;\n          var characteristics = attrs.CHARACTERISTICS;\n          var instreamId = attrs['INSTREAM-ID'];\n          var media = {\n            attrs: attrs,\n            bitrate: 0,\n            id: id++,\n            groupId: attrs['GROUP-ID'] || '',\n            name: attrs.NAME || lang || '',\n            type: type,\n            default: attrs.bool('DEFAULT'),\n            autoselect: attrs.bool('AUTOSELECT'),\n            forced: attrs.bool('FORCED'),\n            lang: lang,\n            url: attrs.URI ? M3U8Parser.resolve(attrs.URI, baseurl) : ''\n          };\n          if (assocLang) {\n            media.assocLang = assocLang;\n          }\n          if (channels) {\n            media.channels = channels;\n          }\n          if (characteristics) {\n            media.characteristics = characteristics;\n          }\n          if (instreamId) {\n            media.instreamId = instreamId;\n          }\n          if (groups != null && groups.length) {\n            // If there are audio or text groups signalled in the manifest, let's look for a matching codec string for this track\n            // If we don't find the track signalled, lets use the first audio groups codec we have\n            // Acting as a best guess\n            var groupCodec = M3U8Parser.findGroup(groups, media.groupId) || groups[0];\n            assignCodec(media, groupCodec, 'audioCodec');\n            assignCodec(media, groupCodec, 'textCodec');\n          }\n          medias.push(media);\n        }\n      }\n      return results;\n    };\n    M3U8Parser.parseLevelPlaylist = function parseLevelPlaylist(string, baseurl, id, type, levelUrlId, multivariantVariableList) {\n      var level = new LevelDetails(baseurl);\n      var fragments = level.fragments;\n      // The most recent init segment seen (applies to all subsequent segments)\n      var currentInitSegment = null;\n      var currentSN = 0;\n      var currentPart = 0;\n      var totalduration = 0;\n      var discontinuityCounter = 0;\n      var prevFrag = null;\n      var frag = new Fragment(type, baseurl);\n      var result;\n      var i;\n      var levelkeys;\n      var firstPdtIndex = -1;\n      var createNextFrag = false;\n      var nextByteRange = null;\n      LEVEL_PLAYLIST_REGEX_FAST.lastIndex = 0;\n      level.m3u8 = string;\n      level.hasVariableRefs = hasVariableReferences(string) ;\n      while ((result = LEVEL_PLAYLIST_REGEX_FAST.exec(string)) !== null) {\n        if (createNextFrag) {\n          createNextFrag = false;\n          frag = new Fragment(type, baseurl);\n          // setup the next fragment for part loading\n          frag.start = totalduration;\n          frag.sn = currentSN;\n          frag.cc = discontinuityCounter;\n          frag.level = id;\n          if (currentInitSegment) {\n            frag.initSegment = currentInitSegment;\n            frag.rawProgramDateTime = currentInitSegment.rawProgramDateTime;\n            currentInitSegment.rawProgramDateTime = null;\n            if (nextByteRange) {\n              frag.setByteRange(nextByteRange);\n              nextByteRange = null;\n            }\n          }\n        }\n        var duration = result[1];\n        if (duration) {\n          // INF\n          frag.duration = parseFloat(duration);\n          // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n          var title = (' ' + result[2]).slice(1);\n          frag.title = title || null;\n          frag.tagList.push(title ? ['INF', duration, title] : ['INF', duration]);\n        } else if (result[3]) {\n          // url\n          if (isFiniteNumber(frag.duration)) {\n            frag.start = totalduration;\n            if (levelkeys) {\n              setFragLevelKeys(frag, levelkeys, level);\n            }\n            frag.sn = currentSN;\n            frag.level = id;\n            frag.cc = discontinuityCounter;\n            fragments.push(frag);\n            // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n            var uri = (' ' + result[3]).slice(1);\n            frag.relurl = substituteVariables(level, uri) ;\n            assignProgramDateTime(frag, prevFrag);\n            prevFrag = frag;\n            totalduration += frag.duration;\n            currentSN++;\n            currentPart = 0;\n            createNextFrag = true;\n          }\n        } else if (result[4]) {\n          // X-BYTERANGE\n          var data = (' ' + result[4]).slice(1);\n          if (prevFrag) {\n            frag.setByteRange(data, prevFrag);\n          } else {\n            frag.setByteRange(data);\n          }\n        } else if (result[5]) {\n          // PROGRAM-DATE-TIME\n          // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n          frag.rawProgramDateTime = (' ' + result[5]).slice(1);\n          frag.tagList.push(['PROGRAM-DATE-TIME', frag.rawProgramDateTime]);\n          if (firstPdtIndex === -1) {\n            firstPdtIndex = fragments.length;\n          }\n        } else {\n          result = result[0].match(LEVEL_PLAYLIST_REGEX_SLOW);\n          if (!result) {\n            logger.warn('No matches on slow regex match for level playlist!');\n            continue;\n          }\n          for (i = 1; i < result.length; i++) {\n            if (typeof result[i] !== 'undefined') {\n              break;\n            }\n          }\n\n          // avoid sliced strings    https://github.com/video-dev/hls.js/issues/939\n          var tag = (' ' + result[i]).slice(1);\n          var value1 = (' ' + result[i + 1]).slice(1);\n          var value2 = result[i + 2] ? (' ' + result[i + 2]).slice(1) : '';\n          switch (tag) {\n            case 'PLAYLIST-TYPE':\n              level.type = value1.toUpperCase();\n              break;\n            case 'MEDIA-SEQUENCE':\n              currentSN = level.startSN = parseInt(value1);\n              break;\n            case 'SKIP':\n              {\n                var skipAttrs = new AttrList(value1);\n                {\n                  substituteVariablesInAttributes(level, skipAttrs, ['RECENTLY-REMOVED-DATERANGES']);\n                }\n                var skippedSegments = skipAttrs.decimalInteger('SKIPPED-SEGMENTS');\n                if (isFiniteNumber(skippedSegments)) {\n                  level.skippedSegments = skippedSegments;\n                  // This will result in fragments[] containing undefined values, which we will fill in with `mergeDetails`\n                  for (var _i = skippedSegments; _i--;) {\n                    fragments.unshift(null);\n                  }\n                  currentSN += skippedSegments;\n                }\n                var recentlyRemovedDateranges = skipAttrs.enumeratedString('RECENTLY-REMOVED-DATERANGES');\n                if (recentlyRemovedDateranges) {\n                  level.recentlyRemovedDateranges = recentlyRemovedDateranges.split('\\t');\n                }\n                break;\n              }\n            case 'TARGETDURATION':\n              level.targetduration = Math.max(parseInt(value1), 1);\n              break;\n            case 'VERSION':\n              level.version = parseInt(value1);\n              break;\n            case 'INDEPENDENT-SEGMENTS':\n            case 'EXTM3U':\n              break;\n            case 'ENDLIST':\n              level.live = false;\n              break;\n            case '#':\n              if (value1 || value2) {\n                frag.tagList.push(value2 ? [value1, value2] : [value1]);\n              }\n              break;\n            case 'DISCONTINUITY':\n              discontinuityCounter++;\n              frag.tagList.push(['DIS']);\n              break;\n            case 'GAP':\n              frag.gap = true;\n              frag.tagList.push([tag]);\n              break;\n            case 'BITRATE':\n              frag.tagList.push([tag, value1]);\n              break;\n            case 'DATERANGE':\n              {\n                var dateRangeAttr = new AttrList(value1);\n                {\n                  substituteVariablesInAttributes(level, dateRangeAttr, ['ID', 'CLASS', 'START-DATE', 'END-DATE', 'SCTE35-CMD', 'SCTE35-OUT', 'SCTE35-IN']);\n                  substituteVariablesInAttributes(level, dateRangeAttr, dateRangeAttr.clientAttrs);\n                }\n                var dateRange = new DateRange(dateRangeAttr, level.dateRanges[dateRangeAttr.ID]);\n                if (dateRange.isValid || level.skippedSegments) {\n                  level.dateRanges[dateRange.id] = dateRange;\n                } else {\n                  logger.warn(\"Ignoring invalid DATERANGE tag: \\\"\" + value1 + \"\\\"\");\n                }\n                // Add to fragment tag list for backwards compatibility (< v1.2.0)\n                frag.tagList.push(['EXT-X-DATERANGE', value1]);\n                break;\n              }\n            case 'DEFINE':\n              {\n                {\n                  var variableAttributes = new AttrList(value1);\n                  substituteVariablesInAttributes(level, variableAttributes, ['NAME', 'VALUE', 'IMPORT', 'QUERYPARAM']);\n                  if ('IMPORT' in variableAttributes) {\n                    importVariableDefinition(level, variableAttributes, multivariantVariableList);\n                  } else {\n                    addVariableDefinition(level, variableAttributes, baseurl);\n                  }\n                }\n                break;\n              }\n            case 'DISCONTINUITY-SEQUENCE':\n              discontinuityCounter = parseInt(value1);\n              break;\n            case 'KEY':\n              {\n                var levelKey = parseKey(value1, baseurl, level);\n                if (levelKey.isSupported()) {\n                  if (levelKey.method === 'NONE') {\n                    levelkeys = undefined;\n                    break;\n                  }\n                  if (!levelkeys) {\n                    levelkeys = {};\n                  }\n                  if (levelkeys[levelKey.keyFormat]) {\n                    levelkeys = _extends({}, levelkeys);\n                  }\n                  levelkeys[levelKey.keyFormat] = levelKey;\n                } else {\n                  logger.warn(\"[Keys] Ignoring invalid EXT-X-KEY tag: \\\"\" + value1 + \"\\\"\");\n                }\n                break;\n              }\n            case 'START':\n              level.startTimeOffset = parseStartTimeOffset(value1);\n              break;\n            case 'MAP':\n              {\n                var mapAttrs = new AttrList(value1);\n                {\n                  substituteVariablesInAttributes(level, mapAttrs, ['BYTERANGE', 'URI']);\n                }\n                if (frag.duration) {\n                  // Initial segment tag is after segment duration tag.\n                  //   #EXTINF: 6.0\n                  //   #EXT-X-MAP:URI=\"init.mp4\n                  var init = new Fragment(type, baseurl);\n                  setInitSegment(init, mapAttrs, id, levelkeys);\n                  currentInitSegment = init;\n                  frag.initSegment = currentInitSegment;\n                  if (currentInitSegment.rawProgramDateTime && !frag.rawProgramDateTime) {\n                    frag.rawProgramDateTime = currentInitSegment.rawProgramDateTime;\n                  }\n                } else {\n                  // Initial segment tag is before segment duration tag\n                  // Handle case where EXT-X-MAP is declared after EXT-X-BYTERANGE\n                  var end = frag.byteRangeEndOffset;\n                  if (end) {\n                    var start = frag.byteRangeStartOffset;\n                    nextByteRange = end - start + \"@\" + start;\n                  } else {\n                    nextByteRange = null;\n                  }\n                  setInitSegment(frag, mapAttrs, id, levelkeys);\n                  currentInitSegment = frag;\n                  createNextFrag = true;\n                }\n                break;\n              }\n            case 'SERVER-CONTROL':\n              {\n                var serverControlAttrs = new AttrList(value1);\n                level.canBlockReload = serverControlAttrs.bool('CAN-BLOCK-RELOAD');\n                level.canSkipUntil = serverControlAttrs.optionalFloat('CAN-SKIP-UNTIL', 0);\n                level.canSkipDateRanges = level.canSkipUntil > 0 && serverControlAttrs.bool('CAN-SKIP-DATERANGES');\n                level.partHoldBack = serverControlAttrs.optionalFloat('PART-HOLD-BACK', 0);\n                level.holdBack = serverControlAttrs.optionalFloat('HOLD-BACK', 0);\n                break;\n              }\n            case 'PART-INF':\n              {\n                var partInfAttrs = new AttrList(value1);\n                level.partTarget = partInfAttrs.decimalFloatingPoint('PART-TARGET');\n                break;\n              }\n            case 'PART':\n              {\n                var partList = level.partList;\n                if (!partList) {\n                  partList = level.partList = [];\n                }\n                var previousFragmentPart = currentPart > 0 ? partList[partList.length - 1] : undefined;\n                var index = currentPart++;\n                var partAttrs = new AttrList(value1);\n                {\n                  substituteVariablesInAttributes(level, partAttrs, ['BYTERANGE', 'URI']);\n                }\n                var part = new Part(partAttrs, frag, baseurl, index, previousFragmentPart);\n                partList.push(part);\n                frag.duration += part.duration;\n                break;\n              }\n            case 'PRELOAD-HINT':\n              {\n                var preloadHintAttrs = new AttrList(value1);\n                {\n                  substituteVariablesInAttributes(level, preloadHintAttrs, ['URI']);\n                }\n                level.preloadHint = preloadHintAttrs;\n                break;\n              }\n            case 'RENDITION-REPORT':\n              {\n                var renditionReportAttrs = new AttrList(value1);\n                {\n                  substituteVariablesInAttributes(level, renditionReportAttrs, ['URI']);\n                }\n                level.renditionReports = level.renditionReports || [];\n                level.renditionReports.push(renditionReportAttrs);\n                break;\n              }\n            default:\n              logger.warn(\"line parsed but not handled: \" + result);\n              break;\n          }\n        }\n      }\n      if (prevFrag && !prevFrag.relurl) {\n        fragments.pop();\n        totalduration -= prevFrag.duration;\n        if (level.partList) {\n          level.fragmentHint = prevFrag;\n        }\n      } else if (level.partList) {\n        assignProgramDateTime(frag, prevFrag);\n        frag.cc = discontinuityCounter;\n        level.fragmentHint = frag;\n        if (levelkeys) {\n          setFragLevelKeys(frag, levelkeys, level);\n        }\n      }\n      var fragmentLength = fragments.length;\n      var firstFragment = fragments[0];\n      var lastFragment = fragments[fragmentLength - 1];\n      totalduration += level.skippedSegments * level.targetduration;\n      if (totalduration > 0 && fragmentLength && lastFragment) {\n        level.averagetargetduration = totalduration / fragmentLength;\n        var lastSn = lastFragment.sn;\n        level.endSN = lastSn !== 'initSegment' ? lastSn : 0;\n        if (!level.live) {\n          lastFragment.endList = true;\n        }\n        if (firstFragment) {\n          level.startCC = firstFragment.cc;\n        }\n      } else {\n        level.endSN = 0;\n        level.startCC = 0;\n      }\n      if (level.fragmentHint) {\n        totalduration += level.fragmentHint.duration;\n      }\n      level.totalduration = totalduration;\n      level.endCC = discontinuityCounter;\n\n      /**\n       * Backfill any missing PDT values\n       * \"If the first EXT-X-PROGRAM-DATE-TIME tag in a Playlist appears after\n       * one or more Media Segment URIs, the client SHOULD extrapolate\n       * backward from that tag (using EXTINF durations and/or media\n       * timestamps) to associate dates with those segments.\"\n       * We have already extrapolated forward, but all fragments up to the first instance of PDT do not have their PDTs\n       * computed.\n       */\n      if (firstPdtIndex > 0) {\n        backfillProgramDateTimes(fragments, firstPdtIndex);\n      }\n      return level;\n    };\n    return M3U8Parser;\n  }();\n  function parseKey(keyTagAttributes, baseurl, parsed) {\n    var _keyAttrs$METHOD, _keyAttrs$KEYFORMAT;\n    // https://tools.ietf.org/html/rfc8216#section-4.3.2.4\n    var keyAttrs = new AttrList(keyTagAttributes);\n    {\n      substituteVariablesInAttributes(parsed, keyAttrs, ['KEYFORMAT', 'KEYFORMATVERSIONS', 'URI', 'IV', 'URI']);\n    }\n    var decryptmethod = (_keyAttrs$METHOD = keyAttrs.METHOD) != null ? _keyAttrs$METHOD : '';\n    var decrypturi = keyAttrs.URI;\n    var decryptiv = keyAttrs.hexadecimalInteger('IV');\n    var decryptkeyformatversions = keyAttrs.KEYFORMATVERSIONS;\n    // From RFC: This attribute is OPTIONAL; its absence indicates an implicit value of \"identity\".\n    var decryptkeyformat = (_keyAttrs$KEYFORMAT = keyAttrs.KEYFORMAT) != null ? _keyAttrs$KEYFORMAT : 'identity';\n    if (decrypturi && keyAttrs.IV && !decryptiv) {\n      logger.error(\"Invalid IV: \" + keyAttrs.IV);\n    }\n    // If decrypturi is a URI with a scheme, then baseurl will be ignored\n    // No uri is allowed when METHOD is NONE\n    var resolvedUri = decrypturi ? M3U8Parser.resolve(decrypturi, baseurl) : '';\n    var keyFormatVersions = (decryptkeyformatversions ? decryptkeyformatversions : '1').split('/').map(Number).filter(Number.isFinite);\n    return new LevelKey(decryptmethod, resolvedUri, decryptkeyformat, keyFormatVersions, decryptiv);\n  }\n  function parseStartTimeOffset(startAttributes) {\n    var startAttrs = new AttrList(startAttributes);\n    var startTimeOffset = startAttrs.decimalFloatingPoint('TIME-OFFSET');\n    if (isFiniteNumber(startTimeOffset)) {\n      return startTimeOffset;\n    }\n    return null;\n  }\n  function setCodecs(codecsAttributeValue, level) {\n    var codecs = (codecsAttributeValue || '').split(/[ ,]+/).filter(function (c) {\n      return c;\n    });\n    ['video', 'audio', 'text'].forEach(function (type) {\n      var filtered = codecs.filter(function (codec) {\n        return isCodecType(codec, type);\n      });\n      if (filtered.length) {\n        // Comma separated list of all codecs for type\n        level[type + \"Codec\"] = filtered.join(',');\n        // Remove known codecs so that only unknownCodecs are left after iterating through each type\n        codecs = codecs.filter(function (codec) {\n          return filtered.indexOf(codec) === -1;\n        });\n      }\n    });\n    level.unknownCodecs = codecs;\n  }\n  function assignCodec(media, groupItem, codecProperty) {\n    var codecValue = groupItem[codecProperty];\n    if (codecValue) {\n      media[codecProperty] = codecValue;\n    }\n  }\n  function backfillProgramDateTimes(fragments, firstPdtIndex) {\n    var fragPrev = fragments[firstPdtIndex];\n    for (var i = firstPdtIndex; i--;) {\n      var frag = fragments[i];\n      // Exit on delta-playlist skipped segments\n      if (!frag) {\n        return;\n      }\n      frag.programDateTime = fragPrev.programDateTime - frag.duration * 1000;\n      fragPrev = frag;\n    }\n  }\n  function assignProgramDateTime(frag, prevFrag) {\n    if (frag.rawProgramDateTime) {\n      frag.programDateTime = Date.parse(frag.rawProgramDateTime);\n    } else if (prevFrag != null && prevFrag.programDateTime) {\n      frag.programDateTime = prevFrag.endProgramDateTime;\n    }\n    if (!isFiniteNumber(frag.programDateTime)) {\n      frag.programDateTime = null;\n      frag.rawProgramDateTime = null;\n    }\n  }\n  function setInitSegment(frag, mapAttrs, id, levelkeys) {\n    frag.relurl = mapAttrs.URI;\n    if (mapAttrs.BYTERANGE) {\n      frag.setByteRange(mapAttrs.BYTERANGE);\n    }\n    frag.level = id;\n    frag.sn = 'initSegment';\n    if (levelkeys) {\n      frag.levelkeys = levelkeys;\n    }\n    frag.initSegment = null;\n  }\n  function setFragLevelKeys(frag, levelkeys, level) {\n    frag.levelkeys = levelkeys;\n    var encryptedFragments = level.encryptedFragments;\n    if ((!encryptedFragments.length || encryptedFragments[encryptedFragments.length - 1].levelkeys !== levelkeys) && Object.keys(levelkeys).some(function (format) {\n      return levelkeys[format].isCommonEncryption;\n    })) {\n      encryptedFragments.push(frag);\n    }\n  }\n\n  var PlaylistContextType = {\n    MANIFEST: \"manifest\",\n    LEVEL: \"level\",\n    AUDIO_TRACK: \"audioTrack\",\n    SUBTITLE_TRACK: \"subtitleTrack\"\n  };\n  var PlaylistLevelType = {\n    MAIN: \"main\",\n    AUDIO: \"audio\",\n    SUBTITLE: \"subtitle\"\n  };\n\n  function mapContextToLevelType(context) {\n    var type = context.type;\n    switch (type) {\n      case PlaylistContextType.AUDIO_TRACK:\n        return PlaylistLevelType.AUDIO;\n      case PlaylistContextType.SUBTITLE_TRACK:\n        return PlaylistLevelType.SUBTITLE;\n      default:\n        return PlaylistLevelType.MAIN;\n    }\n  }\n  function getResponseUrl(response, context) {\n    var url = response.url;\n    // responseURL not supported on some browsers (it is used to detect URL redirection)\n    // data-uri mode also not supported (but no need to detect redirection)\n    if (url === undefined || url.indexOf('data:') === 0) {\n      // fallback to initial URL\n      url = context.url;\n    }\n    return url;\n  }\n  var PlaylistLoader = /*#__PURE__*/function () {\n    function PlaylistLoader(hls) {\n      this.hls = void 0;\n      this.loaders = Object.create(null);\n      this.variableList = null;\n      this.hls = hls;\n      this.registerListeners();\n    }\n    var _proto = PlaylistLoader.prototype;\n    _proto.startLoad = function startLoad(startPosition) {};\n    _proto.stopLoad = function stopLoad() {\n      this.destroyInternalLoaders();\n    };\n    _proto.registerListeners = function registerListeners() {\n      var hls = this.hls;\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);\n      hls.on(Events.AUDIO_TRACK_LOADING, this.onAudioTrackLoading, this);\n      hls.on(Events.SUBTITLE_TRACK_LOADING, this.onSubtitleTrackLoading, this);\n    };\n    _proto.unregisterListeners = function unregisterListeners() {\n      var hls = this.hls;\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.LEVEL_LOADING, this.onLevelLoading, this);\n      hls.off(Events.AUDIO_TRACK_LOADING, this.onAudioTrackLoading, this);\n      hls.off(Events.SUBTITLE_TRACK_LOADING, this.onSubtitleTrackLoading, this);\n    }\n\n    /**\n     * Returns defaults or configured loader-type overloads (pLoader and loader config params)\n     */;\n    _proto.createInternalLoader = function createInternalLoader(context) {\n      var config = this.hls.config;\n      var PLoader = config.pLoader;\n      var Loader = config.loader;\n      var InternalLoader = PLoader || Loader;\n      var loader = new InternalLoader(config);\n      this.loaders[context.type] = loader;\n      return loader;\n    };\n    _proto.getInternalLoader = function getInternalLoader(context) {\n      return this.loaders[context.type];\n    };\n    _proto.resetInternalLoader = function resetInternalLoader(contextType) {\n      if (this.loaders[contextType]) {\n        delete this.loaders[contextType];\n      }\n    }\n\n    /**\n     * Call `destroy` on all internal loader instances mapped (one per context type)\n     */;\n    _proto.destroyInternalLoaders = function destroyInternalLoaders() {\n      for (var contextType in this.loaders) {\n        var loader = this.loaders[contextType];\n        if (loader) {\n          loader.destroy();\n        }\n        this.resetInternalLoader(contextType);\n      }\n    };\n    _proto.destroy = function destroy() {\n      this.variableList = null;\n      this.unregisterListeners();\n      this.destroyInternalLoaders();\n    };\n    _proto.onManifestLoading = function onManifestLoading(event, data) {\n      var url = data.url;\n      this.variableList = null;\n      this.load({\n        id: null,\n        level: 0,\n        responseType: 'text',\n        type: PlaylistContextType.MANIFEST,\n        url: url,\n        deliveryDirectives: null\n      });\n    };\n    _proto.onLevelLoading = function onLevelLoading(event, data) {\n      var id = data.id,\n        level = data.level,\n        pathwayId = data.pathwayId,\n        url = data.url,\n        deliveryDirectives = data.deliveryDirectives;\n      this.load({\n        id: id,\n        level: level,\n        pathwayId: pathwayId,\n        responseType: 'text',\n        type: PlaylistContextType.LEVEL,\n        url: url,\n        deliveryDirectives: deliveryDirectives\n      });\n    };\n    _proto.onAudioTrackLoading = function onAudioTrackLoading(event, data) {\n      var id = data.id,\n        groupId = data.groupId,\n        url = data.url,\n        deliveryDirectives = data.deliveryDirectives;\n      this.load({\n        id: id,\n        groupId: groupId,\n        level: null,\n        responseType: 'text',\n        type: PlaylistContextType.AUDIO_TRACK,\n        url: url,\n        deliveryDirectives: deliveryDirectives\n      });\n    };\n    _proto.onSubtitleTrackLoading = function onSubtitleTrackLoading(event, data) {\n      var id = data.id,\n        groupId = data.groupId,\n        url = data.url,\n        deliveryDirectives = data.deliveryDirectives;\n      this.load({\n        id: id,\n        groupId: groupId,\n        level: null,\n        responseType: 'text',\n        type: PlaylistContextType.SUBTITLE_TRACK,\n        url: url,\n        deliveryDirectives: deliveryDirectives\n      });\n    };\n    _proto.load = function load(context) {\n      var _context$deliveryDire,\n        _this = this;\n      var config = this.hls.config;\n\n      // logger.debug(`[playlist-loader]: Loading playlist of type ${context.type}, level: ${context.level}, id: ${context.id}`);\n\n      // Check if a loader for this context already exists\n      var loader = this.getInternalLoader(context);\n      if (loader) {\n        var loaderContext = loader.context;\n        if (loaderContext && loaderContext.url === context.url && loaderContext.level === context.level) {\n          // same URL can't overlap\n          logger.trace('[playlist-loader]: playlist request ongoing');\n          return;\n        }\n        logger.log(\"[playlist-loader]: aborting previous loader for type: \" + context.type);\n        loader.abort();\n      }\n\n      // apply different configs for retries depending on\n      // context (manifest, level, audio/subs playlist)\n      var loadPolicy;\n      if (context.type === PlaylistContextType.MANIFEST) {\n        loadPolicy = config.manifestLoadPolicy.default;\n      } else {\n        loadPolicy = _extends({}, config.playlistLoadPolicy.default, {\n          timeoutRetry: null,\n          errorRetry: null\n        });\n      }\n      loader = this.createInternalLoader(context);\n\n      // Override level/track timeout for LL-HLS requests\n      // (the default of 10000ms is counter productive to blocking playlist reload requests)\n      if (isFiniteNumber((_context$deliveryDire = context.deliveryDirectives) == null ? void 0 : _context$deliveryDire.part)) {\n        var levelDetails;\n        if (context.type === PlaylistContextType.LEVEL && context.level !== null) {\n          levelDetails = this.hls.levels[context.level].details;\n        } else if (context.type === PlaylistContextType.AUDIO_TRACK && context.id !== null) {\n          levelDetails = this.hls.audioTracks[context.id].details;\n        } else if (context.type === PlaylistContextType.SUBTITLE_TRACK && context.id !== null) {\n          levelDetails = this.hls.subtitleTracks[context.id].details;\n        }\n        if (levelDetails) {\n          var partTarget = levelDetails.partTarget;\n          var targetDuration = levelDetails.targetduration;\n          if (partTarget && targetDuration) {\n            var maxLowLatencyPlaylistRefresh = Math.max(partTarget * 3, targetDuration * 0.8) * 1000;\n            loadPolicy = _extends({}, loadPolicy, {\n              maxTimeToFirstByteMs: Math.min(maxLowLatencyPlaylistRefresh, loadPolicy.maxTimeToFirstByteMs),\n              maxLoadTimeMs: Math.min(maxLowLatencyPlaylistRefresh, loadPolicy.maxTimeToFirstByteMs)\n            });\n          }\n        }\n      }\n      var legacyRetryCompatibility = loadPolicy.errorRetry || loadPolicy.timeoutRetry || {};\n      var loaderConfig = {\n        loadPolicy: loadPolicy,\n        timeout: loadPolicy.maxLoadTimeMs,\n        maxRetry: legacyRetryCompatibility.maxNumRetry || 0,\n        retryDelay: legacyRetryCompatibility.retryDelayMs || 0,\n        maxRetryDelay: legacyRetryCompatibility.maxRetryDelayMs || 0\n      };\n      var loaderCallbacks = {\n        onSuccess: function onSuccess(response, stats, context, networkDetails) {\n          var loader = _this.getInternalLoader(context);\n          _this.resetInternalLoader(context.type);\n          var string = response.data;\n\n          // Validate if it is an M3U8 at all\n          if (string.indexOf('#EXTM3U') !== 0) {\n            _this.handleManifestParsingError(response, context, new Error('no EXTM3U delimiter'), networkDetails || null, stats);\n            return;\n          }\n          stats.parsing.start = performance.now();\n          if (M3U8Parser.isMediaPlaylist(string)) {\n            _this.handleTrackOrLevelPlaylist(response, stats, context, networkDetails || null, loader);\n          } else {\n            _this.handleMasterPlaylist(response, stats, context, networkDetails);\n          }\n        },\n        onError: function onError(response, context, networkDetails, stats) {\n          _this.handleNetworkError(context, networkDetails, false, response, stats);\n        },\n        onTimeout: function onTimeout(stats, context, networkDetails) {\n          _this.handleNetworkError(context, networkDetails, true, undefined, stats);\n        }\n      };\n\n      // logger.debug(`[playlist-loader]: Calling internal loader delegate for URL: ${context.url}`);\n\n      loader.load(context, loaderConfig, loaderCallbacks);\n    };\n    _proto.handleMasterPlaylist = function handleMasterPlaylist(response, stats, context, networkDetails) {\n      var hls = this.hls;\n      var string = response.data;\n      var url = getResponseUrl(response, context);\n      var parsedResult = M3U8Parser.parseMasterPlaylist(string, url);\n      if (parsedResult.playlistParsingError) {\n        this.handleManifestParsingError(response, context, parsedResult.playlistParsingError, networkDetails, stats);\n        return;\n      }\n      var contentSteering = parsedResult.contentSteering,\n        levels = parsedResult.levels,\n        sessionData = parsedResult.sessionData,\n        sessionKeys = parsedResult.sessionKeys,\n        startTimeOffset = parsedResult.startTimeOffset,\n        variableList = parsedResult.variableList;\n      this.variableList = variableList;\n      var _M3U8Parser$parseMast = M3U8Parser.parseMasterPlaylistMedia(string, url, parsedResult),\n        _M3U8Parser$parseMast2 = _M3U8Parser$parseMast.AUDIO,\n        audioTracks = _M3U8Parser$parseMast2 === void 0 ? [] : _M3U8Parser$parseMast2,\n        subtitles = _M3U8Parser$parseMast.SUBTITLES,\n        captions = _M3U8Parser$parseMast['CLOSED-CAPTIONS'];\n      if (audioTracks.length) {\n        // check if we have found an audio track embedded in main playlist (audio track without URI attribute)\n        var embeddedAudioFound = audioTracks.some(function (audioTrack) {\n          return !audioTrack.url;\n        });\n\n        // if no embedded audio track defined, but audio codec signaled in quality level,\n        // we need to signal this main audio track this could happen with playlists with\n        // alt audio rendition in which quality levels (main)\n        // contains both audio+video. but with mixed audio track not signaled\n        if (!embeddedAudioFound && levels[0].audioCodec && !levels[0].attrs.AUDIO) {\n          logger.log('[playlist-loader]: audio codec signaled in quality level, but no embedded audio track signaled, create one');\n          audioTracks.unshift({\n            type: 'main',\n            name: 'main',\n            groupId: 'main',\n            default: false,\n            autoselect: false,\n            forced: false,\n            id: -1,\n            attrs: new AttrList({}),\n            bitrate: 0,\n            url: ''\n          });\n        }\n      }\n      hls.trigger(Events.MANIFEST_LOADED, {\n        levels: levels,\n        audioTracks: audioTracks,\n        subtitles: subtitles,\n        captions: captions,\n        contentSteering: contentSteering,\n        url: url,\n        stats: stats,\n        networkDetails: networkDetails,\n        sessionData: sessionData,\n        sessionKeys: sessionKeys,\n        startTimeOffset: startTimeOffset,\n        variableList: variableList\n      });\n    };\n    _proto.handleTrackOrLevelPlaylist = function handleTrackOrLevelPlaylist(response, stats, context, networkDetails, loader) {\n      var hls = this.hls;\n      var id = context.id,\n        level = context.level,\n        type = context.type;\n      var url = getResponseUrl(response, context);\n      var levelUrlId = 0;\n      var levelId = isFiniteNumber(level) ? level : isFiniteNumber(id) ? id : 0;\n      var levelType = mapContextToLevelType(context);\n      var levelDetails = M3U8Parser.parseLevelPlaylist(response.data, url, levelId, levelType, levelUrlId, this.variableList);\n\n      // We have done our first request (Manifest-type) and receive\n      // not a master playlist but a chunk-list (track/level)\n      // We fire the manifest-loaded event anyway with the parsed level-details\n      // by creating a single-level structure for it.\n      if (type === PlaylistContextType.MANIFEST) {\n        var singleLevel = {\n          attrs: new AttrList({}),\n          bitrate: 0,\n          details: levelDetails,\n          name: '',\n          url: url\n        };\n        hls.trigger(Events.MANIFEST_LOADED, {\n          levels: [singleLevel],\n          audioTracks: [],\n          url: url,\n          stats: stats,\n          networkDetails: networkDetails,\n          sessionData: null,\n          sessionKeys: null,\n          contentSteering: null,\n          startTimeOffset: null,\n          variableList: null\n        });\n      }\n\n      // save parsing time\n      stats.parsing.end = performance.now();\n\n      // extend the context with the new levelDetails property\n      context.levelDetails = levelDetails;\n      this.handlePlaylistLoaded(levelDetails, response, stats, context, networkDetails, loader);\n    };\n    _proto.handleManifestParsingError = function handleManifestParsingError(response, context, error, networkDetails, stats) {\n      this.hls.trigger(Events.ERROR, {\n        type: ErrorTypes.NETWORK_ERROR,\n        details: ErrorDetails.MANIFEST_PARSING_ERROR,\n        fatal: context.type === PlaylistContextType.MANIFEST,\n        url: response.url,\n        err: error,\n        error: error,\n        reason: error.message,\n        response: response,\n        context: context,\n        networkDetails: networkDetails,\n        stats: stats\n      });\n    };\n    _proto.handleNetworkError = function handleNetworkError(context, networkDetails, timeout, response, stats) {\n      if (timeout === void 0) {\n        timeout = false;\n      }\n      var message = \"A network \" + (timeout ? 'timeout' : 'error' + (response ? ' (status ' + response.code + ')' : '')) + \" occurred while loading \" + context.type;\n      if (context.type === PlaylistContextType.LEVEL) {\n        message += \": \" + context.level + \" id: \" + context.id;\n      } else if (context.type === PlaylistContextType.AUDIO_TRACK || context.type === PlaylistContextType.SUBTITLE_TRACK) {\n        message += \" id: \" + context.id + \" group-id: \\\"\" + context.groupId + \"\\\"\";\n      }\n      var error = new Error(message);\n      logger.warn(\"[playlist-loader]: \" + message);\n      var details = ErrorDetails.UNKNOWN;\n      var fatal = false;\n      var loader = this.getInternalLoader(context);\n      switch (context.type) {\n        case PlaylistContextType.MANIFEST:\n          details = timeout ? ErrorDetails.MANIFEST_LOAD_TIMEOUT : ErrorDetails.MANIFEST_LOAD_ERROR;\n          fatal = true;\n          break;\n        case PlaylistContextType.LEVEL:\n          details = timeout ? ErrorDetails.LEVEL_LOAD_TIMEOUT : ErrorDetails.LEVEL_LOAD_ERROR;\n          fatal = false;\n          break;\n        case PlaylistContextType.AUDIO_TRACK:\n          details = timeout ? ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT : ErrorDetails.AUDIO_TRACK_LOAD_ERROR;\n          fatal = false;\n          break;\n        case PlaylistContextType.SUBTITLE_TRACK:\n          details = timeout ? ErrorDetails.SUBTITLE_TRACK_LOAD_TIMEOUT : ErrorDetails.SUBTITLE_LOAD_ERROR;\n          fatal = false;\n          break;\n      }\n      if (loader) {\n        this.resetInternalLoader(context.type);\n      }\n      var errorData = {\n        type: ErrorTypes.NETWORK_ERROR,\n        details: details,\n        fatal: fatal,\n        url: context.url,\n        loader: loader,\n        context: context,\n        error: error,\n        networkDetails: networkDetails,\n        stats: stats\n      };\n      if (response) {\n        var url = (networkDetails == null ? void 0 : networkDetails.url) || context.url;\n        errorData.response = _objectSpread2({\n          url: url,\n          data: undefined\n        }, response);\n      }\n      this.hls.trigger(Events.ERROR, errorData);\n    };\n    _proto.handlePlaylistLoaded = function handlePlaylistLoaded(levelDetails, response, stats, context, networkDetails, loader) {\n      var hls = this.hls;\n      var type = context.type,\n        level = context.level,\n        id = context.id,\n        groupId = context.groupId,\n        deliveryDirectives = context.deliveryDirectives;\n      var url = getResponseUrl(response, context);\n      var parent = mapContextToLevelType(context);\n      var levelIndex = typeof context.level === 'number' && parent === PlaylistLevelType.MAIN ? level : undefined;\n      if (!levelDetails.fragments.length) {\n        var _error = new Error('No Segments found in Playlist');\n        hls.trigger(Events.ERROR, {\n          type: ErrorTypes.NETWORK_ERROR,\n          details: ErrorDetails.LEVEL_EMPTY_ERROR,\n          fatal: false,\n          url: url,\n          error: _error,\n          reason: _error.message,\n          response: response,\n          context: context,\n          level: levelIndex,\n          parent: parent,\n          networkDetails: networkDetails,\n          stats: stats\n        });\n        return;\n      }\n      if (!levelDetails.targetduration) {\n        levelDetails.playlistParsingError = new Error('Missing Target Duration');\n      }\n      var error = levelDetails.playlistParsingError;\n      if (error) {\n        hls.trigger(Events.ERROR, {\n          type: ErrorTypes.NETWORK_ERROR,\n          details: ErrorDetails.LEVEL_PARSING_ERROR,\n          fatal: false,\n          url: url,\n          error: error,\n          reason: error.message,\n          response: response,\n          context: context,\n          level: levelIndex,\n          parent: parent,\n          networkDetails: networkDetails,\n          stats: stats\n        });\n        return;\n      }\n      if (levelDetails.live && loader) {\n        if (loader.getCacheAge) {\n          levelDetails.ageHeader = loader.getCacheAge() || 0;\n        }\n        if (!loader.getCacheAge || isNaN(levelDetails.ageHeader)) {\n          levelDetails.ageHeader = 0;\n        }\n      }\n      switch (type) {\n        case PlaylistContextType.MANIFEST:\n        case PlaylistContextType.LEVEL:\n          hls.trigger(Events.LEVEL_LOADED, {\n            details: levelDetails,\n            level: levelIndex || 0,\n            id: id || 0,\n            stats: stats,\n            networkDetails: networkDetails,\n            deliveryDirectives: deliveryDirectives\n          });\n          break;\n        case PlaylistContextType.AUDIO_TRACK:\n          hls.trigger(Events.AUDIO_TRACK_LOADED, {\n            details: levelDetails,\n            id: id || 0,\n            groupId: groupId || '',\n            stats: stats,\n            networkDetails: networkDetails,\n            deliveryDirectives: deliveryDirectives\n          });\n          break;\n        case PlaylistContextType.SUBTITLE_TRACK:\n          hls.trigger(Events.SUBTITLE_TRACK_LOADED, {\n            details: levelDetails,\n            id: id || 0,\n            groupId: groupId || '',\n            stats: stats,\n            networkDetails: networkDetails,\n            deliveryDirectives: deliveryDirectives\n          });\n          break;\n      }\n    };\n    return PlaylistLoader;\n  }();\n\n  function sendAddTrackEvent(track, videoEl) {\n    var event;\n    try {\n      event = new Event('addtrack');\n    } catch (err) {\n      // for IE11\n      event = document.createEvent('Event');\n      event.initEvent('addtrack', false, false);\n    }\n    event.track = track;\n    videoEl.dispatchEvent(event);\n  }\n  function addCueToTrack(track, cue) {\n    // Sometimes there are cue overlaps on segmented vtts so the same\n    // cue can appear more than once in different vtt files.\n    // This avoid showing duplicated cues with same timecode and text.\n    var mode = track.mode;\n    if (mode === 'disabled') {\n      track.mode = 'hidden';\n    }\n    if (track.cues && !track.cues.getCueById(cue.id)) {\n      try {\n        track.addCue(cue);\n        if (!track.cues.getCueById(cue.id)) {\n          throw new Error(\"addCue is failed for: \" + cue);\n        }\n      } catch (err) {\n        logger.debug(\"[texttrack-utils]: \" + err);\n        try {\n          var textTrackCue = new self.TextTrackCue(cue.startTime, cue.endTime, cue.text);\n          textTrackCue.id = cue.id;\n          track.addCue(textTrackCue);\n        } catch (err2) {\n          logger.debug(\"[texttrack-utils]: Legacy TextTrackCue fallback failed: \" + err2);\n        }\n      }\n    }\n    if (mode === 'disabled') {\n      track.mode = mode;\n    }\n  }\n  function clearCurrentCues(track) {\n    // When track.mode is disabled, track.cues will be null.\n    // To guarantee the removal of cues, we need to temporarily\n    // change the mode to hidden\n    var mode = track.mode;\n    if (mode === 'disabled') {\n      track.mode = 'hidden';\n    }\n    if (track.cues) {\n      for (var i = track.cues.length; i--;) {\n        track.removeCue(track.cues[i]);\n      }\n    }\n    if (mode === 'disabled') {\n      track.mode = mode;\n    }\n  }\n  function removeCuesInRange(track, start, end, predicate) {\n    var mode = track.mode;\n    if (mode === 'disabled') {\n      track.mode = 'hidden';\n    }\n    if (track.cues && track.cues.length > 0) {\n      var cues = getCuesInRange(track.cues, start, end);\n      for (var i = 0; i < cues.length; i++) {\n        if (!predicate || predicate(cues[i])) {\n          track.removeCue(cues[i]);\n        }\n      }\n    }\n    if (mode === 'disabled') {\n      track.mode = mode;\n    }\n  }\n\n  // Find first cue starting after given time.\n  // Modified version of binary search O(log(n)).\n  function getFirstCueIndexAfterTime(cues, time) {\n    // If first cue starts after time, start there\n    if (time < cues[0].startTime) {\n      return 0;\n    }\n    // If the last cue ends before time there is no overlap\n    var len = cues.length - 1;\n    if (time > cues[len].endTime) {\n      return -1;\n    }\n    var left = 0;\n    var right = len;\n    while (left <= right) {\n      var mid = Math.floor((right + left) / 2);\n      if (time < cues[mid].startTime) {\n        right = mid - 1;\n      } else if (time > cues[mid].startTime && left < len) {\n        left = mid + 1;\n      } else {\n        // If it's not lower or higher, it must be equal.\n        return mid;\n      }\n    }\n    // At this point, left and right have swapped.\n    // No direct match was found, left or right element must be the closest. Check which one has the smallest diff.\n    return cues[left].startTime - time < time - cues[right].startTime ? left : right;\n  }\n  function getCuesInRange(cues, start, end) {\n    var cuesFound = [];\n    var firstCueInRange = getFirstCueIndexAfterTime(cues, start);\n    if (firstCueInRange > -1) {\n      for (var i = firstCueInRange, len = cues.length; i < len; i++) {\n        var _cue = cues[i];\n        if (_cue.startTime >= start && _cue.endTime <= end) {\n          cuesFound.push(_cue);\n        } else if (_cue.startTime > end) {\n          return cuesFound;\n        }\n      }\n    }\n    return cuesFound;\n  }\n  function filterSubtitleTracks(textTrackList) {\n    var tracks = [];\n    for (var i = 0; i < textTrackList.length; i++) {\n      var track = textTrackList[i];\n      // Edge adds a track without a label; we don't want to use it\n      if ((track.kind === 'subtitles' || track.kind === 'captions') && track.label) {\n        tracks.push(textTrackList[i]);\n      }\n    }\n    return tracks;\n  }\n\n  var MetadataSchema = {\n    audioId3: \"org.id3\",\n    dateRange: \"com.apple.quicktime.HLS\",\n    emsg: \"https://aomedia.org/emsg/ID3\"\n  };\n\n  var MIN_CUE_DURATION = 0.25;\n  function getCueClass() {\n    if (typeof self === 'undefined') return undefined;\n    return self.VTTCue || self.TextTrackCue;\n  }\n  function createCueWithDataFields(Cue, startTime, endTime, data, type) {\n    var cue = new Cue(startTime, endTime, '');\n    try {\n      cue.value = data;\n      if (type) {\n        cue.type = type;\n      }\n    } catch (e) {\n      cue = new Cue(startTime, endTime, JSON.stringify(type ? _objectSpread2({\n        type: type\n      }, data) : data));\n    }\n    return cue;\n  }\n\n  // VTTCue latest draft allows an infinite duration, fallback\n  // to MAX_VALUE if necessary\n  var MAX_CUE_ENDTIME = function () {\n    var Cue = getCueClass();\n    try {\n      Cue && new Cue(0, Number.POSITIVE_INFINITY, '');\n    } catch (e) {\n      return Number.MAX_VALUE;\n    }\n    return Number.POSITIVE_INFINITY;\n  }();\n  function dateRangeDateToTimelineSeconds(date, offset) {\n    return date.getTime() / 1000 - offset;\n  }\n  function hexToArrayBuffer(str) {\n    return Uint8Array.from(str.replace(/^0x/, '').replace(/([\\da-fA-F]{2}) ?/g, '0x$1 ').replace(/ +$/, '').split(' ')).buffer;\n  }\n  var ID3TrackController = /*#__PURE__*/function () {\n    function ID3TrackController(hls) {\n      this.hls = void 0;\n      this.id3Track = null;\n      this.media = null;\n      this.dateRangeCuesAppended = {};\n      this.hls = hls;\n      this._registerListeners();\n    }\n    var _proto = ID3TrackController.prototype;\n    _proto.destroy = function destroy() {\n      this._unregisterListeners();\n      this.id3Track = null;\n      this.media = null;\n      this.dateRangeCuesAppended = {};\n      // @ts-ignore\n      this.hls = null;\n    };\n    _proto._registerListeners = function _registerListeners() {\n      var hls = this.hls;\n      hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.FRAG_PARSING_METADATA, this.onFragParsingMetadata, this);\n      hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n      hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n    };\n    _proto._unregisterListeners = function _unregisterListeners() {\n      var hls = this.hls;\n      hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.FRAG_PARSING_METADATA, this.onFragParsingMetadata, this);\n      hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n      hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n    }\n\n    // Add ID3 metatadata text track.\n    ;\n    _proto.onMediaAttached = function onMediaAttached(event, data) {\n      this.media = data.media;\n    };\n    _proto.onMediaDetaching = function onMediaDetaching() {\n      if (!this.id3Track) {\n        return;\n      }\n      clearCurrentCues(this.id3Track);\n      this.id3Track = null;\n      this.media = null;\n      this.dateRangeCuesAppended = {};\n    };\n    _proto.onManifestLoading = function onManifestLoading() {\n      this.dateRangeCuesAppended = {};\n    };\n    _proto.createTrack = function createTrack(media) {\n      var track = this.getID3Track(media.textTracks);\n      track.mode = 'hidden';\n      return track;\n    };\n    _proto.getID3Track = function getID3Track(textTracks) {\n      if (!this.media) {\n        return;\n      }\n      for (var i = 0; i < textTracks.length; i++) {\n        var textTrack = textTracks[i];\n        if (textTrack.kind === 'metadata' && textTrack.label === 'id3') {\n          // send 'addtrack' when reusing the textTrack for metadata,\n          // same as what we do for captions\n          sendAddTrackEvent(textTrack, this.media);\n          return textTrack;\n        }\n      }\n      return this.media.addTextTrack('metadata', 'id3');\n    };\n    _proto.onFragParsingMetadata = function onFragParsingMetadata(event, data) {\n      if (!this.media) {\n        return;\n      }\n      var _this$hls$config = this.hls.config,\n        enableEmsgMetadataCues = _this$hls$config.enableEmsgMetadataCues,\n        enableID3MetadataCues = _this$hls$config.enableID3MetadataCues;\n      if (!enableEmsgMetadataCues && !enableID3MetadataCues) {\n        return;\n      }\n      var samples = data.samples;\n\n      // create track dynamically\n      if (!this.id3Track) {\n        this.id3Track = this.createTrack(this.media);\n      }\n      var Cue = getCueClass();\n      if (!Cue) {\n        return;\n      }\n      for (var i = 0; i < samples.length; i++) {\n        var type = samples[i].type;\n        if (type === MetadataSchema.emsg && !enableEmsgMetadataCues || !enableID3MetadataCues) {\n          continue;\n        }\n        var frames = getID3Frames(samples[i].data);\n        if (frames) {\n          var startTime = samples[i].pts;\n          var endTime = startTime + samples[i].duration;\n          if (endTime > MAX_CUE_ENDTIME) {\n            endTime = MAX_CUE_ENDTIME;\n          }\n          var timeDiff = endTime - startTime;\n          if (timeDiff <= 0) {\n            endTime = startTime + MIN_CUE_DURATION;\n          }\n          for (var j = 0; j < frames.length; j++) {\n            var frame = frames[j];\n            // Safari doesn't put the timestamp frame in the TextTrack\n            if (!isTimeStampFrame(frame)) {\n              // add a bounds to any unbounded cues\n              this.updateId3CueEnds(startTime, type);\n              var cue = createCueWithDataFields(Cue, startTime, endTime, frame, type);\n              if (cue) {\n                this.id3Track.addCue(cue);\n              }\n            }\n          }\n        }\n      }\n    };\n    _proto.updateId3CueEnds = function updateId3CueEnds(startTime, type) {\n      var _this$id3Track;\n      var cues = (_this$id3Track = this.id3Track) == null ? void 0 : _this$id3Track.cues;\n      if (cues) {\n        for (var i = cues.length; i--;) {\n          var cue = cues[i];\n          if (cue.type === type && cue.startTime < startTime && cue.endTime === MAX_CUE_ENDTIME) {\n            cue.endTime = startTime;\n          }\n        }\n      }\n    };\n    _proto.onBufferFlushing = function onBufferFlushing(event, _ref) {\n      var startOffset = _ref.startOffset,\n        endOffset = _ref.endOffset,\n        type = _ref.type;\n      var id3Track = this.id3Track,\n        hls = this.hls;\n      if (!hls) {\n        return;\n      }\n      var _hls$config = hls.config,\n        enableEmsgMetadataCues = _hls$config.enableEmsgMetadataCues,\n        enableID3MetadataCues = _hls$config.enableID3MetadataCues;\n      if (id3Track && (enableEmsgMetadataCues || enableID3MetadataCues)) {\n        var predicate;\n        if (type === 'audio') {\n          predicate = function predicate(cue) {\n            return cue.type === MetadataSchema.audioId3 && enableID3MetadataCues;\n          };\n        } else if (type === 'video') {\n          predicate = function predicate(cue) {\n            return cue.type === MetadataSchema.emsg && enableEmsgMetadataCues;\n          };\n        } else {\n          predicate = function predicate(cue) {\n            return cue.type === MetadataSchema.audioId3 && enableID3MetadataCues || cue.type === MetadataSchema.emsg && enableEmsgMetadataCues;\n          };\n        }\n        removeCuesInRange(id3Track, startOffset, endOffset, predicate);\n      }\n    };\n    _proto.onLevelUpdated = function onLevelUpdated(event, _ref2) {\n      var _this = this;\n      var details = _ref2.details;\n      if (!this.media || !details.hasProgramDateTime || !this.hls.config.enableDateRangeMetadataCues) {\n        return;\n      }\n      var dateRangeCuesAppended = this.dateRangeCuesAppended,\n        id3Track = this.id3Track;\n      var dateRanges = details.dateRanges;\n      var ids = Object.keys(dateRanges);\n      // Remove cues from track not found in details.dateRanges\n      if (id3Track) {\n        var idsToRemove = Object.keys(dateRangeCuesAppended).filter(function (id) {\n          return !ids.includes(id);\n        });\n        var _loop = function _loop() {\n          var id = idsToRemove[i];\n          Object.keys(dateRangeCuesAppended[id].cues).forEach(function (key) {\n            id3Track.removeCue(dateRangeCuesAppended[id].cues[key]);\n          });\n          delete dateRangeCuesAppended[id];\n        };\n        for (var i = idsToRemove.length; i--;) {\n          _loop();\n        }\n      }\n      // Exit if the playlist does not have Date Ranges or does not have Program Date Time\n      var lastFragment = details.fragments[details.fragments.length - 1];\n      if (ids.length === 0 || !isFiniteNumber(lastFragment == null ? void 0 : lastFragment.programDateTime)) {\n        return;\n      }\n      if (!this.id3Track) {\n        this.id3Track = this.createTrack(this.media);\n      }\n      var dateTimeOffset = lastFragment.programDateTime / 1000 - lastFragment.start;\n      var Cue = getCueClass();\n      var _loop2 = function _loop2() {\n        var id = ids[_i];\n        var dateRange = dateRanges[id];\n        var startTime = dateRangeDateToTimelineSeconds(dateRange.startDate, dateTimeOffset);\n\n        // Process DateRanges to determine end-time (known DURATION, END-DATE, or END-ON-NEXT)\n        var appendedDateRangeCues = dateRangeCuesAppended[id];\n        var cues = (appendedDateRangeCues == null ? void 0 : appendedDateRangeCues.cues) || {};\n        var durationKnown = (appendedDateRangeCues == null ? void 0 : appendedDateRangeCues.durationKnown) || false;\n        var endTime = MAX_CUE_ENDTIME;\n        var endDate = dateRange.endDate;\n        if (endDate) {\n          endTime = dateRangeDateToTimelineSeconds(endDate, dateTimeOffset);\n          durationKnown = true;\n        } else if (dateRange.endOnNext && !durationKnown) {\n          var nextDateRangeWithSameClass = ids.reduce(function (candidateDateRange, id) {\n            if (id !== dateRange.id) {\n              var otherDateRange = dateRanges[id];\n              if (otherDateRange.class === dateRange.class && otherDateRange.startDate > dateRange.startDate && (!candidateDateRange || dateRange.startDate < candidateDateRange.startDate)) {\n                return otherDateRange;\n              }\n            }\n            return candidateDateRange;\n          }, null);\n          if (nextDateRangeWithSameClass) {\n            endTime = dateRangeDateToTimelineSeconds(nextDateRangeWithSameClass.startDate, dateTimeOffset);\n            durationKnown = true;\n          }\n        }\n\n        // Create TextTrack Cues for each MetadataGroup Item (select DateRange attribute)\n        // This is to emulate Safari HLS playback handling of DateRange tags\n        var attributes = Object.keys(dateRange.attr);\n        for (var j = 0; j < attributes.length; j++) {\n          var key = attributes[j];\n          if (!isDateRangeCueAttribute(key)) {\n            continue;\n          }\n          var cue = cues[key];\n          if (cue) {\n            if (durationKnown && !appendedDateRangeCues.durationKnown) {\n              cue.endTime = endTime;\n            }\n          } else if (Cue) {\n            var data = dateRange.attr[key];\n            if (isSCTE35Attribute(key)) {\n              data = hexToArrayBuffer(data);\n            }\n            var _cue = createCueWithDataFields(Cue, startTime, endTime, {\n              key: key,\n              data: data\n            }, MetadataSchema.dateRange);\n            if (_cue) {\n              _cue.id = id;\n              _this.id3Track.addCue(_cue);\n              cues[key] = _cue;\n            }\n          }\n        }\n\n        // Keep track of processed DateRanges by ID for updating cues with new DateRange tag attributes\n        dateRangeCuesAppended[id] = {\n          cues: cues,\n          dateRange: dateRange,\n          durationKnown: durationKnown\n        };\n      };\n      for (var _i = 0; _i < ids.length; _i++) {\n        _loop2();\n      }\n    };\n    return ID3TrackController;\n  }();\n\n  var LatencyController = /*#__PURE__*/function () {\n    function LatencyController(hls) {\n      var _this = this;\n      this.hls = void 0;\n      this.config = void 0;\n      this.media = null;\n      this.levelDetails = null;\n      this.currentTime = 0;\n      this.stallCount = 0;\n      this._latency = null;\n      this.timeupdateHandler = function () {\n        return _this.timeupdate();\n      };\n      this.hls = hls;\n      this.config = hls.config;\n      this.registerListeners();\n    }\n    var _proto = LatencyController.prototype;\n    _proto.destroy = function destroy() {\n      this.unregisterListeners();\n      this.onMediaDetaching();\n      this.levelDetails = null;\n      // @ts-ignore\n      this.hls = this.timeupdateHandler = null;\n    };\n    _proto.registerListeners = function registerListeners() {\n      this.hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      this.hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      this.hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      this.hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n      this.hls.on(Events.ERROR, this.onError, this);\n    };\n    _proto.unregisterListeners = function unregisterListeners() {\n      this.hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      this.hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      this.hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      this.hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n      this.hls.off(Events.ERROR, this.onError, this);\n    };\n    _proto.onMediaAttached = function onMediaAttached(event, data) {\n      this.media = data.media;\n      this.media.addEventListener('timeupdate', this.timeupdateHandler);\n    };\n    _proto.onMediaDetaching = function onMediaDetaching() {\n      if (this.media) {\n        this.media.removeEventListener('timeupdate', this.timeupdateHandler);\n        this.media = null;\n      }\n    };\n    _proto.onManifestLoading = function onManifestLoading() {\n      this.levelDetails = null;\n      this._latency = null;\n      this.stallCount = 0;\n    };\n    _proto.onLevelUpdated = function onLevelUpdated(event, _ref) {\n      var details = _ref.details;\n      this.levelDetails = details;\n      if (details.advanced) {\n        this.timeupdate();\n      }\n      if (!details.live && this.media) {\n        this.media.removeEventListener('timeupdate', this.timeupdateHandler);\n      }\n    };\n    _proto.onError = function onError(event, data) {\n      var _this$levelDetails;\n      if (data.details !== ErrorDetails.BUFFER_STALLED_ERROR) {\n        return;\n      }\n      this.stallCount++;\n      if ((_this$levelDetails = this.levelDetails) != null && _this$levelDetails.live) {\n        logger.warn('[playback-rate-controller]: Stall detected, adjusting target latency');\n      }\n    };\n    _proto.timeupdate = function timeupdate() {\n      var media = this.media,\n        levelDetails = this.levelDetails;\n      if (!media || !levelDetails) {\n        return;\n      }\n      this.currentTime = media.currentTime;\n      var latency = this.computeLatency();\n      if (latency === null) {\n        return;\n      }\n      this._latency = latency;\n\n      // Adapt playbackRate to meet target latency in low-latency mode\n      var _this$config = this.config,\n        lowLatencyMode = _this$config.lowLatencyMode,\n        maxLiveSyncPlaybackRate = _this$config.maxLiveSyncPlaybackRate;\n      if (!lowLatencyMode || maxLiveSyncPlaybackRate === 1 || !levelDetails.live) {\n        return;\n      }\n      var targetLatency = this.targetLatency;\n      if (targetLatency === null) {\n        return;\n      }\n      var distanceFromTarget = latency - targetLatency;\n      // Only adjust playbackRate when within one target duration of targetLatency\n      // and more than one second from under-buffering.\n      // Playback further than one target duration from target can be considered DVR playback.\n      var liveMinLatencyDuration = Math.min(this.maxLatency, targetLatency + levelDetails.targetduration);\n      var inLiveRange = distanceFromTarget < liveMinLatencyDuration;\n      if (inLiveRange && distanceFromTarget > 0.05 && this.forwardBufferLength > 1) {\n        var max = Math.min(2, Math.max(1.0, maxLiveSyncPlaybackRate));\n        var rate = Math.round(2 / (1 + Math.exp(-0.75 * distanceFromTarget - this.edgeStalled)) * 20) / 20;\n        media.playbackRate = Math.min(max, Math.max(1, rate));\n      } else if (media.playbackRate !== 1 && media.playbackRate !== 0) {\n        media.playbackRate = 1;\n      }\n    };\n    _proto.estimateLiveEdge = function estimateLiveEdge() {\n      var levelDetails = this.levelDetails;\n      if (levelDetails === null) {\n        return null;\n      }\n      return levelDetails.edge + levelDetails.age;\n    };\n    _proto.computeLatency = function computeLatency() {\n      var liveEdge = this.estimateLiveEdge();\n      if (liveEdge === null) {\n        return null;\n      }\n      return liveEdge - this.currentTime;\n    };\n    _createClass(LatencyController, [{\n      key: \"latency\",\n      get: function get() {\n        return this._latency || 0;\n      }\n    }, {\n      key: \"maxLatency\",\n      get: function get() {\n        var config = this.config,\n          levelDetails = this.levelDetails;\n        if (config.liveMaxLatencyDuration !== undefined) {\n          return config.liveMaxLatencyDuration;\n        }\n        return levelDetails ? config.liveMaxLatencyDurationCount * levelDetails.targetduration : 0;\n      }\n    }, {\n      key: \"targetLatency\",\n      get: function get() {\n        var levelDetails = this.levelDetails;\n        if (levelDetails === null) {\n          return null;\n        }\n        var holdBack = levelDetails.holdBack,\n          partHoldBack = levelDetails.partHoldBack,\n          targetduration = levelDetails.targetduration;\n        var _this$config2 = this.config,\n          liveSyncDuration = _this$config2.liveSyncDuration,\n          liveSyncDurationCount = _this$config2.liveSyncDurationCount,\n          lowLatencyMode = _this$config2.lowLatencyMode;\n        var userConfig = this.hls.userConfig;\n        var targetLatency = lowLatencyMode ? partHoldBack || holdBack : holdBack;\n        if (userConfig.liveSyncDuration || userConfig.liveSyncDurationCount || targetLatency === 0) {\n          targetLatency = liveSyncDuration !== undefined ? liveSyncDuration : liveSyncDurationCount * targetduration;\n        }\n        var maxLiveSyncOnStallIncrease = targetduration;\n        var liveSyncOnStallIncrease = 1.0;\n        return targetLatency + Math.min(this.stallCount * liveSyncOnStallIncrease, maxLiveSyncOnStallIncrease);\n      }\n    }, {\n      key: \"liveSyncPosition\",\n      get: function get() {\n        var liveEdge = this.estimateLiveEdge();\n        var targetLatency = this.targetLatency;\n        var levelDetails = this.levelDetails;\n        if (liveEdge === null || targetLatency === null || levelDetails === null) {\n          return null;\n        }\n        var edge = levelDetails.edge;\n        var syncPosition = liveEdge - targetLatency - this.edgeStalled;\n        var min = edge - levelDetails.totalduration;\n        var max = edge - (this.config.lowLatencyMode && levelDetails.partTarget || levelDetails.targetduration);\n        return Math.min(Math.max(min, syncPosition), max);\n      }\n    }, {\n      key: \"drift\",\n      get: function get() {\n        var levelDetails = this.levelDetails;\n        if (levelDetails === null) {\n          return 1;\n        }\n        return levelDetails.drift;\n      }\n    }, {\n      key: \"edgeStalled\",\n      get: function get() {\n        var levelDetails = this.levelDetails;\n        if (levelDetails === null) {\n          return 0;\n        }\n        var maxLevelUpdateAge = (this.config.lowLatencyMode && levelDetails.partTarget || levelDetails.targetduration) * 3;\n        return Math.max(levelDetails.age - maxLevelUpdateAge, 0);\n      }\n    }, {\n      key: \"forwardBufferLength\",\n      get: function get() {\n        var media = this.media,\n          levelDetails = this.levelDetails;\n        if (!media || !levelDetails) {\n          return 0;\n        }\n        var bufferedRanges = media.buffered.length;\n        return (bufferedRanges ? media.buffered.end(bufferedRanges - 1) : levelDetails.edge) - this.currentTime;\n      }\n    }]);\n    return LatencyController;\n  }();\n\n  var HdcpLevels = ['NONE', 'TYPE-0', 'TYPE-1', null];\n  function isHdcpLevel(value) {\n    return HdcpLevels.indexOf(value) > -1;\n  }\n  var VideoRangeValues = ['SDR', 'PQ', 'HLG'];\n  function isVideoRange(value) {\n    return !!value && VideoRangeValues.indexOf(value) > -1;\n  }\n  var HlsSkip = {\n    No: \"\",\n    Yes: \"YES\",\n    v2: \"v2\"\n  };\n  function getSkipValue(details) {\n    var canSkipUntil = details.canSkipUntil,\n      canSkipDateRanges = details.canSkipDateRanges,\n      age = details.age;\n    // A Client SHOULD NOT request a Playlist Delta Update unless it already\n    // has a version of the Playlist that is no older than one-half of the Skip Boundary.\n    // @see: https://datatracker.ietf.org/doc/html/draft-pantos-hls-rfc8216bis#section-6.3.7\n    var playlistRecentEnough = age < canSkipUntil / 2;\n    if (canSkipUntil && playlistRecentEnough) {\n      if (canSkipDateRanges) {\n        return HlsSkip.v2;\n      }\n      return HlsSkip.Yes;\n    }\n    return HlsSkip.No;\n  }\n  var HlsUrlParameters = /*#__PURE__*/function () {\n    function HlsUrlParameters(msn, part, skip) {\n      this.msn = void 0;\n      this.part = void 0;\n      this.skip = void 0;\n      this.msn = msn;\n      this.part = part;\n      this.skip = skip;\n    }\n    var _proto = HlsUrlParameters.prototype;\n    _proto.addDirectives = function addDirectives(uri) {\n      var url = new self.URL(uri);\n      if (this.msn !== undefined) {\n        url.searchParams.set('_HLS_msn', this.msn.toString());\n      }\n      if (this.part !== undefined) {\n        url.searchParams.set('_HLS_part', this.part.toString());\n      }\n      if (this.skip) {\n        url.searchParams.set('_HLS_skip', this.skip);\n      }\n      return url.href;\n    };\n    return HlsUrlParameters;\n  }();\n  var Level = /*#__PURE__*/function () {\n    function Level(data) {\n      this._attrs = void 0;\n      this.audioCodec = void 0;\n      this.bitrate = void 0;\n      this.codecSet = void 0;\n      this.url = void 0;\n      this.frameRate = void 0;\n      this.height = void 0;\n      this.id = void 0;\n      this.name = void 0;\n      this.videoCodec = void 0;\n      this.width = void 0;\n      this.details = void 0;\n      this.fragmentError = 0;\n      this.loadError = 0;\n      this.loaded = void 0;\n      this.realBitrate = 0;\n      this.supportedPromise = void 0;\n      this.supportedResult = void 0;\n      this._avgBitrate = 0;\n      this._audioGroups = void 0;\n      this._subtitleGroups = void 0;\n      // Deprecated (retained for backwards compatibility)\n      this._urlId = 0;\n      this.url = [data.url];\n      this._attrs = [data.attrs];\n      this.bitrate = data.bitrate;\n      if (data.details) {\n        this.details = data.details;\n      }\n      this.id = data.id || 0;\n      this.name = data.name;\n      this.width = data.width || 0;\n      this.height = data.height || 0;\n      this.frameRate = data.attrs.optionalFloat('FRAME-RATE', 0);\n      this._avgBitrate = data.attrs.decimalInteger('AVERAGE-BANDWIDTH');\n      this.audioCodec = data.audioCodec;\n      this.videoCodec = data.videoCodec;\n      this.codecSet = [data.videoCodec, data.audioCodec].filter(function (c) {\n        return !!c;\n      }).map(function (s) {\n        return s.substring(0, 4);\n      }).join(',');\n      this.addGroupId('audio', data.attrs.AUDIO);\n      this.addGroupId('text', data.attrs.SUBTITLES);\n    }\n    var _proto2 = Level.prototype;\n    _proto2.hasAudioGroup = function hasAudioGroup(groupId) {\n      return hasGroup(this._audioGroups, groupId);\n    };\n    _proto2.hasSubtitleGroup = function hasSubtitleGroup(groupId) {\n      return hasGroup(this._subtitleGroups, groupId);\n    };\n    _proto2.addGroupId = function addGroupId(type, groupId) {\n      if (!groupId) {\n        return;\n      }\n      if (type === 'audio') {\n        var audioGroups = this._audioGroups;\n        if (!audioGroups) {\n          audioGroups = this._audioGroups = [];\n        }\n        if (audioGroups.indexOf(groupId) === -1) {\n          audioGroups.push(groupId);\n        }\n      } else if (type === 'text') {\n        var subtitleGroups = this._subtitleGroups;\n        if (!subtitleGroups) {\n          subtitleGroups = this._subtitleGroups = [];\n        }\n        if (subtitleGroups.indexOf(groupId) === -1) {\n          subtitleGroups.push(groupId);\n        }\n      }\n    }\n\n    // Deprecated methods (retained for backwards compatibility)\n    ;\n    _proto2.addFallback = function addFallback() {};\n    _createClass(Level, [{\n      key: \"maxBitrate\",\n      get: function get() {\n        return Math.max(this.realBitrate, this.bitrate);\n      }\n    }, {\n      key: \"averageBitrate\",\n      get: function get() {\n        return this._avgBitrate || this.realBitrate || this.bitrate;\n      }\n    }, {\n      key: \"attrs\",\n      get: function get() {\n        return this._attrs[0];\n      }\n    }, {\n      key: \"codecs\",\n      get: function get() {\n        return this.attrs.CODECS || '';\n      }\n    }, {\n      key: \"pathwayId\",\n      get: function get() {\n        return this.attrs['PATHWAY-ID'] || '.';\n      }\n    }, {\n      key: \"videoRange\",\n      get: function get() {\n        return this.attrs['VIDEO-RANGE'] || 'SDR';\n      }\n    }, {\n      key: \"score\",\n      get: function get() {\n        return this.attrs.optionalFloat('SCORE', 0);\n      }\n    }, {\n      key: \"uri\",\n      get: function get() {\n        return this.url[0] || '';\n      }\n    }, {\n      key: \"audioGroups\",\n      get: function get() {\n        return this._audioGroups;\n      }\n    }, {\n      key: \"subtitleGroups\",\n      get: function get() {\n        return this._subtitleGroups;\n      }\n    }, {\n      key: \"urlId\",\n      get: function get() {\n        return 0;\n      },\n      set: function set(value) {}\n    }, {\n      key: \"audioGroupIds\",\n      get: function get() {\n        return this.audioGroups ? [this.audioGroupId] : undefined;\n      }\n    }, {\n      key: \"textGroupIds\",\n      get: function get() {\n        return this.subtitleGroups ? [this.textGroupId] : undefined;\n      }\n    }, {\n      key: \"audioGroupId\",\n      get: function get() {\n        var _this$audioGroups;\n        return (_this$audioGroups = this.audioGroups) == null ? void 0 : _this$audioGroups[0];\n      }\n    }, {\n      key: \"textGroupId\",\n      get: function get() {\n        var _this$subtitleGroups;\n        return (_this$subtitleGroups = this.subtitleGroups) == null ? void 0 : _this$subtitleGroups[0];\n      }\n    }]);\n    return Level;\n  }();\n  function hasGroup(groups, groupId) {\n    if (!groupId || !groups) {\n      return false;\n    }\n    return groups.indexOf(groupId) !== -1;\n  }\n\n  function updateFromToPTS(fragFrom, fragTo) {\n    var fragToPTS = fragTo.startPTS;\n    // if we know startPTS[toIdx]\n    if (isFiniteNumber(fragToPTS)) {\n      // update fragment duration.\n      // it helps to fix drifts between playlist reported duration and fragment real duration\n      var duration = 0;\n      var frag;\n      if (fragTo.sn > fragFrom.sn) {\n        duration = fragToPTS - fragFrom.start;\n        frag = fragFrom;\n      } else {\n        duration = fragFrom.start - fragToPTS;\n        frag = fragTo;\n      }\n      if (frag.duration !== duration) {\n        frag.duration = duration;\n      }\n      // we dont know startPTS[toIdx]\n    } else if (fragTo.sn > fragFrom.sn) {\n      var contiguous = fragFrom.cc === fragTo.cc;\n      // TODO: With part-loading end/durations we need to confirm the whole fragment is loaded before using (or setting) minEndPTS\n      if (contiguous && fragFrom.minEndPTS) {\n        fragTo.start = fragFrom.start + (fragFrom.minEndPTS - fragFrom.start);\n      } else {\n        fragTo.start = fragFrom.start + fragFrom.duration;\n      }\n    } else {\n      fragTo.start = Math.max(fragFrom.start - fragTo.duration, 0);\n    }\n  }\n  function updateFragPTSDTS(details, frag, startPTS, endPTS, startDTS, endDTS) {\n    var parsedMediaDuration = endPTS - startPTS;\n    if (parsedMediaDuration <= 0) {\n      logger.warn('Fragment should have a positive duration', frag);\n      endPTS = startPTS + frag.duration;\n      endDTS = startDTS + frag.duration;\n    }\n    var maxStartPTS = startPTS;\n    var minEndPTS = endPTS;\n    var fragStartPts = frag.startPTS;\n    var fragEndPts = frag.endPTS;\n    if (isFiniteNumber(fragStartPts)) {\n      // delta PTS between audio and video\n      var deltaPTS = Math.abs(fragStartPts - startPTS);\n      if (!isFiniteNumber(frag.deltaPTS)) {\n        frag.deltaPTS = deltaPTS;\n      } else {\n        frag.deltaPTS = Math.max(deltaPTS, frag.deltaPTS);\n      }\n      maxStartPTS = Math.max(startPTS, fragStartPts);\n      startPTS = Math.min(startPTS, fragStartPts);\n      startDTS = Math.min(startDTS, frag.startDTS);\n      minEndPTS = Math.min(endPTS, fragEndPts);\n      endPTS = Math.max(endPTS, fragEndPts);\n      endDTS = Math.max(endDTS, frag.endDTS);\n    }\n    var drift = startPTS - frag.start;\n    if (frag.start !== 0) {\n      frag.start = startPTS;\n    }\n    frag.duration = endPTS - frag.start;\n    frag.startPTS = startPTS;\n    frag.maxStartPTS = maxStartPTS;\n    frag.startDTS = startDTS;\n    frag.endPTS = endPTS;\n    frag.minEndPTS = minEndPTS;\n    frag.endDTS = endDTS;\n    var sn = frag.sn; // 'initSegment'\n    // exit if sn out of range\n    if (!details || sn < details.startSN || sn > details.endSN) {\n      return 0;\n    }\n    var i;\n    var fragIdx = sn - details.startSN;\n    var fragments = details.fragments;\n    // update frag reference in fragments array\n    // rationale is that fragments array might not contain this frag object.\n    // this will happen if playlist has been refreshed between frag loading and call to updateFragPTSDTS()\n    // if we don't update frag, we won't be able to propagate PTS info on the playlist\n    // resulting in invalid sliding computation\n    fragments[fragIdx] = frag;\n    // adjust fragment PTS/duration from seqnum-1 to frag 0\n    for (i = fragIdx; i > 0; i--) {\n      updateFromToPTS(fragments[i], fragments[i - 1]);\n    }\n\n    // adjust fragment PTS/duration from seqnum to last frag\n    for (i = fragIdx; i < fragments.length - 1; i++) {\n      updateFromToPTS(fragments[i], fragments[i + 1]);\n    }\n    if (details.fragmentHint) {\n      updateFromToPTS(fragments[fragments.length - 1], details.fragmentHint);\n    }\n    details.PTSKnown = details.alignedSliding = true;\n    return drift;\n  }\n  function mergeDetails(oldDetails, newDetails) {\n    // Track the last initSegment processed. Initialize it to the last one on the timeline.\n    var currentInitSegment = null;\n    var oldFragments = oldDetails.fragments;\n    for (var i = oldFragments.length - 1; i >= 0; i--) {\n      var oldInit = oldFragments[i].initSegment;\n      if (oldInit) {\n        currentInitSegment = oldInit;\n        break;\n      }\n    }\n    if (oldDetails.fragmentHint) {\n      // prevent PTS and duration from being adjusted on the next hint\n      delete oldDetails.fragmentHint.endPTS;\n    }\n    // check if old/new playlists have fragments in common\n    // loop through overlapping SN and update startPTS , cc, and duration if any found\n    var ccOffset = 0;\n    var PTSFrag;\n    mapFragmentIntersection(oldDetails, newDetails, function (oldFrag, newFrag) {\n      if (oldFrag.relurl) {\n        // Do not compare CC if the old fragment has no url. This is a level.fragmentHint used by LL-HLS parts.\n        // It maybe be off by 1 if it was created before any parts or discontinuity tags were appended to the end\n        // of the playlist.\n        ccOffset = oldFrag.cc - newFrag.cc;\n      }\n      if (isFiniteNumber(oldFrag.startPTS) && isFiniteNumber(oldFrag.endPTS)) {\n        newFrag.start = newFrag.startPTS = oldFrag.startPTS;\n        newFrag.startDTS = oldFrag.startDTS;\n        newFrag.maxStartPTS = oldFrag.maxStartPTS;\n        newFrag.endPTS = oldFrag.endPTS;\n        newFrag.endDTS = oldFrag.endDTS;\n        newFrag.minEndPTS = oldFrag.minEndPTS;\n        newFrag.duration = oldFrag.endPTS - oldFrag.startPTS;\n        if (newFrag.duration) {\n          PTSFrag = newFrag;\n        }\n\n        // PTS is known when any segment has startPTS and endPTS\n        newDetails.PTSKnown = newDetails.alignedSliding = true;\n      }\n      newFrag.elementaryStreams = oldFrag.elementaryStreams;\n      newFrag.loader = oldFrag.loader;\n      newFrag.stats = oldFrag.stats;\n      if (oldFrag.initSegment) {\n        newFrag.initSegment = oldFrag.initSegment;\n        currentInitSegment = oldFrag.initSegment;\n      }\n    });\n    if (currentInitSegment) {\n      var fragmentsToCheck = newDetails.fragmentHint ? newDetails.fragments.concat(newDetails.fragmentHint) : newDetails.fragments;\n      fragmentsToCheck.forEach(function (frag) {\n        var _currentInitSegment;\n        if (frag && (!frag.initSegment || frag.initSegment.relurl === ((_currentInitSegment = currentInitSegment) == null ? void 0 : _currentInitSegment.relurl))) {\n          frag.initSegment = currentInitSegment;\n        }\n      });\n    }\n    if (newDetails.skippedSegments) {\n      newDetails.deltaUpdateFailed = newDetails.fragments.some(function (frag) {\n        return !frag;\n      });\n      if (newDetails.deltaUpdateFailed) {\n        logger.warn('[level-helper] Previous playlist missing segments skipped in delta playlist');\n        for (var _i = newDetails.skippedSegments; _i--;) {\n          newDetails.fragments.shift();\n        }\n        newDetails.startSN = newDetails.fragments[0].sn;\n        newDetails.startCC = newDetails.fragments[0].cc;\n      } else if (newDetails.canSkipDateRanges) {\n        newDetails.dateRanges = mergeDateRanges(oldDetails.dateRanges, newDetails.dateRanges, newDetails.recentlyRemovedDateranges);\n      }\n    }\n    var newFragments = newDetails.fragments;\n    if (ccOffset) {\n      logger.warn('discontinuity sliding from playlist, take drift into account');\n      for (var _i2 = 0; _i2 < newFragments.length; _i2++) {\n        newFragments[_i2].cc += ccOffset;\n      }\n    }\n    if (newDetails.skippedSegments) {\n      newDetails.startCC = newDetails.fragments[0].cc;\n    }\n\n    // Merge parts\n    mapPartIntersection(oldDetails.partList, newDetails.partList, function (oldPart, newPart) {\n      newPart.elementaryStreams = oldPart.elementaryStreams;\n      newPart.stats = oldPart.stats;\n    });\n\n    // if at least one fragment contains PTS info, recompute PTS information for all fragments\n    if (PTSFrag) {\n      updateFragPTSDTS(newDetails, PTSFrag, PTSFrag.startPTS, PTSFrag.endPTS, PTSFrag.startDTS, PTSFrag.endDTS);\n    } else {\n      // ensure that delta is within oldFragments range\n      // also adjust sliding in case delta is 0 (we could have old=[50-60] and new=old=[50-61])\n      // in that case we also need to adjust start offset of all fragments\n      adjustSliding(oldDetails, newDetails);\n    }\n    if (newFragments.length) {\n      newDetails.totalduration = newDetails.edge - newFragments[0].start;\n    }\n    newDetails.driftStartTime = oldDetails.driftStartTime;\n    newDetails.driftStart = oldDetails.driftStart;\n    var advancedDateTime = newDetails.advancedDateTime;\n    if (newDetails.advanced && advancedDateTime) {\n      var edge = newDetails.edge;\n      if (!newDetails.driftStart) {\n        newDetails.driftStartTime = advancedDateTime;\n        newDetails.driftStart = edge;\n      }\n      newDetails.driftEndTime = advancedDateTime;\n      newDetails.driftEnd = edge;\n    } else {\n      newDetails.driftEndTime = oldDetails.driftEndTime;\n      newDetails.driftEnd = oldDetails.driftEnd;\n      newDetails.advancedDateTime = oldDetails.advancedDateTime;\n    }\n  }\n  function mergeDateRanges(oldDateRanges, deltaDateRanges, recentlyRemovedDateranges) {\n    var dateRanges = _extends({}, oldDateRanges);\n    if (recentlyRemovedDateranges) {\n      recentlyRemovedDateranges.forEach(function (id) {\n        delete dateRanges[id];\n      });\n    }\n    Object.keys(deltaDateRanges).forEach(function (id) {\n      var dateRange = new DateRange(deltaDateRanges[id].attr, dateRanges[id]);\n      if (dateRange.isValid) {\n        dateRanges[id] = dateRange;\n      } else {\n        logger.warn(\"Ignoring invalid Playlist Delta Update DATERANGE tag: \\\"\" + JSON.stringify(deltaDateRanges[id].attr) + \"\\\"\");\n      }\n    });\n    return dateRanges;\n  }\n  function mapPartIntersection(oldParts, newParts, intersectionFn) {\n    if (oldParts && newParts) {\n      var delta = 0;\n      for (var i = 0, len = oldParts.length; i <= len; i++) {\n        var _oldPart = oldParts[i];\n        var _newPart = newParts[i + delta];\n        if (_oldPart && _newPart && _oldPart.index === _newPart.index && _oldPart.fragment.sn === _newPart.fragment.sn) {\n          intersectionFn(_oldPart, _newPart);\n        } else {\n          delta--;\n        }\n      }\n    }\n  }\n  function mapFragmentIntersection(oldDetails, newDetails, intersectionFn) {\n    var skippedSegments = newDetails.skippedSegments;\n    var start = Math.max(oldDetails.startSN, newDetails.startSN) - newDetails.startSN;\n    var end = (oldDetails.fragmentHint ? 1 : 0) + (skippedSegments ? newDetails.endSN : Math.min(oldDetails.endSN, newDetails.endSN)) - newDetails.startSN;\n    var delta = newDetails.startSN - oldDetails.startSN;\n    var newFrags = newDetails.fragmentHint ? newDetails.fragments.concat(newDetails.fragmentHint) : newDetails.fragments;\n    var oldFrags = oldDetails.fragmentHint ? oldDetails.fragments.concat(oldDetails.fragmentHint) : oldDetails.fragments;\n    for (var i = start; i <= end; i++) {\n      var _oldFrag = oldFrags[delta + i];\n      var _newFrag = newFrags[i];\n      if (skippedSegments && !_newFrag && i < skippedSegments) {\n        // Fill in skipped segments in delta playlist\n        _newFrag = newDetails.fragments[i] = _oldFrag;\n      }\n      if (_oldFrag && _newFrag) {\n        intersectionFn(_oldFrag, _newFrag);\n      }\n    }\n  }\n  function adjustSliding(oldDetails, newDetails) {\n    var delta = newDetails.startSN + newDetails.skippedSegments - oldDetails.startSN;\n    var oldFragments = oldDetails.fragments;\n    if (delta < 0 || delta >= oldFragments.length) {\n      return;\n    }\n    addSliding(newDetails, oldFragments[delta].start);\n  }\n  function addSliding(details, start) {\n    if (start) {\n      var fragments = details.fragments;\n      for (var i = details.skippedSegments; i < fragments.length; i++) {\n        fragments[i].start += start;\n      }\n      if (details.fragmentHint) {\n        details.fragmentHint.start += start;\n      }\n    }\n  }\n  function computeReloadInterval(newDetails, distanceToLiveEdgeMs) {\n    if (distanceToLiveEdgeMs === void 0) {\n      distanceToLiveEdgeMs = Infinity;\n    }\n    var reloadInterval = 1000 * newDetails.targetduration;\n    if (newDetails.updated) {\n      // Use last segment duration when shorter than target duration and near live edge\n      var fragments = newDetails.fragments;\n      var liveEdgeMaxTargetDurations = 4;\n      if (fragments.length && reloadInterval * liveEdgeMaxTargetDurations > distanceToLiveEdgeMs) {\n        var lastSegmentDuration = fragments[fragments.length - 1].duration * 1000;\n        if (lastSegmentDuration < reloadInterval) {\n          reloadInterval = lastSegmentDuration;\n        }\n      }\n    } else {\n      // estimate = 'miss half average';\n      // follow HLS Spec, If the client reloads a Playlist file and finds that it has not\n      // changed then it MUST wait for a period of one-half the target\n      // duration before retrying.\n      reloadInterval /= 2;\n    }\n    return Math.round(reloadInterval);\n  }\n  function getFragmentWithSN(level, sn, fragCurrent) {\n    if (!(level != null && level.details)) {\n      return null;\n    }\n    var levelDetails = level.details;\n    var fragment = levelDetails.fragments[sn - levelDetails.startSN];\n    if (fragment) {\n      return fragment;\n    }\n    fragment = levelDetails.fragmentHint;\n    if (fragment && fragment.sn === sn) {\n      return fragment;\n    }\n    if (sn < levelDetails.startSN && fragCurrent && fragCurrent.sn === sn) {\n      return fragCurrent;\n    }\n    return null;\n  }\n  function getPartWith(level, sn, partIndex) {\n    var _level$details;\n    if (!(level != null && level.details)) {\n      return null;\n    }\n    return findPart((_level$details = level.details) == null ? void 0 : _level$details.partList, sn, partIndex);\n  }\n  function findPart(partList, sn, partIndex) {\n    if (partList) {\n      for (var i = partList.length; i--;) {\n        var part = partList[i];\n        if (part.index === partIndex && part.fragment.sn === sn) {\n          return part;\n        }\n      }\n    }\n    return null;\n  }\n  function reassignFragmentLevelIndexes(levels) {\n    levels.forEach(function (level, index) {\n      var details = level.details;\n      if (details != null && details.fragments) {\n        details.fragments.forEach(function (fragment) {\n          fragment.level = index;\n        });\n      }\n    });\n  }\n\n  function isTimeoutError(error) {\n    switch (error.details) {\n      case ErrorDetails.FRAG_LOAD_TIMEOUT:\n      case ErrorDetails.KEY_LOAD_TIMEOUT:\n      case ErrorDetails.LEVEL_LOAD_TIMEOUT:\n      case ErrorDetails.MANIFEST_LOAD_TIMEOUT:\n        return true;\n    }\n    return false;\n  }\n  function getRetryConfig(loadPolicy, error) {\n    var isTimeout = isTimeoutError(error);\n    return loadPolicy.default[(isTimeout ? 'timeout' : 'error') + \"Retry\"];\n  }\n  function getRetryDelay(retryConfig, retryCount) {\n    // exponential backoff capped to max retry delay\n    var backoffFactor = retryConfig.backoff === 'linear' ? 1 : Math.pow(2, retryCount);\n    return Math.min(backoffFactor * retryConfig.retryDelayMs, retryConfig.maxRetryDelayMs);\n  }\n  function getLoaderConfigWithoutReties(loderConfig) {\n    return _objectSpread2(_objectSpread2({}, loderConfig), {\n      errorRetry: null,\n      timeoutRetry: null\n    });\n  }\n  function shouldRetry(retryConfig, retryCount, isTimeout, loaderResponse) {\n    if (!retryConfig) {\n      return false;\n    }\n    var httpStatus = loaderResponse == null ? void 0 : loaderResponse.code;\n    var retry = retryCount < retryConfig.maxNumRetry && (retryForHttpStatus(httpStatus) || !!isTimeout);\n    return retryConfig.shouldRetry ? retryConfig.shouldRetry(retryConfig, retryCount, isTimeout, loaderResponse, retry) : retry;\n  }\n  function retryForHttpStatus(httpStatus) {\n    // Do not retry on status 4xx, status 0 (CORS error), or undefined (decrypt/gap/parse error)\n    return httpStatus === 0 && navigator.onLine === false || !!httpStatus && (httpStatus < 400 || httpStatus > 499);\n  }\n\n  var BinarySearch = {\n    /**\n     * Searches for an item in an array which matches a certain condition.\n     * This requires the condition to only match one item in the array,\n     * and for the array to be ordered.\n     *\n     * @param list The array to search.\n     * @param comparisonFn\n     *      Called and provided a candidate item as the first argument.\n     *      Should return:\n     *          > -1 if the item should be located at a lower index than the provided item.\n     *          > 1 if the item should be located at a higher index than the provided item.\n     *          > 0 if the item is the item you're looking for.\n     *\n     * @returns the object if found, otherwise returns null\n     */\n    search: function search(list, comparisonFn) {\n      var minIndex = 0;\n      var maxIndex = list.length - 1;\n      var currentIndex = null;\n      var currentElement = null;\n      while (minIndex <= maxIndex) {\n        currentIndex = (minIndex + maxIndex) / 2 | 0;\n        currentElement = list[currentIndex];\n        var comparisonResult = comparisonFn(currentElement);\n        if (comparisonResult > 0) {\n          minIndex = currentIndex + 1;\n        } else if (comparisonResult < 0) {\n          maxIndex = currentIndex - 1;\n        } else {\n          return currentElement;\n        }\n      }\n      return null;\n    }\n  };\n\n  /**\n   * Returns first fragment whose endPdt value exceeds the given PDT, or null.\n   * @param fragments - The array of candidate fragments\n   * @param PDTValue - The PDT value which must be exceeded\n   * @param maxFragLookUpTolerance - The amount of time that a fragment's start/end can be within in order to be considered contiguous\n   */\n  function findFragmentByPDT(fragments, PDTValue, maxFragLookUpTolerance) {\n    if (PDTValue === null || !Array.isArray(fragments) || !fragments.length || !isFiniteNumber(PDTValue)) {\n      return null;\n    }\n\n    // if less than start\n    var startPDT = fragments[0].programDateTime;\n    if (PDTValue < (startPDT || 0)) {\n      return null;\n    }\n    var endPDT = fragments[fragments.length - 1].endProgramDateTime;\n    if (PDTValue >= (endPDT || 0)) {\n      return null;\n    }\n    maxFragLookUpTolerance = maxFragLookUpTolerance || 0;\n    for (var seg = 0; seg < fragments.length; ++seg) {\n      var frag = fragments[seg];\n      if (pdtWithinToleranceTest(PDTValue, maxFragLookUpTolerance, frag)) {\n        return frag;\n      }\n    }\n    return null;\n  }\n\n  /**\n   * Finds a fragment based on the SN of the previous fragment; or based on the needs of the current buffer.\n   * This method compensates for small buffer gaps by applying a tolerance to the start of any candidate fragment, thus\n   * breaking any traps which would cause the same fragment to be continuously selected within a small range.\n   * @param fragPrevious - The last frag successfully appended\n   * @param fragments - The array of candidate fragments\n   * @param bufferEnd - The end of the contiguous buffered range the playhead is currently within\n   * @param maxFragLookUpTolerance - The amount of time that a fragment's start/end can be within in order to be considered contiguous\n   * @returns a matching fragment or null\n   */\n  function findFragmentByPTS(fragPrevious, fragments, bufferEnd, maxFragLookUpTolerance, nextFragLookupTolerance) {\n    if (bufferEnd === void 0) {\n      bufferEnd = 0;\n    }\n    if (maxFragLookUpTolerance === void 0) {\n      maxFragLookUpTolerance = 0;\n    }\n    if (nextFragLookupTolerance === void 0) {\n      nextFragLookupTolerance = 0.005;\n    }\n    var fragNext = null;\n    if (fragPrevious) {\n      fragNext = fragments[fragPrevious.sn - fragments[0].sn + 1] || null;\n      // check for buffer-end rounding error\n      var bufferEdgeError = fragPrevious.endDTS - bufferEnd;\n      if (bufferEdgeError > 0 && bufferEdgeError < 0.0000015) {\n        bufferEnd += 0.0000015;\n      }\n    } else if (bufferEnd === 0 && fragments[0].start === 0) {\n      fragNext = fragments[0];\n    }\n    // Prefer the next fragment if it's within tolerance\n    if (fragNext && ((!fragPrevious || fragPrevious.level === fragNext.level) && fragmentWithinToleranceTest(bufferEnd, maxFragLookUpTolerance, fragNext) === 0 || fragmentWithinFastStartSwitch(fragNext, fragPrevious, Math.min(nextFragLookupTolerance, maxFragLookUpTolerance)))) {\n      return fragNext;\n    }\n    // We might be seeking past the tolerance so find the best match\n    var foundFragment = BinarySearch.search(fragments, fragmentWithinToleranceTest.bind(null, bufferEnd, maxFragLookUpTolerance));\n    if (foundFragment && (foundFragment !== fragPrevious || !fragNext)) {\n      return foundFragment;\n    }\n    // If no match was found return the next fragment after fragPrevious, or null\n    return fragNext;\n  }\n  function fragmentWithinFastStartSwitch(fragNext, fragPrevious, nextFragLookupTolerance) {\n    if (fragPrevious && fragPrevious.start === 0 && fragPrevious.level < fragNext.level && (fragPrevious.endPTS || 0) > 0) {\n      var firstDuration = fragPrevious.tagList.reduce(function (duration, tag) {\n        if (tag[0] === 'INF') {\n          duration += parseFloat(tag[1]);\n        }\n        return duration;\n      }, nextFragLookupTolerance);\n      return fragNext.start <= firstDuration;\n    }\n    return false;\n  }\n\n  /**\n   * The test function used by the findFragmentBySn's BinarySearch to look for the best match to the current buffer conditions.\n   * @param candidate - The fragment to test\n   * @param bufferEnd - The end of the current buffered range the playhead is currently within\n   * @param maxFragLookUpTolerance - The amount of time that a fragment's start can be within in order to be considered contiguous\n   * @returns 0 if it matches, 1 if too low, -1 if too high\n   */\n  function fragmentWithinToleranceTest(bufferEnd, maxFragLookUpTolerance, candidate) {\n    if (bufferEnd === void 0) {\n      bufferEnd = 0;\n    }\n    if (maxFragLookUpTolerance === void 0) {\n      maxFragLookUpTolerance = 0;\n    }\n    // eagerly accept an accurate match (no tolerance)\n    if (candidate.start <= bufferEnd && candidate.start + candidate.duration > bufferEnd) {\n      return 0;\n    }\n    // offset should be within fragment boundary - config.maxFragLookUpTolerance\n    // this is to cope with situations like\n    // bufferEnd = 9.991\n    // frag[] : [0,10]\n    // frag[1] : [10,20]\n    // bufferEnd is within frag[0] range ... although what we are expecting is to return frag[1] here\n    //              frag start               frag start+duration\n    //                  |-----------------------------|\n    //              <---\x3e                         <---\x3e\n    //  ...--------\x3e<-----------------------------\x3e<---------....\n    // previous frag         matching fragment         next frag\n    //  return -1             return 0                 return 1\n    // logger.log(`level/sn/start/end/bufEnd:${level}/${candidate.sn}/${candidate.start}/${(candidate.start+candidate.duration)}/${bufferEnd}`);\n    // Set the lookup tolerance to be small enough to detect the current segment - ensures we don't skip over very small segments\n    var candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0));\n    if (candidate.start + candidate.duration - candidateLookupTolerance <= bufferEnd) {\n      return 1;\n    } else if (candidate.start - candidateLookupTolerance > bufferEnd && candidate.start) {\n      // if maxFragLookUpTolerance will have negative value then don't return -1 for first element\n      return -1;\n    }\n    return 0;\n  }\n\n  /**\n   * The test function used by the findFragmentByPdt's BinarySearch to look for the best match to the current buffer conditions.\n   * This function tests the candidate's program date time values, as represented in Unix time\n   * @param candidate - The fragment to test\n   * @param pdtBufferEnd - The Unix time representing the end of the current buffered range\n   * @param maxFragLookUpTolerance - The amount of time that a fragment's start can be within in order to be considered contiguous\n   * @returns true if contiguous, false otherwise\n   */\n  function pdtWithinToleranceTest(pdtBufferEnd, maxFragLookUpTolerance, candidate) {\n    var candidateLookupTolerance = Math.min(maxFragLookUpTolerance, candidate.duration + (candidate.deltaPTS ? candidate.deltaPTS : 0)) * 1000;\n\n    // endProgramDateTime can be null, default to zero\n    var endProgramDateTime = candidate.endProgramDateTime || 0;\n    return endProgramDateTime - candidateLookupTolerance > pdtBufferEnd;\n  }\n  function findFragWithCC(fragments, cc) {\n    return BinarySearch.search(fragments, function (candidate) {\n      if (candidate.cc < cc) {\n        return 1;\n      } else if (candidate.cc > cc) {\n        return -1;\n      } else {\n        return 0;\n      }\n    });\n  }\n\n  var NetworkErrorAction = {\n    DoNothing: 0,\n    SendEndCallback: 1,\n    SendAlternateToPenaltyBox: 2,\n    RemoveAlternatePermanently: 3,\n    InsertDiscontinuity: 4,\n    RetryRequest: 5\n  };\n  var ErrorActionFlags = {\n    None: 0,\n    MoveAllAlternatesMatchingHost: 1,\n    MoveAllAlternatesMatchingHDCP: 2,\n    SwitchToSDR: 4\n  }; // Reserved for future use\n  var ErrorController = /*#__PURE__*/function () {\n    function ErrorController(hls) {\n      this.hls = void 0;\n      this.playlistError = 0;\n      this.penalizedRenditions = {};\n      this.log = void 0;\n      this.warn = void 0;\n      this.error = void 0;\n      this.hls = hls;\n      this.log = logger.log.bind(logger, \"[info]:\");\n      this.warn = logger.warn.bind(logger, \"[warning]:\");\n      this.error = logger.error.bind(logger, \"[error]:\");\n      this.registerListeners();\n    }\n    var _proto = ErrorController.prototype;\n    _proto.registerListeners = function registerListeners() {\n      var hls = this.hls;\n      hls.on(Events.ERROR, this.onError, this);\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n    };\n    _proto.unregisterListeners = function unregisterListeners() {\n      var hls = this.hls;\n      if (!hls) {\n        return;\n      }\n      hls.off(Events.ERROR, this.onError, this);\n      hls.off(Events.ERROR, this.onErrorOut, this);\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n    };\n    _proto.destroy = function destroy() {\n      this.unregisterListeners();\n      // @ts-ignore\n      this.hls = null;\n      this.penalizedRenditions = {};\n    };\n    _proto.startLoad = function startLoad(startPosition) {};\n    _proto.stopLoad = function stopLoad() {\n      this.playlistError = 0;\n    };\n    _proto.getVariantLevelIndex = function getVariantLevelIndex(frag) {\n      return (frag == null ? void 0 : frag.type) === PlaylistLevelType.MAIN ? frag.level : this.hls.loadLevel;\n    };\n    _proto.onManifestLoading = function onManifestLoading() {\n      this.playlistError = 0;\n      this.penalizedRenditions = {};\n    };\n    _proto.onLevelUpdated = function onLevelUpdated() {\n      this.playlistError = 0;\n    };\n    _proto.onError = function onError(event, data) {\n      var _data$frag, _data$level;\n      if (data.fatal) {\n        return;\n      }\n      var hls = this.hls;\n      var context = data.context;\n      switch (data.details) {\n        case ErrorDetails.FRAG_LOAD_ERROR:\n        case ErrorDetails.FRAG_LOAD_TIMEOUT:\n        case ErrorDetails.KEY_LOAD_ERROR:\n        case ErrorDetails.KEY_LOAD_TIMEOUT:\n          data.errorAction = this.getFragRetryOrSwitchAction(data);\n          return;\n        case ErrorDetails.FRAG_PARSING_ERROR:\n          // ignore empty segment errors marked as gap\n          if ((_data$frag = data.frag) != null && _data$frag.gap) {\n            data.errorAction = {\n              action: NetworkErrorAction.DoNothing,\n              flags: ErrorActionFlags.None\n            };\n            return;\n          }\n        // falls through\n        case ErrorDetails.FRAG_GAP:\n        case ErrorDetails.FRAG_DECRYPT_ERROR:\n          {\n            // Switch level if possible, otherwise allow retry count to reach max error retries\n            data.errorAction = this.getFragRetryOrSwitchAction(data);\n            data.errorAction.action = NetworkErrorAction.SendAlternateToPenaltyBox;\n            return;\n          }\n        case ErrorDetails.LEVEL_EMPTY_ERROR:\n        case ErrorDetails.LEVEL_PARSING_ERROR:\n          {\n            var _data$context, _data$context$levelDe;\n            // Only retry when empty and live\n            var levelIndex = data.parent === PlaylistLevelType.MAIN ? data.level : hls.loadLevel;\n            if (data.details === ErrorDetails.LEVEL_EMPTY_ERROR && !!((_data$context = data.context) != null && (_data$context$levelDe = _data$context.levelDetails) != null && _data$context$levelDe.live)) {\n              data.errorAction = this.getPlaylistRetryOrSwitchAction(data, levelIndex);\n            } else {\n              // Escalate to fatal if not retrying or switching\n              data.levelRetry = false;\n              data.errorAction = this.getLevelSwitchAction(data, levelIndex);\n            }\n          }\n          return;\n        case ErrorDetails.LEVEL_LOAD_ERROR:\n        case ErrorDetails.LEVEL_LOAD_TIMEOUT:\n          if (typeof (context == null ? void 0 : context.level) === 'number') {\n            data.errorAction = this.getPlaylistRetryOrSwitchAction(data, context.level);\n          }\n          return;\n        case ErrorDetails.AUDIO_TRACK_LOAD_ERROR:\n        case ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT:\n        case ErrorDetails.SUBTITLE_LOAD_ERROR:\n        case ErrorDetails.SUBTITLE_TRACK_LOAD_TIMEOUT:\n          if (context) {\n            var level = hls.levels[hls.loadLevel];\n            if (level && (context.type === PlaylistContextType.AUDIO_TRACK && level.hasAudioGroup(context.groupId) || context.type === PlaylistContextType.SUBTITLE_TRACK && level.hasSubtitleGroup(context.groupId))) {\n              // Perform Pathway switch or Redundant failover if possible for fastest recovery\n              // otherwise allow playlist retry count to reach max error retries\n              data.errorAction = this.getPlaylistRetryOrSwitchAction(data, hls.loadLevel);\n              data.errorAction.action = NetworkErrorAction.SendAlternateToPenaltyBox;\n              data.errorAction.flags = ErrorActionFlags.MoveAllAlternatesMatchingHost;\n              return;\n            }\n          }\n          return;\n        case ErrorDetails.KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED:\n          {\n            var _level = hls.levels[hls.loadLevel];\n            var restrictedHdcpLevel = _level == null ? void 0 : _level.attrs['HDCP-LEVEL'];\n            if (restrictedHdcpLevel) {\n              data.errorAction = {\n                action: NetworkErrorAction.SendAlternateToPenaltyBox,\n                flags: ErrorActionFlags.MoveAllAlternatesMatchingHDCP,\n                hdcpLevel: restrictedHdcpLevel\n              };\n            } else {\n              this.keySystemError(data);\n            }\n          }\n          return;\n        case ErrorDetails.BUFFER_ADD_CODEC_ERROR:\n        case ErrorDetails.REMUX_ALLOC_ERROR:\n        case ErrorDetails.BUFFER_APPEND_ERROR:\n          data.errorAction = this.getLevelSwitchAction(data, (_data$level = data.level) != null ? _data$level : hls.loadLevel);\n          return;\n        case ErrorDetails.INTERNAL_EXCEPTION:\n        case ErrorDetails.BUFFER_APPENDING_ERROR:\n        case ErrorDetails.BUFFER_FULL_ERROR:\n        case ErrorDetails.LEVEL_SWITCH_ERROR:\n        case ErrorDetails.BUFFER_STALLED_ERROR:\n        case ErrorDetails.BUFFER_SEEK_OVER_HOLE:\n        case ErrorDetails.BUFFER_NUDGE_ON_STALL:\n          data.errorAction = {\n            action: NetworkErrorAction.DoNothing,\n            flags: ErrorActionFlags.None\n          };\n          return;\n      }\n      if (data.type === ErrorTypes.KEY_SYSTEM_ERROR) {\n        this.keySystemError(data);\n      }\n    };\n    _proto.keySystemError = function keySystemError(data) {\n      var levelIndex = this.getVariantLevelIndex(data.frag);\n      // Do not retry level. Escalate to fatal if switching levels fails.\n      data.levelRetry = false;\n      data.errorAction = this.getLevelSwitchAction(data, levelIndex);\n    };\n    _proto.getPlaylistRetryOrSwitchAction = function getPlaylistRetryOrSwitchAction(data, levelIndex) {\n      var hls = this.hls;\n      var retryConfig = getRetryConfig(hls.config.playlistLoadPolicy, data);\n      var retryCount = this.playlistError++;\n      var retry = shouldRetry(retryConfig, retryCount, isTimeoutError(data), data.response);\n      if (retry) {\n        return {\n          action: NetworkErrorAction.RetryRequest,\n          flags: ErrorActionFlags.None,\n          retryConfig: retryConfig,\n          retryCount: retryCount\n        };\n      }\n      var errorAction = this.getLevelSwitchAction(data, levelIndex);\n      if (retryConfig) {\n        errorAction.retryConfig = retryConfig;\n        errorAction.retryCount = retryCount;\n      }\n      return errorAction;\n    };\n    _proto.getFragRetryOrSwitchAction = function getFragRetryOrSwitchAction(data) {\n      var hls = this.hls;\n      // Share fragment error count accross media options (main, audio, subs)\n      // This allows for level based rendition switching when media option assets fail\n      var variantLevelIndex = this.getVariantLevelIndex(data.frag);\n      var level = hls.levels[variantLevelIndex];\n      var _hls$config = hls.config,\n        fragLoadPolicy = _hls$config.fragLoadPolicy,\n        keyLoadPolicy = _hls$config.keyLoadPolicy;\n      var retryConfig = getRetryConfig(data.details.startsWith('key') ? keyLoadPolicy : fragLoadPolicy, data);\n      var fragmentErrors = hls.levels.reduce(function (acc, level) {\n        return acc + level.fragmentError;\n      }, 0);\n      // Switch levels when out of retried or level index out of bounds\n      if (level) {\n        if (data.details !== ErrorDetails.FRAG_GAP) {\n          level.fragmentError++;\n        }\n        var retry = shouldRetry(retryConfig, fragmentErrors, isTimeoutError(data), data.response);\n        if (retry) {\n          return {\n            action: NetworkErrorAction.RetryRequest,\n            flags: ErrorActionFlags.None,\n            retryConfig: retryConfig,\n            retryCount: fragmentErrors\n          };\n        }\n      }\n      // Reach max retry count, or Missing level reference\n      // Switch to valid index\n      var errorAction = this.getLevelSwitchAction(data, variantLevelIndex);\n      // Add retry details to allow skipping of FRAG_PARSING_ERROR\n      if (retryConfig) {\n        errorAction.retryConfig = retryConfig;\n        errorAction.retryCount = fragmentErrors;\n      }\n      return errorAction;\n    };\n    _proto.getLevelSwitchAction = function getLevelSwitchAction(data, levelIndex) {\n      var hls = this.hls;\n      if (levelIndex === null || levelIndex === undefined) {\n        levelIndex = hls.loadLevel;\n      }\n      var level = this.hls.levels[levelIndex];\n      if (level) {\n        var _data$frag2, _data$context2;\n        var errorDetails = data.details;\n        level.loadError++;\n        if (errorDetails === ErrorDetails.BUFFER_APPEND_ERROR) {\n          level.fragmentError++;\n        }\n        // Search for next level to retry\n        var nextLevel = -1;\n        var levels = hls.levels,\n          loadLevel = hls.loadLevel,\n          minAutoLevel = hls.minAutoLevel,\n          maxAutoLevel = hls.maxAutoLevel;\n        if (!hls.autoLevelEnabled) {\n          hls.loadLevel = -1;\n        }\n        var fragErrorType = (_data$frag2 = data.frag) == null ? void 0 : _data$frag2.type;\n        // Find alternate audio codec if available on audio codec error\n        var isAudioCodecError = fragErrorType === PlaylistLevelType.AUDIO && errorDetails === ErrorDetails.FRAG_PARSING_ERROR || data.sourceBufferName === 'audio' && (errorDetails === ErrorDetails.BUFFER_ADD_CODEC_ERROR || errorDetails === ErrorDetails.BUFFER_APPEND_ERROR);\n        var findAudioCodecAlternate = isAudioCodecError && levels.some(function (_ref) {\n          var audioCodec = _ref.audioCodec;\n          return level.audioCodec !== audioCodec;\n        });\n        // Find alternate video codec if available on video codec error\n        var isVideoCodecError = data.sourceBufferName === 'video' && (errorDetails === ErrorDetails.BUFFER_ADD_CODEC_ERROR || errorDetails === ErrorDetails.BUFFER_APPEND_ERROR);\n        var findVideoCodecAlternate = isVideoCodecError && levels.some(function (_ref2) {\n          var codecSet = _ref2.codecSet,\n            audioCodec = _ref2.audioCodec;\n          return level.codecSet !== codecSet && level.audioCodec === audioCodec;\n        });\n        var _ref3 = (_data$context2 = data.context) != null ? _data$context2 : {},\n          playlistErrorType = _ref3.type,\n          playlistErrorGroupId = _ref3.groupId;\n        var _loop = function _loop() {\n            var candidate = (i + loadLevel) % levels.length;\n            if (candidate !== loadLevel && candidate >= minAutoLevel && candidate <= maxAutoLevel && levels[candidate].loadError === 0) {\n              var _level$audioGroups, _level$subtitleGroups;\n              var levelCandidate = levels[candidate];\n              // Skip level switch if GAP tag is found in next level at same position\n              if (errorDetails === ErrorDetails.FRAG_GAP && fragErrorType === PlaylistLevelType.MAIN && data.frag) {\n                var levelDetails = levels[candidate].details;\n                if (levelDetails) {\n                  var fragCandidate = findFragmentByPTS(data.frag, levelDetails.fragments, data.frag.start);\n                  if (fragCandidate != null && fragCandidate.gap) {\n                    return 0; // continue\n                  }\n                }\n              } else if (playlistErrorType === PlaylistContextType.AUDIO_TRACK && levelCandidate.hasAudioGroup(playlistErrorGroupId) || playlistErrorType === PlaylistContextType.SUBTITLE_TRACK && levelCandidate.hasSubtitleGroup(playlistErrorGroupId)) {\n                // For audio/subs playlist errors find another group ID or fallthrough to redundant fail-over\n                return 0; // continue\n              } else if (fragErrorType === PlaylistLevelType.AUDIO && (_level$audioGroups = level.audioGroups) != null && _level$audioGroups.some(function (groupId) {\n                return levelCandidate.hasAudioGroup(groupId);\n              }) || fragErrorType === PlaylistLevelType.SUBTITLE && (_level$subtitleGroups = level.subtitleGroups) != null && _level$subtitleGroups.some(function (groupId) {\n                return levelCandidate.hasSubtitleGroup(groupId);\n              }) || findAudioCodecAlternate && level.audioCodec === levelCandidate.audioCodec || !findAudioCodecAlternate && level.audioCodec !== levelCandidate.audioCodec || findVideoCodecAlternate && level.codecSet === levelCandidate.codecSet) {\n                // For video/audio/subs frag errors find another group ID or fallthrough to redundant fail-over\n                return 0; // continue\n              }\n              nextLevel = candidate;\n              return 1; // break\n            }\n          },\n          _ret;\n        for (var i = levels.length; i--;) {\n          _ret = _loop();\n          if (_ret === 0) continue;\n          if (_ret === 1) break;\n        }\n        if (nextLevel > -1 && hls.loadLevel !== nextLevel) {\n          data.levelRetry = true;\n          this.playlistError = 0;\n          return {\n            action: NetworkErrorAction.SendAlternateToPenaltyBox,\n            flags: ErrorActionFlags.None,\n            nextAutoLevel: nextLevel\n          };\n        }\n      }\n      // No levels to switch / Manual level selection / Level not found\n      // Resolve with Pathway switch, Redundant fail-over, or stay on lowest Level\n      return {\n        action: NetworkErrorAction.SendAlternateToPenaltyBox,\n        flags: ErrorActionFlags.MoveAllAlternatesMatchingHost\n      };\n    };\n    _proto.onErrorOut = function onErrorOut(event, data) {\n      var _data$errorAction;\n      switch ((_data$errorAction = data.errorAction) == null ? void 0 : _data$errorAction.action) {\n        case NetworkErrorAction.DoNothing:\n          break;\n        case NetworkErrorAction.SendAlternateToPenaltyBox:\n          this.sendAlternateToPenaltyBox(data);\n          if (!data.errorAction.resolved && data.details !== ErrorDetails.FRAG_GAP) {\n            data.fatal = true;\n          } else if (/MediaSource readyState: ended/.test(data.error.message)) {\n            this.warn(\"MediaSource ended after \\\"\" + data.sourceBufferName + \"\\\" sourceBuffer append error. Attempting to recover from media error.\");\n            this.hls.recoverMediaError();\n          }\n          break;\n      }\n      if (data.fatal) {\n        this.hls.stopLoad();\n        return;\n      }\n    };\n    _proto.sendAlternateToPenaltyBox = function sendAlternateToPenaltyBox(data) {\n      var hls = this.hls;\n      var errorAction = data.errorAction;\n      if (!errorAction) {\n        return;\n      }\n      var flags = errorAction.flags,\n        hdcpLevel = errorAction.hdcpLevel,\n        nextAutoLevel = errorAction.nextAutoLevel;\n      switch (flags) {\n        case ErrorActionFlags.None:\n          this.switchLevel(data, nextAutoLevel);\n          break;\n        case ErrorActionFlags.MoveAllAlternatesMatchingHDCP:\n          if (hdcpLevel) {\n            hls.maxHdcpLevel = HdcpLevels[HdcpLevels.indexOf(hdcpLevel) - 1];\n            errorAction.resolved = true;\n          }\n          this.warn(\"Restricting playback to HDCP-LEVEL of \\\"\" + hls.maxHdcpLevel + \"\\\" or lower\");\n          break;\n      }\n      // If not resolved by previous actions try to switch to next level\n      if (!errorAction.resolved) {\n        this.switchLevel(data, nextAutoLevel);\n      }\n    };\n    _proto.switchLevel = function switchLevel(data, levelIndex) {\n      if (levelIndex !== undefined && data.errorAction) {\n        this.warn(\"switching to level \" + levelIndex + \" after \" + data.details);\n        this.hls.nextAutoLevel = levelIndex;\n        data.errorAction.resolved = true;\n        // Stream controller is responsible for this but won't switch on false start\n        this.hls.nextLoadLevel = this.hls.nextAutoLevel;\n      }\n    };\n    return ErrorController;\n  }();\n\n  var BasePlaylistController = /*#__PURE__*/function () {\n    function BasePlaylistController(hls, logPrefix) {\n      this.hls = void 0;\n      this.timer = -1;\n      this.requestScheduled = -1;\n      this.canLoad = false;\n      this.log = void 0;\n      this.warn = void 0;\n      this.log = logger.log.bind(logger, logPrefix + \":\");\n      this.warn = logger.warn.bind(logger, logPrefix + \":\");\n      this.hls = hls;\n    }\n    var _proto = BasePlaylistController.prototype;\n    _proto.destroy = function destroy() {\n      this.clearTimer();\n      // @ts-ignore\n      this.hls = this.log = this.warn = null;\n    };\n    _proto.clearTimer = function clearTimer() {\n      if (this.timer !== -1) {\n        self.clearTimeout(this.timer);\n        this.timer = -1;\n      }\n    };\n    _proto.startLoad = function startLoad() {\n      this.canLoad = true;\n      this.requestScheduled = -1;\n      this.loadPlaylist();\n    };\n    _proto.stopLoad = function stopLoad() {\n      this.canLoad = false;\n      this.clearTimer();\n    };\n    _proto.switchParams = function switchParams(playlistUri, previous, current) {\n      var renditionReports = previous == null ? void 0 : previous.renditionReports;\n      if (renditionReports) {\n        var foundIndex = -1;\n        for (var i = 0; i < renditionReports.length; i++) {\n          var attr = renditionReports[i];\n          var uri = void 0;\n          try {\n            uri = new self.URL(attr.URI, previous.url).href;\n          } catch (error) {\n            logger.warn(\"Could not construct new URL for Rendition Report: \" + error);\n            uri = attr.URI || '';\n          }\n          // Use exact match. Otherwise, the last partial match, if any, will be used\n          // (Playlist URI includes a query string that the Rendition Report does not)\n          if (uri === playlistUri) {\n            foundIndex = i;\n            break;\n          } else if (uri === playlistUri.substring(0, uri.length)) {\n            foundIndex = i;\n          }\n        }\n        if (foundIndex !== -1) {\n          var _attr = renditionReports[foundIndex];\n          var msn = parseInt(_attr['LAST-MSN']) || (previous == null ? void 0 : previous.lastPartSn);\n          var part = parseInt(_attr['LAST-PART']) || (previous == null ? void 0 : previous.lastPartIndex);\n          if (this.hls.config.lowLatencyMode) {\n            var currentGoal = Math.min(previous.age - previous.partTarget, previous.targetduration);\n            if (part >= 0 && currentGoal > previous.partTarget) {\n              part += 1;\n            }\n          }\n          var skip = current && getSkipValue(current);\n          return new HlsUrlParameters(msn, part >= 0 ? part : undefined, skip);\n        }\n      }\n    };\n    _proto.loadPlaylist = function loadPlaylist(hlsUrlParameters) {\n      if (this.requestScheduled === -1) {\n        this.requestScheduled = self.performance.now();\n      }\n      // Loading is handled by the subclasses\n    };\n    _proto.shouldLoadPlaylist = function shouldLoadPlaylist(playlist) {\n      return this.canLoad && !!playlist && !!playlist.url && (!playlist.details || playlist.details.live);\n    };\n    _proto.shouldReloadPlaylist = function shouldReloadPlaylist(playlist) {\n      return this.timer === -1 && this.requestScheduled === -1 && this.shouldLoadPlaylist(playlist);\n    };\n    _proto.playlistLoaded = function playlistLoaded(index, data, previousDetails) {\n      var _this = this;\n      var details = data.details,\n        stats = data.stats;\n\n      // Set last updated date-time\n      var now = self.performance.now();\n      var elapsed = stats.loading.first ? Math.max(0, now - stats.loading.first) : 0;\n      details.advancedDateTime = Date.now() - elapsed;\n\n      // if current playlist is a live playlist, arm a timer to reload it\n      if (details.live || previousDetails != null && previousDetails.live) {\n        details.reloaded(previousDetails);\n        if (previousDetails) {\n          this.log(\"live playlist \" + index + \" \" + (details.advanced ? 'REFRESHED ' + details.lastPartSn + '-' + details.lastPartIndex : details.updated ? 'UPDATED' : 'MISSED'));\n        }\n        // Merge live playlists to adjust fragment starts and fill in delta playlist skipped segments\n        if (previousDetails && details.fragments.length > 0) {\n          mergeDetails(previousDetails, details);\n        }\n        if (!this.canLoad || !details.live) {\n          return;\n        }\n        var deliveryDirectives;\n        var msn = undefined;\n        var part = undefined;\n        if (details.canBlockReload && details.endSN && details.advanced) {\n          // Load level with LL-HLS delivery directives\n          var lowLatencyMode = this.hls.config.lowLatencyMode;\n          var lastPartSn = details.lastPartSn;\n          var endSn = details.endSN;\n          var lastPartIndex = details.lastPartIndex;\n          var hasParts = lastPartIndex !== -1;\n          var lastPart = lastPartSn === endSn;\n          // When low latency mode is disabled, we'll skip part requests once the last part index is found\n          var nextSnStartIndex = lowLatencyMode ? 0 : lastPartIndex;\n          if (hasParts) {\n            msn = lastPart ? endSn + 1 : lastPartSn;\n            part = lastPart ? nextSnStartIndex : lastPartIndex + 1;\n          } else {\n            msn = endSn + 1;\n          }\n          // Low-Latency CDN Tune-in: \"age\" header and time since load indicates we're behind by more than one part\n          // Update directives to obtain the Playlist that has the estimated additional duration of media\n          var lastAdvanced = details.age;\n          var cdnAge = lastAdvanced + details.ageHeader;\n          var currentGoal = Math.min(cdnAge - details.partTarget, details.targetduration * 1.5);\n          if (currentGoal > 0) {\n            if (previousDetails && currentGoal > previousDetails.tuneInGoal) {\n              // If we attempted to get the next or latest playlist update, but currentGoal increased,\n              // then we either can't catchup, or the \"age\" header cannot be trusted.\n              this.warn(\"CDN Tune-in goal increased from: \" + previousDetails.tuneInGoal + \" to: \" + currentGoal + \" with playlist age: \" + details.age);\n              currentGoal = 0;\n            } else {\n              var segments = Math.floor(currentGoal / details.targetduration);\n              msn += segments;\n              if (part !== undefined) {\n                var parts = Math.round(currentGoal % details.targetduration / details.partTarget);\n                part += parts;\n              }\n              this.log(\"CDN Tune-in age: \" + details.ageHeader + \"s last advanced \" + lastAdvanced.toFixed(2) + \"s goal: \" + currentGoal + \" skip sn \" + segments + \" to part \" + part);\n            }\n            details.tuneInGoal = currentGoal;\n          }\n          deliveryDirectives = this.getDeliveryDirectives(details, data.deliveryDirectives, msn, part);\n          if (lowLatencyMode || !lastPart) {\n            this.loadPlaylist(deliveryDirectives);\n            return;\n          }\n        } else if (details.canBlockReload || details.canSkipUntil) {\n          deliveryDirectives = this.getDeliveryDirectives(details, data.deliveryDirectives, msn, part);\n        }\n        var bufferInfo = this.hls.mainForwardBufferInfo;\n        var position = bufferInfo ? bufferInfo.end - bufferInfo.len : 0;\n        var distanceToLiveEdgeMs = (details.edge - position) * 1000;\n        var reloadInterval = computeReloadInterval(details, distanceToLiveEdgeMs);\n        if (details.updated && now > this.requestScheduled + reloadInterval) {\n          this.requestScheduled = stats.loading.start;\n        }\n        if (msn !== undefined && details.canBlockReload) {\n          this.requestScheduled = stats.loading.first + reloadInterval - (details.partTarget * 1000 || 1000);\n        } else if (this.requestScheduled === -1 || this.requestScheduled + reloadInterval < now) {\n          this.requestScheduled = now;\n        } else if (this.requestScheduled - now <= 0) {\n          this.requestScheduled += reloadInterval;\n        }\n        var estimatedTimeUntilUpdate = this.requestScheduled - now;\n        estimatedTimeUntilUpdate = Math.max(0, estimatedTimeUntilUpdate);\n        this.log(\"reload live playlist \" + index + \" in \" + Math.round(estimatedTimeUntilUpdate) + \" ms\");\n        // this.log(\n        //   `live reload ${details.updated ? 'REFRESHED' : 'MISSED'}\n        // reload in ${estimatedTimeUntilUpdate / 1000}\n        // round trip ${(stats.loading.end - stats.loading.start) / 1000}\n        // diff ${\n        //   (reloadInterval -\n        //     (estimatedTimeUntilUpdate +\n        //       stats.loading.end -\n        //       stats.loading.start)) /\n        //   1000\n        // }\n        // reload interval ${reloadInterval / 1000}\n        // target duration ${details.targetduration}\n        // distance to edge ${distanceToLiveEdgeMs / 1000}`\n        // );\n\n        this.timer = self.setTimeout(function () {\n          return _this.loadPlaylist(deliveryDirectives);\n        }, estimatedTimeUntilUpdate);\n      } else {\n        this.clearTimer();\n      }\n    };\n    _proto.getDeliveryDirectives = function getDeliveryDirectives(details, previousDeliveryDirectives, msn, part) {\n      var skip = getSkipValue(details);\n      if (previousDeliveryDirectives != null && previousDeliveryDirectives.skip && details.deltaUpdateFailed) {\n        msn = previousDeliveryDirectives.msn;\n        part = previousDeliveryDirectives.part;\n        skip = HlsSkip.No;\n      }\n      return new HlsUrlParameters(msn, part, skip);\n    };\n    _proto.checkRetry = function checkRetry(errorEvent) {\n      var _this2 = this;\n      var errorDetails = errorEvent.details;\n      var isTimeout = isTimeoutError(errorEvent);\n      var errorAction = errorEvent.errorAction;\n      var _ref = errorAction || {},\n        action = _ref.action,\n        _ref$retryCount = _ref.retryCount,\n        retryCount = _ref$retryCount === void 0 ? 0 : _ref$retryCount,\n        retryConfig = _ref.retryConfig;\n      var retry = !!errorAction && !!retryConfig && (action === NetworkErrorAction.RetryRequest || !errorAction.resolved && action === NetworkErrorAction.SendAlternateToPenaltyBox);\n      if (retry) {\n        var _errorEvent$context;\n        this.requestScheduled = -1;\n        if (retryCount >= retryConfig.maxNumRetry) {\n          return false;\n        }\n        if (isTimeout && (_errorEvent$context = errorEvent.context) != null && _errorEvent$context.deliveryDirectives) {\n          // The LL-HLS request already timed out so retry immediately\n          this.warn(\"Retrying playlist loading \" + (retryCount + 1) + \"/\" + retryConfig.maxNumRetry + \" after \\\"\" + errorDetails + \"\\\" without delivery-directives\");\n          this.loadPlaylist();\n        } else {\n          var delay = getRetryDelay(retryConfig, retryCount);\n          // Schedule level/track reload\n          this.timer = self.setTimeout(function () {\n            return _this2.loadPlaylist();\n          }, delay);\n          this.warn(\"Retrying playlist loading \" + (retryCount + 1) + \"/\" + retryConfig.maxNumRetry + \" after \\\"\" + errorDetails + \"\\\" in \" + delay + \"ms\");\n        }\n        // `levelRetry = true` used to inform other controllers that a retry is happening\n        errorEvent.levelRetry = true;\n        errorAction.resolved = true;\n      }\n      return retry;\n    };\n    return BasePlaylistController;\n  }();\n\n  /*\n   * compute an Exponential Weighted moving average\n   * - https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average\n   *  - heavily inspired from shaka-player\n   */\n  var EWMA = /*#__PURE__*/function () {\n    //  About half of the estimated value will be from the last |halfLife| samples by weight.\n    function EWMA(halfLife, estimate, weight) {\n      if (estimate === void 0) {\n        estimate = 0;\n      }\n      if (weight === void 0) {\n        weight = 0;\n      }\n      this.halfLife = void 0;\n      this.alpha_ = void 0;\n      this.estimate_ = void 0;\n      this.totalWeight_ = void 0;\n      this.halfLife = halfLife;\n      // Larger values of alpha expire historical data more slowly.\n      this.alpha_ = halfLife ? Math.exp(Math.log(0.5) / halfLife) : 0;\n      this.estimate_ = estimate;\n      this.totalWeight_ = weight;\n    }\n    var _proto = EWMA.prototype;\n    _proto.sample = function sample(weight, value) {\n      var adjAlpha = Math.pow(this.alpha_, weight);\n      this.estimate_ = value * (1 - adjAlpha) + adjAlpha * this.estimate_;\n      this.totalWeight_ += weight;\n    };\n    _proto.getTotalWeight = function getTotalWeight() {\n      return this.totalWeight_;\n    };\n    _proto.getEstimate = function getEstimate() {\n      if (this.alpha_) {\n        var zeroFactor = 1 - Math.pow(this.alpha_, this.totalWeight_);\n        if (zeroFactor) {\n          return this.estimate_ / zeroFactor;\n        }\n      }\n      return this.estimate_;\n    };\n    return EWMA;\n  }();\n\n  /*\n   * EWMA Bandwidth Estimator\n   *  - heavily inspired from shaka-player\n   * Tracks bandwidth samples and estimates available bandwidth.\n   * Based on the minimum of two exponentially-weighted moving averages with\n   * different half-lives.\n   */\n\n  var EwmaBandWidthEstimator = /*#__PURE__*/function () {\n    function EwmaBandWidthEstimator(slow, fast, defaultEstimate, defaultTTFB) {\n      if (defaultTTFB === void 0) {\n        defaultTTFB = 100;\n      }\n      this.defaultEstimate_ = void 0;\n      this.minWeight_ = void 0;\n      this.minDelayMs_ = void 0;\n      this.slow_ = void 0;\n      this.fast_ = void 0;\n      this.defaultTTFB_ = void 0;\n      this.ttfb_ = void 0;\n      this.defaultEstimate_ = defaultEstimate;\n      this.minWeight_ = 0.001;\n      this.minDelayMs_ = 50;\n      this.slow_ = new EWMA(slow);\n      this.fast_ = new EWMA(fast);\n      this.defaultTTFB_ = defaultTTFB;\n      this.ttfb_ = new EWMA(slow);\n    }\n    var _proto = EwmaBandWidthEstimator.prototype;\n    _proto.update = function update(slow, fast) {\n      var slow_ = this.slow_,\n        fast_ = this.fast_,\n        ttfb_ = this.ttfb_;\n      if (slow_.halfLife !== slow) {\n        this.slow_ = new EWMA(slow, slow_.getEstimate(), slow_.getTotalWeight());\n      }\n      if (fast_.halfLife !== fast) {\n        this.fast_ = new EWMA(fast, fast_.getEstimate(), fast_.getTotalWeight());\n      }\n      if (ttfb_.halfLife !== slow) {\n        this.ttfb_ = new EWMA(slow, ttfb_.getEstimate(), ttfb_.getTotalWeight());\n      }\n    };\n    _proto.sample = function sample(durationMs, numBytes) {\n      durationMs = Math.max(durationMs, this.minDelayMs_);\n      var numBits = 8 * numBytes;\n      // weight is duration in seconds\n      var durationS = durationMs / 1000;\n      // value is bandwidth in bits/s\n      var bandwidthInBps = numBits / durationS;\n      this.fast_.sample(durationS, bandwidthInBps);\n      this.slow_.sample(durationS, bandwidthInBps);\n    };\n    _proto.sampleTTFB = function sampleTTFB(ttfb) {\n      // weight is frequency curve applied to TTFB in seconds\n      // (longer times have less weight with expected input under 1 second)\n      var seconds = ttfb / 1000;\n      var weight = Math.sqrt(2) * Math.exp(-Math.pow(seconds, 2) / 2);\n      this.ttfb_.sample(weight, Math.max(ttfb, 5));\n    };\n    _proto.canEstimate = function canEstimate() {\n      return this.fast_.getTotalWeight() >= this.minWeight_;\n    };\n    _proto.getEstimate = function getEstimate() {\n      if (this.canEstimate()) {\n        // console.log('slow estimate:'+ Math.round(this.slow_.getEstimate()));\n        // console.log('fast estimate:'+ Math.round(this.fast_.getEstimate()));\n        // Take the minimum of these two estimates.  This should have the effect of\n        // adapting down quickly, but up more slowly.\n        return Math.min(this.fast_.getEstimate(), this.slow_.getEstimate());\n      } else {\n        return this.defaultEstimate_;\n      }\n    };\n    _proto.getEstimateTTFB = function getEstimateTTFB() {\n      if (this.ttfb_.getTotalWeight() >= this.minWeight_) {\n        return this.ttfb_.getEstimate();\n      } else {\n        return this.defaultTTFB_;\n      }\n    };\n    _proto.destroy = function destroy() {};\n    return EwmaBandWidthEstimator;\n  }();\n\n  var SUPPORTED_INFO_DEFAULT = {\n    supported: true,\n    configurations: [],\n    decodingInfoResults: [{\n      supported: true,\n      powerEfficient: true,\n      smooth: true\n    }]\n  };\n  var SUPPORTED_INFO_CACHE = {};\n  function requiresMediaCapabilitiesDecodingInfo(level, audioTracksByGroup, currentVideoRange, currentFrameRate, currentBw, audioPreference) {\n    // Only test support when configuration is exceeds minimum options\n    var audioGroups = level.audioCodec ? level.audioGroups : null;\n    var audioCodecPreference = audioPreference == null ? void 0 : audioPreference.audioCodec;\n    var channelsPreference = audioPreference == null ? void 0 : audioPreference.channels;\n    var maxChannels = channelsPreference ? parseInt(channelsPreference) : audioCodecPreference ? Infinity : 2;\n    var audioChannels = null;\n    if (audioGroups != null && audioGroups.length) {\n      try {\n        if (audioGroups.length === 1 && audioGroups[0]) {\n          audioChannels = audioTracksByGroup.groups[audioGroups[0]].channels;\n        } else {\n          audioChannels = audioGroups.reduce(function (acc, groupId) {\n            if (groupId) {\n              var audioTrackGroup = audioTracksByGroup.groups[groupId];\n              if (!audioTrackGroup) {\n                throw new Error(\"Audio track group \" + groupId + \" not found\");\n              }\n              // Sum all channel key values\n              Object.keys(audioTrackGroup.channels).forEach(function (key) {\n                acc[key] = (acc[key] || 0) + audioTrackGroup.channels[key];\n              });\n            }\n            return acc;\n          }, {\n            2: 0\n          });\n        }\n      } catch (error) {\n        return true;\n      }\n    }\n    return level.videoCodec !== undefined && (level.width > 1920 && level.height > 1088 || level.height > 1920 && level.width > 1088 || level.frameRate > Math.max(currentFrameRate, 30) || level.videoRange !== 'SDR' && level.videoRange !== currentVideoRange || level.bitrate > Math.max(currentBw, 8e6)) || !!audioChannels && isFiniteNumber(maxChannels) && Object.keys(audioChannels).some(function (channels) {\n      return parseInt(channels) > maxChannels;\n    });\n  }\n  function getMediaDecodingInfoPromise(level, audioTracksByGroup, mediaCapabilities) {\n    var videoCodecs = level.videoCodec;\n    var audioCodecs = level.audioCodec;\n    if (!videoCodecs || !audioCodecs || !mediaCapabilities) {\n      return Promise.resolve(SUPPORTED_INFO_DEFAULT);\n    }\n    var baseVideoConfiguration = {\n      width: level.width,\n      height: level.height,\n      bitrate: Math.ceil(Math.max(level.bitrate * 0.9, level.averageBitrate)),\n      // Assume a framerate of 30fps since MediaCapabilities will not accept Level default of 0.\n      framerate: level.frameRate || 30\n    };\n    var videoRange = level.videoRange;\n    if (videoRange !== 'SDR') {\n      baseVideoConfiguration.transferFunction = videoRange.toLowerCase();\n    }\n    var configurations = videoCodecs.split(',').map(function (videoCodec) {\n      return {\n        type: 'media-source',\n        video: _objectSpread2(_objectSpread2({}, baseVideoConfiguration), {}, {\n          contentType: mimeTypeForCodec(videoCodec, 'video')\n        })\n      };\n    });\n    if (audioCodecs && level.audioGroups) {\n      level.audioGroups.forEach(function (audioGroupId) {\n        var _audioTracksByGroup$g;\n        if (!audioGroupId) {\n          return;\n        }\n        (_audioTracksByGroup$g = audioTracksByGroup.groups[audioGroupId]) == null ? void 0 : _audioTracksByGroup$g.tracks.forEach(function (audioTrack) {\n          if (audioTrack.groupId === audioGroupId) {\n            var channels = audioTrack.channels || '';\n            var channelsNumber = parseFloat(channels);\n            if (isFiniteNumber(channelsNumber) && channelsNumber > 2) {\n              configurations.push.apply(configurations, audioCodecs.split(',').map(function (audioCodec) {\n                return {\n                  type: 'media-source',\n                  audio: {\n                    contentType: mimeTypeForCodec(audioCodec, 'audio'),\n                    channels: '' + channelsNumber\n                    // spatialRendering:\n                    //   audioCodec === 'ec-3' && channels.indexOf('JOC'),\n                  }\n                };\n              }));\n            }\n          }\n        });\n      });\n    }\n    return Promise.all(configurations.map(function (configuration) {\n      // Cache MediaCapabilities promises\n      var decodingInfoKey = getMediaDecodingInfoKey(configuration);\n      return SUPPORTED_INFO_CACHE[decodingInfoKey] || (SUPPORTED_INFO_CACHE[decodingInfoKey] = mediaCapabilities.decodingInfo(configuration));\n    })).then(function (decodingInfoResults) {\n      return {\n        supported: !decodingInfoResults.some(function (info) {\n          return !info.supported;\n        }),\n        configurations: configurations,\n        decodingInfoResults: decodingInfoResults\n      };\n    }).catch(function (error) {\n      return {\n        supported: false,\n        configurations: configurations,\n        decodingInfoResults: [],\n        error: error\n      };\n    });\n  }\n  function getMediaDecodingInfoKey(config) {\n    var audio = config.audio,\n      video = config.video;\n    var mediaConfig = video || audio;\n    if (mediaConfig) {\n      var codec = mediaConfig.contentType.split('\"')[1];\n      if (video) {\n        return \"r\" + video.height + \"x\" + video.width + \"f\" + Math.ceil(video.framerate) + (video.transferFunction || 'sd') + \"_\" + codec + \"_\" + Math.ceil(video.bitrate / 1e5);\n      }\n      if (audio) {\n        return \"c\" + audio.channels + (audio.spatialRendering ? 's' : 'n') + \"_\" + codec;\n      }\n    }\n    return '';\n  }\n\n  /**\n   * @returns Whether we can detect and validate HDR capability within the window context\n   */\n  function isHdrSupported() {\n    if (typeof matchMedia === 'function') {\n      var mediaQueryList = matchMedia('(dynamic-range: high)');\n      var badQuery = matchMedia('bad query');\n      if (mediaQueryList.media !== badQuery.media) {\n        return mediaQueryList.matches === true;\n      }\n    }\n    return false;\n  }\n\n  /**\n   * Sanitizes inputs to return the active video selection options for HDR/SDR.\n   * When both inputs are null:\n   *\n   *    `{ preferHDR: false, allowedVideoRanges: [] }`\n   *\n   * When `currentVideoRange` non-null, maintain the active range:\n   *\n   *    `{ preferHDR: currentVideoRange !== 'SDR', allowedVideoRanges: [currentVideoRange] }`\n   *\n   * When VideoSelectionOption non-null:\n   *\n   *  - Allow all video ranges if `allowedVideoRanges` unspecified.\n   *  - If `preferHDR` is non-null use the value to filter `allowedVideoRanges`.\n   *  - Else check window for HDR support and set `preferHDR` to the result.\n   *\n   * @param currentVideoRange\n   * @param videoPreference\n   */\n  function getVideoSelectionOptions(currentVideoRange, videoPreference) {\n    var preferHDR = false;\n    var allowedVideoRanges = [];\n    if (currentVideoRange) {\n      preferHDR = currentVideoRange !== 'SDR';\n      allowedVideoRanges = [currentVideoRange];\n    }\n    if (videoPreference) {\n      allowedVideoRanges = videoPreference.allowedVideoRanges || VideoRangeValues.slice(0);\n      preferHDR = videoPreference.preferHDR !== undefined ? videoPreference.preferHDR : isHdrSupported();\n      if (preferHDR) {\n        allowedVideoRanges = allowedVideoRanges.filter(function (range) {\n          return range !== 'SDR';\n        });\n      } else {\n        allowedVideoRanges = ['SDR'];\n      }\n    }\n    return {\n      preferHDR: preferHDR,\n      allowedVideoRanges: allowedVideoRanges\n    };\n  }\n\n  function getStartCodecTier(codecTiers, currentVideoRange, currentBw, audioPreference, videoPreference) {\n    var codecSets = Object.keys(codecTiers);\n    var channelsPreference = audioPreference == null ? void 0 : audioPreference.channels;\n    var audioCodecPreference = audioPreference == null ? void 0 : audioPreference.audioCodec;\n    var preferStereo = channelsPreference && parseInt(channelsPreference) === 2;\n    // Use first level set to determine stereo, and minimum resolution and framerate\n    var hasStereo = true;\n    var hasCurrentVideoRange = false;\n    var minHeight = Infinity;\n    var minFramerate = Infinity;\n    var minBitrate = Infinity;\n    var selectedScore = 0;\n    var videoRanges = [];\n    var _getVideoSelectionOpt = getVideoSelectionOptions(currentVideoRange, videoPreference),\n      preferHDR = _getVideoSelectionOpt.preferHDR,\n      allowedVideoRanges = _getVideoSelectionOpt.allowedVideoRanges;\n    var _loop = function _loop() {\n      var tier = codecTiers[codecSets[i]];\n      hasStereo = tier.channels[2] > 0;\n      minHeight = Math.min(minHeight, tier.minHeight);\n      minFramerate = Math.min(minFramerate, tier.minFramerate);\n      minBitrate = Math.min(minBitrate, tier.minBitrate);\n      var matchingVideoRanges = allowedVideoRanges.filter(function (range) {\n        return tier.videoRanges[range] > 0;\n      });\n      if (matchingVideoRanges.length > 0) {\n        hasCurrentVideoRange = true;\n        videoRanges = matchingVideoRanges;\n      }\n    };\n    for (var i = codecSets.length; i--;) {\n      _loop();\n    }\n    minHeight = isFiniteNumber(minHeight) ? minHeight : 0;\n    minFramerate = isFiniteNumber(minFramerate) ? minFramerate : 0;\n    var maxHeight = Math.max(1080, minHeight);\n    var maxFramerate = Math.max(30, minFramerate);\n    minBitrate = isFiniteNumber(minBitrate) ? minBitrate : currentBw;\n    currentBw = Math.max(minBitrate, currentBw);\n    // If there are no variants with matching preference, set currentVideoRange to undefined\n    if (!hasCurrentVideoRange) {\n      currentVideoRange = undefined;\n      videoRanges = [];\n    }\n    var codecSet = codecSets.reduce(function (selected, candidate) {\n      // Remove candiates which do not meet bitrate, default audio, stereo or channels preference, 1080p or lower, 30fps or lower, or SDR/HDR selection if present\n      var candidateTier = codecTiers[candidate];\n      if (candidate === selected) {\n        return selected;\n      }\n      if (candidateTier.minBitrate > currentBw) {\n        logStartCodecCandidateIgnored(candidate, \"min bitrate of \" + candidateTier.minBitrate + \" > current estimate of \" + currentBw);\n        return selected;\n      }\n      if (!candidateTier.hasDefaultAudio) {\n        logStartCodecCandidateIgnored(candidate, \"no renditions with default or auto-select sound found\");\n        return selected;\n      }\n      if (audioCodecPreference && candidate.indexOf(audioCodecPreference.substring(0, 4)) % 5 !== 0) {\n        logStartCodecCandidateIgnored(candidate, \"audio codec preference \\\"\" + audioCodecPreference + \"\\\" not found\");\n        return selected;\n      }\n      if (channelsPreference && !preferStereo) {\n        if (!candidateTier.channels[channelsPreference]) {\n          logStartCodecCandidateIgnored(candidate, \"no renditions with \" + channelsPreference + \" channel sound found (channels options: \" + Object.keys(candidateTier.channels) + \")\");\n          return selected;\n        }\n      } else if ((!audioCodecPreference || preferStereo) && hasStereo && candidateTier.channels['2'] === 0) {\n        logStartCodecCandidateIgnored(candidate, \"no renditions with stereo sound found\");\n        return selected;\n      }\n      if (candidateTier.minHeight > maxHeight) {\n        logStartCodecCandidateIgnored(candidate, \"min resolution of \" + candidateTier.minHeight + \" > maximum of \" + maxHeight);\n        return selected;\n      }\n      if (candidateTier.minFramerate > maxFramerate) {\n        logStartCodecCandidateIgnored(candidate, \"min framerate of \" + candidateTier.minFramerate + \" > maximum of \" + maxFramerate);\n        return selected;\n      }\n      if (!videoRanges.some(function (range) {\n        return candidateTier.videoRanges[range] > 0;\n      })) {\n        logStartCodecCandidateIgnored(candidate, \"no variants with VIDEO-RANGE of \" + JSON.stringify(videoRanges) + \" found\");\n        return selected;\n      }\n      if (candidateTier.maxScore < selectedScore) {\n        logStartCodecCandidateIgnored(candidate, \"max score of \" + candidateTier.maxScore + \" < selected max of \" + selectedScore);\n        return selected;\n      }\n      // Remove candiates with less preferred codecs or more errors\n      if (selected && (codecsSetSelectionPreferenceValue(candidate) >= codecsSetSelectionPreferenceValue(selected) || candidateTier.fragmentError > codecTiers[selected].fragmentError)) {\n        return selected;\n      }\n      selectedScore = candidateTier.maxScore;\n      return candidate;\n    }, undefined);\n    return {\n      codecSet: codecSet,\n      videoRanges: videoRanges,\n      preferHDR: preferHDR,\n      minFramerate: minFramerate,\n      minBitrate: minBitrate\n    };\n  }\n  function logStartCodecCandidateIgnored(codeSet, reason) {\n    logger.log(\"[abr] start candidates with \\\"\" + codeSet + \"\\\" ignored because \" + reason);\n  }\n  function getAudioTracksByGroup(allAudioTracks) {\n    return allAudioTracks.reduce(function (audioTracksByGroup, track) {\n      var trackGroup = audioTracksByGroup.groups[track.groupId];\n      if (!trackGroup) {\n        trackGroup = audioTracksByGroup.groups[track.groupId] = {\n          tracks: [],\n          channels: {\n            2: 0\n          },\n          hasDefault: false,\n          hasAutoSelect: false\n        };\n      }\n      trackGroup.tracks.push(track);\n      var channelsKey = track.channels || '2';\n      trackGroup.channels[channelsKey] = (trackGroup.channels[channelsKey] || 0) + 1;\n      trackGroup.hasDefault = trackGroup.hasDefault || track.default;\n      trackGroup.hasAutoSelect = trackGroup.hasAutoSelect || track.autoselect;\n      if (trackGroup.hasDefault) {\n        audioTracksByGroup.hasDefaultAudio = true;\n      }\n      if (trackGroup.hasAutoSelect) {\n        audioTracksByGroup.hasAutoSelectAudio = true;\n      }\n      return audioTracksByGroup;\n    }, {\n      hasDefaultAudio: false,\n      hasAutoSelectAudio: false,\n      groups: {}\n    });\n  }\n  function getCodecTiers(levels, audioTracksByGroup, minAutoLevel, maxAutoLevel) {\n    return levels.slice(minAutoLevel, maxAutoLevel + 1).reduce(function (tiers, level) {\n      if (!level.codecSet) {\n        return tiers;\n      }\n      var audioGroups = level.audioGroups;\n      var tier = tiers[level.codecSet];\n      if (!tier) {\n        tiers[level.codecSet] = tier = {\n          minBitrate: Infinity,\n          minHeight: Infinity,\n          minFramerate: Infinity,\n          maxScore: 0,\n          videoRanges: {\n            SDR: 0\n          },\n          channels: {\n            '2': 0\n          },\n          hasDefaultAudio: !audioGroups,\n          fragmentError: 0\n        };\n      }\n      tier.minBitrate = Math.min(tier.minBitrate, level.bitrate);\n      var lesserWidthOrHeight = Math.min(level.height, level.width);\n      tier.minHeight = Math.min(tier.minHeight, lesserWidthOrHeight);\n      tier.minFramerate = Math.min(tier.minFramerate, level.frameRate);\n      tier.maxScore = Math.max(tier.maxScore, level.score);\n      tier.fragmentError += level.fragmentError;\n      tier.videoRanges[level.videoRange] = (tier.videoRanges[level.videoRange] || 0) + 1;\n      if (audioGroups) {\n        audioGroups.forEach(function (audioGroupId) {\n          if (!audioGroupId) {\n            return;\n          }\n          var audioGroup = audioTracksByGroup.groups[audioGroupId];\n          if (!audioGroup) {\n            return;\n          }\n          // Default audio is any group with DEFAULT=YES, or if missing then any group with AUTOSELECT=YES, or all variants\n          tier.hasDefaultAudio = tier.hasDefaultAudio || audioTracksByGroup.hasDefaultAudio ? audioGroup.hasDefault : audioGroup.hasAutoSelect || !audioTracksByGroup.hasDefaultAudio && !audioTracksByGroup.hasAutoSelectAudio;\n          Object.keys(audioGroup.channels).forEach(function (channels) {\n            tier.channels[channels] = (tier.channels[channels] || 0) + audioGroup.channels[channels];\n          });\n        });\n      }\n      return tiers;\n    }, {});\n  }\n  function findMatchingOption(option, tracks, matchPredicate) {\n    if ('attrs' in option) {\n      var index = tracks.indexOf(option);\n      if (index !== -1) {\n        return index;\n      }\n    }\n    for (var i = 0; i < tracks.length; i++) {\n      var _track = tracks[i];\n      if (matchesOption(option, _track, matchPredicate)) {\n        return i;\n      }\n    }\n    return -1;\n  }\n  function matchesOption(option, track, matchPredicate) {\n    var groupId = option.groupId,\n      name = option.name,\n      lang = option.lang,\n      assocLang = option.assocLang,\n      characteristics = option.characteristics,\n      isDefault = option.default;\n    var forced = option.forced;\n    return (groupId === undefined || track.groupId === groupId) && (name === undefined || track.name === name) && (lang === undefined || track.lang === lang) && (lang === undefined || track.assocLang === assocLang) && (isDefault === undefined || track.default === isDefault) && (forced === undefined || track.forced === forced) && (characteristics === undefined || characteristicsMatch(characteristics, track.characteristics)) && (matchPredicate === undefined || matchPredicate(option, track));\n  }\n  function characteristicsMatch(characteristicsA, characteristicsB) {\n    if (characteristicsB === void 0) {\n      characteristicsB = '';\n    }\n    var arrA = characteristicsA.split(',');\n    var arrB = characteristicsB.split(',');\n    // Expects each item to be unique:\n    return arrA.length === arrB.length && !arrA.some(function (el) {\n      return arrB.indexOf(el) === -1;\n    });\n  }\n  function audioMatchPredicate(option, track) {\n    var audioCodec = option.audioCodec,\n      channels = option.channels;\n    return (audioCodec === undefined || (track.audioCodec || '').substring(0, 4) === audioCodec.substring(0, 4)) && (channels === undefined || channels === (track.channels || '2'));\n  }\n  function findClosestLevelWithAudioGroup(option, levels, allAudioTracks, searchIndex, matchPredicate) {\n    var currentLevel = levels[searchIndex];\n    // Are there variants with same URI as current level?\n    // If so, find a match that does not require any level URI change\n    var variants = levels.reduce(function (variantMap, level, index) {\n      var uri = level.uri;\n      var renditions = variantMap[uri] || (variantMap[uri] = []);\n      renditions.push(index);\n      return variantMap;\n    }, {});\n    var renditions = variants[currentLevel.uri];\n    if (renditions.length > 1) {\n      searchIndex = Math.max.apply(Math, renditions);\n    }\n    // Find best match\n    var currentVideoRange = currentLevel.videoRange;\n    var currentFrameRate = currentLevel.frameRate;\n    var currentVideoCodec = currentLevel.codecSet.substring(0, 4);\n    var matchingVideo = searchDownAndUpList(levels, searchIndex, function (level) {\n      if (level.videoRange !== currentVideoRange || level.frameRate !== currentFrameRate || level.codecSet.substring(0, 4) !== currentVideoCodec) {\n        return false;\n      }\n      var audioGroups = level.audioGroups;\n      var tracks = allAudioTracks.filter(function (track) {\n        return !audioGroups || audioGroups.indexOf(track.groupId) !== -1;\n      });\n      return findMatchingOption(option, tracks, matchPredicate) > -1;\n    });\n    if (matchingVideo > -1) {\n      return matchingVideo;\n    }\n    return searchDownAndUpList(levels, searchIndex, function (level) {\n      var audioGroups = level.audioGroups;\n      var tracks = allAudioTracks.filter(function (track) {\n        return !audioGroups || audioGroups.indexOf(track.groupId) !== -1;\n      });\n      return findMatchingOption(option, tracks, matchPredicate) > -1;\n    });\n  }\n  function searchDownAndUpList(arr, searchIndex, predicate) {\n    for (var i = searchIndex; i > -1; i--) {\n      if (predicate(arr[i])) {\n        return i;\n      }\n    }\n    for (var _i = searchIndex + 1; _i < arr.length; _i++) {\n      if (predicate(arr[_i])) {\n        return _i;\n      }\n    }\n    return -1;\n  }\n\n  var AbrController = /*#__PURE__*/function () {\n    function AbrController(_hls) {\n      var _this = this;\n      this.hls = void 0;\n      this.lastLevelLoadSec = 0;\n      this.lastLoadedFragLevel = -1;\n      this.firstSelection = -1;\n      this._nextAutoLevel = -1;\n      this.nextAutoLevelKey = '';\n      this.audioTracksByGroup = null;\n      this.codecTiers = null;\n      this.timer = -1;\n      this.fragCurrent = null;\n      this.partCurrent = null;\n      this.bitrateTestDelay = 0;\n      this.bwEstimator = void 0;\n      /*\n          This method monitors the download rate of the current fragment, and will downswitch if that fragment will not load\n          quickly enough to prevent underbuffering\n        */\n      this._abandonRulesCheck = function () {\n        var frag = _this.fragCurrent,\n          part = _this.partCurrent,\n          hls = _this.hls;\n        var autoLevelEnabled = hls.autoLevelEnabled,\n          media = hls.media;\n        if (!frag || !media) {\n          return;\n        }\n        var now = performance.now();\n        var stats = part ? part.stats : frag.stats;\n        var duration = part ? part.duration : frag.duration;\n        var timeLoading = now - stats.loading.start;\n        var minAutoLevel = hls.minAutoLevel;\n        // If frag loading is aborted, complete, or from lowest level, stop timer and return\n        if (stats.aborted || stats.loaded && stats.loaded === stats.total || frag.level <= minAutoLevel) {\n          _this.clearTimer();\n          // reset forced auto level value so that next level will be selected\n          _this._nextAutoLevel = -1;\n          return;\n        }\n\n        // This check only runs if we're in ABR mode and actually playing\n        if (!autoLevelEnabled || media.paused || !media.playbackRate || !media.readyState) {\n          return;\n        }\n        var bufferInfo = hls.mainForwardBufferInfo;\n        if (bufferInfo === null) {\n          return;\n        }\n        var ttfbEstimate = _this.bwEstimator.getEstimateTTFB();\n        var playbackRate = Math.abs(media.playbackRate);\n        // To maintain stable adaptive playback, only begin monitoring frag loading after half or more of its playback duration has passed\n        if (timeLoading <= Math.max(ttfbEstimate, 1000 * (duration / (playbackRate * 2)))) {\n          return;\n        }\n\n        // bufferStarvationDelay is an estimate of the amount time (in seconds) it will take to exhaust the buffer\n        var bufferStarvationDelay = bufferInfo.len / playbackRate;\n        var ttfb = stats.loading.first ? stats.loading.first - stats.loading.start : -1;\n        var loadedFirstByte = stats.loaded && ttfb > -1;\n        var bwEstimate = _this.getBwEstimate();\n        var levels = hls.levels;\n        var level = levels[frag.level];\n        var expectedLen = stats.total || Math.max(stats.loaded, Math.round(duration * level.averageBitrate / 8));\n        var timeStreaming = loadedFirstByte ? timeLoading - ttfb : timeLoading;\n        if (timeStreaming < 1 && loadedFirstByte) {\n          timeStreaming = Math.min(timeLoading, stats.loaded * 8 / bwEstimate);\n        }\n        var loadRate = loadedFirstByte ? stats.loaded * 1000 / timeStreaming : 0;\n        // fragLoadDelay is an estimate of the time (in seconds) it will take to buffer the remainder of the fragment\n        var fragLoadedDelay = loadRate ? (expectedLen - stats.loaded) / loadRate : expectedLen * 8 / bwEstimate + ttfbEstimate / 1000;\n        // Only downswitch if the time to finish loading the current fragment is greater than the amount of buffer left\n        if (fragLoadedDelay <= bufferStarvationDelay) {\n          return;\n        }\n        var bwe = loadRate ? loadRate * 8 : bwEstimate;\n        var fragLevelNextLoadedDelay = Number.POSITIVE_INFINITY;\n        var nextLoadLevel;\n        // Iterate through lower level and try to find the largest one that avoids rebuffering\n        for (nextLoadLevel = frag.level - 1; nextLoadLevel > minAutoLevel; nextLoadLevel--) {\n          // compute time to load next fragment at lower level\n          // 8 = bits per byte (bps/Bps)\n          var levelNextBitrate = levels[nextLoadLevel].maxBitrate;\n          fragLevelNextLoadedDelay = _this.getTimeToLoadFrag(ttfbEstimate / 1000, bwe, duration * levelNextBitrate, !levels[nextLoadLevel].details);\n          if (fragLevelNextLoadedDelay < bufferStarvationDelay) {\n            break;\n          }\n        }\n        // Only emergency switch down if it takes less time to load a new fragment at lowest level instead of continuing\n        // to load the current one\n        if (fragLevelNextLoadedDelay >= fragLoadedDelay) {\n          return;\n        }\n\n        // if estimated load time of new segment is completely unreasonable, ignore and do not emergency switch down\n        if (fragLevelNextLoadedDelay > duration * 10) {\n          return;\n        }\n        hls.nextLoadLevel = hls.nextAutoLevel = nextLoadLevel;\n        if (loadedFirstByte) {\n          // If there has been loading progress, sample bandwidth using loading time offset by minimum TTFB time\n          _this.bwEstimator.sample(timeLoading - Math.min(ttfbEstimate, ttfb), stats.loaded);\n        } else {\n          // If there has been no loading progress, sample TTFB\n          _this.bwEstimator.sampleTTFB(timeLoading);\n        }\n        var nextLoadLevelBitrate = levels[nextLoadLevel].maxBitrate;\n        if (_this.getBwEstimate() * _this.hls.config.abrBandWidthUpFactor > nextLoadLevelBitrate) {\n          _this.resetEstimator(nextLoadLevelBitrate);\n        }\n        _this.clearTimer();\n        logger.warn(\"[abr] Fragment \" + frag.sn + (part ? ' part ' + part.index : '') + \" of level \" + frag.level + \" is loading too slowly;\\n      Time to underbuffer: \" + bufferStarvationDelay.toFixed(3) + \" s\\n      Estimated load time for current fragment: \" + fragLoadedDelay.toFixed(3) + \" s\\n      Estimated load time for down switch fragment: \" + fragLevelNextLoadedDelay.toFixed(3) + \" s\\n      TTFB estimate: \" + (ttfb | 0) + \" ms\\n      Current BW estimate: \" + (isFiniteNumber(bwEstimate) ? bwEstimate | 0 : 'Unknown') + \" bps\\n      New BW estimate: \" + (_this.getBwEstimate() | 0) + \" bps\\n      Switching to level \" + nextLoadLevel + \" @ \" + (nextLoadLevelBitrate | 0) + \" bps\");\n        hls.trigger(Events.FRAG_LOAD_EMERGENCY_ABORTED, {\n          frag: frag,\n          part: part,\n          stats: stats\n        });\n      };\n      this.hls = _hls;\n      this.bwEstimator = this.initEstimator();\n      this.registerListeners();\n    }\n    var _proto = AbrController.prototype;\n    _proto.resetEstimator = function resetEstimator(abrEwmaDefaultEstimate) {\n      if (abrEwmaDefaultEstimate) {\n        logger.log(\"setting initial bwe to \" + abrEwmaDefaultEstimate);\n        this.hls.config.abrEwmaDefaultEstimate = abrEwmaDefaultEstimate;\n      }\n      this.firstSelection = -1;\n      this.bwEstimator = this.initEstimator();\n    };\n    _proto.initEstimator = function initEstimator() {\n      var config = this.hls.config;\n      return new EwmaBandWidthEstimator(config.abrEwmaSlowVoD, config.abrEwmaFastVoD, config.abrEwmaDefaultEstimate);\n    };\n    _proto.registerListeners = function registerListeners() {\n      var hls = this.hls;\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.FRAG_LOADING, this.onFragLoading, this);\n      hls.on(Events.FRAG_LOADED, this.onFragLoaded, this);\n      hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n      hls.on(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n      hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n      hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n      hls.on(Events.MAX_AUTO_LEVEL_UPDATED, this.onMaxAutoLevelUpdated, this);\n      hls.on(Events.ERROR, this.onError, this);\n    };\n    _proto.unregisterListeners = function unregisterListeners() {\n      var hls = this.hls;\n      if (!hls) {\n        return;\n      }\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.FRAG_LOADING, this.onFragLoading, this);\n      hls.off(Events.FRAG_LOADED, this.onFragLoaded, this);\n      hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n      hls.off(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n      hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n      hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n      hls.off(Events.MAX_AUTO_LEVEL_UPDATED, this.onMaxAutoLevelUpdated, this);\n      hls.off(Events.ERROR, this.onError, this);\n    };\n    _proto.destroy = function destroy() {\n      this.unregisterListeners();\n      this.clearTimer();\n      // @ts-ignore\n      this.hls = this._abandonRulesCheck = null;\n      this.fragCurrent = this.partCurrent = null;\n    };\n    _proto.onManifestLoading = function onManifestLoading(event, data) {\n      this.lastLoadedFragLevel = -1;\n      this.firstSelection = -1;\n      this.lastLevelLoadSec = 0;\n      this.fragCurrent = this.partCurrent = null;\n      this.onLevelsUpdated();\n      this.clearTimer();\n    };\n    _proto.onLevelsUpdated = function onLevelsUpdated() {\n      if (this.lastLoadedFragLevel > -1 && this.fragCurrent) {\n        this.lastLoadedFragLevel = this.fragCurrent.level;\n      }\n      this._nextAutoLevel = -1;\n      this.onMaxAutoLevelUpdated();\n      this.codecTiers = null;\n      this.audioTracksByGroup = null;\n    };\n    _proto.onMaxAutoLevelUpdated = function onMaxAutoLevelUpdated() {\n      this.firstSelection = -1;\n      this.nextAutoLevelKey = '';\n    };\n    _proto.onFragLoading = function onFragLoading(event, data) {\n      var frag = data.frag;\n      if (this.ignoreFragment(frag)) {\n        return;\n      }\n      if (!frag.bitrateTest) {\n        var _data$part;\n        this.fragCurrent = frag;\n        this.partCurrent = (_data$part = data.part) != null ? _data$part : null;\n      }\n      this.clearTimer();\n      this.timer = self.setInterval(this._abandonRulesCheck, 100);\n    };\n    _proto.onLevelSwitching = function onLevelSwitching(event, data) {\n      this.clearTimer();\n    };\n    _proto.onError = function onError(event, data) {\n      if (data.fatal) {\n        return;\n      }\n      switch (data.details) {\n        case ErrorDetails.BUFFER_ADD_CODEC_ERROR:\n        case ErrorDetails.BUFFER_APPEND_ERROR:\n          // Reset last loaded level so that a new selection can be made after calling recoverMediaError\n          this.lastLoadedFragLevel = -1;\n          this.firstSelection = -1;\n          break;\n        case ErrorDetails.FRAG_LOAD_TIMEOUT:\n          {\n            var frag = data.frag;\n            var fragCurrent = this.fragCurrent,\n              part = this.partCurrent;\n            if (frag && fragCurrent && frag.sn === fragCurrent.sn && frag.level === fragCurrent.level) {\n              var now = performance.now();\n              var stats = part ? part.stats : frag.stats;\n              var timeLoading = now - stats.loading.start;\n              var ttfb = stats.loading.first ? stats.loading.first - stats.loading.start : -1;\n              var loadedFirstByte = stats.loaded && ttfb > -1;\n              if (loadedFirstByte) {\n                var ttfbEstimate = this.bwEstimator.getEstimateTTFB();\n                this.bwEstimator.sample(timeLoading - Math.min(ttfbEstimate, ttfb), stats.loaded);\n              } else {\n                this.bwEstimator.sampleTTFB(timeLoading);\n              }\n            }\n            break;\n          }\n      }\n    };\n    _proto.getTimeToLoadFrag = function getTimeToLoadFrag(timeToFirstByteSec, bandwidth, fragSizeBits, isSwitch) {\n      var fragLoadSec = timeToFirstByteSec + fragSizeBits / bandwidth;\n      var playlistLoadSec = isSwitch ? this.lastLevelLoadSec : 0;\n      return fragLoadSec + playlistLoadSec;\n    };\n    _proto.onLevelLoaded = function onLevelLoaded(event, data) {\n      var config = this.hls.config;\n      var loading = data.stats.loading;\n      var timeLoadingMs = loading.end - loading.start;\n      if (isFiniteNumber(timeLoadingMs)) {\n        this.lastLevelLoadSec = timeLoadingMs / 1000;\n      }\n      if (data.details.live) {\n        this.bwEstimator.update(config.abrEwmaSlowLive, config.abrEwmaFastLive);\n      } else {\n        this.bwEstimator.update(config.abrEwmaSlowVoD, config.abrEwmaFastVoD);\n      }\n    };\n    _proto.onFragLoaded = function onFragLoaded(event, _ref) {\n      var frag = _ref.frag,\n        part = _ref.part;\n      var stats = part ? part.stats : frag.stats;\n      if (frag.type === PlaylistLevelType.MAIN) {\n        this.bwEstimator.sampleTTFB(stats.loading.first - stats.loading.start);\n      }\n      if (this.ignoreFragment(frag)) {\n        return;\n      }\n      // stop monitoring bw once frag loaded\n      this.clearTimer();\n      // reset forced auto level value so that next level will be selected\n      if (frag.level === this._nextAutoLevel) {\n        this._nextAutoLevel = -1;\n      }\n      this.firstSelection = -1;\n\n      // compute level average bitrate\n      if (this.hls.config.abrMaxWithRealBitrate) {\n        var duration = part ? part.duration : frag.duration;\n        var level = this.hls.levels[frag.level];\n        var loadedBytes = (level.loaded ? level.loaded.bytes : 0) + stats.loaded;\n        var loadedDuration = (level.loaded ? level.loaded.duration : 0) + duration;\n        level.loaded = {\n          bytes: loadedBytes,\n          duration: loadedDuration\n        };\n        level.realBitrate = Math.round(8 * loadedBytes / loadedDuration);\n      }\n      if (frag.bitrateTest) {\n        var fragBufferedData = {\n          stats: stats,\n          frag: frag,\n          part: part,\n          id: frag.type\n        };\n        this.onFragBuffered(Events.FRAG_BUFFERED, fragBufferedData);\n        frag.bitrateTest = false;\n      } else {\n        // store level id after successful fragment load for playback\n        this.lastLoadedFragLevel = frag.level;\n      }\n    };\n    _proto.onFragBuffered = function onFragBuffered(event, data) {\n      var frag = data.frag,\n        part = data.part;\n      var stats = part != null && part.stats.loaded ? part.stats : frag.stats;\n      if (stats.aborted) {\n        return;\n      }\n      if (this.ignoreFragment(frag)) {\n        return;\n      }\n      // Use the difference between parsing and request instead of buffering and request to compute fragLoadingProcessing;\n      // rationale is that buffer appending only happens once media is attached. This can happen when config.startFragPrefetch\n      // is used. If we used buffering in that case, our BW estimate sample will be very large.\n      var processingMs = stats.parsing.end - stats.loading.start - Math.min(stats.loading.first - stats.loading.start, this.bwEstimator.getEstimateTTFB());\n      this.bwEstimator.sample(processingMs, stats.loaded);\n      stats.bwEstimate = this.getBwEstimate();\n      if (frag.bitrateTest) {\n        this.bitrateTestDelay = processingMs / 1000;\n      } else {\n        this.bitrateTestDelay = 0;\n      }\n    };\n    _proto.ignoreFragment = function ignoreFragment(frag) {\n      // Only count non-alt-audio frags which were actually buffered in our BW calculations\n      return frag.type !== PlaylistLevelType.MAIN || frag.sn === 'initSegment';\n    };\n    _proto.clearTimer = function clearTimer() {\n      if (this.timer > -1) {\n        self.clearInterval(this.timer);\n        this.timer = -1;\n      }\n    };\n    _proto.getAutoLevelKey = function getAutoLevelKey() {\n      return this.getBwEstimate() + \"_\" + this.getStarvationDelay().toFixed(2);\n    };\n    _proto.getNextABRAutoLevel = function getNextABRAutoLevel() {\n      var fragCurrent = this.fragCurrent,\n        partCurrent = this.partCurrent,\n        hls = this.hls;\n      var maxAutoLevel = hls.maxAutoLevel,\n        config = hls.config,\n        minAutoLevel = hls.minAutoLevel;\n      var currentFragDuration = partCurrent ? partCurrent.duration : fragCurrent ? fragCurrent.duration : 0;\n      var avgbw = this.getBwEstimate();\n      // bufferStarvationDelay is the wall-clock time left until the playback buffer is exhausted.\n      var bufferStarvationDelay = this.getStarvationDelay();\n      var bwFactor = config.abrBandWidthFactor;\n      var bwUpFactor = config.abrBandWidthUpFactor;\n\n      // First, look to see if we can find a level matching with our avg bandwidth AND that could also guarantee no rebuffering at all\n      if (bufferStarvationDelay) {\n        var _bestLevel = this.findBestLevel(avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, 0, bwFactor, bwUpFactor);\n        if (_bestLevel >= 0) {\n          return _bestLevel;\n        }\n      }\n      // not possible to get rid of rebuffering... try to find level that will guarantee less than maxStarvationDelay of rebuffering\n      var maxStarvationDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxStarvationDelay) : config.maxStarvationDelay;\n      if (!bufferStarvationDelay) {\n        // in case buffer is empty, let's check if previous fragment was loaded to perform a bitrate test\n        var bitrateTestDelay = this.bitrateTestDelay;\n        if (bitrateTestDelay) {\n          // if it is the case, then we need to adjust our max starvation delay using maxLoadingDelay config value\n          // max video loading delay used in  automatic start level selection :\n          // in that mode ABR controller will ensure that video loading time (ie the time to fetch the first fragment at lowest quality level +\n          // the time to fetch the fragment at the appropriate quality level is less than ```maxLoadingDelay``` )\n          // cap maxLoadingDelay and ensure it is not bigger 'than bitrate test' frag duration\n          var maxLoadingDelay = currentFragDuration ? Math.min(currentFragDuration, config.maxLoadingDelay) : config.maxLoadingDelay;\n          maxStarvationDelay = maxLoadingDelay - bitrateTestDelay;\n          logger.info(\"[abr] bitrate test took \" + Math.round(1000 * bitrateTestDelay) + \"ms, set first fragment max fetchDuration to \" + Math.round(1000 * maxStarvationDelay) + \" ms\");\n          // don't use conservative factor on bitrate test\n          bwFactor = bwUpFactor = 1;\n        }\n      }\n      var bestLevel = this.findBestLevel(avgbw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, maxStarvationDelay, bwFactor, bwUpFactor);\n      logger.info(\"[abr] \" + (bufferStarvationDelay ? 'rebuffering expected' : 'buffer is empty') + \", optimal quality level \" + bestLevel);\n      if (bestLevel > -1) {\n        return bestLevel;\n      }\n      // If no matching level found, see if min auto level would be a better option\n      var minLevel = hls.levels[minAutoLevel];\n      var autoLevel = hls.levels[hls.loadLevel];\n      if ((minLevel == null ? void 0 : minLevel.bitrate) < (autoLevel == null ? void 0 : autoLevel.bitrate)) {\n        return minAutoLevel;\n      }\n      // or if bitrate is not lower, continue to use loadLevel\n      return hls.loadLevel;\n    };\n    _proto.getStarvationDelay = function getStarvationDelay() {\n      var hls = this.hls;\n      var media = hls.media;\n      if (!media) {\n        return Infinity;\n      }\n      // playbackRate is the absolute value of the playback rate; if media.playbackRate is 0, we use 1 to load as\n      // if we're playing back at the normal rate.\n      var playbackRate = media && media.playbackRate !== 0 ? Math.abs(media.playbackRate) : 1.0;\n      var bufferInfo = hls.mainForwardBufferInfo;\n      return (bufferInfo ? bufferInfo.len : 0) / playbackRate;\n    };\n    _proto.getBwEstimate = function getBwEstimate() {\n      return this.bwEstimator.canEstimate() ? this.bwEstimator.getEstimate() : this.hls.config.abrEwmaDefaultEstimate;\n    };\n    _proto.findBestLevel = function findBestLevel(currentBw, minAutoLevel, maxAutoLevel, bufferStarvationDelay, maxStarvationDelay, bwFactor, bwUpFactor) {\n      var _level$details,\n        _this2 = this;\n      var maxFetchDuration = bufferStarvationDelay + maxStarvationDelay;\n      var lastLoadedFragLevel = this.lastLoadedFragLevel;\n      var selectionBaseLevel = lastLoadedFragLevel === -1 ? this.hls.firstLevel : lastLoadedFragLevel;\n      var fragCurrent = this.fragCurrent,\n        partCurrent = this.partCurrent;\n      var _this$hls = this.hls,\n        levels = _this$hls.levels,\n        allAudioTracks = _this$hls.allAudioTracks,\n        loadLevel = _this$hls.loadLevel,\n        config = _this$hls.config;\n      if (levels.length === 1) {\n        return 0;\n      }\n      var level = levels[selectionBaseLevel];\n      var live = !!(level != null && (_level$details = level.details) != null && _level$details.live);\n      var firstSelection = loadLevel === -1 || lastLoadedFragLevel === -1;\n      var currentCodecSet;\n      var currentVideoRange = 'SDR';\n      var currentFrameRate = (level == null ? void 0 : level.frameRate) || 0;\n      var audioPreference = config.audioPreference,\n        videoPreference = config.videoPreference;\n      var audioTracksByGroup = this.audioTracksByGroup || (this.audioTracksByGroup = getAudioTracksByGroup(allAudioTracks));\n      if (firstSelection) {\n        if (this.firstSelection !== -1) {\n          return this.firstSelection;\n        }\n        var codecTiers = this.codecTiers || (this.codecTiers = getCodecTiers(levels, audioTracksByGroup, minAutoLevel, maxAutoLevel));\n        var startTier = getStartCodecTier(codecTiers, currentVideoRange, currentBw, audioPreference, videoPreference);\n        var codecSet = startTier.codecSet,\n          videoRanges = startTier.videoRanges,\n          minFramerate = startTier.minFramerate,\n          minBitrate = startTier.minBitrate,\n          preferHDR = startTier.preferHDR;\n        currentCodecSet = codecSet;\n        currentVideoRange = preferHDR ? videoRanges[videoRanges.length - 1] : videoRanges[0];\n        currentFrameRate = minFramerate;\n        currentBw = Math.max(currentBw, minBitrate);\n        logger.log(\"[abr] picked start tier \" + JSON.stringify(startTier));\n      } else {\n        currentCodecSet = level == null ? void 0 : level.codecSet;\n        currentVideoRange = level == null ? void 0 : level.videoRange;\n      }\n      var currentFragDuration = partCurrent ? partCurrent.duration : fragCurrent ? fragCurrent.duration : 0;\n      var ttfbEstimateSec = this.bwEstimator.getEstimateTTFB() / 1000;\n      var levelsSkipped = [];\n      var _loop = function _loop() {\n          var _levelInfo$supportedR;\n          var levelInfo = levels[i];\n          var upSwitch = i > selectionBaseLevel;\n          if (!levelInfo) {\n            return 0; // continue\n          }\n          if (config.useMediaCapabilities && !levelInfo.supportedResult && !levelInfo.supportedPromise) {\n            var mediaCapabilities = navigator.mediaCapabilities;\n            if (typeof (mediaCapabilities == null ? void 0 : mediaCapabilities.decodingInfo) === 'function' && requiresMediaCapabilitiesDecodingInfo(levelInfo, audioTracksByGroup, currentVideoRange, currentFrameRate, currentBw, audioPreference)) {\n              levelInfo.supportedPromise = getMediaDecodingInfoPromise(levelInfo, audioTracksByGroup, mediaCapabilities);\n              levelInfo.supportedPromise.then(function (decodingInfo) {\n                if (!_this2.hls) {\n                  return;\n                }\n                levelInfo.supportedResult = decodingInfo;\n                var levels = _this2.hls.levels;\n                var index = levels.indexOf(levelInfo);\n                if (decodingInfo.error) {\n                  logger.warn(\"[abr] MediaCapabilities decodingInfo error: \\\"\" + decodingInfo.error + \"\\\" for level \" + index + \" \" + JSON.stringify(decodingInfo));\n                } else if (!decodingInfo.supported) {\n                  logger.warn(\"[abr] Unsupported MediaCapabilities decodingInfo result for level \" + index + \" \" + JSON.stringify(decodingInfo));\n                  if (index > -1 && levels.length > 1) {\n                    logger.log(\"[abr] Removing unsupported level \" + index);\n                    _this2.hls.removeLevel(index);\n                  }\n                }\n              });\n            } else {\n              levelInfo.supportedResult = SUPPORTED_INFO_DEFAULT;\n            }\n          }\n\n          // skip candidates which change codec-family or video-range,\n          // and which decrease or increase frame-rate for up and down-switch respectfully\n          if (currentCodecSet && levelInfo.codecSet !== currentCodecSet || currentVideoRange && levelInfo.videoRange !== currentVideoRange || upSwitch && currentFrameRate > levelInfo.frameRate || !upSwitch && currentFrameRate > 0 && currentFrameRate < levelInfo.frameRate || levelInfo.supportedResult && !((_levelInfo$supportedR = levelInfo.supportedResult.decodingInfoResults) != null && _levelInfo$supportedR[0].smooth)) {\n            levelsSkipped.push(i);\n            return 0; // continue\n          }\n          var levelDetails = levelInfo.details;\n          var avgDuration = (partCurrent ? levelDetails == null ? void 0 : levelDetails.partTarget : levelDetails == null ? void 0 : levelDetails.averagetargetduration) || currentFragDuration;\n          var adjustedbw;\n          // follow algorithm captured from stagefright :\n          // https://android.googlesource.com/platform/frameworks/av/+/master/media/libstagefright/httplive/LiveSession.cpp\n          // Pick the highest bandwidth stream below or equal to estimated bandwidth.\n          // consider only 80% of the available bandwidth, but if we are switching up,\n          // be even more conservative (70%) to avoid overestimating and immediately\n          // switching back.\n          if (!upSwitch) {\n            adjustedbw = bwFactor * currentBw;\n          } else {\n            adjustedbw = bwUpFactor * currentBw;\n          }\n\n          // Use average bitrate when starvation delay (buffer length) is gt or eq two segment durations and rebuffering is not expected (maxStarvationDelay > 0)\n          var bitrate = currentFragDuration && bufferStarvationDelay >= currentFragDuration * 2 && maxStarvationDelay === 0 ? levels[i].averageBitrate : levels[i].maxBitrate;\n          var fetchDuration = _this2.getTimeToLoadFrag(ttfbEstimateSec, adjustedbw, bitrate * avgDuration, levelDetails === undefined);\n          var canSwitchWithinTolerance =\n          // if adjusted bw is greater than level bitrate AND\n          adjustedbw >= bitrate && (\n          // no level change, or new level has no error history\n          i === lastLoadedFragLevel || levelInfo.loadError === 0 && levelInfo.fragmentError === 0) && (\n          // fragment fetchDuration unknown OR live stream OR fragment fetchDuration less than max allowed fetch duration, then this level matches\n          // we don't account for max Fetch Duration for live streams, this is to avoid switching down when near the edge of live sliding window ...\n          // special case to support startLevel = -1 (bitrateTest) on live streams : in that case we should not exit loop so that findBestLevel will return -1\n          fetchDuration <= ttfbEstimateSec || !isFiniteNumber(fetchDuration) || live && !_this2.bitrateTestDelay || fetchDuration < maxFetchDuration);\n          if (canSwitchWithinTolerance) {\n            var forcedAutoLevel = _this2.forcedAutoLevel;\n            if (i !== loadLevel && (forcedAutoLevel === -1 || forcedAutoLevel !== loadLevel)) {\n              if (levelsSkipped.length) {\n                logger.trace(\"[abr] Skipped level(s) \" + levelsSkipped.join(',') + \" of \" + maxAutoLevel + \" max with CODECS and VIDEO-RANGE:\\\"\" + levels[levelsSkipped[0]].codecs + \"\\\" \" + levels[levelsSkipped[0]].videoRange + \"; not compatible with \\\"\" + level.codecs + \"\\\" \" + currentVideoRange);\n              }\n              logger.info(\"[abr] switch candidate:\" + selectionBaseLevel + \"->\" + i + \" adjustedbw(\" + Math.round(adjustedbw) + \")-bitrate=\" + Math.round(adjustedbw - bitrate) + \" ttfb:\" + ttfbEstimateSec.toFixed(1) + \" avgDuration:\" + avgDuration.toFixed(1) + \" maxFetchDuration:\" + maxFetchDuration.toFixed(1) + \" fetchDuration:\" + fetchDuration.toFixed(1) + \" firstSelection:\" + firstSelection + \" codecSet:\" + currentCodecSet + \" videoRange:\" + currentVideoRange + \" hls.loadLevel:\" + loadLevel);\n            }\n            if (firstSelection) {\n              _this2.firstSelection = i;\n            }\n            // as we are looping from highest to lowest, this will return the best achievable quality level\n            return {\n              v: i\n            };\n          }\n        },\n        _ret;\n      for (var i = maxAutoLevel; i >= minAutoLevel; i--) {\n        _ret = _loop();\n        if (_ret === 0) continue;\n        if (_ret) return _ret.v;\n      }\n      // not enough time budget even with quality level 0 ... rebuffering might happen\n      return -1;\n    };\n    _createClass(AbrController, [{\n      key: \"firstAutoLevel\",\n      get: function get() {\n        var _this$hls2 = this.hls,\n          maxAutoLevel = _this$hls2.maxAutoLevel,\n          minAutoLevel = _this$hls2.minAutoLevel;\n        var bwEstimate = this.getBwEstimate();\n        var maxStartDelay = this.hls.config.maxStarvationDelay;\n        var abrAutoLevel = this.findBestLevel(bwEstimate, minAutoLevel, maxAutoLevel, 0, maxStartDelay, 1, 1);\n        if (abrAutoLevel > -1) {\n          return abrAutoLevel;\n        }\n        var firstLevel = this.hls.firstLevel;\n        var clamped = Math.min(Math.max(firstLevel, minAutoLevel), maxAutoLevel);\n        logger.warn(\"[abr] Could not find best starting auto level. Defaulting to first in playlist \" + firstLevel + \" clamped to \" + clamped);\n        return clamped;\n      }\n    }, {\n      key: \"forcedAutoLevel\",\n      get: function get() {\n        if (this.nextAutoLevelKey) {\n          return -1;\n        }\n        return this._nextAutoLevel;\n      }\n\n      // return next auto level\n    }, {\n      key: \"nextAutoLevel\",\n      get: function get() {\n        var forcedAutoLevel = this.forcedAutoLevel;\n        var bwEstimator = this.bwEstimator;\n        var useEstimate = bwEstimator.canEstimate();\n        var loadedFirstFrag = this.lastLoadedFragLevel > -1;\n        // in case next auto level has been forced, and bw not available or not reliable, return forced value\n        if (forcedAutoLevel !== -1 && (!useEstimate || !loadedFirstFrag || this.nextAutoLevelKey === this.getAutoLevelKey())) {\n          return forcedAutoLevel;\n        }\n\n        // compute next level using ABR logic\n        var nextABRAutoLevel = useEstimate && loadedFirstFrag ? this.getNextABRAutoLevel() : this.firstAutoLevel;\n\n        // use forced auto level while it hasn't errored more than ABR selection\n        if (forcedAutoLevel !== -1) {\n          var levels = this.hls.levels;\n          if (levels.length > Math.max(forcedAutoLevel, nextABRAutoLevel) && levels[forcedAutoLevel].loadError <= levels[nextABRAutoLevel].loadError) {\n            return forcedAutoLevel;\n          }\n        }\n\n        // save result until state has changed\n        this._nextAutoLevel = nextABRAutoLevel;\n        this.nextAutoLevelKey = this.getAutoLevelKey();\n        return nextABRAutoLevel;\n      },\n      set: function set(nextLevel) {\n        var _this$hls3 = this.hls,\n          maxAutoLevel = _this$hls3.maxAutoLevel,\n          minAutoLevel = _this$hls3.minAutoLevel;\n        var value = Math.min(Math.max(nextLevel, minAutoLevel), maxAutoLevel);\n        if (this._nextAutoLevel !== value) {\n          this.nextAutoLevelKey = '';\n          this._nextAutoLevel = value;\n        }\n      }\n    }]);\n    return AbrController;\n  }();\n\n  /**\n   * @ignore\n   * Sub-class specialization of EventHandler base class.\n   *\n   * TaskLoop allows to schedule a task function being called (optionnaly repeatedly) on the main loop,\n   * scheduled asynchroneously, avoiding recursive calls in the same tick.\n   *\n   * The task itself is implemented in `doTick`. It can be requested and called for single execution\n   * using the `tick` method.\n   *\n   * It will be assured that the task execution method (`tick`) only gets called once per main loop \"tick\",\n   * no matter how often it gets requested for execution. Execution in further ticks will be scheduled accordingly.\n   *\n   * If further execution requests have already been scheduled on the next tick, it can be checked with `hasNextTick`,\n   * and cancelled with `clearNextTick`.\n   *\n   * The task can be scheduled as an interval repeatedly with a period as parameter (see `setInterval`, `clearInterval`).\n   *\n   * Sub-classes need to implement the `doTick` method which will effectively have the task execution routine.\n   *\n   * Further explanations:\n   *\n   * The baseclass has a `tick` method that will schedule the doTick call. It may be called synchroneously\n   * only for a stack-depth of one. On re-entrant calls, sub-sequent calls are scheduled for next main loop ticks.\n   *\n   * When the task execution (`tick` method) is called in re-entrant way this is detected and\n   * we are limiting the task execution per call stack to exactly one, but scheduling/post-poning further\n   * task processing on the next main loop iteration (also known as \"next tick\" in the Node/JS runtime lingo).\n   */\n  var TaskLoop = /*#__PURE__*/function () {\n    function TaskLoop() {\n      this._boundTick = void 0;\n      this._tickTimer = null;\n      this._tickInterval = null;\n      this._tickCallCount = 0;\n      this._boundTick = this.tick.bind(this);\n    }\n    var _proto = TaskLoop.prototype;\n    _proto.destroy = function destroy() {\n      this.onHandlerDestroying();\n      this.onHandlerDestroyed();\n    };\n    _proto.onHandlerDestroying = function onHandlerDestroying() {\n      // clear all timers before unregistering from event bus\n      this.clearNextTick();\n      this.clearInterval();\n    };\n    _proto.onHandlerDestroyed = function onHandlerDestroyed() {};\n    _proto.hasInterval = function hasInterval() {\n      return !!this._tickInterval;\n    };\n    _proto.hasNextTick = function hasNextTick() {\n      return !!this._tickTimer;\n    }\n\n    /**\n     * @param millis - Interval time (ms)\n     * @eturns True when interval has been scheduled, false when already scheduled (no effect)\n     */;\n    _proto.setInterval = function setInterval(millis) {\n      if (!this._tickInterval) {\n        this._tickCallCount = 0;\n        this._tickInterval = self.setInterval(this._boundTick, millis);\n        return true;\n      }\n      return false;\n    }\n\n    /**\n     * @returns True when interval was cleared, false when none was set (no effect)\n     */;\n    _proto.clearInterval = function clearInterval() {\n      if (this._tickInterval) {\n        self.clearInterval(this._tickInterval);\n        this._tickInterval = null;\n        return true;\n      }\n      return false;\n    }\n\n    /**\n     * @returns True when timeout was cleared, false when none was set (no effect)\n     */;\n    _proto.clearNextTick = function clearNextTick() {\n      if (this._tickTimer) {\n        self.clearTimeout(this._tickTimer);\n        this._tickTimer = null;\n        return true;\n      }\n      return false;\n    }\n\n    /**\n     * Will call the subclass doTick implementation in this main loop tick\n     * or in the next one (via setTimeout(,0)) in case it has already been called\n     * in this tick (in case this is a re-entrant call).\n     */;\n    _proto.tick = function tick() {\n      this._tickCallCount++;\n      if (this._tickCallCount === 1) {\n        this.doTick();\n        // re-entrant call to tick from previous doTick call stack\n        // -> schedule a call on the next main loop iteration to process this task processing request\n        if (this._tickCallCount > 1) {\n          // make sure only one timer exists at any time at max\n          this.tickImmediate();\n        }\n        this._tickCallCount = 0;\n      }\n    };\n    _proto.tickImmediate = function tickImmediate() {\n      this.clearNextTick();\n      this._tickTimer = self.setTimeout(this._boundTick, 0);\n    }\n\n    /**\n     * For subclass to implement task logic\n     * @abstract\n     */;\n    _proto.doTick = function doTick() {};\n    return TaskLoop;\n  }();\n\n  var FragmentState = {\n    NOT_LOADED: \"NOT_LOADED\",\n    APPENDING: \"APPENDING\",\n    PARTIAL: \"PARTIAL\",\n    OK: \"OK\"\n  };\n  var FragmentTracker = /*#__PURE__*/function () {\n    function FragmentTracker(hls) {\n      this.activePartLists = Object.create(null);\n      this.endListFragments = Object.create(null);\n      this.fragments = Object.create(null);\n      this.timeRanges = Object.create(null);\n      this.bufferPadding = 0.2;\n      this.hls = void 0;\n      this.hasGaps = false;\n      this.hls = hls;\n      this._registerListeners();\n    }\n    var _proto = FragmentTracker.prototype;\n    _proto._registerListeners = function _registerListeners() {\n      var hls = this.hls;\n      hls.on(Events.BUFFER_APPENDED, this.onBufferAppended, this);\n      hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n      hls.on(Events.FRAG_LOADED, this.onFragLoaded, this);\n    };\n    _proto._unregisterListeners = function _unregisterListeners() {\n      var hls = this.hls;\n      hls.off(Events.BUFFER_APPENDED, this.onBufferAppended, this);\n      hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n      hls.off(Events.FRAG_LOADED, this.onFragLoaded, this);\n    };\n    _proto.destroy = function destroy() {\n      this._unregisterListeners();\n      // @ts-ignore\n      this.fragments =\n      // @ts-ignore\n      this.activePartLists =\n      // @ts-ignore\n      this.endListFragments = this.timeRanges = null;\n    }\n\n    /**\n     * Return a Fragment or Part with an appended range that matches the position and levelType\n     * Otherwise, return null\n     */;\n    _proto.getAppendedFrag = function getAppendedFrag(position, levelType) {\n      var activeParts = this.activePartLists[levelType];\n      if (activeParts) {\n        for (var i = activeParts.length; i--;) {\n          var activePart = activeParts[i];\n          if (!activePart) {\n            break;\n          }\n          var appendedPTS = activePart.end;\n          if (activePart.start <= position && appendedPTS !== null && position <= appendedPTS) {\n            return activePart;\n          }\n        }\n      }\n      return this.getBufferedFrag(position, levelType);\n    }\n\n    /**\n     * Return a buffered Fragment that matches the position and levelType.\n     * A buffered Fragment is one whose loading, parsing and appending is done (completed or \"partial\" meaning aborted).\n     * If not found any Fragment, return null\n     */;\n    _proto.getBufferedFrag = function getBufferedFrag(position, levelType) {\n      var fragments = this.fragments;\n      var keys = Object.keys(fragments);\n      for (var i = keys.length; i--;) {\n        var fragmentEntity = fragments[keys[i]];\n        if ((fragmentEntity == null ? void 0 : fragmentEntity.body.type) === levelType && fragmentEntity.buffered) {\n          var frag = fragmentEntity.body;\n          if (frag.start <= position && position <= frag.end) {\n            return frag;\n          }\n        }\n      }\n      return null;\n    }\n\n    /**\n     * Partial fragments effected by coded frame eviction will be removed\n     * The browser will unload parts of the buffer to free up memory for new buffer data\n     * Fragments will need to be reloaded when the buffer is freed up, removing partial fragments will allow them to reload(since there might be parts that are still playable)\n     */;\n    _proto.detectEvictedFragments = function detectEvictedFragments(elementaryStream, timeRange, playlistType, appendedPart) {\n      var _this = this;\n      if (this.timeRanges) {\n        this.timeRanges[elementaryStream] = timeRange;\n      }\n      // Check if any flagged fragments have been unloaded\n      // excluding anything newer than appendedPartSn\n      var appendedPartSn = (appendedPart == null ? void 0 : appendedPart.fragment.sn) || -1;\n      Object.keys(this.fragments).forEach(function (key) {\n        var fragmentEntity = _this.fragments[key];\n        if (!fragmentEntity) {\n          return;\n        }\n        if (appendedPartSn >= fragmentEntity.body.sn) {\n          return;\n        }\n        if (!fragmentEntity.buffered && !fragmentEntity.loaded) {\n          if (fragmentEntity.body.type === playlistType) {\n            _this.removeFragment(fragmentEntity.body);\n          }\n          return;\n        }\n        var esData = fragmentEntity.range[elementaryStream];\n        if (!esData) {\n          return;\n        }\n        esData.time.some(function (time) {\n          var isNotBuffered = !_this.isTimeBuffered(time.startPTS, time.endPTS, timeRange);\n          if (isNotBuffered) {\n            // Unregister partial fragment as it needs to load again to be reused\n            _this.removeFragment(fragmentEntity.body);\n          }\n          return isNotBuffered;\n        });\n      });\n    }\n\n    /**\n     * Checks if the fragment passed in is loaded in the buffer properly\n     * Partially loaded fragments will be registered as a partial fragment\n     */;\n    _proto.detectPartialFragments = function detectPartialFragments(data) {\n      var _this2 = this;\n      var timeRanges = this.timeRanges;\n      var frag = data.frag,\n        part = data.part;\n      if (!timeRanges || frag.sn === 'initSegment') {\n        return;\n      }\n      var fragKey = getFragmentKey(frag);\n      var fragmentEntity = this.fragments[fragKey];\n      if (!fragmentEntity || fragmentEntity.buffered && frag.gap) {\n        return;\n      }\n      var isFragHint = !frag.relurl;\n      Object.keys(timeRanges).forEach(function (elementaryStream) {\n        var streamInfo = frag.elementaryStreams[elementaryStream];\n        if (!streamInfo) {\n          return;\n        }\n        var timeRange = timeRanges[elementaryStream];\n        var partial = isFragHint || streamInfo.partial === true;\n        fragmentEntity.range[elementaryStream] = _this2.getBufferedTimes(frag, part, partial, timeRange);\n      });\n      fragmentEntity.loaded = null;\n      if (Object.keys(fragmentEntity.range).length) {\n        fragmentEntity.buffered = true;\n        var endList = fragmentEntity.body.endList = frag.endList || fragmentEntity.body.endList;\n        if (endList) {\n          this.endListFragments[fragmentEntity.body.type] = fragmentEntity;\n        }\n        if (!isPartial(fragmentEntity)) {\n          // Remove older fragment parts from lookup after frag is tracked as buffered\n          this.removeParts(frag.sn - 1, frag.type);\n        }\n      } else {\n        // remove fragment if nothing was appended\n        this.removeFragment(fragmentEntity.body);\n      }\n    };\n    _proto.removeParts = function removeParts(snToKeep, levelType) {\n      var activeParts = this.activePartLists[levelType];\n      if (!activeParts) {\n        return;\n      }\n      this.activePartLists[levelType] = activeParts.filter(function (part) {\n        return part.fragment.sn >= snToKeep;\n      });\n    };\n    _proto.fragBuffered = function fragBuffered(frag, force) {\n      var fragKey = getFragmentKey(frag);\n      var fragmentEntity = this.fragments[fragKey];\n      if (!fragmentEntity && force) {\n        fragmentEntity = this.fragments[fragKey] = {\n          body: frag,\n          appendedPTS: null,\n          loaded: null,\n          buffered: false,\n          range: Object.create(null)\n        };\n        if (frag.gap) {\n          this.hasGaps = true;\n        }\n      }\n      if (fragmentEntity) {\n        fragmentEntity.loaded = null;\n        fragmentEntity.buffered = true;\n      }\n    };\n    _proto.getBufferedTimes = function getBufferedTimes(fragment, part, partial, timeRange) {\n      var buffered = {\n        time: [],\n        partial: partial\n      };\n      var startPTS = fragment.start;\n      var endPTS = fragment.end;\n      var minEndPTS = fragment.minEndPTS || endPTS;\n      var maxStartPTS = fragment.maxStartPTS || startPTS;\n      for (var i = 0; i < timeRange.length; i++) {\n        var startTime = timeRange.start(i) - this.bufferPadding;\n        var endTime = timeRange.end(i) + this.bufferPadding;\n        if (maxStartPTS >= startTime && minEndPTS <= endTime) {\n          // Fragment is entirely contained in buffer\n          // No need to check the other timeRange times since it's completely playable\n          buffered.time.push({\n            startPTS: Math.max(startPTS, timeRange.start(i)),\n            endPTS: Math.min(endPTS, timeRange.end(i))\n          });\n          break;\n        } else if (startPTS < endTime && endPTS > startTime) {\n          var start = Math.max(startPTS, timeRange.start(i));\n          var end = Math.min(endPTS, timeRange.end(i));\n          if (end > start) {\n            buffered.partial = true;\n            // Check for intersection with buffer\n            // Get playable sections of the fragment\n            buffered.time.push({\n              startPTS: start,\n              endPTS: end\n            });\n          }\n        } else if (endPTS <= startTime) {\n          // No need to check the rest of the timeRange as it is in order\n          break;\n        }\n      }\n      return buffered;\n    }\n\n    /**\n     * Gets the partial fragment for a certain time\n     */;\n    _proto.getPartialFragment = function getPartialFragment(time) {\n      var bestFragment = null;\n      var timePadding;\n      var startTime;\n      var endTime;\n      var bestOverlap = 0;\n      var bufferPadding = this.bufferPadding,\n        fragments = this.fragments;\n      Object.keys(fragments).forEach(function (key) {\n        var fragmentEntity = fragments[key];\n        if (!fragmentEntity) {\n          return;\n        }\n        if (isPartial(fragmentEntity)) {\n          startTime = fragmentEntity.body.start - bufferPadding;\n          endTime = fragmentEntity.body.end + bufferPadding;\n          if (time >= startTime && time <= endTime) {\n            // Use the fragment that has the most padding from start and end time\n            timePadding = Math.min(time - startTime, endTime - time);\n            if (bestOverlap <= timePadding) {\n              bestFragment = fragmentEntity.body;\n              bestOverlap = timePadding;\n            }\n          }\n        }\n      });\n      return bestFragment;\n    };\n    _proto.isEndListAppended = function isEndListAppended(type) {\n      var lastFragmentEntity = this.endListFragments[type];\n      return lastFragmentEntity !== undefined && (lastFragmentEntity.buffered || isPartial(lastFragmentEntity));\n    };\n    _proto.getState = function getState(fragment) {\n      var fragKey = getFragmentKey(fragment);\n      var fragmentEntity = this.fragments[fragKey];\n      if (fragmentEntity) {\n        if (!fragmentEntity.buffered) {\n          return FragmentState.APPENDING;\n        } else if (isPartial(fragmentEntity)) {\n          return FragmentState.PARTIAL;\n        } else {\n          return FragmentState.OK;\n        }\n      }\n      return FragmentState.NOT_LOADED;\n    };\n    _proto.isTimeBuffered = function isTimeBuffered(startPTS, endPTS, timeRange) {\n      var startTime;\n      var endTime;\n      for (var i = 0; i < timeRange.length; i++) {\n        startTime = timeRange.start(i) - this.bufferPadding;\n        endTime = timeRange.end(i) + this.bufferPadding;\n        if (startPTS >= startTime && endPTS <= endTime) {\n          return true;\n        }\n        if (endPTS <= startTime) {\n          // No need to check the rest of the timeRange as it is in order\n          return false;\n        }\n      }\n      return false;\n    };\n    _proto.onFragLoaded = function onFragLoaded(event, data) {\n      var frag = data.frag,\n        part = data.part;\n      // don't track initsegment (for which sn is not a number)\n      // don't track frags used for bitrateTest, they're irrelevant.\n      if (frag.sn === 'initSegment' || frag.bitrateTest) {\n        return;\n      }\n\n      // Fragment entity `loaded` FragLoadedData is null when loading parts\n      var loaded = part ? null : data;\n      var fragKey = getFragmentKey(frag);\n      this.fragments[fragKey] = {\n        body: frag,\n        appendedPTS: null,\n        loaded: loaded,\n        buffered: false,\n        range: Object.create(null)\n      };\n    };\n    _proto.onBufferAppended = function onBufferAppended(event, data) {\n      var _this3 = this;\n      var frag = data.frag,\n        part = data.part,\n        timeRanges = data.timeRanges;\n      if (frag.sn === 'initSegment') {\n        return;\n      }\n      var playlistType = frag.type;\n      if (part) {\n        var activeParts = this.activePartLists[playlistType];\n        if (!activeParts) {\n          this.activePartLists[playlistType] = activeParts = [];\n        }\n        activeParts.push(part);\n      }\n      // Store the latest timeRanges loaded in the buffer\n      this.timeRanges = timeRanges;\n      Object.keys(timeRanges).forEach(function (elementaryStream) {\n        var timeRange = timeRanges[elementaryStream];\n        _this3.detectEvictedFragments(elementaryStream, timeRange, playlistType, part);\n      });\n    };\n    _proto.onFragBuffered = function onFragBuffered(event, data) {\n      this.detectPartialFragments(data);\n    };\n    _proto.hasFragment = function hasFragment(fragment) {\n      var fragKey = getFragmentKey(fragment);\n      return !!this.fragments[fragKey];\n    };\n    _proto.hasParts = function hasParts(type) {\n      var _this$activePartLists;\n      return !!((_this$activePartLists = this.activePartLists[type]) != null && _this$activePartLists.length);\n    };\n    _proto.removeFragmentsInRange = function removeFragmentsInRange(start, end, playlistType, withGapOnly, unbufferedOnly) {\n      var _this4 = this;\n      if (withGapOnly && !this.hasGaps) {\n        return;\n      }\n      Object.keys(this.fragments).forEach(function (key) {\n        var fragmentEntity = _this4.fragments[key];\n        if (!fragmentEntity) {\n          return;\n        }\n        var frag = fragmentEntity.body;\n        if (frag.type !== playlistType || withGapOnly && !frag.gap) {\n          return;\n        }\n        if (frag.start < end && frag.end > start && (fragmentEntity.buffered || unbufferedOnly)) {\n          _this4.removeFragment(frag);\n        }\n      });\n    };\n    _proto.removeFragment = function removeFragment(fragment) {\n      var fragKey = getFragmentKey(fragment);\n      fragment.stats.loaded = 0;\n      fragment.clearElementaryStreamInfo();\n      var activeParts = this.activePartLists[fragment.type];\n      if (activeParts) {\n        var snToRemove = fragment.sn;\n        this.activePartLists[fragment.type] = activeParts.filter(function (part) {\n          return part.fragment.sn !== snToRemove;\n        });\n      }\n      delete this.fragments[fragKey];\n      if (fragment.endList) {\n        delete this.endListFragments[fragment.type];\n      }\n    };\n    _proto.removeAllFragments = function removeAllFragments() {\n      this.fragments = Object.create(null);\n      this.endListFragments = Object.create(null);\n      this.activePartLists = Object.create(null);\n      this.hasGaps = false;\n    };\n    return FragmentTracker;\n  }();\n  function isPartial(fragmentEntity) {\n    var _fragmentEntity$range, _fragmentEntity$range2, _fragmentEntity$range3;\n    return fragmentEntity.buffered && (fragmentEntity.body.gap || ((_fragmentEntity$range = fragmentEntity.range.video) == null ? void 0 : _fragmentEntity$range.partial) || ((_fragmentEntity$range2 = fragmentEntity.range.audio) == null ? void 0 : _fragmentEntity$range2.partial) || ((_fragmentEntity$range3 = fragmentEntity.range.audiovideo) == null ? void 0 : _fragmentEntity$range3.partial));\n  }\n  function getFragmentKey(fragment) {\n    return fragment.type + \"_\" + fragment.level + \"_\" + fragment.sn;\n  }\n\n  /**\n   * Provides methods dealing with buffer length retrieval for example.\n   *\n   * In general, a helper around HTML5 MediaElement TimeRanges gathered from `buffered` property.\n   *\n   * Also @see https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/buffered\n   */\n\n  var noopBuffered = {\n    length: 0,\n    start: function start() {\n      return 0;\n    },\n    end: function end() {\n      return 0;\n    }\n  };\n  var BufferHelper = /*#__PURE__*/function () {\n    function BufferHelper() {}\n    /**\n     * Return true if `media`'s buffered include `position`\n     */\n    BufferHelper.isBuffered = function isBuffered(media, position) {\n      try {\n        if (media) {\n          var buffered = BufferHelper.getBuffered(media);\n          for (var i = 0; i < buffered.length; i++) {\n            if (position >= buffered.start(i) && position <= buffered.end(i)) {\n              return true;\n            }\n          }\n        }\n      } catch (error) {\n        // this is to catch\n        // InvalidStateError: Failed to read the 'buffered' property from 'SourceBuffer':\n        // This SourceBuffer has been removed from the parent media source\n      }\n      return false;\n    };\n    BufferHelper.bufferInfo = function bufferInfo(media, pos, maxHoleDuration) {\n      try {\n        if (media) {\n          var vbuffered = BufferHelper.getBuffered(media);\n          var buffered = [];\n          var i;\n          for (i = 0; i < vbuffered.length; i++) {\n            buffered.push({\n              start: vbuffered.start(i),\n              end: vbuffered.end(i)\n            });\n          }\n          return this.bufferedInfo(buffered, pos, maxHoleDuration);\n        }\n      } catch (error) {\n        // this is to catch\n        // InvalidStateError: Failed to read the 'buffered' property from 'SourceBuffer':\n        // This SourceBuffer has been removed from the parent media source\n      }\n      return {\n        len: 0,\n        start: pos,\n        end: pos,\n        nextStart: undefined\n      };\n    };\n    BufferHelper.bufferedInfo = function bufferedInfo(buffered, pos, maxHoleDuration) {\n      pos = Math.max(0, pos);\n      // sort on buffer.start/smaller end (IE does not always return sorted buffered range)\n      buffered.sort(function (a, b) {\n        var diff = a.start - b.start;\n        if (diff) {\n          return diff;\n        } else {\n          return b.end - a.end;\n        }\n      });\n      var buffered2 = [];\n      if (maxHoleDuration) {\n        // there might be some small holes between buffer time range\n        // consider that holes smaller than maxHoleDuration are irrelevant and build another\n        // buffer time range representations that discards those holes\n        for (var i = 0; i < buffered.length; i++) {\n          var buf2len = buffered2.length;\n          if (buf2len) {\n            var buf2end = buffered2[buf2len - 1].end;\n            // if small hole (value between 0 or maxHoleDuration ) or overlapping (negative)\n            if (buffered[i].start - buf2end < maxHoleDuration) {\n              // merge overlapping time ranges\n              // update lastRange.end only if smaller than item.end\n              // e.g.  [ 1, 15] with  [ 2,8] => [ 1,15] (no need to modify lastRange.end)\n              // whereas [ 1, 8] with  [ 2,15] => [ 1,15] ( lastRange should switch from [1,8] to [1,15])\n              if (buffered[i].end > buf2end) {\n                buffered2[buf2len - 1].end = buffered[i].end;\n              }\n            } else {\n              // big hole\n              buffered2.push(buffered[i]);\n            }\n          } else {\n            // first value\n            buffered2.push(buffered[i]);\n          }\n        }\n      } else {\n        buffered2 = buffered;\n      }\n      var bufferLen = 0;\n\n      // bufferStartNext can possibly be undefined based on the conditional logic below\n      var bufferStartNext;\n\n      // bufferStart and bufferEnd are buffer boundaries around current video position\n      var bufferStart = pos;\n      var bufferEnd = pos;\n      for (var _i = 0; _i < buffered2.length; _i++) {\n        var start = buffered2[_i].start;\n        var end = buffered2[_i].end;\n        // logger.log('buf start/end:' + buffered.start(i) + '/' + buffered.end(i));\n        if (pos + maxHoleDuration >= start && pos < end) {\n          // play position is inside this buffer TimeRange, retrieve end of buffer position and buffer length\n          bufferStart = start;\n          bufferEnd = end;\n          bufferLen = bufferEnd - pos;\n        } else if (pos + maxHoleDuration < start) {\n          bufferStartNext = start;\n          break;\n        }\n      }\n      return {\n        len: bufferLen,\n        start: bufferStart || 0,\n        end: bufferEnd || 0,\n        nextStart: bufferStartNext\n      };\n    }\n\n    /**\n     * Safe method to get buffered property.\n     * SourceBuffer.buffered may throw if SourceBuffer is removed from it's MediaSource\n     */;\n    BufferHelper.getBuffered = function getBuffered(media) {\n      try {\n        return media.buffered;\n      } catch (e) {\n        logger.log('failed to get media.buffered', e);\n        return noopBuffered;\n      }\n    };\n    return BufferHelper;\n  }();\n\n  var ChunkMetadata = function ChunkMetadata(level, sn, id, size, part, partial) {\n    if (size === void 0) {\n      size = 0;\n    }\n    if (part === void 0) {\n      part = -1;\n    }\n    if (partial === void 0) {\n      partial = false;\n    }\n    this.level = void 0;\n    this.sn = void 0;\n    this.part = void 0;\n    this.id = void 0;\n    this.size = void 0;\n    this.partial = void 0;\n    this.transmuxing = getNewPerformanceTiming();\n    this.buffering = {\n      audio: getNewPerformanceTiming(),\n      video: getNewPerformanceTiming(),\n      audiovideo: getNewPerformanceTiming()\n    };\n    this.level = level;\n    this.sn = sn;\n    this.id = id;\n    this.size = size;\n    this.part = part;\n    this.partial = partial;\n  };\n  function getNewPerformanceTiming() {\n    return {\n      start: 0,\n      executeStart: 0,\n      executeEnd: 0,\n      end: 0\n    };\n  }\n\n  function findFirstFragWithCC(fragments, cc) {\n    for (var i = 0, len = fragments.length; i < len; i++) {\n      var _fragments$i;\n      if (((_fragments$i = fragments[i]) == null ? void 0 : _fragments$i.cc) === cc) {\n        return fragments[i];\n      }\n    }\n    return null;\n  }\n  function shouldAlignOnDiscontinuities(lastFrag, switchDetails, details) {\n    if (switchDetails) {\n      if (details.endCC > details.startCC || lastFrag && lastFrag.cc < details.startCC) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  // Find the first frag in the previous level which matches the CC of the first frag of the new level\n  function findDiscontinuousReferenceFrag(prevDetails, curDetails) {\n    var prevFrags = prevDetails.fragments;\n    var curFrags = curDetails.fragments;\n    if (!curFrags.length || !prevFrags.length) {\n      logger.log('No fragments to align');\n      return;\n    }\n    var prevStartFrag = findFirstFragWithCC(prevFrags, curFrags[0].cc);\n    if (!prevStartFrag || prevStartFrag && !prevStartFrag.startPTS) {\n      logger.log('No frag in previous level to align on');\n      return;\n    }\n    return prevStartFrag;\n  }\n  function adjustFragmentStart(frag, sliding) {\n    if (frag) {\n      var start = frag.start + sliding;\n      frag.start = frag.startPTS = start;\n      frag.endPTS = start + frag.duration;\n    }\n  }\n  function adjustSlidingStart(sliding, details) {\n    // Update segments\n    var fragments = details.fragments;\n    for (var i = 0, len = fragments.length; i < len; i++) {\n      adjustFragmentStart(fragments[i], sliding);\n    }\n    // Update LL-HLS parts at the end of the playlist\n    if (details.fragmentHint) {\n      adjustFragmentStart(details.fragmentHint, sliding);\n    }\n    details.alignedSliding = true;\n  }\n\n  /**\n   * Using the parameters of the last level, this function computes PTS' of the new fragments so that they form a\n   * contiguous stream with the last fragments.\n   * The PTS of a fragment lets Hls.js know where it fits into a stream - by knowing every PTS, we know which fragment to\n   * download at any given time. PTS is normally computed when the fragment is demuxed, so taking this step saves us time\n   * and an extra download.\n   * @param lastFrag\n   * @param lastLevel\n   * @param details\n   */\n  function alignStream(lastFrag, switchDetails, details) {\n    if (!switchDetails) {\n      return;\n    }\n    alignDiscontinuities(lastFrag, details, switchDetails);\n    if (!details.alignedSliding && switchDetails) {\n      // If the PTS wasn't figured out via discontinuity sequence that means there was no CC increase within the level.\n      // Aligning via Program Date Time should therefore be reliable, since PDT should be the same within the same\n      // discontinuity sequence.\n      alignMediaPlaylistByPDT(details, switchDetails);\n    }\n    if (!details.alignedSliding && switchDetails && !details.skippedSegments) {\n      // Try to align on sn so that we pick a better start fragment.\n      // Do not perform this on playlists with delta updates as this is only to align levels on switch\n      // and adjustSliding only adjusts fragments after skippedSegments.\n      adjustSliding(switchDetails, details);\n    }\n  }\n\n  /**\n   * Computes the PTS if a new level's fragments using the PTS of a fragment in the last level which shares the same\n   * discontinuity sequence.\n   * @param lastFrag - The last Fragment which shares the same discontinuity sequence\n   * @param lastLevel - The details of the last loaded level\n   * @param details - The details of the new level\n   */\n  function alignDiscontinuities(lastFrag, details, switchDetails) {\n    if (shouldAlignOnDiscontinuities(lastFrag, switchDetails, details)) {\n      var referenceFrag = findDiscontinuousReferenceFrag(switchDetails, details);\n      if (referenceFrag && isFiniteNumber(referenceFrag.start)) {\n        logger.log(\"Adjusting PTS using last level due to CC increase within current level \" + details.url);\n        adjustSlidingStart(referenceFrag.start, details);\n      }\n    }\n  }\n\n  /**\n   * Ensures appropriate time-alignment between renditions based on PDT.\n   * This function assumes the timelines represented in `refDetails` are accurate, including the PDTs\n   * for the last discontinuity sequence number shared by both playlists when present,\n   * and uses the \"wallclock\"/PDT timeline as a cross-reference to `details`, adjusting the presentation\n   * times/timelines of `details` accordingly.\n   * Given the asynchronous nature of fetches and initial loads of live `main` and audio/subtitle tracks,\n   * the primary purpose of this function is to ensure the \"local timelines\" of audio/subtitle tracks\n   * are aligned to the main/video timeline, using PDT as the cross-reference/\"anchor\" that should\n   * be consistent across playlists, per the HLS spec.\n   * @param details - The details of the rendition you'd like to time-align (e.g. an audio rendition).\n   * @param refDetails - The details of the reference rendition with start and PDT times for alignment.\n   */\n  function alignMediaPlaylistByPDT(details, refDetails) {\n    if (!details.hasProgramDateTime || !refDetails.hasProgramDateTime) {\n      return;\n    }\n    var fragments = details.fragments;\n    var refFragments = refDetails.fragments;\n    if (!fragments.length || !refFragments.length) {\n      return;\n    }\n\n    // Calculate a delta to apply to all fragments according to the delta in PDT times and start times\n    // of a fragment in the reference details, and a fragment in the target details of the same discontinuity.\n    // If a fragment of the same discontinuity was not found use the middle fragment of both.\n    var refFrag;\n    var frag;\n    var targetCC = Math.min(refDetails.endCC, details.endCC);\n    if (refDetails.startCC < targetCC && details.startCC < targetCC) {\n      refFrag = findFirstFragWithCC(refFragments, targetCC);\n      frag = findFirstFragWithCC(fragments, targetCC);\n    }\n    if (!refFrag || !frag) {\n      refFrag = refFragments[Math.floor(refFragments.length / 2)];\n      frag = findFirstFragWithCC(fragments, refFrag.cc) || fragments[Math.floor(fragments.length / 2)];\n    }\n    var refPDT = refFrag.programDateTime;\n    var targetPDT = frag.programDateTime;\n    if (!refPDT || !targetPDT) {\n      return;\n    }\n    var delta = (targetPDT - refPDT) / 1000 - (frag.start - refFrag.start);\n    adjustSlidingStart(delta, details);\n  }\n\n  var MIN_CHUNK_SIZE = Math.pow(2, 17); // 128kb\n  var FragmentLoader = /*#__PURE__*/function () {\n    function FragmentLoader(config) {\n      this.config = void 0;\n      this.loader = null;\n      this.partLoadTimeout = -1;\n      this.config = config;\n    }\n    var _proto = FragmentLoader.prototype;\n    _proto.destroy = function destroy() {\n      if (this.loader) {\n        this.loader.destroy();\n        this.loader = null;\n      }\n    };\n    _proto.abort = function abort() {\n      if (this.loader) {\n        // Abort the loader for current fragment. Only one may load at any given time\n        this.loader.abort();\n      }\n    };\n    _proto.load = function load(frag, _onProgress) {\n      var _this = this;\n      var url = frag.url;\n      if (!url) {\n        return Promise.reject(new LoadError({\n          type: ErrorTypes.NETWORK_ERROR,\n          details: ErrorDetails.FRAG_LOAD_ERROR,\n          fatal: false,\n          frag: frag,\n          error: new Error(\"Fragment does not have a \" + (url ? 'part list' : 'url')),\n          networkDetails: null\n        }));\n      }\n      this.abort();\n      var config = this.config;\n      var FragmentILoader = config.fLoader;\n      var DefaultILoader = config.loader;\n      return new Promise(function (resolve, reject) {\n        if (_this.loader) {\n          _this.loader.destroy();\n        }\n        if (frag.gap) {\n          if (frag.tagList.some(function (tags) {\n            return tags[0] === 'GAP';\n          })) {\n            reject(createGapLoadError(frag));\n            return;\n          } else {\n            // Reset temporary treatment as GAP tag\n            frag.gap = false;\n          }\n        }\n        var loader = _this.loader = frag.loader = FragmentILoader ? new FragmentILoader(config) : new DefaultILoader(config);\n        var loaderContext = createLoaderContext(frag);\n        var loadPolicy = getLoaderConfigWithoutReties(config.fragLoadPolicy.default);\n        var loaderConfig = {\n          loadPolicy: loadPolicy,\n          timeout: loadPolicy.maxLoadTimeMs,\n          maxRetry: 0,\n          retryDelay: 0,\n          maxRetryDelay: 0,\n          highWaterMark: frag.sn === 'initSegment' ? Infinity : MIN_CHUNK_SIZE\n        };\n        // Assign frag stats to the loader's stats reference\n        frag.stats = loader.stats;\n        loader.load(loaderContext, loaderConfig, {\n          onSuccess: function onSuccess(response, stats, context, networkDetails) {\n            _this.resetLoader(frag, loader);\n            var payload = response.data;\n            if (context.resetIV && frag.decryptdata) {\n              frag.decryptdata.iv = new Uint8Array(payload.slice(0, 16));\n              payload = payload.slice(16);\n            }\n            resolve({\n              frag: frag,\n              part: null,\n              payload: payload,\n              networkDetails: networkDetails\n            });\n          },\n          onError: function onError(response, context, networkDetails, stats) {\n            _this.resetLoader(frag, loader);\n            reject(new LoadError({\n              type: ErrorTypes.NETWORK_ERROR,\n              details: ErrorDetails.FRAG_LOAD_ERROR,\n              fatal: false,\n              frag: frag,\n              response: _objectSpread2({\n                url: url,\n                data: undefined\n              }, response),\n              error: new Error(\"HTTP Error \" + response.code + \" \" + response.text),\n              networkDetails: networkDetails,\n              stats: stats\n            }));\n          },\n          onAbort: function onAbort(stats, context, networkDetails) {\n            _this.resetLoader(frag, loader);\n            reject(new LoadError({\n              type: ErrorTypes.NETWORK_ERROR,\n              details: ErrorDetails.INTERNAL_ABORTED,\n              fatal: false,\n              frag: frag,\n              error: new Error('Aborted'),\n              networkDetails: networkDetails,\n              stats: stats\n            }));\n          },\n          onTimeout: function onTimeout(stats, context, networkDetails) {\n            _this.resetLoader(frag, loader);\n            reject(new LoadError({\n              type: ErrorTypes.NETWORK_ERROR,\n              details: ErrorDetails.FRAG_LOAD_TIMEOUT,\n              fatal: false,\n              frag: frag,\n              error: new Error(\"Timeout after \" + loaderConfig.timeout + \"ms\"),\n              networkDetails: networkDetails,\n              stats: stats\n            }));\n          },\n          onProgress: function onProgress(stats, context, data, networkDetails) {\n            if (_onProgress) {\n              _onProgress({\n                frag: frag,\n                part: null,\n                payload: data,\n                networkDetails: networkDetails\n              });\n            }\n          }\n        });\n      });\n    };\n    _proto.loadPart = function loadPart(frag, part, onProgress) {\n      var _this2 = this;\n      this.abort();\n      var config = this.config;\n      var FragmentILoader = config.fLoader;\n      var DefaultILoader = config.loader;\n      return new Promise(function (resolve, reject) {\n        if (_this2.loader) {\n          _this2.loader.destroy();\n        }\n        if (frag.gap || part.gap) {\n          reject(createGapLoadError(frag, part));\n          return;\n        }\n        var loader = _this2.loader = frag.loader = FragmentILoader ? new FragmentILoader(config) : new DefaultILoader(config);\n        var loaderContext = createLoaderContext(frag, part);\n        // Should we define another load policy for parts?\n        var loadPolicy = getLoaderConfigWithoutReties(config.fragLoadPolicy.default);\n        var loaderConfig = {\n          loadPolicy: loadPolicy,\n          timeout: loadPolicy.maxLoadTimeMs,\n          maxRetry: 0,\n          retryDelay: 0,\n          maxRetryDelay: 0,\n          highWaterMark: MIN_CHUNK_SIZE\n        };\n        // Assign part stats to the loader's stats reference\n        part.stats = loader.stats;\n        loader.load(loaderContext, loaderConfig, {\n          onSuccess: function onSuccess(response, stats, context, networkDetails) {\n            _this2.resetLoader(frag, loader);\n            _this2.updateStatsFromPart(frag, part);\n            var partLoadedData = {\n              frag: frag,\n              part: part,\n              payload: response.data,\n              networkDetails: networkDetails\n            };\n            onProgress(partLoadedData);\n            resolve(partLoadedData);\n          },\n          onError: function onError(response, context, networkDetails, stats) {\n            _this2.resetLoader(frag, loader);\n            reject(new LoadError({\n              type: ErrorTypes.NETWORK_ERROR,\n              details: ErrorDetails.FRAG_LOAD_ERROR,\n              fatal: false,\n              frag: frag,\n              part: part,\n              response: _objectSpread2({\n                url: loaderContext.url,\n                data: undefined\n              }, response),\n              error: new Error(\"HTTP Error \" + response.code + \" \" + response.text),\n              networkDetails: networkDetails,\n              stats: stats\n            }));\n          },\n          onAbort: function onAbort(stats, context, networkDetails) {\n            frag.stats.aborted = part.stats.aborted;\n            _this2.resetLoader(frag, loader);\n            reject(new LoadError({\n              type: ErrorTypes.NETWORK_ERROR,\n              details: ErrorDetails.INTERNAL_ABORTED,\n              fatal: false,\n              frag: frag,\n              part: part,\n              error: new Error('Aborted'),\n              networkDetails: networkDetails,\n              stats: stats\n            }));\n          },\n          onTimeout: function onTimeout(stats, context, networkDetails) {\n            _this2.resetLoader(frag, loader);\n            reject(new LoadError({\n              type: ErrorTypes.NETWORK_ERROR,\n              details: ErrorDetails.FRAG_LOAD_TIMEOUT,\n              fatal: false,\n              frag: frag,\n              part: part,\n              error: new Error(\"Timeout after \" + loaderConfig.timeout + \"ms\"),\n              networkDetails: networkDetails,\n              stats: stats\n            }));\n          }\n        });\n      });\n    };\n    _proto.updateStatsFromPart = function updateStatsFromPart(frag, part) {\n      var fragStats = frag.stats;\n      var partStats = part.stats;\n      var partTotal = partStats.total;\n      fragStats.loaded += partStats.loaded;\n      if (partTotal) {\n        var estTotalParts = Math.round(frag.duration / part.duration);\n        var estLoadedParts = Math.min(Math.round(fragStats.loaded / partTotal), estTotalParts);\n        var estRemainingParts = estTotalParts - estLoadedParts;\n        var estRemainingBytes = estRemainingParts * Math.round(fragStats.loaded / estLoadedParts);\n        fragStats.total = fragStats.loaded + estRemainingBytes;\n      } else {\n        fragStats.total = Math.max(fragStats.loaded, fragStats.total);\n      }\n      var fragLoading = fragStats.loading;\n      var partLoading = partStats.loading;\n      if (fragLoading.start) {\n        // add to fragment loader latency\n        fragLoading.first += partLoading.first - partLoading.start;\n      } else {\n        fragLoading.start = partLoading.start;\n        fragLoading.first = partLoading.first;\n      }\n      fragLoading.end = partLoading.end;\n    };\n    _proto.resetLoader = function resetLoader(frag, loader) {\n      frag.loader = null;\n      if (this.loader === loader) {\n        self.clearTimeout(this.partLoadTimeout);\n        this.loader = null;\n      }\n      loader.destroy();\n    };\n    return FragmentLoader;\n  }();\n  function createLoaderContext(frag, part) {\n    if (part === void 0) {\n      part = null;\n    }\n    var segment = part || frag;\n    var loaderContext = {\n      frag: frag,\n      part: part,\n      responseType: 'arraybuffer',\n      url: segment.url,\n      headers: {},\n      rangeStart: 0,\n      rangeEnd: 0\n    };\n    var start = segment.byteRangeStartOffset;\n    var end = segment.byteRangeEndOffset;\n    if (isFiniteNumber(start) && isFiniteNumber(end)) {\n      var _frag$decryptdata;\n      var byteRangeStart = start;\n      var byteRangeEnd = end;\n      if (frag.sn === 'initSegment' && ((_frag$decryptdata = frag.decryptdata) == null ? void 0 : _frag$decryptdata.method) === 'AES-128') {\n        // MAP segment encrypted with method 'AES-128', when served with HTTP Range,\n        // has the unencrypted size specified in the range.\n        // Ref: https://tools.ietf.org/html/draft-pantos-hls-rfc8216bis-08#section-6.3.6\n        var fragmentLen = end - start;\n        if (fragmentLen % 16) {\n          byteRangeEnd = end + (16 - fragmentLen % 16);\n        }\n        if (start !== 0) {\n          loaderContext.resetIV = true;\n          byteRangeStart = start - 16;\n        }\n      }\n      loaderContext.rangeStart = byteRangeStart;\n      loaderContext.rangeEnd = byteRangeEnd;\n    }\n    return loaderContext;\n  }\n  function createGapLoadError(frag, part) {\n    var error = new Error(\"GAP \" + (frag.gap ? 'tag' : 'attribute') + \" found\");\n    var errorData = {\n      type: ErrorTypes.MEDIA_ERROR,\n      details: ErrorDetails.FRAG_GAP,\n      fatal: false,\n      frag: frag,\n      error: error,\n      networkDetails: null\n    };\n    if (part) {\n      errorData.part = part;\n    }\n    (part ? part : frag).stats.aborted = true;\n    return new LoadError(errorData);\n  }\n  var LoadError = /*#__PURE__*/function (_Error) {\n    _inheritsLoose(LoadError, _Error);\n    function LoadError(data) {\n      var _this3;\n      _this3 = _Error.call(this, data.error.message) || this;\n      _this3.data = void 0;\n      _this3.data = data;\n      return _this3;\n    }\n    return LoadError;\n  }( /*#__PURE__*/_wrapNativeSuper(Error));\n\n  var AESCrypto = /*#__PURE__*/function () {\n    function AESCrypto(subtle, iv) {\n      this.subtle = void 0;\n      this.aesIV = void 0;\n      this.subtle = subtle;\n      this.aesIV = iv;\n    }\n    var _proto = AESCrypto.prototype;\n    _proto.decrypt = function decrypt(data, key) {\n      return this.subtle.decrypt({\n        name: 'AES-CBC',\n        iv: this.aesIV\n      }, key, data);\n    };\n    return AESCrypto;\n  }();\n\n  var FastAESKey = /*#__PURE__*/function () {\n    function FastAESKey(subtle, key) {\n      this.subtle = void 0;\n      this.key = void 0;\n      this.subtle = subtle;\n      this.key = key;\n    }\n    var _proto = FastAESKey.prototype;\n    _proto.expandKey = function expandKey() {\n      return this.subtle.importKey('raw', this.key, {\n        name: 'AES-CBC'\n      }, false, ['encrypt', 'decrypt']);\n    };\n    return FastAESKey;\n  }();\n\n  // PKCS7\n  function removePadding(array) {\n    var outputBytes = array.byteLength;\n    var paddingBytes = outputBytes && new DataView(array.buffer).getUint8(outputBytes - 1);\n    if (paddingBytes) {\n      return sliceUint8(array, 0, outputBytes - paddingBytes);\n    }\n    return array;\n  }\n  var AESDecryptor = /*#__PURE__*/function () {\n    function AESDecryptor() {\n      this.rcon = [0x0, 0x1, 0x2, 0x4, 0x8, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36];\n      this.subMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];\n      this.invSubMix = [new Uint32Array(256), new Uint32Array(256), new Uint32Array(256), new Uint32Array(256)];\n      this.sBox = new Uint32Array(256);\n      this.invSBox = new Uint32Array(256);\n      this.key = new Uint32Array(0);\n      this.ksRows = 0;\n      this.keySize = 0;\n      this.keySchedule = void 0;\n      this.invKeySchedule = void 0;\n      this.initTable();\n    }\n\n    // Using view.getUint32() also swaps the byte order.\n    var _proto = AESDecryptor.prototype;\n    _proto.uint8ArrayToUint32Array_ = function uint8ArrayToUint32Array_(arrayBuffer) {\n      var view = new DataView(arrayBuffer);\n      var newArray = new Uint32Array(4);\n      for (var i = 0; i < 4; i++) {\n        newArray[i] = view.getUint32(i * 4);\n      }\n      return newArray;\n    };\n    _proto.initTable = function initTable() {\n      var sBox = this.sBox;\n      var invSBox = this.invSBox;\n      var subMix = this.subMix;\n      var subMix0 = subMix[0];\n      var subMix1 = subMix[1];\n      var subMix2 = subMix[2];\n      var subMix3 = subMix[3];\n      var invSubMix = this.invSubMix;\n      var invSubMix0 = invSubMix[0];\n      var invSubMix1 = invSubMix[1];\n      var invSubMix2 = invSubMix[2];\n      var invSubMix3 = invSubMix[3];\n      var d = new Uint32Array(256);\n      var x = 0;\n      var xi = 0;\n      var i = 0;\n      for (i = 0; i < 256; i++) {\n        if (i < 128) {\n          d[i] = i << 1;\n        } else {\n          d[i] = i << 1 ^ 0x11b;\n        }\n      }\n      for (i = 0; i < 256; i++) {\n        var sx = xi ^ xi << 1 ^ xi << 2 ^ xi << 3 ^ xi << 4;\n        sx = sx >>> 8 ^ sx & 0xff ^ 0x63;\n        sBox[x] = sx;\n        invSBox[sx] = x;\n\n        // Compute multiplication\n        var x2 = d[x];\n        var x4 = d[x2];\n        var x8 = d[x4];\n\n        // Compute sub/invSub bytes, mix columns tables\n        var t = d[sx] * 0x101 ^ sx * 0x1010100;\n        subMix0[x] = t << 24 | t >>> 8;\n        subMix1[x] = t << 16 | t >>> 16;\n        subMix2[x] = t << 8 | t >>> 24;\n        subMix3[x] = t;\n\n        // Compute inv sub bytes, inv mix columns tables\n        t = x8 * 0x1010101 ^ x4 * 0x10001 ^ x2 * 0x101 ^ x * 0x1010100;\n        invSubMix0[sx] = t << 24 | t >>> 8;\n        invSubMix1[sx] = t << 16 | t >>> 16;\n        invSubMix2[sx] = t << 8 | t >>> 24;\n        invSubMix3[sx] = t;\n\n        // Compute next counter\n        if (!x) {\n          x = xi = 1;\n        } else {\n          x = x2 ^ d[d[d[x8 ^ x2]]];\n          xi ^= d[d[xi]];\n        }\n      }\n    };\n    _proto.expandKey = function expandKey(keyBuffer) {\n      // convert keyBuffer to Uint32Array\n      var key = this.uint8ArrayToUint32Array_(keyBuffer);\n      var sameKey = true;\n      var offset = 0;\n      while (offset < key.length && sameKey) {\n        sameKey = key[offset] === this.key[offset];\n        offset++;\n      }\n      if (sameKey) {\n        return;\n      }\n      this.key = key;\n      var keySize = this.keySize = key.length;\n      if (keySize !== 4 && keySize !== 6 && keySize !== 8) {\n        throw new Error('Invalid aes key size=' + keySize);\n      }\n      var ksRows = this.ksRows = (keySize + 6 + 1) * 4;\n      var ksRow;\n      var invKsRow;\n      var keySchedule = this.keySchedule = new Uint32Array(ksRows);\n      var invKeySchedule = this.invKeySchedule = new Uint32Array(ksRows);\n      var sbox = this.sBox;\n      var rcon = this.rcon;\n      var invSubMix = this.invSubMix;\n      var invSubMix0 = invSubMix[0];\n      var invSubMix1 = invSubMix[1];\n      var invSubMix2 = invSubMix[2];\n      var invSubMix3 = invSubMix[3];\n      var prev;\n      var t;\n      for (ksRow = 0; ksRow < ksRows; ksRow++) {\n        if (ksRow < keySize) {\n          prev = keySchedule[ksRow] = key[ksRow];\n          continue;\n        }\n        t = prev;\n        if (ksRow % keySize === 0) {\n          // Rot word\n          t = t << 8 | t >>> 24;\n\n          // Sub word\n          t = sbox[t >>> 24] << 24 | sbox[t >>> 16 & 0xff] << 16 | sbox[t >>> 8 & 0xff] << 8 | sbox[t & 0xff];\n\n          // Mix Rcon\n          t ^= rcon[ksRow / keySize | 0] << 24;\n        } else if (keySize > 6 && ksRow % keySize === 4) {\n          // Sub word\n          t = sbox[t >>> 24] << 24 | sbox[t >>> 16 & 0xff] << 16 | sbox[t >>> 8 & 0xff] << 8 | sbox[t & 0xff];\n        }\n        keySchedule[ksRow] = prev = (keySchedule[ksRow - keySize] ^ t) >>> 0;\n      }\n      for (invKsRow = 0; invKsRow < ksRows; invKsRow++) {\n        ksRow = ksRows - invKsRow;\n        if (invKsRow & 3) {\n          t = keySchedule[ksRow];\n        } else {\n          t = keySchedule[ksRow - 4];\n        }\n        if (invKsRow < 4 || ksRow <= 4) {\n          invKeySchedule[invKsRow] = t;\n        } else {\n          invKeySchedule[invKsRow] = invSubMix0[sbox[t >>> 24]] ^ invSubMix1[sbox[t >>> 16 & 0xff]] ^ invSubMix2[sbox[t >>> 8 & 0xff]] ^ invSubMix3[sbox[t & 0xff]];\n        }\n        invKeySchedule[invKsRow] = invKeySchedule[invKsRow] >>> 0;\n      }\n    }\n\n    // Adding this as a method greatly improves performance.\n    ;\n    _proto.networkToHostOrderSwap = function networkToHostOrderSwap(word) {\n      return word << 24 | (word & 0xff00) << 8 | (word & 0xff0000) >> 8 | word >>> 24;\n    };\n    _proto.decrypt = function decrypt(inputArrayBuffer, offset, aesIV) {\n      var nRounds = this.keySize + 6;\n      var invKeySchedule = this.invKeySchedule;\n      var invSBOX = this.invSBox;\n      var invSubMix = this.invSubMix;\n      var invSubMix0 = invSubMix[0];\n      var invSubMix1 = invSubMix[1];\n      var invSubMix2 = invSubMix[2];\n      var invSubMix3 = invSubMix[3];\n      var initVector = this.uint8ArrayToUint32Array_(aesIV);\n      var initVector0 = initVector[0];\n      var initVector1 = initVector[1];\n      var initVector2 = initVector[2];\n      var initVector3 = initVector[3];\n      var inputInt32 = new Int32Array(inputArrayBuffer);\n      var outputInt32 = new Int32Array(inputInt32.length);\n      var t0, t1, t2, t3;\n      var s0, s1, s2, s3;\n      var inputWords0, inputWords1, inputWords2, inputWords3;\n      var ksRow, i;\n      var swapWord = this.networkToHostOrderSwap;\n      while (offset < inputInt32.length) {\n        inputWords0 = swapWord(inputInt32[offset]);\n        inputWords1 = swapWord(inputInt32[offset + 1]);\n        inputWords2 = swapWord(inputInt32[offset + 2]);\n        inputWords3 = swapWord(inputInt32[offset + 3]);\n        s0 = inputWords0 ^ invKeySchedule[0];\n        s1 = inputWords3 ^ invKeySchedule[1];\n        s2 = inputWords2 ^ invKeySchedule[2];\n        s3 = inputWords1 ^ invKeySchedule[3];\n        ksRow = 4;\n\n        // Iterate through the rounds of decryption\n        for (i = 1; i < nRounds; i++) {\n          t0 = invSubMix0[s0 >>> 24] ^ invSubMix1[s1 >> 16 & 0xff] ^ invSubMix2[s2 >> 8 & 0xff] ^ invSubMix3[s3 & 0xff] ^ invKeySchedule[ksRow];\n          t1 = invSubMix0[s1 >>> 24] ^ invSubMix1[s2 >> 16 & 0xff] ^ invSubMix2[s3 >> 8 & 0xff] ^ invSubMix3[s0 & 0xff] ^ invKeySchedule[ksRow + 1];\n          t2 = invSubMix0[s2 >>> 24] ^ invSubMix1[s3 >> 16 & 0xff] ^ invSubMix2[s0 >> 8 & 0xff] ^ invSubMix3[s1 & 0xff] ^ invKeySchedule[ksRow + 2];\n          t3 = invSubMix0[s3 >>> 24] ^ invSubMix1[s0 >> 16 & 0xff] ^ invSubMix2[s1 >> 8 & 0xff] ^ invSubMix3[s2 & 0xff] ^ invKeySchedule[ksRow + 3];\n          // Update state\n          s0 = t0;\n          s1 = t1;\n          s2 = t2;\n          s3 = t3;\n          ksRow = ksRow + 4;\n        }\n\n        // Shift rows, sub bytes, add round key\n        t0 = invSBOX[s0 >>> 24] << 24 ^ invSBOX[s1 >> 16 & 0xff] << 16 ^ invSBOX[s2 >> 8 & 0xff] << 8 ^ invSBOX[s3 & 0xff] ^ invKeySchedule[ksRow];\n        t1 = invSBOX[s1 >>> 24] << 24 ^ invSBOX[s2 >> 16 & 0xff] << 16 ^ invSBOX[s3 >> 8 & 0xff] << 8 ^ invSBOX[s0 & 0xff] ^ invKeySchedule[ksRow + 1];\n        t2 = invSBOX[s2 >>> 24] << 24 ^ invSBOX[s3 >> 16 & 0xff] << 16 ^ invSBOX[s0 >> 8 & 0xff] << 8 ^ invSBOX[s1 & 0xff] ^ invKeySchedule[ksRow + 2];\n        t3 = invSBOX[s3 >>> 24] << 24 ^ invSBOX[s0 >> 16 & 0xff] << 16 ^ invSBOX[s1 >> 8 & 0xff] << 8 ^ invSBOX[s2 & 0xff] ^ invKeySchedule[ksRow + 3];\n\n        // Write\n        outputInt32[offset] = swapWord(t0 ^ initVector0);\n        outputInt32[offset + 1] = swapWord(t3 ^ initVector1);\n        outputInt32[offset + 2] = swapWord(t2 ^ initVector2);\n        outputInt32[offset + 3] = swapWord(t1 ^ initVector3);\n\n        // reset initVector to last 4 unsigned int\n        initVector0 = inputWords0;\n        initVector1 = inputWords1;\n        initVector2 = inputWords2;\n        initVector3 = inputWords3;\n        offset = offset + 4;\n      }\n      return outputInt32.buffer;\n    };\n    return AESDecryptor;\n  }();\n\n  var CHUNK_SIZE = 16; // 16 bytes, 128 bits\n  var Decrypter = /*#__PURE__*/function () {\n    function Decrypter(config, _temp) {\n      var _ref = _temp === void 0 ? {} : _temp,\n        _ref$removePKCS7Paddi = _ref.removePKCS7Padding,\n        removePKCS7Padding = _ref$removePKCS7Paddi === void 0 ? true : _ref$removePKCS7Paddi;\n      this.logEnabled = true;\n      this.removePKCS7Padding = void 0;\n      this.subtle = null;\n      this.softwareDecrypter = null;\n      this.key = null;\n      this.fastAesKey = null;\n      this.remainderData = null;\n      this.currentIV = null;\n      this.currentResult = null;\n      this.useSoftware = void 0;\n      this.useSoftware = config.enableSoftwareAES;\n      this.removePKCS7Padding = removePKCS7Padding;\n      // built in decryptor expects PKCS7 padding\n      if (removePKCS7Padding) {\n        try {\n          var browserCrypto = self.crypto;\n          if (browserCrypto) {\n            this.subtle = browserCrypto.subtle || browserCrypto.webkitSubtle;\n          }\n        } catch (e) {\n          /* no-op */\n        }\n      }\n      this.useSoftware = !this.subtle;\n    }\n    var _proto = Decrypter.prototype;\n    _proto.destroy = function destroy() {\n      this.subtle = null;\n      this.softwareDecrypter = null;\n      this.key = null;\n      this.fastAesKey = null;\n      this.remainderData = null;\n      this.currentIV = null;\n      this.currentResult = null;\n    };\n    _proto.isSync = function isSync() {\n      return this.useSoftware;\n    };\n    _proto.flush = function flush() {\n      var currentResult = this.currentResult,\n        remainderData = this.remainderData;\n      if (!currentResult || remainderData) {\n        this.reset();\n        return null;\n      }\n      var data = new Uint8Array(currentResult);\n      this.reset();\n      if (this.removePKCS7Padding) {\n        return removePadding(data);\n      }\n      return data;\n    };\n    _proto.reset = function reset() {\n      this.currentResult = null;\n      this.currentIV = null;\n      this.remainderData = null;\n      if (this.softwareDecrypter) {\n        this.softwareDecrypter = null;\n      }\n    };\n    _proto.decrypt = function decrypt(data, key, iv) {\n      var _this = this;\n      if (this.useSoftware) {\n        return new Promise(function (resolve, reject) {\n          _this.softwareDecrypt(new Uint8Array(data), key, iv);\n          var decryptResult = _this.flush();\n          if (decryptResult) {\n            resolve(decryptResult.buffer);\n          } else {\n            reject(new Error('[softwareDecrypt] Failed to decrypt data'));\n          }\n        });\n      }\n      return this.webCryptoDecrypt(new Uint8Array(data), key, iv);\n    }\n\n    // Software decryption is progressive. Progressive decryption may not return a result on each call. Any cached\n    // data is handled in the flush() call\n    ;\n    _proto.softwareDecrypt = function softwareDecrypt(data, key, iv) {\n      var currentIV = this.currentIV,\n        currentResult = this.currentResult,\n        remainderData = this.remainderData;\n      this.logOnce('JS AES decrypt');\n      // The output is staggered during progressive parsing - the current result is cached, and emitted on the next call\n      // This is done in order to strip PKCS7 padding, which is found at the end of each segment. We only know we've reached\n      // the end on flush(), but by that time we have already received all bytes for the segment.\n      // Progressive decryption does not work with WebCrypto\n\n      if (remainderData) {\n        data = appendUint8Array(remainderData, data);\n        this.remainderData = null;\n      }\n\n      // Byte length must be a multiple of 16 (AES-128 = 128 bit blocks = 16 bytes)\n      var currentChunk = this.getValidChunk(data);\n      if (!currentChunk.length) {\n        return null;\n      }\n      if (currentIV) {\n        iv = currentIV;\n      }\n      var softwareDecrypter = this.softwareDecrypter;\n      if (!softwareDecrypter) {\n        softwareDecrypter = this.softwareDecrypter = new AESDecryptor();\n      }\n      softwareDecrypter.expandKey(key);\n      var result = currentResult;\n      this.currentResult = softwareDecrypter.decrypt(currentChunk.buffer, 0, iv);\n      this.currentIV = sliceUint8(currentChunk, -16).buffer;\n      if (!result) {\n        return null;\n      }\n      return result;\n    };\n    _proto.webCryptoDecrypt = function webCryptoDecrypt(data, key, iv) {\n      var _this2 = this;\n      if (this.key !== key || !this.fastAesKey) {\n        if (!this.subtle) {\n          return Promise.resolve(this.onWebCryptoError(data, key, iv));\n        }\n        this.key = key;\n        this.fastAesKey = new FastAESKey(this.subtle, key);\n      }\n      return this.fastAesKey.expandKey().then(function (aesKey) {\n        // decrypt using web crypto\n        if (!_this2.subtle) {\n          return Promise.reject(new Error('web crypto not initialized'));\n        }\n        _this2.logOnce('WebCrypto AES decrypt');\n        var crypto = new AESCrypto(_this2.subtle, new Uint8Array(iv));\n        return crypto.decrypt(data.buffer, aesKey);\n      }).catch(function (err) {\n        logger.warn(\"[decrypter]: WebCrypto Error, disable WebCrypto API, \" + err.name + \": \" + err.message);\n        return _this2.onWebCryptoError(data, key, iv);\n      });\n    };\n    _proto.onWebCryptoError = function onWebCryptoError(data, key, iv) {\n      this.useSoftware = true;\n      this.logEnabled = true;\n      this.softwareDecrypt(data, key, iv);\n      var decryptResult = this.flush();\n      if (decryptResult) {\n        return decryptResult.buffer;\n      }\n      throw new Error('WebCrypto and softwareDecrypt: failed to decrypt data');\n    };\n    _proto.getValidChunk = function getValidChunk(data) {\n      var currentChunk = data;\n      var splitPoint = data.length - data.length % CHUNK_SIZE;\n      if (splitPoint !== data.length) {\n        currentChunk = sliceUint8(data, 0, splitPoint);\n        this.remainderData = sliceUint8(data, splitPoint);\n      }\n      return currentChunk;\n    };\n    _proto.logOnce = function logOnce(msg) {\n      if (!this.logEnabled) {\n        return;\n      }\n      logger.log(\"[decrypter]: \" + msg);\n      this.logEnabled = false;\n    };\n    return Decrypter;\n  }();\n\n  /**\n   *  TimeRanges to string helper\n   */\n\n  var TimeRanges = {\n    toString: function toString(r) {\n      var log = '';\n      var len = r.length;\n      for (var i = 0; i < len; i++) {\n        log += \"[\" + r.start(i).toFixed(3) + \"-\" + r.end(i).toFixed(3) + \"]\";\n      }\n      return log;\n    }\n  };\n\n  var State = {\n    STOPPED: 'STOPPED',\n    IDLE: 'IDLE',\n    KEY_LOADING: 'KEY_LOADING',\n    FRAG_LOADING: 'FRAG_LOADING',\n    FRAG_LOADING_WAITING_RETRY: 'FRAG_LOADING_WAITING_RETRY',\n    WAITING_TRACK: 'WAITING_TRACK',\n    PARSING: 'PARSING',\n    PARSED: 'PARSED',\n    ENDED: 'ENDED',\n    ERROR: 'ERROR',\n    WAITING_INIT_PTS: 'WAITING_INIT_PTS',\n    WAITING_LEVEL: 'WAITING_LEVEL'\n  };\n  var BaseStreamController = /*#__PURE__*/function (_TaskLoop) {\n    _inheritsLoose(BaseStreamController, _TaskLoop);\n    function BaseStreamController(hls, fragmentTracker, keyLoader, logPrefix, playlistType) {\n      var _this;\n      _this = _TaskLoop.call(this) || this;\n      _this.hls = void 0;\n      _this.fragPrevious = null;\n      _this.fragCurrent = null;\n      _this.fragmentTracker = void 0;\n      _this.transmuxer = null;\n      _this._state = State.STOPPED;\n      _this.playlistType = void 0;\n      _this.media = null;\n      _this.mediaBuffer = null;\n      _this.config = void 0;\n      _this.bitrateTest = false;\n      _this.lastCurrentTime = 0;\n      _this.nextLoadPosition = 0;\n      _this.startPosition = 0;\n      _this.startTimeOffset = null;\n      _this.loadedmetadata = false;\n      _this.retryDate = 0;\n      _this.levels = null;\n      _this.fragmentLoader = void 0;\n      _this.keyLoader = void 0;\n      _this.levelLastLoaded = null;\n      _this.startFragRequested = false;\n      _this.decrypter = void 0;\n      _this.initPTS = [];\n      _this.onvseeking = null;\n      _this.onvended = null;\n      _this.logPrefix = '';\n      _this.log = void 0;\n      _this.warn = void 0;\n      _this.playlistType = playlistType;\n      _this.logPrefix = logPrefix;\n      _this.log = logger.log.bind(logger, logPrefix + \":\");\n      _this.warn = logger.warn.bind(logger, logPrefix + \":\");\n      _this.hls = hls;\n      _this.fragmentLoader = new FragmentLoader(hls.config);\n      _this.keyLoader = keyLoader;\n      _this.fragmentTracker = fragmentTracker;\n      _this.config = hls.config;\n      _this.decrypter = new Decrypter(hls.config);\n      hls.on(Events.MANIFEST_LOADED, _this.onManifestLoaded, _assertThisInitialized(_this));\n      return _this;\n    }\n    var _proto = BaseStreamController.prototype;\n    _proto.doTick = function doTick() {\n      this.onTickEnd();\n    };\n    _proto.onTickEnd = function onTickEnd() {}\n\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    ;\n    _proto.startLoad = function startLoad(startPosition) {};\n    _proto.stopLoad = function stopLoad() {\n      this.fragmentLoader.abort();\n      this.keyLoader.abort(this.playlistType);\n      var frag = this.fragCurrent;\n      if (frag != null && frag.loader) {\n        frag.abortRequests();\n        this.fragmentTracker.removeFragment(frag);\n      }\n      this.resetTransmuxer();\n      this.fragCurrent = null;\n      this.fragPrevious = null;\n      this.clearInterval();\n      this.clearNextTick();\n      this.state = State.STOPPED;\n    };\n    _proto._streamEnded = function _streamEnded(bufferInfo, levelDetails) {\n      // If playlist is live, there is another buffered range after the current range, nothing buffered, media is detached,\n      // of nothing loading/loaded return false\n      if (levelDetails.live || bufferInfo.nextStart || !bufferInfo.end || !this.media) {\n        return false;\n      }\n      var partList = levelDetails.partList;\n      // Since the last part isn't guaranteed to correspond to the last playlist segment for Low-Latency HLS,\n      // check instead if the last part is buffered.\n      if (partList != null && partList.length) {\n        var lastPart = partList[partList.length - 1];\n\n        // Checking the midpoint of the part for potential margin of error and related issues.\n        // NOTE: Technically I believe parts could yield content that is < the computed duration (including potential a duration of 0)\n        // and still be spec-compliant, so there may still be edge cases here. Likewise, there could be issues in end of stream\n        // part mismatches for independent audio and video playlists/segments.\n        var lastPartBuffered = BufferHelper.isBuffered(this.media, lastPart.start + lastPart.duration / 2);\n        return lastPartBuffered;\n      }\n      var playlistType = levelDetails.fragments[levelDetails.fragments.length - 1].type;\n      return this.fragmentTracker.isEndListAppended(playlistType);\n    };\n    _proto.getLevelDetails = function getLevelDetails() {\n      if (this.levels && this.levelLastLoaded !== null) {\n        var _this$levelLastLoaded;\n        return (_this$levelLastLoaded = this.levelLastLoaded) == null ? void 0 : _this$levelLastLoaded.details;\n      }\n    };\n    _proto.onMediaAttached = function onMediaAttached(event, data) {\n      var media = this.media = this.mediaBuffer = data.media;\n      this.onvseeking = this.onMediaSeeking.bind(this);\n      this.onvended = this.onMediaEnded.bind(this);\n      media.addEventListener('seeking', this.onvseeking);\n      media.addEventListener('ended', this.onvended);\n      var config = this.config;\n      if (this.levels && config.autoStartLoad && this.state === State.STOPPED) {\n        this.startLoad(config.startPosition);\n      }\n    };\n    _proto.onMediaDetaching = function onMediaDetaching() {\n      var media = this.media;\n      if (media != null && media.ended) {\n        this.log('MSE detaching and video ended, reset startPosition');\n        this.startPosition = this.lastCurrentTime = 0;\n      }\n\n      // remove video listeners\n      if (media && this.onvseeking && this.onvended) {\n        media.removeEventListener('seeking', this.onvseeking);\n        media.removeEventListener('ended', this.onvended);\n        this.onvseeking = this.onvended = null;\n      }\n      if (this.keyLoader) {\n        this.keyLoader.detach();\n      }\n      this.media = this.mediaBuffer = null;\n      this.loadedmetadata = false;\n      this.fragmentTracker.removeAllFragments();\n      this.stopLoad();\n    };\n    _proto.onMediaSeeking = function onMediaSeeking() {\n      var config = this.config,\n        fragCurrent = this.fragCurrent,\n        media = this.media,\n        mediaBuffer = this.mediaBuffer,\n        state = this.state;\n      var currentTime = media ? media.currentTime : 0;\n      var bufferInfo = BufferHelper.bufferInfo(mediaBuffer ? mediaBuffer : media, currentTime, config.maxBufferHole);\n      this.log(\"media seeking to \" + (isFiniteNumber(currentTime) ? currentTime.toFixed(3) : currentTime) + \", state: \" + state);\n      if (this.state === State.ENDED) {\n        this.resetLoadingState();\n      } else if (fragCurrent) {\n        // Seeking while frag load is in progress\n        var tolerance = config.maxFragLookUpTolerance;\n        var fragStartOffset = fragCurrent.start - tolerance;\n        var fragEndOffset = fragCurrent.start + fragCurrent.duration + tolerance;\n        // if seeking out of buffered range or into new one\n        if (!bufferInfo.len || fragEndOffset < bufferInfo.start || fragStartOffset > bufferInfo.end) {\n          var pastFragment = currentTime > fragEndOffset;\n          // if the seek position is outside the current fragment range\n          if (currentTime < fragStartOffset || pastFragment) {\n            if (pastFragment && fragCurrent.loader) {\n              this.log('seeking outside of buffer while fragment load in progress, cancel fragment load');\n              fragCurrent.abortRequests();\n              this.resetLoadingState();\n            }\n            this.fragPrevious = null;\n          }\n        }\n      }\n      if (media) {\n        // Remove gap fragments\n        this.fragmentTracker.removeFragmentsInRange(currentTime, Infinity, this.playlistType, true);\n        this.lastCurrentTime = currentTime;\n      }\n\n      // in case seeking occurs although no media buffered, adjust startPosition and nextLoadPosition to seek target\n      if (!this.loadedmetadata && !bufferInfo.len) {\n        this.nextLoadPosition = this.startPosition = currentTime;\n      }\n\n      // Async tick to speed up processing\n      this.tickImmediate();\n    };\n    _proto.onMediaEnded = function onMediaEnded() {\n      // reset startPosition and lastCurrentTime to restart playback @ stream beginning\n      this.startPosition = this.lastCurrentTime = 0;\n    };\n    _proto.onManifestLoaded = function onManifestLoaded(event, data) {\n      this.startTimeOffset = data.startTimeOffset;\n      this.initPTS = [];\n    };\n    _proto.onHandlerDestroying = function onHandlerDestroying() {\n      this.hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n      this.stopLoad();\n      _TaskLoop.prototype.onHandlerDestroying.call(this);\n      // @ts-ignore\n      this.hls = null;\n    };\n    _proto.onHandlerDestroyed = function onHandlerDestroyed() {\n      this.state = State.STOPPED;\n      if (this.fragmentLoader) {\n        this.fragmentLoader.destroy();\n      }\n      if (this.keyLoader) {\n        this.keyLoader.destroy();\n      }\n      if (this.decrypter) {\n        this.decrypter.destroy();\n      }\n      this.hls = this.log = this.warn = this.decrypter = this.keyLoader = this.fragmentLoader = this.fragmentTracker = null;\n      _TaskLoop.prototype.onHandlerDestroyed.call(this);\n    };\n    _proto.loadFragment = function loadFragment(frag, level, targetBufferTime) {\n      this._loadFragForPlayback(frag, level, targetBufferTime);\n    };\n    _proto._loadFragForPlayback = function _loadFragForPlayback(frag, level, targetBufferTime) {\n      var _this2 = this;\n      var progressCallback = function progressCallback(data) {\n        if (_this2.fragContextChanged(frag)) {\n          _this2.warn(\"Fragment \" + frag.sn + (data.part ? ' p: ' + data.part.index : '') + \" of level \" + frag.level + \" was dropped during download.\");\n          _this2.fragmentTracker.removeFragment(frag);\n          return;\n        }\n        frag.stats.chunkCount++;\n        _this2._handleFragmentLoadProgress(data);\n      };\n      this._doFragLoad(frag, level, targetBufferTime, progressCallback).then(function (data) {\n        if (!data) {\n          // if we're here we probably needed to backtrack or are waiting for more parts\n          return;\n        }\n        var state = _this2.state;\n        if (_this2.fragContextChanged(frag)) {\n          if (state === State.FRAG_LOADING || !_this2.fragCurrent && state === State.PARSING) {\n            _this2.fragmentTracker.removeFragment(frag);\n            _this2.state = State.IDLE;\n          }\n          return;\n        }\n        if ('payload' in data) {\n          _this2.log(\"Loaded fragment \" + frag.sn + \" of level \" + frag.level);\n          _this2.hls.trigger(Events.FRAG_LOADED, data);\n        }\n\n        // Pass through the whole payload; controllers not implementing progressive loading receive data from this callback\n        _this2._handleFragmentLoadComplete(data);\n      }).catch(function (reason) {\n        if (_this2.state === State.STOPPED || _this2.state === State.ERROR) {\n          return;\n        }\n        _this2.warn(\"Frag error: \" + ((reason == null ? void 0 : reason.message) || reason));\n        _this2.resetFragmentLoading(frag);\n      });\n    };\n    _proto.clearTrackerIfNeeded = function clearTrackerIfNeeded(frag) {\n      var _this$mediaBuffer;\n      var fragmentTracker = this.fragmentTracker;\n      var fragState = fragmentTracker.getState(frag);\n      if (fragState === FragmentState.APPENDING) {\n        // Lower the max buffer length and try again\n        var playlistType = frag.type;\n        var bufferedInfo = this.getFwdBufferInfo(this.mediaBuffer, playlistType);\n        var minForwardBufferLength = Math.max(frag.duration, bufferedInfo ? bufferedInfo.len : this.config.maxBufferLength);\n        // If backtracking, always remove from the tracker without reducing max buffer length\n        var backtrackFragment = this.backtrackFragment;\n        var backtracked = backtrackFragment ? frag.sn - backtrackFragment.sn : 0;\n        if (backtracked === 1 || this.reduceMaxBufferLength(minForwardBufferLength, frag.duration)) {\n          fragmentTracker.removeFragment(frag);\n        }\n      } else if (((_this$mediaBuffer = this.mediaBuffer) == null ? void 0 : _this$mediaBuffer.buffered.length) === 0) {\n        // Stop gap for bad tracker / buffer flush behavior\n        fragmentTracker.removeAllFragments();\n      } else if (fragmentTracker.hasParts(frag.type)) {\n        // In low latency mode, remove fragments for which only some parts were buffered\n        fragmentTracker.detectPartialFragments({\n          frag: frag,\n          part: null,\n          stats: frag.stats,\n          id: frag.type\n        });\n        if (fragmentTracker.getState(frag) === FragmentState.PARTIAL) {\n          fragmentTracker.removeFragment(frag);\n        }\n      }\n    };\n    _proto.checkLiveUpdate = function checkLiveUpdate(details) {\n      if (details.updated && !details.live) {\n        // Live stream ended, update fragment tracker\n        var lastFragment = details.fragments[details.fragments.length - 1];\n        this.fragmentTracker.detectPartialFragments({\n          frag: lastFragment,\n          part: null,\n          stats: lastFragment.stats,\n          id: lastFragment.type\n        });\n      }\n      if (!details.fragments[0]) {\n        details.deltaUpdateFailed = true;\n      }\n    };\n    _proto.flushMainBuffer = function flushMainBuffer(startOffset, endOffset, type) {\n      if (type === void 0) {\n        type = null;\n      }\n      if (!(startOffset - endOffset)) {\n        return;\n      }\n      // When alternate audio is playing, the audio-stream-controller is responsible for the audio buffer. Otherwise,\n      // passing a null type flushes both buffers\n      var flushScope = {\n        startOffset: startOffset,\n        endOffset: endOffset,\n        type: type\n      };\n      this.hls.trigger(Events.BUFFER_FLUSHING, flushScope);\n    };\n    _proto._loadInitSegment = function _loadInitSegment(frag, level) {\n      var _this3 = this;\n      this._doFragLoad(frag, level).then(function (data) {\n        if (!data || _this3.fragContextChanged(frag) || !_this3.levels) {\n          throw new Error('init load aborted');\n        }\n        return data;\n      }).then(function (data) {\n        var hls = _this3.hls;\n        var payload = data.payload;\n        var decryptData = frag.decryptdata;\n\n        // check to see if the payload needs to be decrypted\n        if (payload && payload.byteLength > 0 && decryptData != null && decryptData.key && decryptData.iv && decryptData.method === 'AES-128') {\n          var startTime = self.performance.now();\n          // decrypt init segment data\n          return _this3.decrypter.decrypt(new Uint8Array(payload), decryptData.key.buffer, decryptData.iv.buffer).catch(function (err) {\n            hls.trigger(Events.ERROR, {\n              type: ErrorTypes.MEDIA_ERROR,\n              details: ErrorDetails.FRAG_DECRYPT_ERROR,\n              fatal: false,\n              error: err,\n              reason: err.message,\n              frag: frag\n            });\n            throw err;\n          }).then(function (decryptedData) {\n            var endTime = self.performance.now();\n            hls.trigger(Events.FRAG_DECRYPTED, {\n              frag: frag,\n              payload: decryptedData,\n              stats: {\n                tstart: startTime,\n                tdecrypt: endTime\n              }\n            });\n            data.payload = decryptedData;\n            return _this3.completeInitSegmentLoad(data);\n          });\n        }\n        return _this3.completeInitSegmentLoad(data);\n      }).catch(function (reason) {\n        if (_this3.state === State.STOPPED || _this3.state === State.ERROR) {\n          return;\n        }\n        _this3.warn(reason);\n        _this3.resetFragmentLoading(frag);\n      });\n    };\n    _proto.completeInitSegmentLoad = function completeInitSegmentLoad(data) {\n      var levels = this.levels;\n      if (!levels) {\n        throw new Error('init load aborted, missing levels');\n      }\n      var stats = data.frag.stats;\n      this.state = State.IDLE;\n      data.frag.data = new Uint8Array(data.payload);\n      stats.parsing.start = stats.buffering.start = self.performance.now();\n      stats.parsing.end = stats.buffering.end = self.performance.now();\n      this.tick();\n    };\n    _proto.fragContextChanged = function fragContextChanged(frag) {\n      var fragCurrent = this.fragCurrent;\n      return !frag || !fragCurrent || frag.sn !== fragCurrent.sn || frag.level !== fragCurrent.level;\n    };\n    _proto.fragBufferedComplete = function fragBufferedComplete(frag, part) {\n      var _frag$startPTS, _frag$endPTS, _this$fragCurrent, _this$fragPrevious;\n      var media = this.mediaBuffer ? this.mediaBuffer : this.media;\n      this.log(\"Buffered \" + frag.type + \" sn: \" + frag.sn + (part ? ' part: ' + part.index : '') + \" of \" + (this.playlistType === PlaylistLevelType.MAIN ? 'level' : 'track') + \" \" + frag.level + \" (frag:[\" + ((_frag$startPTS = frag.startPTS) != null ? _frag$startPTS : NaN).toFixed(3) + \"-\" + ((_frag$endPTS = frag.endPTS) != null ? _frag$endPTS : NaN).toFixed(3) + \"] > buffer:\" + (media ? TimeRanges.toString(BufferHelper.getBuffered(media)) : '(detached)') + \")\");\n      if (frag.sn !== 'initSegment') {\n        var _this$levels;\n        if (frag.type !== PlaylistLevelType.SUBTITLE) {\n          var el = frag.elementaryStreams;\n          if (!Object.keys(el).some(function (type) {\n            return !!el[type];\n          })) {\n            // empty segment\n            this.state = State.IDLE;\n            return;\n          }\n        }\n        var level = (_this$levels = this.levels) == null ? void 0 : _this$levels[frag.level];\n        if (level != null && level.fragmentError) {\n          this.log(\"Resetting level fragment error count of \" + level.fragmentError + \" on frag buffered\");\n          level.fragmentError = 0;\n        }\n      }\n      this.state = State.IDLE;\n      if (!media) {\n        return;\n      }\n      if (!this.loadedmetadata && frag.type == PlaylistLevelType.MAIN && media.buffered.length && ((_this$fragCurrent = this.fragCurrent) == null ? void 0 : _this$fragCurrent.sn) === ((_this$fragPrevious = this.fragPrevious) == null ? void 0 : _this$fragPrevious.sn)) {\n        this.loadedmetadata = true;\n        this.seekToStartPos();\n      }\n      this.tick();\n    };\n    _proto.seekToStartPos = function seekToStartPos() {};\n    _proto._handleFragmentLoadComplete = function _handleFragmentLoadComplete(fragLoadedEndData) {\n      var transmuxer = this.transmuxer;\n      if (!transmuxer) {\n        return;\n      }\n      var frag = fragLoadedEndData.frag,\n        part = fragLoadedEndData.part,\n        partsLoaded = fragLoadedEndData.partsLoaded;\n      // If we did not load parts, or loaded all parts, we have complete (not partial) fragment data\n      var complete = !partsLoaded || partsLoaded.length === 0 || partsLoaded.some(function (fragLoaded) {\n        return !fragLoaded;\n      });\n      var chunkMeta = new ChunkMetadata(frag.level, frag.sn, frag.stats.chunkCount + 1, 0, part ? part.index : -1, !complete);\n      transmuxer.flush(chunkMeta);\n    }\n\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    ;\n    _proto._handleFragmentLoadProgress = function _handleFragmentLoadProgress(frag) {};\n    _proto._doFragLoad = function _doFragLoad(frag, level, targetBufferTime, progressCallback) {\n      var _frag$decryptdata,\n        _this4 = this;\n      if (targetBufferTime === void 0) {\n        targetBufferTime = null;\n      }\n      var details = level == null ? void 0 : level.details;\n      if (!this.levels || !details) {\n        throw new Error(\"frag load aborted, missing level\" + (details ? '' : ' detail') + \"s\");\n      }\n      var keyLoadingPromise = null;\n      if (frag.encrypted && !((_frag$decryptdata = frag.decryptdata) != null && _frag$decryptdata.key)) {\n        this.log(\"Loading key for \" + frag.sn + \" of [\" + details.startSN + \"-\" + details.endSN + \"], \" + (this.logPrefix === '[stream-controller]' ? 'level' : 'track') + \" \" + frag.level);\n        this.state = State.KEY_LOADING;\n        this.fragCurrent = frag;\n        keyLoadingPromise = this.keyLoader.load(frag).then(function (keyLoadedData) {\n          if (!_this4.fragContextChanged(keyLoadedData.frag)) {\n            _this4.hls.trigger(Events.KEY_LOADED, keyLoadedData);\n            if (_this4.state === State.KEY_LOADING) {\n              _this4.state = State.IDLE;\n            }\n            return keyLoadedData;\n          }\n        });\n        this.hls.trigger(Events.KEY_LOADING, {\n          frag: frag\n        });\n        if (this.fragCurrent === null) {\n          keyLoadingPromise = Promise.reject(new Error(\"frag load aborted, context changed in KEY_LOADING\"));\n        }\n      } else if (!frag.encrypted && details.encryptedFragments.length) {\n        this.keyLoader.loadClear(frag, details.encryptedFragments);\n      }\n      targetBufferTime = Math.max(frag.start, targetBufferTime || 0);\n      if (this.config.lowLatencyMode && frag.sn !== 'initSegment') {\n        var partList = details.partList;\n        if (partList && progressCallback) {\n          if (targetBufferTime > frag.end && details.fragmentHint) {\n            frag = details.fragmentHint;\n          }\n          var partIndex = this.getNextPart(partList, frag, targetBufferTime);\n          if (partIndex > -1) {\n            var part = partList[partIndex];\n            this.log(\"Loading part sn: \" + frag.sn + \" p: \" + part.index + \" cc: \" + frag.cc + \" of playlist [\" + details.startSN + \"-\" + details.endSN + \"] parts [0-\" + partIndex + \"-\" + (partList.length - 1) + \"] \" + (this.logPrefix === '[stream-controller]' ? 'level' : 'track') + \": \" + frag.level + \", target: \" + parseFloat(targetBufferTime.toFixed(3)));\n            this.nextLoadPosition = part.start + part.duration;\n            this.state = State.FRAG_LOADING;\n            var _result;\n            if (keyLoadingPromise) {\n              _result = keyLoadingPromise.then(function (keyLoadedData) {\n                if (!keyLoadedData || _this4.fragContextChanged(keyLoadedData.frag)) {\n                  return null;\n                }\n                return _this4.doFragPartsLoad(frag, part, level, progressCallback);\n              }).catch(function (error) {\n                return _this4.handleFragLoadError(error);\n              });\n            } else {\n              _result = this.doFragPartsLoad(frag, part, level, progressCallback).catch(function (error) {\n                return _this4.handleFragLoadError(error);\n              });\n            }\n            this.hls.trigger(Events.FRAG_LOADING, {\n              frag: frag,\n              part: part,\n              targetBufferTime: targetBufferTime\n            });\n            if (this.fragCurrent === null) {\n              return Promise.reject(new Error(\"frag load aborted, context changed in FRAG_LOADING parts\"));\n            }\n            return _result;\n          } else if (!frag.url || this.loadedEndOfParts(partList, targetBufferTime)) {\n            // Fragment hint has no parts\n            return Promise.resolve(null);\n          }\n        }\n      }\n      this.log(\"Loading fragment \" + frag.sn + \" cc: \" + frag.cc + \" \" + (details ? 'of [' + details.startSN + '-' + details.endSN + '] ' : '') + (this.logPrefix === '[stream-controller]' ? 'level' : 'track') + \": \" + frag.level + \", target: \" + parseFloat(targetBufferTime.toFixed(3)));\n      // Don't update nextLoadPosition for fragments which are not buffered\n      if (isFiniteNumber(frag.sn) && !this.bitrateTest) {\n        this.nextLoadPosition = frag.start + frag.duration;\n      }\n      this.state = State.FRAG_LOADING;\n\n      // Load key before streaming fragment data\n      var dataOnProgress = this.config.progressive;\n      var result;\n      if (dataOnProgress && keyLoadingPromise) {\n        result = keyLoadingPromise.then(function (keyLoadedData) {\n          if (!keyLoadedData || _this4.fragContextChanged(keyLoadedData == null ? void 0 : keyLoadedData.frag)) {\n            return null;\n          }\n          return _this4.fragmentLoader.load(frag, progressCallback);\n        }).catch(function (error) {\n          return _this4.handleFragLoadError(error);\n        });\n      } else {\n        // load unencrypted fragment data with progress event,\n        // or handle fragment result after key and fragment are finished loading\n        result = Promise.all([this.fragmentLoader.load(frag, dataOnProgress ? progressCallback : undefined), keyLoadingPromise]).then(function (_ref) {\n          var fragLoadedData = _ref[0];\n          if (!dataOnProgress && fragLoadedData && progressCallback) {\n            progressCallback(fragLoadedData);\n          }\n          return fragLoadedData;\n        }).catch(function (error) {\n          return _this4.handleFragLoadError(error);\n        });\n      }\n      this.hls.trigger(Events.FRAG_LOADING, {\n        frag: frag,\n        targetBufferTime: targetBufferTime\n      });\n      if (this.fragCurrent === null) {\n        return Promise.reject(new Error(\"frag load aborted, context changed in FRAG_LOADING\"));\n      }\n      return result;\n    };\n    _proto.doFragPartsLoad = function doFragPartsLoad(frag, fromPart, level, progressCallback) {\n      var _this5 = this;\n      return new Promise(function (resolve, reject) {\n        var _level$details;\n        var partsLoaded = [];\n        var initialPartList = (_level$details = level.details) == null ? void 0 : _level$details.partList;\n        var loadPart = function loadPart(part) {\n          _this5.fragmentLoader.loadPart(frag, part, progressCallback).then(function (partLoadedData) {\n            partsLoaded[part.index] = partLoadedData;\n            var loadedPart = partLoadedData.part;\n            _this5.hls.trigger(Events.FRAG_LOADED, partLoadedData);\n            var nextPart = getPartWith(level, frag.sn, part.index + 1) || findPart(initialPartList, frag.sn, part.index + 1);\n            if (nextPart) {\n              loadPart(nextPart);\n            } else {\n              return resolve({\n                frag: frag,\n                part: loadedPart,\n                partsLoaded: partsLoaded\n              });\n            }\n          }).catch(reject);\n        };\n        loadPart(fromPart);\n      });\n    };\n    _proto.handleFragLoadError = function handleFragLoadError(error) {\n      if ('data' in error) {\n        var data = error.data;\n        if (error.data && data.details === ErrorDetails.INTERNAL_ABORTED) {\n          this.handleFragLoadAborted(data.frag, data.part);\n        } else {\n          this.hls.trigger(Events.ERROR, data);\n        }\n      } else {\n        this.hls.trigger(Events.ERROR, {\n          type: ErrorTypes.OTHER_ERROR,\n          details: ErrorDetails.INTERNAL_EXCEPTION,\n          err: error,\n          error: error,\n          fatal: true\n        });\n      }\n      return null;\n    };\n    _proto._handleTransmuxerFlush = function _handleTransmuxerFlush(chunkMeta) {\n      var context = this.getCurrentContext(chunkMeta);\n      if (!context || this.state !== State.PARSING) {\n        if (!this.fragCurrent && this.state !== State.STOPPED && this.state !== State.ERROR) {\n          this.state = State.IDLE;\n        }\n        return;\n      }\n      var frag = context.frag,\n        part = context.part,\n        level = context.level;\n      var now = self.performance.now();\n      frag.stats.parsing.end = now;\n      if (part) {\n        part.stats.parsing.end = now;\n      }\n      this.updateLevelTiming(frag, part, level, chunkMeta.partial);\n    };\n    _proto.getCurrentContext = function getCurrentContext(chunkMeta) {\n      var levels = this.levels,\n        fragCurrent = this.fragCurrent;\n      var levelIndex = chunkMeta.level,\n        sn = chunkMeta.sn,\n        partIndex = chunkMeta.part;\n      if (!(levels != null && levels[levelIndex])) {\n        this.warn(\"Levels object was unset while buffering fragment \" + sn + \" of level \" + levelIndex + \". The current chunk will not be buffered.\");\n        return null;\n      }\n      var level = levels[levelIndex];\n      var part = partIndex > -1 ? getPartWith(level, sn, partIndex) : null;\n      var frag = part ? part.fragment : getFragmentWithSN(level, sn, fragCurrent);\n      if (!frag) {\n        return null;\n      }\n      if (fragCurrent && fragCurrent !== frag) {\n        frag.stats = fragCurrent.stats;\n      }\n      return {\n        frag: frag,\n        part: part,\n        level: level\n      };\n    };\n    _proto.bufferFragmentData = function bufferFragmentData(data, frag, part, chunkMeta, noBacktracking) {\n      var _buffer;\n      if (!data || this.state !== State.PARSING) {\n        return;\n      }\n      var data1 = data.data1,\n        data2 = data.data2;\n      var buffer = data1;\n      if (data1 && data2) {\n        // Combine the moof + mdat so that we buffer with a single append\n        buffer = appendUint8Array(data1, data2);\n      }\n      if (!((_buffer = buffer) != null && _buffer.length)) {\n        return;\n      }\n      var segment = {\n        type: data.type,\n        frag: frag,\n        part: part,\n        chunkMeta: chunkMeta,\n        parent: frag.type,\n        data: buffer\n      };\n      this.hls.trigger(Events.BUFFER_APPENDING, segment);\n      if (data.dropped && data.independent && !part) {\n        if (noBacktracking) {\n          return;\n        }\n        // Clear buffer so that we reload previous segments sequentially if required\n        this.flushBufferGap(frag);\n      }\n    };\n    _proto.flushBufferGap = function flushBufferGap(frag) {\n      var media = this.media;\n      if (!media) {\n        return;\n      }\n      // If currentTime is not buffered, clear the back buffer so that we can backtrack as much as needed\n      if (!BufferHelper.isBuffered(media, media.currentTime)) {\n        this.flushMainBuffer(0, frag.start);\n        return;\n      }\n      // Remove back-buffer without interrupting playback to allow back tracking\n      var currentTime = media.currentTime;\n      var bufferInfo = BufferHelper.bufferInfo(media, currentTime, 0);\n      var fragDuration = frag.duration;\n      var segmentFraction = Math.min(this.config.maxFragLookUpTolerance * 2, fragDuration * 0.25);\n      var start = Math.max(Math.min(frag.start - segmentFraction, bufferInfo.end - segmentFraction), currentTime + segmentFraction);\n      if (frag.start - start > segmentFraction) {\n        this.flushMainBuffer(start, frag.start);\n      }\n    };\n    _proto.getFwdBufferInfo = function getFwdBufferInfo(bufferable, type) {\n      var pos = this.getLoadPosition();\n      if (!isFiniteNumber(pos)) {\n        return null;\n      }\n      return this.getFwdBufferInfoAtPos(bufferable, pos, type);\n    };\n    _proto.getFwdBufferInfoAtPos = function getFwdBufferInfoAtPos(bufferable, pos, type) {\n      var maxBufferHole = this.config.maxBufferHole;\n      var bufferInfo = BufferHelper.bufferInfo(bufferable, pos, maxBufferHole);\n      // Workaround flaw in getting forward buffer when maxBufferHole is smaller than gap at current pos\n      if (bufferInfo.len === 0 && bufferInfo.nextStart !== undefined) {\n        var bufferedFragAtPos = this.fragmentTracker.getBufferedFrag(pos, type);\n        if (bufferedFragAtPos && bufferInfo.nextStart < bufferedFragAtPos.end) {\n          return BufferHelper.bufferInfo(bufferable, pos, Math.max(bufferInfo.nextStart, maxBufferHole));\n        }\n      }\n      return bufferInfo;\n    };\n    _proto.getMaxBufferLength = function getMaxBufferLength(levelBitrate) {\n      var config = this.config;\n      var maxBufLen;\n      if (levelBitrate) {\n        maxBufLen = Math.max(8 * config.maxBufferSize / levelBitrate, config.maxBufferLength);\n      } else {\n        maxBufLen = config.maxBufferLength;\n      }\n      return Math.min(maxBufLen, config.maxMaxBufferLength);\n    };\n    _proto.reduceMaxBufferLength = function reduceMaxBufferLength(threshold, fragDuration) {\n      var config = this.config;\n      var minLength = Math.max(Math.min(threshold - fragDuration, config.maxBufferLength), fragDuration);\n      var reducedLength = Math.max(threshold - fragDuration * 3, config.maxMaxBufferLength / 2, minLength);\n      if (reducedLength >= minLength) {\n        // reduce max buffer length as it might be too high. we do this to avoid loop flushing ...\n        config.maxMaxBufferLength = reducedLength;\n        this.warn(\"Reduce max buffer length to \" + reducedLength + \"s\");\n        return true;\n      }\n      return false;\n    };\n    _proto.getAppendedFrag = function getAppendedFrag(position, playlistType) {\n      var fragOrPart = this.fragmentTracker.getAppendedFrag(position, PlaylistLevelType.MAIN);\n      if (fragOrPart && 'fragment' in fragOrPart) {\n        return fragOrPart.fragment;\n      }\n      return fragOrPart;\n    };\n    _proto.getNextFragment = function getNextFragment(pos, levelDetails) {\n      var fragments = levelDetails.fragments;\n      var fragLen = fragments.length;\n      if (!fragLen) {\n        return null;\n      }\n\n      // find fragment index, contiguous with end of buffer position\n      var config = this.config;\n      var start = fragments[0].start;\n      var frag;\n      if (levelDetails.live) {\n        var initialLiveManifestSize = config.initialLiveManifestSize;\n        if (fragLen < initialLiveManifestSize) {\n          this.warn(\"Not enough fragments to start playback (have: \" + fragLen + \", need: \" + initialLiveManifestSize + \")\");\n          return null;\n        }\n        // The real fragment start times for a live stream are only known after the PTS range for that level is known.\n        // In order to discover the range, we load the best matching fragment for that level and demux it.\n        // Do not load using live logic if the starting frag is requested - we want to use getFragmentAtPosition() so that\n        // we get the fragment matching that start time\n        if (!levelDetails.PTSKnown && !this.startFragRequested && this.startPosition === -1 || pos < start) {\n          frag = this.getInitialLiveFragment(levelDetails, fragments);\n          this.startPosition = this.nextLoadPosition = frag ? this.hls.liveSyncPosition || frag.start : pos;\n        }\n      } else if (pos <= start) {\n        // VoD playlist: if loadPosition before start of playlist, load first fragment\n        frag = fragments[0];\n      }\n\n      // If we haven't run into any special cases already, just load the fragment most closely matching the requested position\n      if (!frag) {\n        var end = config.lowLatencyMode ? levelDetails.partEnd : levelDetails.fragmentEnd;\n        frag = this.getFragmentAtPosition(pos, end, levelDetails);\n      }\n      return this.mapToInitFragWhenRequired(frag);\n    };\n    _proto.isLoopLoading = function isLoopLoading(frag, targetBufferTime) {\n      var trackerState = this.fragmentTracker.getState(frag);\n      return (trackerState === FragmentState.OK || trackerState === FragmentState.PARTIAL && !!frag.gap) && this.nextLoadPosition > targetBufferTime;\n    };\n    _proto.getNextFragmentLoopLoading = function getNextFragmentLoopLoading(frag, levelDetails, bufferInfo, playlistType, maxBufLen) {\n      var gapStart = frag.gap;\n      var nextFragment = this.getNextFragment(this.nextLoadPosition, levelDetails);\n      if (nextFragment === null) {\n        return nextFragment;\n      }\n      frag = nextFragment;\n      if (gapStart && frag && !frag.gap && bufferInfo.nextStart) {\n        // Media buffered after GAP tags should not make the next buffer timerange exceed forward buffer length\n        var nextbufferInfo = this.getFwdBufferInfoAtPos(this.mediaBuffer ? this.mediaBuffer : this.media, bufferInfo.nextStart, playlistType);\n        if (nextbufferInfo !== null && bufferInfo.len + nextbufferInfo.len >= maxBufLen) {\n          // Returning here might result in not finding an audio and video candiate to skip to\n          this.log(\"buffer full after gaps in \\\"\" + playlistType + \"\\\" playlist starting at sn: \" + frag.sn);\n          return null;\n        }\n      }\n      return frag;\n    };\n    _proto.mapToInitFragWhenRequired = function mapToInitFragWhenRequired(frag) {\n      // If an initSegment is present, it must be buffered first\n      if (frag != null && frag.initSegment && !(frag != null && frag.initSegment.data) && !this.bitrateTest) {\n        return frag.initSegment;\n      }\n      return frag;\n    };\n    _proto.getNextPart = function getNextPart(partList, frag, targetBufferTime) {\n      var nextPart = -1;\n      var contiguous = false;\n      var independentAttrOmitted = true;\n      for (var i = 0, len = partList.length; i < len; i++) {\n        var part = partList[i];\n        independentAttrOmitted = independentAttrOmitted && !part.independent;\n        if (nextPart > -1 && targetBufferTime < part.start) {\n          break;\n        }\n        var loaded = part.loaded;\n        if (loaded) {\n          nextPart = -1;\n        } else if ((contiguous || part.independent || independentAttrOmitted) && part.fragment === frag) {\n          nextPart = i;\n        }\n        contiguous = loaded;\n      }\n      return nextPart;\n    };\n    _proto.loadedEndOfParts = function loadedEndOfParts(partList, targetBufferTime) {\n      var lastPart = partList[partList.length - 1];\n      return lastPart && targetBufferTime > lastPart.start && lastPart.loaded;\n    }\n\n    /*\n     This method is used find the best matching first fragment for a live playlist. This fragment is used to calculate the\n     \"sliding\" of the playlist, which is its offset from the start of playback. After sliding we can compute the real\n     start and end times for each fragment in the playlist (after which this method will not need to be called).\n    */;\n    _proto.getInitialLiveFragment = function getInitialLiveFragment(levelDetails, fragments) {\n      var fragPrevious = this.fragPrevious;\n      var frag = null;\n      if (fragPrevious) {\n        if (levelDetails.hasProgramDateTime) {\n          // Prefer using PDT, because it can be accurate enough to choose the correct fragment without knowing the level sliding\n          this.log(\"Live playlist, switching playlist, load frag with same PDT: \" + fragPrevious.programDateTime);\n          frag = findFragmentByPDT(fragments, fragPrevious.endProgramDateTime, this.config.maxFragLookUpTolerance);\n        }\n        if (!frag) {\n          // SN does not need to be accurate between renditions, but depending on the packaging it may be so.\n          var targetSN = fragPrevious.sn + 1;\n          if (targetSN >= levelDetails.startSN && targetSN <= levelDetails.endSN) {\n            var fragNext = fragments[targetSN - levelDetails.startSN];\n            // Ensure that we're staying within the continuity range, since PTS resets upon a new range\n            if (fragPrevious.cc === fragNext.cc) {\n              frag = fragNext;\n              this.log(\"Live playlist, switching playlist, load frag with next SN: \" + frag.sn);\n            }\n          }\n          // It's important to stay within the continuity range if available; otherwise the fragments in the playlist\n          // will have the wrong start times\n          if (!frag) {\n            frag = findFragWithCC(fragments, fragPrevious.cc);\n            if (frag) {\n              this.log(\"Live playlist, switching playlist, load frag with same CC: \" + frag.sn);\n            }\n          }\n        }\n      } else {\n        // Find a new start fragment when fragPrevious is null\n        var liveStart = this.hls.liveSyncPosition;\n        if (liveStart !== null) {\n          frag = this.getFragmentAtPosition(liveStart, this.bitrateTest ? levelDetails.fragmentEnd : levelDetails.edge, levelDetails);\n        }\n      }\n      return frag;\n    }\n\n    /*\n    This method finds the best matching fragment given the provided position.\n     */;\n    _proto.getFragmentAtPosition = function getFragmentAtPosition(bufferEnd, end, levelDetails) {\n      var config = this.config;\n      var fragPrevious = this.fragPrevious;\n      var fragments = levelDetails.fragments,\n        endSN = levelDetails.endSN;\n      var fragmentHint = levelDetails.fragmentHint;\n      var maxFragLookUpTolerance = config.maxFragLookUpTolerance;\n      var partList = levelDetails.partList;\n      var loadingParts = !!(config.lowLatencyMode && partList != null && partList.length && fragmentHint);\n      if (loadingParts && fragmentHint && !this.bitrateTest) {\n        // Include incomplete fragment with parts at end\n        fragments = fragments.concat(fragmentHint);\n        endSN = fragmentHint.sn;\n      }\n      var frag;\n      if (bufferEnd < end) {\n        var lookupTolerance = bufferEnd > end - maxFragLookUpTolerance ? 0 : maxFragLookUpTolerance;\n        // Remove the tolerance if it would put the bufferEnd past the actual end of stream\n        // Uses buffer and sequence number to calculate switch segment (required if using EXT-X-DISCONTINUITY-SEQUENCE)\n        frag = findFragmentByPTS(fragPrevious, fragments, bufferEnd, lookupTolerance);\n      } else {\n        // reach end of playlist\n        frag = fragments[fragments.length - 1];\n      }\n      if (frag) {\n        var curSNIdx = frag.sn - levelDetails.startSN;\n        // Move fragPrevious forward to support forcing the next fragment to load\n        // when the buffer catches up to a previously buffered range.\n        var fragState = this.fragmentTracker.getState(frag);\n        if (fragState === FragmentState.OK || fragState === FragmentState.PARTIAL && frag.gap) {\n          fragPrevious = frag;\n        }\n        if (fragPrevious && frag.sn === fragPrevious.sn && (!loadingParts || partList[0].fragment.sn > frag.sn)) {\n          // Force the next fragment to load if the previous one was already selected. This can occasionally happen with\n          // non-uniform fragment durations\n          var sameLevel = fragPrevious && frag.level === fragPrevious.level;\n          if (sameLevel) {\n            var nextFrag = fragments[curSNIdx + 1];\n            if (frag.sn < endSN && this.fragmentTracker.getState(nextFrag) !== FragmentState.OK) {\n              frag = nextFrag;\n            } else {\n              frag = null;\n            }\n          }\n        }\n      }\n      return frag;\n    };\n    _proto.synchronizeToLiveEdge = function synchronizeToLiveEdge(levelDetails) {\n      var config = this.config,\n        media = this.media;\n      if (!media) {\n        return;\n      }\n      var liveSyncPosition = this.hls.liveSyncPosition;\n      var currentTime = media.currentTime;\n      var start = levelDetails.fragments[0].start;\n      var end = levelDetails.edge;\n      var withinSlidingWindow = currentTime >= start - config.maxFragLookUpTolerance && currentTime <= end;\n      // Continue if we can seek forward to sync position or if current time is outside of sliding window\n      if (liveSyncPosition !== null && media.duration > liveSyncPosition && (currentTime < liveSyncPosition || !withinSlidingWindow)) {\n        // Continue if buffer is starving or if current time is behind max latency\n        var maxLatency = config.liveMaxLatencyDuration !== undefined ? config.liveMaxLatencyDuration : config.liveMaxLatencyDurationCount * levelDetails.targetduration;\n        if (!withinSlidingWindow && media.readyState < 4 || currentTime < end - maxLatency) {\n          if (!this.loadedmetadata) {\n            this.nextLoadPosition = liveSyncPosition;\n          }\n          // Only seek if ready and there is not a significant forward buffer available for playback\n          if (media.readyState) {\n            this.warn(\"Playback: \" + currentTime.toFixed(3) + \" is located too far from the end of live sliding playlist: \" + end + \", reset currentTime to : \" + liveSyncPosition.toFixed(3));\n            media.currentTime = liveSyncPosition;\n          }\n        }\n      }\n    };\n    _proto.alignPlaylists = function alignPlaylists(details, previousDetails, switchDetails) {\n      // FIXME: If not for `shouldAlignOnDiscontinuities` requiring fragPrevious.cc,\n      //  this could all go in level-helper mergeDetails()\n      var length = details.fragments.length;\n      if (!length) {\n        this.warn(\"No fragments in live playlist\");\n        return 0;\n      }\n      var slidingStart = details.fragments[0].start;\n      var firstLevelLoad = !previousDetails;\n      var aligned = details.alignedSliding && isFiniteNumber(slidingStart);\n      if (firstLevelLoad || !aligned && !slidingStart) {\n        var fragPrevious = this.fragPrevious;\n        alignStream(fragPrevious, switchDetails, details);\n        var alignedSlidingStart = details.fragments[0].start;\n        this.log(\"Live playlist sliding: \" + alignedSlidingStart.toFixed(2) + \" start-sn: \" + (previousDetails ? previousDetails.startSN : 'na') + \"->\" + details.startSN + \" prev-sn: \" + (fragPrevious ? fragPrevious.sn : 'na') + \" fragments: \" + length);\n        return alignedSlidingStart;\n      }\n      return slidingStart;\n    };\n    _proto.waitForCdnTuneIn = function waitForCdnTuneIn(details) {\n      // Wait for Low-Latency CDN Tune-in to get an updated playlist\n      var advancePartLimit = 3;\n      return details.live && details.canBlockReload && details.partTarget && details.tuneInGoal > Math.max(details.partHoldBack, details.partTarget * advancePartLimit);\n    };\n    _proto.setStartPosition = function setStartPosition(details, sliding) {\n      // compute start position if set to -1. use it straight away if value is defined\n      var startPosition = this.startPosition;\n      if (startPosition < sliding) {\n        startPosition = -1;\n      }\n      if (startPosition === -1 || this.lastCurrentTime === -1) {\n        // Use Playlist EXT-X-START:TIME-OFFSET when set\n        // Prioritize Multivariant Playlist offset so that main, audio, and subtitle stream-controller start times match\n        var offsetInMultivariantPlaylist = this.startTimeOffset !== null;\n        var startTimeOffset = offsetInMultivariantPlaylist ? this.startTimeOffset : details.startTimeOffset;\n        if (startTimeOffset !== null && isFiniteNumber(startTimeOffset)) {\n          startPosition = sliding + startTimeOffset;\n          if (startTimeOffset < 0) {\n            startPosition += details.totalduration;\n          }\n          startPosition = Math.min(Math.max(sliding, startPosition), sliding + details.totalduration);\n          this.log(\"Start time offset \" + startTimeOffset + \" found in \" + (offsetInMultivariantPlaylist ? 'multivariant' : 'media') + \" playlist, adjust startPosition to \" + startPosition);\n          this.startPosition = startPosition;\n        } else if (details.live) {\n          // Leave this.startPosition at -1, so that we can use `getInitialLiveFragment` logic when startPosition has\n          // not been specified via the config or an as an argument to startLoad (#3736).\n          startPosition = this.hls.liveSyncPosition || sliding;\n        } else {\n          this.startPosition = startPosition = 0;\n        }\n        this.lastCurrentTime = startPosition;\n      }\n      this.nextLoadPosition = startPosition;\n    };\n    _proto.getLoadPosition = function getLoadPosition() {\n      var media = this.media;\n      // if we have not yet loaded any fragment, start loading from start position\n      var pos = 0;\n      if (this.loadedmetadata && media) {\n        pos = media.currentTime;\n      } else if (this.nextLoadPosition) {\n        pos = this.nextLoadPosition;\n      }\n      return pos;\n    };\n    _proto.handleFragLoadAborted = function handleFragLoadAborted(frag, part) {\n      if (this.transmuxer && frag.sn !== 'initSegment' && frag.stats.aborted) {\n        this.warn(\"Fragment \" + frag.sn + (part ? ' part ' + part.index : '') + \" of level \" + frag.level + \" was aborted\");\n        this.resetFragmentLoading(frag);\n      }\n    };\n    _proto.resetFragmentLoading = function resetFragmentLoading(frag) {\n      if (!this.fragCurrent || !this.fragContextChanged(frag) && this.state !== State.FRAG_LOADING_WAITING_RETRY) {\n        this.state = State.IDLE;\n      }\n    };\n    _proto.onFragmentOrKeyLoadError = function onFragmentOrKeyLoadError(filterType, data) {\n      if (data.chunkMeta && !data.frag) {\n        var context = this.getCurrentContext(data.chunkMeta);\n        if (context) {\n          data.frag = context.frag;\n        }\n      }\n      var frag = data.frag;\n      // Handle frag error related to caller's filterType\n      if (!frag || frag.type !== filterType || !this.levels) {\n        return;\n      }\n      if (this.fragContextChanged(frag)) {\n        var _this$fragCurrent2;\n        this.warn(\"Frag load error must match current frag to retry \" + frag.url + \" > \" + ((_this$fragCurrent2 = this.fragCurrent) == null ? void 0 : _this$fragCurrent2.url));\n        return;\n      }\n      var gapTagEncountered = data.details === ErrorDetails.FRAG_GAP;\n      if (gapTagEncountered) {\n        this.fragmentTracker.fragBuffered(frag, true);\n      }\n      // keep retrying until the limit will be reached\n      var errorAction = data.errorAction;\n      var _ref2 = errorAction || {},\n        action = _ref2.action,\n        _ref2$retryCount = _ref2.retryCount,\n        retryCount = _ref2$retryCount === void 0 ? 0 : _ref2$retryCount,\n        retryConfig = _ref2.retryConfig;\n      if (errorAction && action === NetworkErrorAction.RetryRequest && retryConfig) {\n        this.resetStartWhenNotLoaded(this.levelLastLoaded);\n        var delay = getRetryDelay(retryConfig, retryCount);\n        this.warn(\"Fragment \" + frag.sn + \" of \" + filterType + \" \" + frag.level + \" errored with \" + data.details + \", retrying loading \" + (retryCount + 1) + \"/\" + retryConfig.maxNumRetry + \" in \" + delay + \"ms\");\n        errorAction.resolved = true;\n        this.retryDate = self.performance.now() + delay;\n        this.state = State.FRAG_LOADING_WAITING_RETRY;\n      } else if (retryConfig && errorAction) {\n        this.resetFragmentErrors(filterType);\n        if (retryCount < retryConfig.maxNumRetry) {\n          // Network retry is skipped when level switch is preferred\n          if (!gapTagEncountered && action !== NetworkErrorAction.RemoveAlternatePermanently) {\n            errorAction.resolved = true;\n          }\n        } else {\n          logger.warn(data.details + \" reached or exceeded max retry (\" + retryCount + \")\");\n          return;\n        }\n      } else if ((errorAction == null ? void 0 : errorAction.action) === NetworkErrorAction.SendAlternateToPenaltyBox) {\n        this.state = State.WAITING_LEVEL;\n      } else {\n        this.state = State.ERROR;\n      }\n      // Perform next async tick sooner to speed up error action resolution\n      this.tickImmediate();\n    };\n    _proto.reduceLengthAndFlushBuffer = function reduceLengthAndFlushBuffer(data) {\n      // if in appending state\n      if (this.state === State.PARSING || this.state === State.PARSED) {\n        var frag = data.frag;\n        var playlistType = data.parent;\n        var bufferedInfo = this.getFwdBufferInfo(this.mediaBuffer, playlistType);\n        // 0.5 : tolerance needed as some browsers stalls playback before reaching buffered end\n        // reduce max buf len if current position is buffered\n        var buffered = bufferedInfo && bufferedInfo.len > 0.5;\n        if (buffered) {\n          this.reduceMaxBufferLength(bufferedInfo.len, (frag == null ? void 0 : frag.duration) || 10);\n        }\n        var flushBuffer = !buffered;\n        if (flushBuffer) {\n          // current position is not buffered, but browser is still complaining about buffer full error\n          // this happens on IE/Edge, refer to https://github.com/video-dev/hls.js/pull/708\n          // in that case flush the whole audio buffer to recover\n          this.warn(\"Buffer full error while media.currentTime is not buffered, flush \" + playlistType + \" buffer\");\n        }\n        if (frag) {\n          this.fragmentTracker.removeFragment(frag);\n          this.nextLoadPosition = frag.start;\n        }\n        this.resetLoadingState();\n        return flushBuffer;\n      }\n      return false;\n    };\n    _proto.resetFragmentErrors = function resetFragmentErrors(filterType) {\n      if (filterType === PlaylistLevelType.AUDIO) {\n        // Reset current fragment since audio track audio is essential and may not have a fail-over track\n        this.fragCurrent = null;\n      }\n      // Fragment errors that result in a level switch or redundant fail-over\n      // should reset the stream controller state to idle\n      if (!this.loadedmetadata) {\n        this.startFragRequested = false;\n      }\n      if (this.state !== State.STOPPED) {\n        this.state = State.IDLE;\n      }\n    };\n    _proto.afterBufferFlushed = function afterBufferFlushed(media, bufferType, playlistType) {\n      if (!media) {\n        return;\n      }\n      // After successful buffer flushing, filter flushed fragments from bufferedFrags use mediaBuffered instead of media\n      // (so that we will check against video.buffered ranges in case of alt audio track)\n      var bufferedTimeRanges = BufferHelper.getBuffered(media);\n      this.fragmentTracker.detectEvictedFragments(bufferType, bufferedTimeRanges, playlistType);\n      if (this.state === State.ENDED) {\n        this.resetLoadingState();\n      }\n    };\n    _proto.resetLoadingState = function resetLoadingState() {\n      this.log('Reset loading state');\n      this.fragCurrent = null;\n      this.fragPrevious = null;\n      this.state = State.IDLE;\n    };\n    _proto.resetStartWhenNotLoaded = function resetStartWhenNotLoaded(level) {\n      // if loadedmetadata is not set, it means that first frag request failed\n      // in that case, reset startFragRequested flag\n      if (!this.loadedmetadata) {\n        this.startFragRequested = false;\n        var details = level ? level.details : null;\n        if (details != null && details.live) {\n          // Update the start position and return to IDLE to recover live start\n          this.startPosition = -1;\n          this.setStartPosition(details, 0);\n          this.resetLoadingState();\n        } else {\n          this.nextLoadPosition = this.startPosition;\n        }\n      }\n    };\n    _proto.resetWhenMissingContext = function resetWhenMissingContext(chunkMeta) {\n      this.warn(\"The loading context changed while buffering fragment \" + chunkMeta.sn + \" of level \" + chunkMeta.level + \". This chunk will not be buffered.\");\n      this.removeUnbufferedFrags();\n      this.resetStartWhenNotLoaded(this.levelLastLoaded);\n      this.resetLoadingState();\n    };\n    _proto.removeUnbufferedFrags = function removeUnbufferedFrags(start) {\n      if (start === void 0) {\n        start = 0;\n      }\n      this.fragmentTracker.removeFragmentsInRange(start, Infinity, this.playlistType, false, true);\n    };\n    _proto.updateLevelTiming = function updateLevelTiming(frag, part, level, partial) {\n      var _this6 = this,\n        _this$transmuxer;\n      var details = level.details;\n      if (!details) {\n        this.warn('level.details undefined');\n        return;\n      }\n      var parsed = Object.keys(frag.elementaryStreams).reduce(function (result, type) {\n        var info = frag.elementaryStreams[type];\n        if (info) {\n          var parsedDuration = info.endPTS - info.startPTS;\n          if (parsedDuration <= 0) {\n            // Destroy the transmuxer after it's next time offset failed to advance because duration was <= 0.\n            // The new transmuxer will be configured with a time offset matching the next fragment start,\n            // preventing the timeline from shifting.\n            _this6.warn(\"Could not parse fragment \" + frag.sn + \" \" + type + \" duration reliably (\" + parsedDuration + \")\");\n            return result || false;\n          }\n          var drift = partial ? 0 : updateFragPTSDTS(details, frag, info.startPTS, info.endPTS, info.startDTS, info.endDTS);\n          _this6.hls.trigger(Events.LEVEL_PTS_UPDATED, {\n            details: details,\n            level: level,\n            drift: drift,\n            type: type,\n            frag: frag,\n            start: info.startPTS,\n            end: info.endPTS\n          });\n          return true;\n        }\n        return result;\n      }, false);\n      if (!parsed && ((_this$transmuxer = this.transmuxer) == null ? void 0 : _this$transmuxer.error) === null) {\n        var error = new Error(\"Found no media in fragment \" + frag.sn + \" of level \" + frag.level + \" resetting transmuxer to fallback to playlist timing\");\n        if (level.fragmentError === 0) {\n          // Mark and track the odd empty segment as a gap to avoid reloading\n          level.fragmentError++;\n          frag.gap = true;\n          this.fragmentTracker.removeFragment(frag);\n          this.fragmentTracker.fragBuffered(frag, true);\n        }\n        this.warn(error.message);\n        this.hls.trigger(Events.ERROR, {\n          type: ErrorTypes.MEDIA_ERROR,\n          details: ErrorDetails.FRAG_PARSING_ERROR,\n          fatal: false,\n          error: error,\n          frag: frag,\n          reason: \"Found no media in msn \" + frag.sn + \" of level \\\"\" + level.url + \"\\\"\"\n        });\n        if (!this.hls) {\n          return;\n        }\n        this.resetTransmuxer();\n        // For this error fallthrough. Marking parsed will allow advancing to next fragment.\n      }\n      this.state = State.PARSED;\n      this.hls.trigger(Events.FRAG_PARSED, {\n        frag: frag,\n        part: part\n      });\n    };\n    _proto.resetTransmuxer = function resetTransmuxer() {\n      if (this.transmuxer) {\n        this.transmuxer.destroy();\n        this.transmuxer = null;\n      }\n    };\n    _proto.recoverWorkerError = function recoverWorkerError(data) {\n      if (data.event === 'demuxerWorker') {\n        this.fragmentTracker.removeAllFragments();\n        this.resetTransmuxer();\n        this.resetStartWhenNotLoaded(this.levelLastLoaded);\n        this.resetLoadingState();\n      }\n    };\n    _createClass(BaseStreamController, [{\n      key: \"state\",\n      get: function get() {\n        return this._state;\n      },\n      set: function set(nextState) {\n        var previousState = this._state;\n        if (previousState !== nextState) {\n          this._state = nextState;\n          this.log(previousState + \"->\" + nextState);\n        }\n      }\n    }]);\n    return BaseStreamController;\n  }(TaskLoop);\n\n  var ChunkCache = /*#__PURE__*/function () {\n    function ChunkCache() {\n      this.chunks = [];\n      this.dataLength = 0;\n    }\n    var _proto = ChunkCache.prototype;\n    _proto.push = function push(chunk) {\n      this.chunks.push(chunk);\n      this.dataLength += chunk.length;\n    };\n    _proto.flush = function flush() {\n      var chunks = this.chunks,\n        dataLength = this.dataLength;\n      var result;\n      if (!chunks.length) {\n        return new Uint8Array(0);\n      } else if (chunks.length === 1) {\n        result = chunks[0];\n      } else {\n        result = concatUint8Arrays(chunks, dataLength);\n      }\n      this.reset();\n      return result;\n    };\n    _proto.reset = function reset() {\n      this.chunks.length = 0;\n      this.dataLength = 0;\n    };\n    return ChunkCache;\n  }();\n  function concatUint8Arrays(chunks, dataLength) {\n    var result = new Uint8Array(dataLength);\n    var offset = 0;\n    for (var i = 0; i < chunks.length; i++) {\n      var chunk = chunks[i];\n      result.set(chunk, offset);\n      offset += chunk.length;\n    }\n    return result;\n  }\n\n  function dummyTrack(type, inputTimeScale) {\n    if (type === void 0) {\n      type = '';\n    }\n    if (inputTimeScale === void 0) {\n      inputTimeScale = 90000;\n    }\n    return {\n      type: type,\n      id: -1,\n      pid: -1,\n      inputTimeScale: inputTimeScale,\n      sequenceNumber: -1,\n      samples: [],\n      dropped: 0\n    };\n  }\n\n  var BaseAudioDemuxer = /*#__PURE__*/function () {\n    function BaseAudioDemuxer() {\n      this._audioTrack = void 0;\n      this._id3Track = void 0;\n      this.frameIndex = 0;\n      this.cachedData = null;\n      this.basePTS = null;\n      this.initPTS = null;\n      this.lastPTS = null;\n    }\n    var _proto = BaseAudioDemuxer.prototype;\n    _proto.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n      this._id3Track = {\n        type: 'id3',\n        id: 3,\n        pid: -1,\n        inputTimeScale: 90000,\n        sequenceNumber: 0,\n        samples: [],\n        dropped: 0\n      };\n    };\n    _proto.resetTimeStamp = function resetTimeStamp(deaultTimestamp) {\n      this.initPTS = deaultTimestamp;\n      this.resetContiguity();\n    };\n    _proto.resetContiguity = function resetContiguity() {\n      this.basePTS = null;\n      this.lastPTS = null;\n      this.frameIndex = 0;\n    };\n    _proto.canParse = function canParse(data, offset) {\n      return false;\n    };\n    _proto.appendFrame = function appendFrame(track, data, offset) {}\n\n    // feed incoming data to the front of the parsing pipeline\n    ;\n    _proto.demux = function demux(data, timeOffset) {\n      if (this.cachedData) {\n        data = appendUint8Array(this.cachedData, data);\n        this.cachedData = null;\n      }\n      var id3Data = getID3Data(data, 0);\n      var offset = id3Data ? id3Data.length : 0;\n      var lastDataIndex;\n      var track = this._audioTrack;\n      var id3Track = this._id3Track;\n      var timestamp = id3Data ? getTimeStamp(id3Data) : undefined;\n      var length = data.length;\n      if (this.basePTS === null || this.frameIndex === 0 && isFiniteNumber(timestamp)) {\n        this.basePTS = initPTSFn(timestamp, timeOffset, this.initPTS);\n        this.lastPTS = this.basePTS;\n      }\n      if (this.lastPTS === null) {\n        this.lastPTS = this.basePTS;\n      }\n\n      // more expressive than alternative: id3Data?.length\n      if (id3Data && id3Data.length > 0) {\n        id3Track.samples.push({\n          pts: this.lastPTS,\n          dts: this.lastPTS,\n          data: id3Data,\n          type: MetadataSchema.audioId3,\n          duration: Number.POSITIVE_INFINITY\n        });\n      }\n      while (offset < length) {\n        if (this.canParse(data, offset)) {\n          var frame = this.appendFrame(track, data, offset);\n          if (frame) {\n            this.frameIndex++;\n            this.lastPTS = frame.sample.pts;\n            offset += frame.length;\n            lastDataIndex = offset;\n          } else {\n            offset = length;\n          }\n        } else if (canParse$2(data, offset)) {\n          // after a ID3.canParse, a call to ID3.getID3Data *should* always returns some data\n          id3Data = getID3Data(data, offset);\n          id3Track.samples.push({\n            pts: this.lastPTS,\n            dts: this.lastPTS,\n            data: id3Data,\n            type: MetadataSchema.audioId3,\n            duration: Number.POSITIVE_INFINITY\n          });\n          offset += id3Data.length;\n          lastDataIndex = offset;\n        } else {\n          offset++;\n        }\n        if (offset === length && lastDataIndex !== length) {\n          var partialData = sliceUint8(data, lastDataIndex);\n          if (this.cachedData) {\n            this.cachedData = appendUint8Array(this.cachedData, partialData);\n          } else {\n            this.cachedData = partialData;\n          }\n        }\n      }\n      return {\n        audioTrack: track,\n        videoTrack: dummyTrack(),\n        id3Track: id3Track,\n        textTrack: dummyTrack()\n      };\n    };\n    _proto.demuxSampleAes = function demuxSampleAes(data, keyData, timeOffset) {\n      return Promise.reject(new Error(\"[\" + this + \"] This demuxer does not support Sample-AES decryption\"));\n    };\n    _proto.flush = function flush(timeOffset) {\n      // Parse cache in case of remaining frames.\n      var cachedData = this.cachedData;\n      if (cachedData) {\n        this.cachedData = null;\n        this.demux(cachedData, 0);\n      }\n      return {\n        audioTrack: this._audioTrack,\n        videoTrack: dummyTrack(),\n        id3Track: this._id3Track,\n        textTrack: dummyTrack()\n      };\n    };\n    _proto.destroy = function destroy() {};\n    return BaseAudioDemuxer;\n  }();\n  /**\n   * Initialize PTS\n   * <p>\n   *    use timestamp unless it is undefined, NaN or Infinity\n   * </p>\n   */\n  var initPTSFn = function initPTSFn(timestamp, timeOffset, initPTS) {\n    if (isFiniteNumber(timestamp)) {\n      return timestamp * 90;\n    }\n    var init90kHz = initPTS ? initPTS.baseTime * 90000 / initPTS.timescale : 0;\n    return timeOffset * 90000 + init90kHz;\n  };\n\n  /**\n   * ADTS parser helper\n   * @link https://wiki.multimedia.cx/index.php?title=ADTS\n   */\n  function getAudioConfig(observer, data, offset, audioCodec) {\n    var adtsObjectType;\n    var adtsExtensionSamplingIndex;\n    var adtsChannelConfig;\n    var config;\n    var userAgent = navigator.userAgent.toLowerCase();\n    var manifestCodec = audioCodec;\n    var adtsSamplingRates = [96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050, 16000, 12000, 11025, 8000, 7350];\n    // byte 2\n    adtsObjectType = ((data[offset + 2] & 0xc0) >>> 6) + 1;\n    var adtsSamplingIndex = (data[offset + 2] & 0x3c) >>> 2;\n    if (adtsSamplingIndex > adtsSamplingRates.length - 1) {\n      var error = new Error(\"invalid ADTS sampling index:\" + adtsSamplingIndex);\n      observer.emit(Events.ERROR, Events.ERROR, {\n        type: ErrorTypes.MEDIA_ERROR,\n        details: ErrorDetails.FRAG_PARSING_ERROR,\n        fatal: true,\n        error: error,\n        reason: error.message\n      });\n      return;\n    }\n    adtsChannelConfig = (data[offset + 2] & 0x01) << 2;\n    // byte 3\n    adtsChannelConfig |= (data[offset + 3] & 0xc0) >>> 6;\n    logger.log(\"manifest codec:\" + audioCodec + \", ADTS type:\" + adtsObjectType + \", samplingIndex:\" + adtsSamplingIndex);\n    // firefox: freq less than 24kHz = AAC SBR (HE-AAC)\n    if (/firefox/i.test(userAgent)) {\n      if (adtsSamplingIndex >= 6) {\n        adtsObjectType = 5;\n        config = new Array(4);\n        // HE-AAC uses SBR (Spectral Band Replication) , high frequencies are constructed from low frequencies\n        // there is a factor 2 between frame sample rate and output sample rate\n        // multiply frequency by 2 (see table below, equivalent to substract 3)\n        adtsExtensionSamplingIndex = adtsSamplingIndex - 3;\n      } else {\n        adtsObjectType = 2;\n        config = new Array(2);\n        adtsExtensionSamplingIndex = adtsSamplingIndex;\n      }\n      // Android : always use AAC\n    } else if (userAgent.indexOf('android') !== -1) {\n      adtsObjectType = 2;\n      config = new Array(2);\n      adtsExtensionSamplingIndex = adtsSamplingIndex;\n    } else {\n      /*  for other browsers (Chrome/Vivaldi/Opera ...)\n          always force audio type to be HE-AAC SBR, as some browsers do not support audio codec switch properly (like Chrome ...)\n      */\n      adtsObjectType = 5;\n      config = new Array(4);\n      // if (manifest codec is HE-AAC or HE-AACv2) OR (manifest codec not specified AND frequency less than 24kHz)\n      if (audioCodec && (audioCodec.indexOf('mp4a.40.29') !== -1 || audioCodec.indexOf('mp4a.40.5') !== -1) || !audioCodec && adtsSamplingIndex >= 6) {\n        // HE-AAC uses SBR (Spectral Band Replication) , high frequencies are constructed from low frequencies\n        // there is a factor 2 between frame sample rate and output sample rate\n        // multiply frequency by 2 (see table below, equivalent to substract 3)\n        adtsExtensionSamplingIndex = adtsSamplingIndex - 3;\n      } else {\n        // if (manifest codec is AAC) AND (frequency less than 24kHz AND nb channel is 1) OR (manifest codec not specified and mono audio)\n        // Chrome fails to play back with low frequency AAC LC mono when initialized with HE-AAC.  This is not a problem with stereo.\n        if (audioCodec && audioCodec.indexOf('mp4a.40.2') !== -1 && (adtsSamplingIndex >= 6 && adtsChannelConfig === 1 || /vivaldi/i.test(userAgent)) || !audioCodec && adtsChannelConfig === 1) {\n          adtsObjectType = 2;\n          config = new Array(2);\n        }\n        adtsExtensionSamplingIndex = adtsSamplingIndex;\n      }\n    }\n    /* refer to http://wiki.multimedia.cx/index.php?title=MPEG-4_Audio#Audio_Specific_Config\n        ISO 14496-3 (AAC).pdf - Table 1.13  Syntax of AudioSpecificConfig()\n      Audio Profile / Audio Object Type\n      0: Null\n      1: AAC Main\n      2: AAC LC (Low Complexity)\n      3: AAC SSR (Scalable Sample Rate)\n      4: AAC LTP (Long Term Prediction)\n      5: SBR (Spectral Band Replication)\n      6: AAC Scalable\n     sampling freq\n      0: 96000 Hz\n      1: 88200 Hz\n      2: 64000 Hz\n      3: 48000 Hz\n      4: 44100 Hz\n      5: 32000 Hz\n      6: 24000 Hz\n      7: 22050 Hz\n      8: 16000 Hz\n      9: 12000 Hz\n      10: 11025 Hz\n      11: 8000 Hz\n      12: 7350 Hz\n      13: Reserved\n      14: Reserved\n      15: frequency is written explictly\n      Channel Configurations\n      These are the channel configurations:\n      0: Defined in AOT Specifc Config\n      1: 1 channel: front-center\n      2: 2 channels: front-left, front-right\n    */\n    // audioObjectType = profile => profile, the MPEG-4 Audio Object Type minus 1\n    config[0] = adtsObjectType << 3;\n    // samplingFrequencyIndex\n    config[0] |= (adtsSamplingIndex & 0x0e) >> 1;\n    config[1] |= (adtsSamplingIndex & 0x01) << 7;\n    // channelConfiguration\n    config[1] |= adtsChannelConfig << 3;\n    if (adtsObjectType === 5) {\n      // adtsExtensionSamplingIndex\n      config[1] |= (adtsExtensionSamplingIndex & 0x0e) >> 1;\n      config[2] = (adtsExtensionSamplingIndex & 0x01) << 7;\n      // adtsObjectType (force to 2, chrome is checking that object type is less than 5 ???\n      //    https://chromium.googlesource.com/chromium/src.git/+/master/media/formats/mp4/aac.cc\n      config[2] |= 2 << 2;\n      config[3] = 0;\n    }\n    return {\n      config: config,\n      samplerate: adtsSamplingRates[adtsSamplingIndex],\n      channelCount: adtsChannelConfig,\n      codec: 'mp4a.40.' + adtsObjectType,\n      manifestCodec: manifestCodec\n    };\n  }\n  function isHeaderPattern$1(data, offset) {\n    return data[offset] === 0xff && (data[offset + 1] & 0xf6) === 0xf0;\n  }\n  function getHeaderLength(data, offset) {\n    return data[offset + 1] & 0x01 ? 7 : 9;\n  }\n  function getFullFrameLength(data, offset) {\n    return (data[offset + 3] & 0x03) << 11 | data[offset + 4] << 3 | (data[offset + 5] & 0xe0) >>> 5;\n  }\n  function canGetFrameLength(data, offset) {\n    return offset + 5 < data.length;\n  }\n  function isHeader$1(data, offset) {\n    // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1\n    // Layer bits (position 14 and 15) in header should be always 0 for ADTS\n    // More info https://wiki.multimedia.cx/index.php?title=ADTS\n    return offset + 1 < data.length && isHeaderPattern$1(data, offset);\n  }\n  function canParse$1(data, offset) {\n    return canGetFrameLength(data, offset) && isHeaderPattern$1(data, offset) && getFullFrameLength(data, offset) <= data.length - offset;\n  }\n  function probe$1(data, offset) {\n    // same as isHeader but we also check that ADTS frame follows last ADTS frame\n    // or end of data is reached\n    if (isHeader$1(data, offset)) {\n      // ADTS header Length\n      var headerLength = getHeaderLength(data, offset);\n      if (offset + headerLength >= data.length) {\n        return false;\n      }\n      // ADTS frame Length\n      var frameLength = getFullFrameLength(data, offset);\n      if (frameLength <= headerLength) {\n        return false;\n      }\n      var newOffset = offset + frameLength;\n      return newOffset === data.length || isHeader$1(data, newOffset);\n    }\n    return false;\n  }\n  function initTrackConfig(track, observer, data, offset, audioCodec) {\n    if (!track.samplerate) {\n      var config = getAudioConfig(observer, data, offset, audioCodec);\n      if (!config) {\n        return;\n      }\n      track.config = config.config;\n      track.samplerate = config.samplerate;\n      track.channelCount = config.channelCount;\n      track.codec = config.codec;\n      track.manifestCodec = config.manifestCodec;\n      logger.log(\"parsed codec:\" + track.codec + \", rate:\" + config.samplerate + \", channels:\" + config.channelCount);\n    }\n  }\n  function getFrameDuration(samplerate) {\n    return 1024 * 90000 / samplerate;\n  }\n  function parseFrameHeader(data, offset) {\n    // The protection skip bit tells us if we have 2 bytes of CRC data at the end of the ADTS header\n    var headerLength = getHeaderLength(data, offset);\n    if (offset + headerLength <= data.length) {\n      // retrieve frame size\n      var frameLength = getFullFrameLength(data, offset) - headerLength;\n      if (frameLength > 0) {\n        // logger.log(`AAC frame, offset/length/total/pts:${offset+headerLength}/${frameLength}/${data.byteLength}`);\n        return {\n          headerLength: headerLength,\n          frameLength: frameLength\n        };\n      }\n    }\n  }\n  function appendFrame$1(track, data, offset, pts, frameIndex) {\n    var frameDuration = getFrameDuration(track.samplerate);\n    var stamp = pts + frameIndex * frameDuration;\n    var header = parseFrameHeader(data, offset);\n    var unit;\n    if (header) {\n      var frameLength = header.frameLength,\n        headerLength = header.headerLength;\n      var _length = headerLength + frameLength;\n      var missing = Math.max(0, offset + _length - data.length);\n      // logger.log(`AAC frame ${frameIndex}, pts:${stamp} length@offset/total: ${frameLength}@${offset+headerLength}/${data.byteLength} missing: ${missing}`);\n      if (missing) {\n        unit = new Uint8Array(_length - headerLength);\n        unit.set(data.subarray(offset + headerLength, data.length), 0);\n      } else {\n        unit = data.subarray(offset + headerLength, offset + _length);\n      }\n      var _sample = {\n        unit: unit,\n        pts: stamp\n      };\n      if (!missing) {\n        track.samples.push(_sample);\n      }\n      return {\n        sample: _sample,\n        length: _length,\n        missing: missing\n      };\n    }\n    // overflow incomplete header\n    var length = data.length - offset;\n    unit = new Uint8Array(length);\n    unit.set(data.subarray(offset, data.length), 0);\n    var sample = {\n      unit: unit,\n      pts: stamp\n    };\n    return {\n      sample: sample,\n      length: length,\n      missing: -1\n    };\n  }\n\n  /**\n   *  MPEG parser helper\n   */\n\n  var chromeVersion$1 = null;\n  var BitratesMap = [32, 64, 96, 128, 160, 192, 224, 256, 288, 320, 352, 384, 416, 448, 32, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 384, 32, 40, 48, 56, 64, 80, 96, 112, 128, 160, 192, 224, 256, 320, 32, 48, 56, 64, 80, 96, 112, 128, 144, 160, 176, 192, 224, 256, 8, 16, 24, 32, 40, 48, 56, 64, 80, 96, 112, 128, 144, 160];\n  var SamplingRateMap = [44100, 48000, 32000, 22050, 24000, 16000, 11025, 12000, 8000];\n  var SamplesCoefficients = [\n  // MPEG 2.5\n  [0,\n  // Reserved\n  72,\n  // Layer3\n  144,\n  // Layer2\n  12 // Layer1\n  ],\n  // Reserved\n  [0,\n  // Reserved\n  0,\n  // Layer3\n  0,\n  // Layer2\n  0 // Layer1\n  ],\n  // MPEG 2\n  [0,\n  // Reserved\n  72,\n  // Layer3\n  144,\n  // Layer2\n  12 // Layer1\n  ],\n  // MPEG 1\n  [0,\n  // Reserved\n  144,\n  // Layer3\n  144,\n  // Layer2\n  12 // Layer1\n  ]];\n  var BytesInSlot = [0,\n  // Reserved\n  1,\n  // Layer3\n  1,\n  // Layer2\n  4 // Layer1\n  ];\n  function appendFrame(track, data, offset, pts, frameIndex) {\n    // Using http://www.datavoyage.com/mpgscript/mpeghdr.htm as a reference\n    if (offset + 24 > data.length) {\n      return;\n    }\n    var header = parseHeader(data, offset);\n    if (header && offset + header.frameLength <= data.length) {\n      var frameDuration = header.samplesPerFrame * 90000 / header.sampleRate;\n      var stamp = pts + frameIndex * frameDuration;\n      var sample = {\n        unit: data.subarray(offset, offset + header.frameLength),\n        pts: stamp,\n        dts: stamp\n      };\n      track.config = [];\n      track.channelCount = header.channelCount;\n      track.samplerate = header.sampleRate;\n      track.samples.push(sample);\n      return {\n        sample: sample,\n        length: header.frameLength,\n        missing: 0\n      };\n    }\n  }\n  function parseHeader(data, offset) {\n    var mpegVersion = data[offset + 1] >> 3 & 3;\n    var mpegLayer = data[offset + 1] >> 1 & 3;\n    var bitRateIndex = data[offset + 2] >> 4 & 15;\n    var sampleRateIndex = data[offset + 2] >> 2 & 3;\n    if (mpegVersion !== 1 && bitRateIndex !== 0 && bitRateIndex !== 15 && sampleRateIndex !== 3) {\n      var paddingBit = data[offset + 2] >> 1 & 1;\n      var channelMode = data[offset + 3] >> 6;\n      var columnInBitrates = mpegVersion === 3 ? 3 - mpegLayer : mpegLayer === 3 ? 3 : 4;\n      var bitRate = BitratesMap[columnInBitrates * 14 + bitRateIndex - 1] * 1000;\n      var columnInSampleRates = mpegVersion === 3 ? 0 : mpegVersion === 2 ? 1 : 2;\n      var sampleRate = SamplingRateMap[columnInSampleRates * 3 + sampleRateIndex];\n      var channelCount = channelMode === 3 ? 1 : 2; // If bits of channel mode are `11` then it is a single channel (Mono)\n      var sampleCoefficient = SamplesCoefficients[mpegVersion][mpegLayer];\n      var bytesInSlot = BytesInSlot[mpegLayer];\n      var samplesPerFrame = sampleCoefficient * 8 * bytesInSlot;\n      var frameLength = Math.floor(sampleCoefficient * bitRate / sampleRate + paddingBit) * bytesInSlot;\n      if (chromeVersion$1 === null) {\n        var userAgent = navigator.userAgent || '';\n        var result = userAgent.match(/Chrome\\/(\\d+)/i);\n        chromeVersion$1 = result ? parseInt(result[1]) : 0;\n      }\n      var needChromeFix = !!chromeVersion$1 && chromeVersion$1 <= 87;\n      if (needChromeFix && mpegLayer === 2 && bitRate >= 224000 && channelMode === 0) {\n        // Work around bug in Chromium by setting channelMode to dual-channel (01) instead of stereo (00)\n        data[offset + 3] = data[offset + 3] | 0x80;\n      }\n      return {\n        sampleRate: sampleRate,\n        channelCount: channelCount,\n        frameLength: frameLength,\n        samplesPerFrame: samplesPerFrame\n      };\n    }\n  }\n  function isHeaderPattern(data, offset) {\n    return data[offset] === 0xff && (data[offset + 1] & 0xe0) === 0xe0 && (data[offset + 1] & 0x06) !== 0x00;\n  }\n  function isHeader(data, offset) {\n    // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1\n    // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)\n    // More info http://www.mp3-tech.org/programmer/frame_header.html\n    return offset + 1 < data.length && isHeaderPattern(data, offset);\n  }\n  function canParse(data, offset) {\n    var headerSize = 4;\n    return isHeaderPattern(data, offset) && headerSize <= data.length - offset;\n  }\n  function probe(data, offset) {\n    // same as isHeader but we also check that MPEG frame follows last MPEG frame\n    // or end of data is reached\n    if (offset + 1 < data.length && isHeaderPattern(data, offset)) {\n      // MPEG header Length\n      var headerLength = 4;\n      // MPEG frame Length\n      var header = parseHeader(data, offset);\n      var frameLength = headerLength;\n      if (header != null && header.frameLength) {\n        frameLength = header.frameLength;\n      }\n      var newOffset = offset + frameLength;\n      return newOffset === data.length || isHeader(data, newOffset);\n    }\n    return false;\n  }\n\n  var AACDemuxer = /*#__PURE__*/function (_BaseAudioDemuxer) {\n    _inheritsLoose(AACDemuxer, _BaseAudioDemuxer);\n    function AACDemuxer(observer, config) {\n      var _this;\n      _this = _BaseAudioDemuxer.call(this) || this;\n      _this.observer = void 0;\n      _this.config = void 0;\n      _this.observer = observer;\n      _this.config = config;\n      return _this;\n    }\n    var _proto = AACDemuxer.prototype;\n    _proto.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n      _BaseAudioDemuxer.prototype.resetInitSegment.call(this, initSegment, audioCodec, videoCodec, trackDuration);\n      this._audioTrack = {\n        container: 'audio/adts',\n        type: 'audio',\n        id: 2,\n        pid: -1,\n        sequenceNumber: 0,\n        segmentCodec: 'aac',\n        samples: [],\n        manifestCodec: audioCodec,\n        duration: trackDuration,\n        inputTimeScale: 90000,\n        dropped: 0\n      };\n    }\n\n    // Source for probe info - https://wiki.multimedia.cx/index.php?title=ADTS\n    ;\n    AACDemuxer.probe = function probe$2(data) {\n      if (!data) {\n        return false;\n      }\n\n      // Check for the ADTS sync word\n      // Look for ADTS header | 1111 1111 | 1111 X00X | where X can be either 0 or 1\n      // Layer bits (position 14 and 15) in header should be always 0 for ADTS\n      // More info https://wiki.multimedia.cx/index.php?title=ADTS\n      var id3Data = getID3Data(data, 0);\n      var offset = (id3Data == null ? void 0 : id3Data.length) || 0;\n      if (probe(data, offset)) {\n        return false;\n      }\n      for (var length = data.length; offset < length; offset++) {\n        if (probe$1(data, offset)) {\n          logger.log('ADTS sync word found !');\n          return true;\n        }\n      }\n      return false;\n    };\n    _proto.canParse = function canParse(data, offset) {\n      return canParse$1(data, offset);\n    };\n    _proto.appendFrame = function appendFrame(track, data, offset) {\n      initTrackConfig(track, this.observer, data, offset, track.manifestCodec);\n      var frame = appendFrame$1(track, data, offset, this.basePTS, this.frameIndex);\n      if (frame && frame.missing === 0) {\n        return frame;\n      }\n    };\n    return AACDemuxer;\n  }(BaseAudioDemuxer);\n\n  var emsgSchemePattern = /\\/emsg[-/]ID3/i;\n  var MP4Demuxer = /*#__PURE__*/function () {\n    function MP4Demuxer(observer, config) {\n      this.remainderData = null;\n      this.timeOffset = 0;\n      this.config = void 0;\n      this.videoTrack = void 0;\n      this.audioTrack = void 0;\n      this.id3Track = void 0;\n      this.txtTrack = void 0;\n      this.config = config;\n    }\n    var _proto = MP4Demuxer.prototype;\n    _proto.resetTimeStamp = function resetTimeStamp() {};\n    _proto.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n      var videoTrack = this.videoTrack = dummyTrack('video', 1);\n      var audioTrack = this.audioTrack = dummyTrack('audio', 1);\n      var captionTrack = this.txtTrack = dummyTrack('text', 1);\n      this.id3Track = dummyTrack('id3', 1);\n      this.timeOffset = 0;\n      if (!(initSegment != null && initSegment.byteLength)) {\n        return;\n      }\n      var initData = parseInitSegment(initSegment);\n      if (initData.video) {\n        var _initData$video = initData.video,\n          id = _initData$video.id,\n          timescale = _initData$video.timescale,\n          codec = _initData$video.codec;\n        videoTrack.id = id;\n        videoTrack.timescale = captionTrack.timescale = timescale;\n        videoTrack.codec = codec;\n      }\n      if (initData.audio) {\n        var _initData$audio = initData.audio,\n          _id = _initData$audio.id,\n          _timescale = _initData$audio.timescale,\n          _codec = _initData$audio.codec;\n        audioTrack.id = _id;\n        audioTrack.timescale = _timescale;\n        audioTrack.codec = _codec;\n      }\n      captionTrack.id = RemuxerTrackIdConfig.text;\n      videoTrack.sampleDuration = 0;\n      videoTrack.duration = audioTrack.duration = trackDuration;\n    };\n    _proto.resetContiguity = function resetContiguity() {\n      this.remainderData = null;\n    };\n    MP4Demuxer.probe = function probe(data) {\n      return hasMoofData(data);\n    };\n    _proto.demux = function demux(data, timeOffset) {\n      this.timeOffset = timeOffset;\n      // Load all data into the avc track. The CMAF remuxer will look for the data in the samples object; the rest of the fields do not matter\n      var videoSamples = data;\n      var videoTrack = this.videoTrack;\n      var textTrack = this.txtTrack;\n      if (this.config.progressive) {\n        // Split the bytestream into two ranges: one encompassing all data up until the start of the last moof, and everything else.\n        // This is done to guarantee that we're sending valid data to MSE - when demuxing progressively, we have no guarantee\n        // that the fetch loader gives us flush moof+mdat pairs. If we push jagged data to MSE, it will throw an exception.\n        if (this.remainderData) {\n          videoSamples = appendUint8Array(this.remainderData, data);\n        }\n        var segmentedData = segmentValidRange(videoSamples);\n        this.remainderData = segmentedData.remainder;\n        videoTrack.samples = segmentedData.valid || new Uint8Array();\n      } else {\n        videoTrack.samples = videoSamples;\n      }\n      var id3Track = this.extractID3Track(videoTrack, timeOffset);\n      textTrack.samples = parseSamples(timeOffset, videoTrack);\n      return {\n        videoTrack: videoTrack,\n        audioTrack: this.audioTrack,\n        id3Track: id3Track,\n        textTrack: this.txtTrack\n      };\n    };\n    _proto.flush = function flush() {\n      var timeOffset = this.timeOffset;\n      var videoTrack = this.videoTrack;\n      var textTrack = this.txtTrack;\n      videoTrack.samples = this.remainderData || new Uint8Array();\n      this.remainderData = null;\n      var id3Track = this.extractID3Track(videoTrack, this.timeOffset);\n      textTrack.samples = parseSamples(timeOffset, videoTrack);\n      return {\n        videoTrack: videoTrack,\n        audioTrack: dummyTrack(),\n        id3Track: id3Track,\n        textTrack: dummyTrack()\n      };\n    };\n    _proto.extractID3Track = function extractID3Track(videoTrack, timeOffset) {\n      var id3Track = this.id3Track;\n      if (videoTrack.samples.length) {\n        var emsgs = findBox(videoTrack.samples, ['emsg']);\n        if (emsgs) {\n          emsgs.forEach(function (data) {\n            var emsgInfo = parseEmsg(data);\n            if (emsgSchemePattern.test(emsgInfo.schemeIdUri)) {\n              var pts = isFiniteNumber(emsgInfo.presentationTime) ? emsgInfo.presentationTime / emsgInfo.timeScale : timeOffset + emsgInfo.presentationTimeDelta / emsgInfo.timeScale;\n              var duration = emsgInfo.eventDuration === 0xffffffff ? Number.POSITIVE_INFINITY : emsgInfo.eventDuration / emsgInfo.timeScale;\n              // Safari takes anything <= 0.001 seconds and maps it to Infinity\n              if (duration <= 0.001) {\n                duration = Number.POSITIVE_INFINITY;\n              }\n              var payload = emsgInfo.payload;\n              id3Track.samples.push({\n                data: payload,\n                len: payload.byteLength,\n                dts: pts,\n                pts: pts,\n                type: MetadataSchema.emsg,\n                duration: duration\n              });\n            }\n          });\n        }\n      }\n      return id3Track;\n    };\n    _proto.demuxSampleAes = function demuxSampleAes(data, keyData, timeOffset) {\n      return Promise.reject(new Error('The MP4 demuxer does not support SAMPLE-AES decryption'));\n    };\n    _proto.destroy = function destroy() {};\n    return MP4Demuxer;\n  }();\n\n  var getAudioBSID = function getAudioBSID(data, offset) {\n    // check the bsid to confirm ac-3 | ec-3\n    var bsid = 0;\n    var numBits = 5;\n    offset += numBits;\n    var temp = new Uint32Array(1); // unsigned 32 bit for temporary storage\n    var mask = new Uint32Array(1); // unsigned 32 bit mask value\n    var _byte = new Uint8Array(1); // unsigned 8 bit for temporary storage\n    while (numBits > 0) {\n      _byte[0] = data[offset];\n      // read remaining bits, upto 8 bits at a time\n      var bits = Math.min(numBits, 8);\n      var shift = 8 - bits;\n      mask[0] = 0xff000000 >>> 24 + shift << shift;\n      temp[0] = (_byte[0] & mask[0]) >> shift;\n      bsid = !bsid ? temp[0] : bsid << bits | temp[0];\n      offset += 1;\n      numBits -= bits;\n    }\n    return bsid;\n  };\n\n  var AC3Demuxer = /*#__PURE__*/function (_BaseAudioDemuxer) {\n    _inheritsLoose(AC3Demuxer, _BaseAudioDemuxer);\n    function AC3Demuxer(observer) {\n      var _this;\n      _this = _BaseAudioDemuxer.call(this) || this;\n      _this.observer = void 0;\n      _this.observer = observer;\n      return _this;\n    }\n    var _proto = AC3Demuxer.prototype;\n    _proto.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n      _BaseAudioDemuxer.prototype.resetInitSegment.call(this, initSegment, audioCodec, videoCodec, trackDuration);\n      this._audioTrack = {\n        container: 'audio/ac-3',\n        type: 'audio',\n        id: 2,\n        pid: -1,\n        sequenceNumber: 0,\n        segmentCodec: 'ac3',\n        samples: [],\n        manifestCodec: audioCodec,\n        duration: trackDuration,\n        inputTimeScale: 90000,\n        dropped: 0\n      };\n    };\n    _proto.canParse = function canParse(data, offset) {\n      return offset + 64 < data.length;\n    };\n    _proto.appendFrame = function appendFrame(track, data, offset) {\n      var frameLength = _appendFrame(track, data, offset, this.basePTS, this.frameIndex);\n      if (frameLength !== -1) {\n        var sample = track.samples[track.samples.length - 1];\n        return {\n          sample: sample,\n          length: frameLength,\n          missing: 0\n        };\n      }\n    };\n    AC3Demuxer.probe = function probe(data) {\n      if (!data) {\n        return false;\n      }\n      var id3Data = getID3Data(data, 0);\n      if (!id3Data) {\n        return false;\n      }\n\n      // look for the ac-3 sync bytes\n      var offset = id3Data.length;\n      if (data[offset] === 0x0b && data[offset + 1] === 0x77 && getTimeStamp(id3Data) !== undefined &&\n      // check the bsid to confirm ac-3\n      getAudioBSID(data, offset) < 16) {\n        return true;\n      }\n      return false;\n    };\n    return AC3Demuxer;\n  }(BaseAudioDemuxer);\n  function _appendFrame(track, data, start, pts, frameIndex) {\n    if (start + 8 > data.length) {\n      return -1; // not enough bytes left\n    }\n    if (data[start] !== 0x0b || data[start + 1] !== 0x77) {\n      return -1; // invalid magic\n    }\n\n    // get sample rate\n    var samplingRateCode = data[start + 4] >> 6;\n    if (samplingRateCode >= 3) {\n      return -1; // invalid sampling rate\n    }\n    var samplingRateMap = [48000, 44100, 32000];\n    var sampleRate = samplingRateMap[samplingRateCode];\n\n    // get frame size\n    var frameSizeCode = data[start + 4] & 0x3f;\n    var frameSizeMap = [64, 69, 96, 64, 70, 96, 80, 87, 120, 80, 88, 120, 96, 104, 144, 96, 105, 144, 112, 121, 168, 112, 122, 168, 128, 139, 192, 128, 140, 192, 160, 174, 240, 160, 175, 240, 192, 208, 288, 192, 209, 288, 224, 243, 336, 224, 244, 336, 256, 278, 384, 256, 279, 384, 320, 348, 480, 320, 349, 480, 384, 417, 576, 384, 418, 576, 448, 487, 672, 448, 488, 672, 512, 557, 768, 512, 558, 768, 640, 696, 960, 640, 697, 960, 768, 835, 1152, 768, 836, 1152, 896, 975, 1344, 896, 976, 1344, 1024, 1114, 1536, 1024, 1115, 1536, 1152, 1253, 1728, 1152, 1254, 1728, 1280, 1393, 1920, 1280, 1394, 1920];\n    var frameLength = frameSizeMap[frameSizeCode * 3 + samplingRateCode] * 2;\n    if (start + frameLength > data.length) {\n      return -1;\n    }\n\n    // get channel count\n    var channelMode = data[start + 6] >> 5;\n    var skipCount = 0;\n    if (channelMode === 2) {\n      skipCount += 2;\n    } else {\n      if (channelMode & 1 && channelMode !== 1) {\n        skipCount += 2;\n      }\n      if (channelMode & 4) {\n        skipCount += 2;\n      }\n    }\n    var lfeon = (data[start + 6] << 8 | data[start + 7]) >> 12 - skipCount & 1;\n    var channelsMap = [2, 1, 2, 3, 3, 4, 4, 5];\n    var channelCount = channelsMap[channelMode] + lfeon;\n\n    // build dac3 box\n    var bsid = data[start + 5] >> 3;\n    var bsmod = data[start + 5] & 7;\n    var config = new Uint8Array([samplingRateCode << 6 | bsid << 1 | bsmod >> 2, (bsmod & 3) << 6 | channelMode << 3 | lfeon << 2 | frameSizeCode >> 4, frameSizeCode << 4 & 0xe0]);\n    var frameDuration = 1536 / sampleRate * 90000;\n    var stamp = pts + frameIndex * frameDuration;\n    var unit = data.subarray(start, start + frameLength);\n    track.config = config;\n    track.channelCount = channelCount;\n    track.samplerate = sampleRate;\n    track.samples.push({\n      unit: unit,\n      pts: stamp\n    });\n    return frameLength;\n  }\n\n  var BaseVideoParser = /*#__PURE__*/function () {\n    function BaseVideoParser() {\n      this.VideoSample = null;\n    }\n    var _proto = BaseVideoParser.prototype;\n    _proto.createVideoSample = function createVideoSample(key, pts, dts, debug) {\n      return {\n        key: key,\n        frame: false,\n        pts: pts,\n        dts: dts,\n        units: [],\n        debug: debug,\n        length: 0\n      };\n    };\n    _proto.getLastNalUnit = function getLastNalUnit(samples) {\n      var _VideoSample;\n      var VideoSample = this.VideoSample;\n      var lastUnit;\n      // try to fallback to previous sample if current one is empty\n      if (!VideoSample || VideoSample.units.length === 0) {\n        VideoSample = samples[samples.length - 1];\n      }\n      if ((_VideoSample = VideoSample) != null && _VideoSample.units) {\n        var units = VideoSample.units;\n        lastUnit = units[units.length - 1];\n      }\n      return lastUnit;\n    };\n    _proto.pushAccessUnit = function pushAccessUnit(VideoSample, videoTrack) {\n      if (VideoSample.units.length && VideoSample.frame) {\n        // if sample does not have PTS/DTS, patch with last sample PTS/DTS\n        if (VideoSample.pts === undefined) {\n          var samples = videoTrack.samples;\n          var nbSamples = samples.length;\n          if (nbSamples) {\n            var lastSample = samples[nbSamples - 1];\n            VideoSample.pts = lastSample.pts;\n            VideoSample.dts = lastSample.dts;\n          } else {\n            // dropping samples, no timestamp found\n            videoTrack.dropped++;\n            return;\n          }\n        }\n        videoTrack.samples.push(VideoSample);\n      }\n      if (VideoSample.debug.length) {\n        logger.log(VideoSample.pts + '/' + VideoSample.dts + ':' + VideoSample.debug);\n      }\n    };\n    return BaseVideoParser;\n  }();\n\n  /**\n   * Parser for exponential Golomb codes, a variable-bitwidth number encoding scheme used by h264.\n   */\n\n  var ExpGolomb = /*#__PURE__*/function () {\n    function ExpGolomb(data) {\n      this.data = void 0;\n      this.bytesAvailable = void 0;\n      this.word = void 0;\n      this.bitsAvailable = void 0;\n      this.data = data;\n      // the number of bytes left to examine in this.data\n      this.bytesAvailable = data.byteLength;\n      // the current word being examined\n      this.word = 0; // :uint\n      // the number of bits left to examine in the current word\n      this.bitsAvailable = 0; // :uint\n    }\n\n    // ():void\n    var _proto = ExpGolomb.prototype;\n    _proto.loadWord = function loadWord() {\n      var data = this.data;\n      var bytesAvailable = this.bytesAvailable;\n      var position = data.byteLength - bytesAvailable;\n      var workingBytes = new Uint8Array(4);\n      var availableBytes = Math.min(4, bytesAvailable);\n      if (availableBytes === 0) {\n        throw new Error('no bytes available');\n      }\n      workingBytes.set(data.subarray(position, position + availableBytes));\n      this.word = new DataView(workingBytes.buffer).getUint32(0);\n      // track the amount of this.data that has been processed\n      this.bitsAvailable = availableBytes * 8;\n      this.bytesAvailable -= availableBytes;\n    }\n\n    // (count:int):void\n    ;\n    _proto.skipBits = function skipBits(count) {\n      var skipBytes; // :int\n      count = Math.min(count, this.bytesAvailable * 8 + this.bitsAvailable);\n      if (this.bitsAvailable > count) {\n        this.word <<= count;\n        this.bitsAvailable -= count;\n      } else {\n        count -= this.bitsAvailable;\n        skipBytes = count >> 3;\n        count -= skipBytes << 3;\n        this.bytesAvailable -= skipBytes;\n        this.loadWord();\n        this.word <<= count;\n        this.bitsAvailable -= count;\n      }\n    }\n\n    // (size:int):uint\n    ;\n    _proto.readBits = function readBits(size) {\n      var bits = Math.min(this.bitsAvailable, size); // :uint\n      var valu = this.word >>> 32 - bits; // :uint\n      if (size > 32) {\n        logger.error('Cannot read more than 32 bits at a time');\n      }\n      this.bitsAvailable -= bits;\n      if (this.bitsAvailable > 0) {\n        this.word <<= bits;\n      } else if (this.bytesAvailable > 0) {\n        this.loadWord();\n      } else {\n        throw new Error('no bits available');\n      }\n      bits = size - bits;\n      if (bits > 0 && this.bitsAvailable) {\n        return valu << bits | this.readBits(bits);\n      } else {\n        return valu;\n      }\n    }\n\n    // ():uint\n    ;\n    _proto.skipLZ = function skipLZ() {\n      var leadingZeroCount; // :uint\n      for (leadingZeroCount = 0; leadingZeroCount < this.bitsAvailable; ++leadingZeroCount) {\n        if ((this.word & 0x80000000 >>> leadingZeroCount) !== 0) {\n          // the first bit of working word is 1\n          this.word <<= leadingZeroCount;\n          this.bitsAvailable -= leadingZeroCount;\n          return leadingZeroCount;\n        }\n      }\n      // we exhausted word and still have not found a 1\n      this.loadWord();\n      return leadingZeroCount + this.skipLZ();\n    }\n\n    // ():void\n    ;\n    _proto.skipUEG = function skipUEG() {\n      this.skipBits(1 + this.skipLZ());\n    }\n\n    // ():void\n    ;\n    _proto.skipEG = function skipEG() {\n      this.skipBits(1 + this.skipLZ());\n    }\n\n    // ():uint\n    ;\n    _proto.readUEG = function readUEG() {\n      var clz = this.skipLZ(); // :uint\n      return this.readBits(clz + 1) - 1;\n    }\n\n    // ():int\n    ;\n    _proto.readEG = function readEG() {\n      var valu = this.readUEG(); // :int\n      if (0x01 & valu) {\n        // the number is odd if the low order bit is set\n        return 1 + valu >>> 1; // add 1 to make it even, and divide by 2\n      } else {\n        return -1 * (valu >>> 1); // divide by two then make it negative\n      }\n    }\n\n    // Some convenience functions\n    // :Boolean\n    ;\n    _proto.readBoolean = function readBoolean() {\n      return this.readBits(1) === 1;\n    }\n\n    // ():int\n    ;\n    _proto.readUByte = function readUByte() {\n      return this.readBits(8);\n    }\n\n    // ():int\n    ;\n    _proto.readUShort = function readUShort() {\n      return this.readBits(16);\n    }\n\n    // ():int\n    ;\n    _proto.readUInt = function readUInt() {\n      return this.readBits(32);\n    }\n\n    /**\n     * Advance the ExpGolomb decoder past a scaling list. The scaling\n     * list is optionally transmitted as part of a sequence parameter\n     * set and is not relevant to transmuxing.\n     * @param count the number of entries in this scaling list\n     * @see Recommendation ITU-T H.264, Section 7.3.2.1.1.1\n     */;\n    _proto.skipScalingList = function skipScalingList(count) {\n      var lastScale = 8;\n      var nextScale = 8;\n      var deltaScale;\n      for (var j = 0; j < count; j++) {\n        if (nextScale !== 0) {\n          deltaScale = this.readEG();\n          nextScale = (lastScale + deltaScale + 256) % 256;\n        }\n        lastScale = nextScale === 0 ? lastScale : nextScale;\n      }\n    }\n\n    /**\n     * Read a sequence parameter set and return some interesting video\n     * properties. A sequence parameter set is the H264 metadata that\n     * describes the properties of upcoming video frames.\n     * @returns an object with configuration parsed from the\n     * sequence parameter set, including the dimensions of the\n     * associated video frames.\n     */;\n    _proto.readSPS = function readSPS() {\n      var frameCropLeftOffset = 0;\n      var frameCropRightOffset = 0;\n      var frameCropTopOffset = 0;\n      var frameCropBottomOffset = 0;\n      var numRefFramesInPicOrderCntCycle;\n      var scalingListCount;\n      var i;\n      var readUByte = this.readUByte.bind(this);\n      var readBits = this.readBits.bind(this);\n      var readUEG = this.readUEG.bind(this);\n      var readBoolean = this.readBoolean.bind(this);\n      var skipBits = this.skipBits.bind(this);\n      var skipEG = this.skipEG.bind(this);\n      var skipUEG = this.skipUEG.bind(this);\n      var skipScalingList = this.skipScalingList.bind(this);\n      readUByte();\n      var profileIdc = readUByte(); // profile_idc\n      readBits(5); // profileCompat constraint_set[0-4]_flag, u(5)\n      skipBits(3); // reserved_zero_3bits u(3),\n      readUByte(); // level_idc u(8)\n      skipUEG(); // seq_parameter_set_id\n      // some profiles have more optional data we don't need\n      if (profileIdc === 100 || profileIdc === 110 || profileIdc === 122 || profileIdc === 244 || profileIdc === 44 || profileIdc === 83 || profileIdc === 86 || profileIdc === 118 || profileIdc === 128) {\n        var chromaFormatIdc = readUEG();\n        if (chromaFormatIdc === 3) {\n          skipBits(1);\n        } // separate_colour_plane_flag\n\n        skipUEG(); // bit_depth_luma_minus8\n        skipUEG(); // bit_depth_chroma_minus8\n        skipBits(1); // qpprime_y_zero_transform_bypass_flag\n        if (readBoolean()) {\n          // seq_scaling_matrix_present_flag\n          scalingListCount = chromaFormatIdc !== 3 ? 8 : 12;\n          for (i = 0; i < scalingListCount; i++) {\n            if (readBoolean()) {\n              // seq_scaling_list_present_flag[ i ]\n              if (i < 6) {\n                skipScalingList(16);\n              } else {\n                skipScalingList(64);\n              }\n            }\n          }\n        }\n      }\n      skipUEG(); // log2_max_frame_num_minus4\n      var picOrderCntType = readUEG();\n      if (picOrderCntType === 0) {\n        readUEG(); // log2_max_pic_order_cnt_lsb_minus4\n      } else if (picOrderCntType === 1) {\n        skipBits(1); // delta_pic_order_always_zero_flag\n        skipEG(); // offset_for_non_ref_pic\n        skipEG(); // offset_for_top_to_bottom_field\n        numRefFramesInPicOrderCntCycle = readUEG();\n        for (i = 0; i < numRefFramesInPicOrderCntCycle; i++) {\n          skipEG();\n        } // offset_for_ref_frame[ i ]\n      }\n      skipUEG(); // max_num_ref_frames\n      skipBits(1); // gaps_in_frame_num_value_allowed_flag\n      var picWidthInMbsMinus1 = readUEG();\n      var picHeightInMapUnitsMinus1 = readUEG();\n      var frameMbsOnlyFlag = readBits(1);\n      if (frameMbsOnlyFlag === 0) {\n        skipBits(1);\n      } // mb_adaptive_frame_field_flag\n\n      skipBits(1); // direct_8x8_inference_flag\n      if (readBoolean()) {\n        // frame_cropping_flag\n        frameCropLeftOffset = readUEG();\n        frameCropRightOffset = readUEG();\n        frameCropTopOffset = readUEG();\n        frameCropBottomOffset = readUEG();\n      }\n      var pixelRatio = [1, 1];\n      if (readBoolean()) {\n        // vui_parameters_present_flag\n        if (readBoolean()) {\n          // aspect_ratio_info_present_flag\n          var aspectRatioIdc = readUByte();\n          switch (aspectRatioIdc) {\n            case 1:\n              pixelRatio = [1, 1];\n              break;\n            case 2:\n              pixelRatio = [12, 11];\n              break;\n            case 3:\n              pixelRatio = [10, 11];\n              break;\n            case 4:\n              pixelRatio = [16, 11];\n              break;\n            case 5:\n              pixelRatio = [40, 33];\n              break;\n            case 6:\n              pixelRatio = [24, 11];\n              break;\n            case 7:\n              pixelRatio = [20, 11];\n              break;\n            case 8:\n              pixelRatio = [32, 11];\n              break;\n            case 9:\n              pixelRatio = [80, 33];\n              break;\n            case 10:\n              pixelRatio = [18, 11];\n              break;\n            case 11:\n              pixelRatio = [15, 11];\n              break;\n            case 12:\n              pixelRatio = [64, 33];\n              break;\n            case 13:\n              pixelRatio = [160, 99];\n              break;\n            case 14:\n              pixelRatio = [4, 3];\n              break;\n            case 15:\n              pixelRatio = [3, 2];\n              break;\n            case 16:\n              pixelRatio = [2, 1];\n              break;\n            case 255:\n              {\n                pixelRatio = [readUByte() << 8 | readUByte(), readUByte() << 8 | readUByte()];\n                break;\n              }\n          }\n        }\n      }\n      return {\n        width: Math.ceil((picWidthInMbsMinus1 + 1) * 16 - frameCropLeftOffset * 2 - frameCropRightOffset * 2),\n        height: (2 - frameMbsOnlyFlag) * (picHeightInMapUnitsMinus1 + 1) * 16 - (frameMbsOnlyFlag ? 2 : 4) * (frameCropTopOffset + frameCropBottomOffset),\n        pixelRatio: pixelRatio\n      };\n    };\n    _proto.readSliceType = function readSliceType() {\n      // skip NALu type\n      this.readUByte();\n      // discard first_mb_in_slice\n      this.readUEG();\n      // return slice_type\n      return this.readUEG();\n    };\n    return ExpGolomb;\n  }();\n\n  var AvcVideoParser = /*#__PURE__*/function (_BaseVideoParser) {\n    _inheritsLoose(AvcVideoParser, _BaseVideoParser);\n    function AvcVideoParser() {\n      return _BaseVideoParser.apply(this, arguments) || this;\n    }\n    var _proto = AvcVideoParser.prototype;\n    _proto.parseAVCPES = function parseAVCPES(track, textTrack, pes, last, duration) {\n      var _this = this;\n      var units = this.parseAVCNALu(track, pes.data);\n      var VideoSample = this.VideoSample;\n      var push;\n      var spsfound = false;\n      // free pes.data to save up some memory\n      pes.data = null;\n\n      // if new NAL units found and last sample still there, let's push ...\n      // this helps parsing streams with missing AUD (only do this if AUD never found)\n      if (VideoSample && units.length && !track.audFound) {\n        this.pushAccessUnit(VideoSample, track);\n        VideoSample = this.VideoSample = this.createVideoSample(false, pes.pts, pes.dts, '');\n      }\n      units.forEach(function (unit) {\n        var _VideoSample2;\n        switch (unit.type) {\n          // NDR\n          case 1:\n            {\n              var iskey = false;\n              push = true;\n              var data = unit.data;\n              // only check slice type to detect KF in case SPS found in same packet (any keyframe is preceded by SPS ...)\n              if (spsfound && data.length > 4) {\n                // retrieve slice type by parsing beginning of NAL unit (follow H264 spec, slice_header definition) to detect keyframe embedded in NDR\n                var sliceType = new ExpGolomb(data).readSliceType();\n                // 2 : I slice, 4 : SI slice, 7 : I slice, 9: SI slice\n                // SI slice : A slice that is coded using intra prediction only and using quantisation of the prediction samples.\n                // An SI slice can be coded such that its decoded samples can be constructed identically to an SP slice.\n                // I slice: A slice that is not an SI slice that is decoded using intra prediction only.\n                // if (sliceType === 2 || sliceType === 7) {\n                if (sliceType === 2 || sliceType === 4 || sliceType === 7 || sliceType === 9) {\n                  iskey = true;\n                }\n              }\n              if (iskey) {\n                var _VideoSample;\n                // if we have non-keyframe data already, that cannot belong to the same frame as a keyframe, so force a push\n                if ((_VideoSample = VideoSample) != null && _VideoSample.frame && !VideoSample.key) {\n                  _this.pushAccessUnit(VideoSample, track);\n                  VideoSample = _this.VideoSample = null;\n                }\n              }\n              if (!VideoSample) {\n                VideoSample = _this.VideoSample = _this.createVideoSample(true, pes.pts, pes.dts, '');\n              }\n              VideoSample.frame = true;\n              VideoSample.key = iskey;\n              break;\n              // IDR\n            }\n          case 5:\n            push = true;\n            // handle PES not starting with AUD\n            // if we have frame data already, that cannot belong to the same frame, so force a push\n            if ((_VideoSample2 = VideoSample) != null && _VideoSample2.frame && !VideoSample.key) {\n              _this.pushAccessUnit(VideoSample, track);\n              VideoSample = _this.VideoSample = null;\n            }\n            if (!VideoSample) {\n              VideoSample = _this.VideoSample = _this.createVideoSample(true, pes.pts, pes.dts, '');\n            }\n            VideoSample.key = true;\n            VideoSample.frame = true;\n            break;\n          // SEI\n          case 6:\n            {\n              push = true;\n              parseSEIMessageFromNALu(unit.data, 1, pes.pts, textTrack.samples);\n              break;\n              // SPS\n            }\n          case 7:\n            {\n              var _track$pixelRatio, _track$pixelRatio2;\n              push = true;\n              spsfound = true;\n              var sps = unit.data;\n              var expGolombDecoder = new ExpGolomb(sps);\n              var config = expGolombDecoder.readSPS();\n              if (!track.sps || track.width !== config.width || track.height !== config.height || ((_track$pixelRatio = track.pixelRatio) == null ? void 0 : _track$pixelRatio[0]) !== config.pixelRatio[0] || ((_track$pixelRatio2 = track.pixelRatio) == null ? void 0 : _track$pixelRatio2[1]) !== config.pixelRatio[1]) {\n                track.width = config.width;\n                track.height = config.height;\n                track.pixelRatio = config.pixelRatio;\n                track.sps = [sps];\n                track.duration = duration;\n                var codecarray = sps.subarray(1, 4);\n                var codecstring = 'avc1.';\n                for (var i = 0; i < 3; i++) {\n                  var h = codecarray[i].toString(16);\n                  if (h.length < 2) {\n                    h = '0' + h;\n                  }\n                  codecstring += h;\n                }\n                track.codec = codecstring;\n              }\n              break;\n            }\n          // PPS\n          case 8:\n            push = true;\n            track.pps = [unit.data];\n            break;\n          // AUD\n          case 9:\n            push = true;\n            track.audFound = true;\n            if (VideoSample) {\n              _this.pushAccessUnit(VideoSample, track);\n            }\n            VideoSample = _this.VideoSample = _this.createVideoSample(false, pes.pts, pes.dts, '');\n            break;\n          // Filler Data\n          case 12:\n            push = true;\n            break;\n          default:\n            push = false;\n            if (VideoSample) {\n              VideoSample.debug += 'unknown NAL ' + unit.type + ' ';\n            }\n            break;\n        }\n        if (VideoSample && push) {\n          var _units = VideoSample.units;\n          _units.push(unit);\n        }\n      });\n      // if last PES packet, push samples\n      if (last && VideoSample) {\n        this.pushAccessUnit(VideoSample, track);\n        this.VideoSample = null;\n      }\n    };\n    _proto.parseAVCNALu = function parseAVCNALu(track, array) {\n      var len = array.byteLength;\n      var state = track.naluState || 0;\n      var lastState = state;\n      var units = [];\n      var i = 0;\n      var value;\n      var overflow;\n      var unitType;\n      var lastUnitStart = -1;\n      var lastUnitType = 0;\n      // logger.log('PES:' + Hex.hexDump(array));\n\n      if (state === -1) {\n        // special use case where we found 3 or 4-byte start codes exactly at the end of previous PES packet\n        lastUnitStart = 0;\n        // NALu type is value read from offset 0\n        lastUnitType = array[0] & 0x1f;\n        state = 0;\n        i = 1;\n      }\n      while (i < len) {\n        value = array[i++];\n        // optimization. state 0 and 1 are the predominant case. let's handle them outside of the switch/case\n        if (!state) {\n          state = value ? 0 : 1;\n          continue;\n        }\n        if (state === 1) {\n          state = value ? 0 : 2;\n          continue;\n        }\n        // here we have state either equal to 2 or 3\n        if (!value) {\n          state = 3;\n        } else if (value === 1) {\n          overflow = i - state - 1;\n          if (lastUnitStart >= 0) {\n            var unit = {\n              data: array.subarray(lastUnitStart, overflow),\n              type: lastUnitType\n            };\n            // logger.log('pushing NALU, type/size:' + unit.type + '/' + unit.data.byteLength);\n            units.push(unit);\n          } else {\n            // lastUnitStart is undefined => this is the first start code found in this PES packet\n            // first check if start code delimiter is overlapping between 2 PES packets,\n            // ie it started in last packet (lastState not zero)\n            // and ended at the beginning of this PES packet (i <= 4 - lastState)\n            var lastUnit = this.getLastNalUnit(track.samples);\n            if (lastUnit) {\n              if (lastState && i <= 4 - lastState) {\n                // start delimiter overlapping between PES packets\n                // strip start delimiter bytes from the end of last NAL unit\n                // check if lastUnit had a state different from zero\n                if (lastUnit.state) {\n                  // strip last bytes\n                  lastUnit.data = lastUnit.data.subarray(0, lastUnit.data.byteLength - lastState);\n                }\n              }\n              // If NAL units are not starting right at the beginning of the PES packet, push preceding data into previous NAL unit.\n\n              if (overflow > 0) {\n                // logger.log('first NALU found with overflow:' + overflow);\n                lastUnit.data = appendUint8Array(lastUnit.data, array.subarray(0, overflow));\n                lastUnit.state = 0;\n              }\n            }\n          }\n          // check if we can read unit type\n          if (i < len) {\n            unitType = array[i] & 0x1f;\n            // logger.log('find NALU @ offset:' + i + ',type:' + unitType);\n            lastUnitStart = i;\n            lastUnitType = unitType;\n            state = 0;\n          } else {\n            // not enough byte to read unit type. let's read it on next PES parsing\n            state = -1;\n          }\n        } else {\n          state = 0;\n        }\n      }\n      if (lastUnitStart >= 0 && state >= 0) {\n        var _unit = {\n          data: array.subarray(lastUnitStart, len),\n          type: lastUnitType,\n          state: state\n        };\n        units.push(_unit);\n        // logger.log('pushing NALU, type/size/state:' + unit.type + '/' + unit.data.byteLength + '/' + state);\n      }\n      // no NALu found\n      if (units.length === 0) {\n        // append pes.data to previous NAL unit\n        var _lastUnit = this.getLastNalUnit(track.samples);\n        if (_lastUnit) {\n          _lastUnit.data = appendUint8Array(_lastUnit.data, array);\n        }\n      }\n      track.naluState = state;\n      return units;\n    };\n    return AvcVideoParser;\n  }(BaseVideoParser);\n\n  /**\n   * SAMPLE-AES decrypter\n   */\n\n  var SampleAesDecrypter = /*#__PURE__*/function () {\n    function SampleAesDecrypter(observer, config, keyData) {\n      this.keyData = void 0;\n      this.decrypter = void 0;\n      this.keyData = keyData;\n      this.decrypter = new Decrypter(config, {\n        removePKCS7Padding: false\n      });\n    }\n    var _proto = SampleAesDecrypter.prototype;\n    _proto.decryptBuffer = function decryptBuffer(encryptedData) {\n      return this.decrypter.decrypt(encryptedData, this.keyData.key.buffer, this.keyData.iv.buffer);\n    }\n\n    // AAC - encrypt all full 16 bytes blocks starting from offset 16\n    ;\n    _proto.decryptAacSample = function decryptAacSample(samples, sampleIndex, callback) {\n      var _this = this;\n      var curUnit = samples[sampleIndex].unit;\n      if (curUnit.length <= 16) {\n        // No encrypted portion in this sample (first 16 bytes is not\n        // encrypted, see https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/HLS_Sample_Encryption/Encryption/Encryption.html),\n        return;\n      }\n      var encryptedData = curUnit.subarray(16, curUnit.length - curUnit.length % 16);\n      var encryptedBuffer = encryptedData.buffer.slice(encryptedData.byteOffset, encryptedData.byteOffset + encryptedData.length);\n      this.decryptBuffer(encryptedBuffer).then(function (decryptedBuffer) {\n        var decryptedData = new Uint8Array(decryptedBuffer);\n        curUnit.set(decryptedData, 16);\n        if (!_this.decrypter.isSync()) {\n          _this.decryptAacSamples(samples, sampleIndex + 1, callback);\n        }\n      });\n    };\n    _proto.decryptAacSamples = function decryptAacSamples(samples, sampleIndex, callback) {\n      for (;; sampleIndex++) {\n        if (sampleIndex >= samples.length) {\n          callback();\n          return;\n        }\n        if (samples[sampleIndex].unit.length < 32) {\n          continue;\n        }\n        this.decryptAacSample(samples, sampleIndex, callback);\n        if (!this.decrypter.isSync()) {\n          return;\n        }\n      }\n    }\n\n    // AVC - encrypt one 16 bytes block out of ten, starting from offset 32\n    ;\n    _proto.getAvcEncryptedData = function getAvcEncryptedData(decodedData) {\n      var encryptedDataLen = Math.floor((decodedData.length - 48) / 160) * 16 + 16;\n      var encryptedData = new Int8Array(encryptedDataLen);\n      var outputPos = 0;\n      for (var inputPos = 32; inputPos < decodedData.length - 16; inputPos += 160, outputPos += 16) {\n        encryptedData.set(decodedData.subarray(inputPos, inputPos + 16), outputPos);\n      }\n      return encryptedData;\n    };\n    _proto.getAvcDecryptedUnit = function getAvcDecryptedUnit(decodedData, decryptedData) {\n      var uint8DecryptedData = new Uint8Array(decryptedData);\n      var inputPos = 0;\n      for (var outputPos = 32; outputPos < decodedData.length - 16; outputPos += 160, inputPos += 16) {\n        decodedData.set(uint8DecryptedData.subarray(inputPos, inputPos + 16), outputPos);\n      }\n      return decodedData;\n    };\n    _proto.decryptAvcSample = function decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit) {\n      var _this2 = this;\n      var decodedData = discardEPB(curUnit.data);\n      var encryptedData = this.getAvcEncryptedData(decodedData);\n      this.decryptBuffer(encryptedData.buffer).then(function (decryptedBuffer) {\n        curUnit.data = _this2.getAvcDecryptedUnit(decodedData, decryptedBuffer);\n        if (!_this2.decrypter.isSync()) {\n          _this2.decryptAvcSamples(samples, sampleIndex, unitIndex + 1, callback);\n        }\n      });\n    };\n    _proto.decryptAvcSamples = function decryptAvcSamples(samples, sampleIndex, unitIndex, callback) {\n      if (samples instanceof Uint8Array) {\n        throw new Error('Cannot decrypt samples of type Uint8Array');\n      }\n      for (;; sampleIndex++, unitIndex = 0) {\n        if (sampleIndex >= samples.length) {\n          callback();\n          return;\n        }\n        var curUnits = samples[sampleIndex].units;\n        for (;; unitIndex++) {\n          if (unitIndex >= curUnits.length) {\n            break;\n          }\n          var curUnit = curUnits[unitIndex];\n          if (curUnit.data.length <= 48 || curUnit.type !== 1 && curUnit.type !== 5) {\n            continue;\n          }\n          this.decryptAvcSample(samples, sampleIndex, unitIndex, callback, curUnit);\n          if (!this.decrypter.isSync()) {\n            return;\n          }\n        }\n      }\n    };\n    return SampleAesDecrypter;\n  }();\n\n  var PACKET_LENGTH = 188;\n  var TSDemuxer = /*#__PURE__*/function () {\n    function TSDemuxer(observer, config, typeSupported) {\n      this.observer = void 0;\n      this.config = void 0;\n      this.typeSupported = void 0;\n      this.sampleAes = null;\n      this.pmtParsed = false;\n      this.audioCodec = void 0;\n      this.videoCodec = void 0;\n      this._duration = 0;\n      this._pmtId = -1;\n      this._videoTrack = void 0;\n      this._audioTrack = void 0;\n      this._id3Track = void 0;\n      this._txtTrack = void 0;\n      this.aacOverFlow = null;\n      this.remainderData = null;\n      this.videoParser = void 0;\n      this.observer = observer;\n      this.config = config;\n      this.typeSupported = typeSupported;\n      this.videoParser = new AvcVideoParser();\n    }\n    TSDemuxer.probe = function probe(data) {\n      var syncOffset = TSDemuxer.syncOffset(data);\n      if (syncOffset > 0) {\n        logger.warn(\"MPEG2-TS detected but first sync word found @ offset \" + syncOffset);\n      }\n      return syncOffset !== -1;\n    };\n    TSDemuxer.syncOffset = function syncOffset(data) {\n      var length = data.length;\n      var scanwindow = Math.min(PACKET_LENGTH * 5, length - PACKET_LENGTH) + 1;\n      var i = 0;\n      while (i < scanwindow) {\n        // a TS init segment should contain at least 2 TS packets: PAT and PMT, each starting with 0x47\n        var foundPat = false;\n        var packetStart = -1;\n        var tsPackets = 0;\n        for (var j = i; j < length; j += PACKET_LENGTH) {\n          if (data[j] === 0x47 && (length - j === PACKET_LENGTH || data[j + PACKET_LENGTH] === 0x47)) {\n            tsPackets++;\n            if (packetStart === -1) {\n              packetStart = j;\n              // First sync word found at offset, increase scan length (#5251)\n              if (packetStart !== 0) {\n                scanwindow = Math.min(packetStart + PACKET_LENGTH * 99, data.length - PACKET_LENGTH) + 1;\n              }\n            }\n            if (!foundPat) {\n              foundPat = parsePID(data, j) === 0;\n            }\n            // Sync word found at 0 with 3 packets, or found at offset least 2 packets up to scanwindow (#5501)\n            if (foundPat && tsPackets > 1 && (packetStart === 0 && tsPackets > 2 || j + PACKET_LENGTH > scanwindow)) {\n              return packetStart;\n            }\n          } else if (tsPackets) {\n            // Exit if sync word found, but does not contain contiguous packets\n            return -1;\n          } else {\n            break;\n          }\n        }\n        i++;\n      }\n      return -1;\n    }\n\n    /**\n     * Creates a track model internal to demuxer used to drive remuxing input\n     */;\n    TSDemuxer.createTrack = function createTrack(type, duration) {\n      return {\n        container: type === 'video' || type === 'audio' ? 'video/mp2t' : undefined,\n        type: type,\n        id: RemuxerTrackIdConfig[type],\n        pid: -1,\n        inputTimeScale: 90000,\n        sequenceNumber: 0,\n        samples: [],\n        dropped: 0,\n        duration: type === 'audio' ? duration : undefined\n      };\n    }\n\n    /**\n     * Initializes a new init segment on the demuxer/remuxer interface. Needed for discontinuities/track-switches (or at stream start)\n     * Resets all internal track instances of the demuxer.\n     */;\n    var _proto = TSDemuxer.prototype;\n    _proto.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n      this.pmtParsed = false;\n      this._pmtId = -1;\n      this._videoTrack = TSDemuxer.createTrack('video');\n      this._audioTrack = TSDemuxer.createTrack('audio', trackDuration);\n      this._id3Track = TSDemuxer.createTrack('id3');\n      this._txtTrack = TSDemuxer.createTrack('text');\n      this._audioTrack.segmentCodec = 'aac';\n\n      // flush any partial content\n      this.aacOverFlow = null;\n      this.remainderData = null;\n      this.audioCodec = audioCodec;\n      this.videoCodec = videoCodec;\n      this._duration = trackDuration;\n    };\n    _proto.resetTimeStamp = function resetTimeStamp() {};\n    _proto.resetContiguity = function resetContiguity() {\n      var _audioTrack = this._audioTrack,\n        _videoTrack = this._videoTrack,\n        _id3Track = this._id3Track;\n      if (_audioTrack) {\n        _audioTrack.pesData = null;\n      }\n      if (_videoTrack) {\n        _videoTrack.pesData = null;\n      }\n      if (_id3Track) {\n        _id3Track.pesData = null;\n      }\n      this.aacOverFlow = null;\n      this.remainderData = null;\n    };\n    _proto.demux = function demux(data, timeOffset, isSampleAes, flush) {\n      if (isSampleAes === void 0) {\n        isSampleAes = false;\n      }\n      if (flush === void 0) {\n        flush = false;\n      }\n      if (!isSampleAes) {\n        this.sampleAes = null;\n      }\n      var pes;\n      var videoTrack = this._videoTrack;\n      var audioTrack = this._audioTrack;\n      var id3Track = this._id3Track;\n      var textTrack = this._txtTrack;\n      var videoPid = videoTrack.pid;\n      var videoData = videoTrack.pesData;\n      var audioPid = audioTrack.pid;\n      var id3Pid = id3Track.pid;\n      var audioData = audioTrack.pesData;\n      var id3Data = id3Track.pesData;\n      var unknownPID = null;\n      var pmtParsed = this.pmtParsed;\n      var pmtId = this._pmtId;\n      var len = data.length;\n      if (this.remainderData) {\n        data = appendUint8Array(this.remainderData, data);\n        len = data.length;\n        this.remainderData = null;\n      }\n      if (len < PACKET_LENGTH && !flush) {\n        this.remainderData = data;\n        return {\n          audioTrack: audioTrack,\n          videoTrack: videoTrack,\n          id3Track: id3Track,\n          textTrack: textTrack\n        };\n      }\n      var syncOffset = Math.max(0, TSDemuxer.syncOffset(data));\n      len -= (len - syncOffset) % PACKET_LENGTH;\n      if (len < data.byteLength && !flush) {\n        this.remainderData = new Uint8Array(data.buffer, len, data.buffer.byteLength - len);\n      }\n\n      // loop through TS packets\n      var tsPacketErrors = 0;\n      for (var start = syncOffset; start < len; start += PACKET_LENGTH) {\n        if (data[start] === 0x47) {\n          var stt = !!(data[start + 1] & 0x40);\n          var pid = parsePID(data, start);\n          var atf = (data[start + 3] & 0x30) >> 4;\n\n          // if an adaption field is present, its length is specified by the fifth byte of the TS packet header.\n          var offset = void 0;\n          if (atf > 1) {\n            offset = start + 5 + data[start + 4];\n            // continue if there is only adaptation field\n            if (offset === start + PACKET_LENGTH) {\n              continue;\n            }\n          } else {\n            offset = start + 4;\n          }\n          switch (pid) {\n            case videoPid:\n              if (stt) {\n                if (videoData && (pes = parsePES(videoData))) {\n                  this.videoParser.parseAVCPES(videoTrack, textTrack, pes, false, this._duration);\n                }\n                videoData = {\n                  data: [],\n                  size: 0\n                };\n              }\n              if (videoData) {\n                videoData.data.push(data.subarray(offset, start + PACKET_LENGTH));\n                videoData.size += start + PACKET_LENGTH - offset;\n              }\n              break;\n            case audioPid:\n              if (stt) {\n                if (audioData && (pes = parsePES(audioData))) {\n                  switch (audioTrack.segmentCodec) {\n                    case 'aac':\n                      this.parseAACPES(audioTrack, pes);\n                      break;\n                    case 'mp3':\n                      this.parseMPEGPES(audioTrack, pes);\n                      break;\n                    case 'ac3':\n                      {\n                        this.parseAC3PES(audioTrack, pes);\n                      }\n                      break;\n                  }\n                }\n                audioData = {\n                  data: [],\n                  size: 0\n                };\n              }\n              if (audioData) {\n                audioData.data.push(data.subarray(offset, start + PACKET_LENGTH));\n                audioData.size += start + PACKET_LENGTH - offset;\n              }\n              break;\n            case id3Pid:\n              if (stt) {\n                if (id3Data && (pes = parsePES(id3Data))) {\n                  this.parseID3PES(id3Track, pes);\n                }\n                id3Data = {\n                  data: [],\n                  size: 0\n                };\n              }\n              if (id3Data) {\n                id3Data.data.push(data.subarray(offset, start + PACKET_LENGTH));\n                id3Data.size += start + PACKET_LENGTH - offset;\n              }\n              break;\n            case 0:\n              if (stt) {\n                offset += data[offset] + 1;\n              }\n              pmtId = this._pmtId = parsePAT(data, offset);\n              // logger.log('PMT PID:'  + this._pmtId);\n              break;\n            case pmtId:\n              {\n                if (stt) {\n                  offset += data[offset] + 1;\n                }\n                var parsedPIDs = parsePMT(data, offset, this.typeSupported, isSampleAes, this.observer);\n\n                // only update track id if track PID found while parsing PMT\n                // this is to avoid resetting the PID to -1 in case\n                // track PID transiently disappears from the stream\n                // this could happen in case of transient missing audio samples for example\n                // NOTE this is only the PID of the track as found in TS,\n                // but we are not using this for MP4 track IDs.\n                videoPid = parsedPIDs.videoPid;\n                if (videoPid > 0) {\n                  videoTrack.pid = videoPid;\n                  videoTrack.segmentCodec = parsedPIDs.segmentVideoCodec;\n                }\n                audioPid = parsedPIDs.audioPid;\n                if (audioPid > 0) {\n                  audioTrack.pid = audioPid;\n                  audioTrack.segmentCodec = parsedPIDs.segmentAudioCodec;\n                }\n                id3Pid = parsedPIDs.id3Pid;\n                if (id3Pid > 0) {\n                  id3Track.pid = id3Pid;\n                }\n                if (unknownPID !== null && !pmtParsed) {\n                  logger.warn(\"MPEG-TS PMT found at \" + start + \" after unknown PID '\" + unknownPID + \"'. Backtracking to sync byte @\" + syncOffset + \" to parse all TS packets.\");\n                  unknownPID = null;\n                  // we set it to -188, the += 188 in the for loop will reset start to 0\n                  start = syncOffset - 188;\n                }\n                pmtParsed = this.pmtParsed = true;\n                break;\n              }\n            case 0x11:\n            case 0x1fff:\n              break;\n            default:\n              unknownPID = pid;\n              break;\n          }\n        } else {\n          tsPacketErrors++;\n        }\n      }\n      if (tsPacketErrors > 0) {\n        emitParsingError(this.observer, new Error(\"Found \" + tsPacketErrors + \" TS packet/s that do not start with 0x47\"));\n      }\n      videoTrack.pesData = videoData;\n      audioTrack.pesData = audioData;\n      id3Track.pesData = id3Data;\n      var demuxResult = {\n        audioTrack: audioTrack,\n        videoTrack: videoTrack,\n        id3Track: id3Track,\n        textTrack: textTrack\n      };\n      if (flush) {\n        this.extractRemainingSamples(demuxResult);\n      }\n      return demuxResult;\n    };\n    _proto.flush = function flush() {\n      var remainderData = this.remainderData;\n      this.remainderData = null;\n      var result;\n      if (remainderData) {\n        result = this.demux(remainderData, -1, false, true);\n      } else {\n        result = {\n          videoTrack: this._videoTrack,\n          audioTrack: this._audioTrack,\n          id3Track: this._id3Track,\n          textTrack: this._txtTrack\n        };\n      }\n      this.extractRemainingSamples(result);\n      if (this.sampleAes) {\n        return this.decrypt(result, this.sampleAes);\n      }\n      return result;\n    };\n    _proto.extractRemainingSamples = function extractRemainingSamples(demuxResult) {\n      var audioTrack = demuxResult.audioTrack,\n        videoTrack = demuxResult.videoTrack,\n        id3Track = demuxResult.id3Track,\n        textTrack = demuxResult.textTrack;\n      var videoData = videoTrack.pesData;\n      var audioData = audioTrack.pesData;\n      var id3Data = id3Track.pesData;\n      // try to parse last PES packets\n      var pes;\n      if (videoData && (pes = parsePES(videoData))) {\n        this.videoParser.parseAVCPES(videoTrack, textTrack, pes, true, this._duration);\n        videoTrack.pesData = null;\n      } else {\n        // either avcData null or PES truncated, keep it for next frag parsing\n        videoTrack.pesData = videoData;\n      }\n      if (audioData && (pes = parsePES(audioData))) {\n        switch (audioTrack.segmentCodec) {\n          case 'aac':\n            this.parseAACPES(audioTrack, pes);\n            break;\n          case 'mp3':\n            this.parseMPEGPES(audioTrack, pes);\n            break;\n          case 'ac3':\n            {\n              this.parseAC3PES(audioTrack, pes);\n            }\n            break;\n        }\n        audioTrack.pesData = null;\n      } else {\n        if (audioData != null && audioData.size) {\n          logger.log('last AAC PES packet truncated,might overlap between fragments');\n        }\n\n        // either audioData null or PES truncated, keep it for next frag parsing\n        audioTrack.pesData = audioData;\n      }\n      if (id3Data && (pes = parsePES(id3Data))) {\n        this.parseID3PES(id3Track, pes);\n        id3Track.pesData = null;\n      } else {\n        // either id3Data null or PES truncated, keep it for next frag parsing\n        id3Track.pesData = id3Data;\n      }\n    };\n    _proto.demuxSampleAes = function demuxSampleAes(data, keyData, timeOffset) {\n      var demuxResult = this.demux(data, timeOffset, true, !this.config.progressive);\n      var sampleAes = this.sampleAes = new SampleAesDecrypter(this.observer, this.config, keyData);\n      return this.decrypt(demuxResult, sampleAes);\n    };\n    _proto.decrypt = function decrypt(demuxResult, sampleAes) {\n      return new Promise(function (resolve) {\n        var audioTrack = demuxResult.audioTrack,\n          videoTrack = demuxResult.videoTrack;\n        if (audioTrack.samples && audioTrack.segmentCodec === 'aac') {\n          sampleAes.decryptAacSamples(audioTrack.samples, 0, function () {\n            if (videoTrack.samples) {\n              sampleAes.decryptAvcSamples(videoTrack.samples, 0, 0, function () {\n                resolve(demuxResult);\n              });\n            } else {\n              resolve(demuxResult);\n            }\n          });\n        } else if (videoTrack.samples) {\n          sampleAes.decryptAvcSamples(videoTrack.samples, 0, 0, function () {\n            resolve(demuxResult);\n          });\n        }\n      });\n    };\n    _proto.destroy = function destroy() {\n      this._duration = 0;\n    };\n    _proto.parseAACPES = function parseAACPES(track, pes) {\n      var startOffset = 0;\n      var aacOverFlow = this.aacOverFlow;\n      var data = pes.data;\n      if (aacOverFlow) {\n        this.aacOverFlow = null;\n        var frameMissingBytes = aacOverFlow.missing;\n        var sampleLength = aacOverFlow.sample.unit.byteLength;\n        // logger.log(`AAC: append overflowing ${sampleLength} bytes to beginning of new PES`);\n        if (frameMissingBytes === -1) {\n          data = appendUint8Array(aacOverFlow.sample.unit, data);\n        } else {\n          var frameOverflowBytes = sampleLength - frameMissingBytes;\n          aacOverFlow.sample.unit.set(data.subarray(0, frameMissingBytes), frameOverflowBytes);\n          track.samples.push(aacOverFlow.sample);\n          startOffset = aacOverFlow.missing;\n        }\n      }\n      // look for ADTS header (0xFFFx)\n      var offset;\n      var len;\n      for (offset = startOffset, len = data.length; offset < len - 1; offset++) {\n        if (isHeader$1(data, offset)) {\n          break;\n        }\n      }\n      // if ADTS header does not start straight from the beginning of the PES payload, raise an error\n      if (offset !== startOffset) {\n        var reason;\n        var recoverable = offset < len - 1;\n        if (recoverable) {\n          reason = \"AAC PES did not start with ADTS header,offset:\" + offset;\n        } else {\n          reason = 'No ADTS header found in AAC PES';\n        }\n        emitParsingError(this.observer, new Error(reason), recoverable);\n        if (!recoverable) {\n          return;\n        }\n      }\n      initTrackConfig(track, this.observer, data, offset, this.audioCodec);\n      var pts;\n      if (pes.pts !== undefined) {\n        pts = pes.pts;\n      } else if (aacOverFlow) {\n        // if last AAC frame is overflowing, we should ensure timestamps are contiguous:\n        // first sample PTS should be equal to last sample PTS + frameDuration\n        var frameDuration = getFrameDuration(track.samplerate);\n        pts = aacOverFlow.sample.pts + frameDuration;\n      } else {\n        logger.warn('[tsdemuxer]: AAC PES unknown PTS');\n        return;\n      }\n\n      // scan for aac samples\n      var frameIndex = 0;\n      var frame;\n      while (offset < len) {\n        frame = appendFrame$1(track, data, offset, pts, frameIndex);\n        offset += frame.length;\n        if (!frame.missing) {\n          frameIndex++;\n          for (; offset < len - 1; offset++) {\n            if (isHeader$1(data, offset)) {\n              break;\n            }\n          }\n        } else {\n          this.aacOverFlow = frame;\n          break;\n        }\n      }\n    };\n    _proto.parseMPEGPES = function parseMPEGPES(track, pes) {\n      var data = pes.data;\n      var length = data.length;\n      var frameIndex = 0;\n      var offset = 0;\n      var pts = pes.pts;\n      if (pts === undefined) {\n        logger.warn('[tsdemuxer]: MPEG PES unknown PTS');\n        return;\n      }\n      while (offset < length) {\n        if (isHeader(data, offset)) {\n          var frame = appendFrame(track, data, offset, pts, frameIndex);\n          if (frame) {\n            offset += frame.length;\n            frameIndex++;\n          } else {\n            // logger.log('Unable to parse Mpeg audio frame');\n            break;\n          }\n        } else {\n          // nothing found, keep looking\n          offset++;\n        }\n      }\n    };\n    _proto.parseAC3PES = function parseAC3PES(track, pes) {\n      {\n        var data = pes.data;\n        var pts = pes.pts;\n        if (pts === undefined) {\n          logger.warn('[tsdemuxer]: AC3 PES unknown PTS');\n          return;\n        }\n        var length = data.length;\n        var frameIndex = 0;\n        var offset = 0;\n        var parsed;\n        while (offset < length && (parsed = _appendFrame(track, data, offset, pts, frameIndex++)) > 0) {\n          offset += parsed;\n        }\n      }\n    };\n    _proto.parseID3PES = function parseID3PES(id3Track, pes) {\n      if (pes.pts === undefined) {\n        logger.warn('[tsdemuxer]: ID3 PES unknown PTS');\n        return;\n      }\n      var id3Sample = _extends({}, pes, {\n        type: this._videoTrack ? MetadataSchema.emsg : MetadataSchema.audioId3,\n        duration: Number.POSITIVE_INFINITY\n      });\n      id3Track.samples.push(id3Sample);\n    };\n    return TSDemuxer;\n  }();\n  function parsePID(data, offset) {\n    // pid is a 13-bit field starting at the last bit of TS[1]\n    return ((data[offset + 1] & 0x1f) << 8) + data[offset + 2];\n  }\n  function parsePAT(data, offset) {\n    // skip the PSI header and parse the first PMT entry\n    return (data[offset + 10] & 0x1f) << 8 | data[offset + 11];\n  }\n  function parsePMT(data, offset, typeSupported, isSampleAes, observer) {\n    var result = {\n      audioPid: -1,\n      videoPid: -1,\n      id3Pid: -1,\n      segmentVideoCodec: 'avc',\n      segmentAudioCodec: 'aac'\n    };\n    var sectionLength = (data[offset + 1] & 0x0f) << 8 | data[offset + 2];\n    var tableEnd = offset + 3 + sectionLength - 4;\n    // to determine where the table is, we have to figure out how\n    // long the program info descriptors are\n    var programInfoLength = (data[offset + 10] & 0x0f) << 8 | data[offset + 11];\n    // advance the offset to the first entry in the mapping table\n    offset += 12 + programInfoLength;\n    while (offset < tableEnd) {\n      var pid = parsePID(data, offset);\n      var esInfoLength = (data[offset + 3] & 0x0f) << 8 | data[offset + 4];\n      switch (data[offset]) {\n        case 0xcf:\n          // SAMPLE-AES AAC\n          if (!isSampleAes) {\n            logEncryptedSamplesFoundInUnencryptedStream('ADTS AAC');\n            break;\n          }\n        /* falls through */\n        case 0x0f:\n          // ISO/IEC 13818-7 ADTS AAC (MPEG-2 lower bit-rate audio)\n          // logger.log('AAC PID:'  + pid);\n          if (result.audioPid === -1) {\n            result.audioPid = pid;\n          }\n          break;\n\n        // Packetized metadata (ID3)\n        case 0x15:\n          // logger.log('ID3 PID:'  + pid);\n          if (result.id3Pid === -1) {\n            result.id3Pid = pid;\n          }\n          break;\n        case 0xdb:\n          // SAMPLE-AES AVC\n          if (!isSampleAes) {\n            logEncryptedSamplesFoundInUnencryptedStream('H.264');\n            break;\n          }\n        /* falls through */\n        case 0x1b:\n          // ITU-T Rec. H.264 and ISO/IEC 14496-10 (lower bit-rate video)\n          // logger.log('AVC PID:'  + pid);\n          if (result.videoPid === -1) {\n            result.videoPid = pid;\n            result.segmentVideoCodec = 'avc';\n          }\n          break;\n\n        // ISO/IEC 11172-3 (MPEG-1 audio)\n        // or ISO/IEC 13818-3 (MPEG-2 halved sample rate audio)\n        case 0x03:\n        case 0x04:\n          // logger.log('MPEG PID:'  + pid);\n          if (!typeSupported.mpeg && !typeSupported.mp3) {\n            logger.log('MPEG audio found, not supported in this browser');\n          } else if (result.audioPid === -1) {\n            result.audioPid = pid;\n            result.segmentAudioCodec = 'mp3';\n          }\n          break;\n        case 0xc1:\n          // SAMPLE-AES AC3\n          if (!isSampleAes) {\n            logEncryptedSamplesFoundInUnencryptedStream('AC-3');\n            break;\n          }\n        /* falls through */\n        case 0x81:\n          {\n            if (!typeSupported.ac3) {\n              logger.log('AC-3 audio found, not supported in this browser');\n            } else if (result.audioPid === -1) {\n              result.audioPid = pid;\n              result.segmentAudioCodec = 'ac3';\n            }\n          }\n          break;\n        case 0x06:\n          // stream_type 6 can mean a lot of different things in case of DVB.\n          // We need to look at the descriptors. Right now, we're only interested\n          // in AC-3 audio, so we do the descriptor parsing only when we don't have\n          // an audio PID yet.\n          if (result.audioPid === -1 && esInfoLength > 0) {\n            var parsePos = offset + 5;\n            var remaining = esInfoLength;\n            while (remaining > 2) {\n              var descriptorId = data[parsePos];\n              switch (descriptorId) {\n                case 0x6a:\n                  // DVB Descriptor for AC-3\n                  {\n                    if (typeSupported.ac3 !== true) {\n                      logger.log('AC-3 audio found, not supported in this browser for now');\n                    } else {\n                      result.audioPid = pid;\n                      result.segmentAudioCodec = 'ac3';\n                    }\n                  }\n                  break;\n              }\n              var descriptorLen = data[parsePos + 1] + 2;\n              parsePos += descriptorLen;\n              remaining -= descriptorLen;\n            }\n          }\n          break;\n        case 0xc2: // SAMPLE-AES EC3\n        /* falls through */\n        case 0x87:\n          emitParsingError(observer, new Error('Unsupported EC-3 in M2TS found'));\n          return result;\n        case 0x24:\n          emitParsingError(observer, new Error('Unsupported HEVC in M2TS found'));\n          return result;\n      }\n      // move to the next table entry\n      // skip past the elementary stream descriptors, if present\n      offset += esInfoLength + 5;\n    }\n    return result;\n  }\n  function emitParsingError(observer, error, levelRetry) {\n    logger.warn(\"parsing error: \" + error.message);\n    observer.emit(Events.ERROR, Events.ERROR, {\n      type: ErrorTypes.MEDIA_ERROR,\n      details: ErrorDetails.FRAG_PARSING_ERROR,\n      fatal: false,\n      levelRetry: levelRetry,\n      error: error,\n      reason: error.message\n    });\n  }\n  function logEncryptedSamplesFoundInUnencryptedStream(type) {\n    logger.log(type + \" with AES-128-CBC encryption found in unencrypted stream\");\n  }\n  function parsePES(stream) {\n    var i = 0;\n    var frag;\n    var pesLen;\n    var pesHdrLen;\n    var pesPts;\n    var pesDts;\n    var data = stream.data;\n    // safety check\n    if (!stream || stream.size === 0) {\n      return null;\n    }\n\n    // we might need up to 19 bytes to read PES header\n    // if first chunk of data is less than 19 bytes, let's merge it with following ones until we get 19 bytes\n    // usually only one merge is needed (and this is rare ...)\n    while (data[0].length < 19 && data.length > 1) {\n      data[0] = appendUint8Array(data[0], data[1]);\n      data.splice(1, 1);\n    }\n    // retrieve PTS/DTS from first fragment\n    frag = data[0];\n    var pesPrefix = (frag[0] << 16) + (frag[1] << 8) + frag[2];\n    if (pesPrefix === 1) {\n      pesLen = (frag[4] << 8) + frag[5];\n      // if PES parsed length is not zero and greater than total received length, stop parsing. PES might be truncated\n      // minus 6 : PES header size\n      if (pesLen && pesLen > stream.size - 6) {\n        return null;\n      }\n      var pesFlags = frag[7];\n      if (pesFlags & 0xc0) {\n        /* PES header described here : http://dvd.sourceforge.net/dvdinfo/pes-hdr.html\n            as PTS / DTS is 33 bit we cannot use bitwise operator in JS,\n            as Bitwise operators treat their operands as a sequence of 32 bits */\n        pesPts = (frag[9] & 0x0e) * 536870912 +\n        // 1 << 29\n        (frag[10] & 0xff) * 4194304 +\n        // 1 << 22\n        (frag[11] & 0xfe) * 16384 +\n        // 1 << 14\n        (frag[12] & 0xff) * 128 +\n        // 1 << 7\n        (frag[13] & 0xfe) / 2;\n        if (pesFlags & 0x40) {\n          pesDts = (frag[14] & 0x0e) * 536870912 +\n          // 1 << 29\n          (frag[15] & 0xff) * 4194304 +\n          // 1 << 22\n          (frag[16] & 0xfe) * 16384 +\n          // 1 << 14\n          (frag[17] & 0xff) * 128 +\n          // 1 << 7\n          (frag[18] & 0xfe) / 2;\n          if (pesPts - pesDts > 60 * 90000) {\n            logger.warn(Math.round((pesPts - pesDts) / 90000) + \"s delta between PTS and DTS, align them\");\n            pesPts = pesDts;\n          }\n        } else {\n          pesDts = pesPts;\n        }\n      }\n      pesHdrLen = frag[8];\n      // 9 bytes : 6 bytes for PES header + 3 bytes for PES extension\n      var payloadStartOffset = pesHdrLen + 9;\n      if (stream.size <= payloadStartOffset) {\n        return null;\n      }\n      stream.size -= payloadStartOffset;\n      // reassemble PES packet\n      var pesData = new Uint8Array(stream.size);\n      for (var j = 0, dataLen = data.length; j < dataLen; j++) {\n        frag = data[j];\n        var len = frag.byteLength;\n        if (payloadStartOffset) {\n          if (payloadStartOffset > len) {\n            // trim full frag if PES header bigger than frag\n            payloadStartOffset -= len;\n            continue;\n          } else {\n            // trim partial frag if PES header smaller than frag\n            frag = frag.subarray(payloadStartOffset);\n            len -= payloadStartOffset;\n            payloadStartOffset = 0;\n          }\n        }\n        pesData.set(frag, i);\n        i += len;\n      }\n      if (pesLen) {\n        // payload size : remove PES header + PES extension\n        pesLen -= pesHdrLen + 3;\n      }\n      return {\n        data: pesData,\n        pts: pesPts,\n        dts: pesDts,\n        len: pesLen\n      };\n    }\n    return null;\n  }\n\n  var MP3Demuxer = /*#__PURE__*/function (_BaseAudioDemuxer) {\n    _inheritsLoose(MP3Demuxer, _BaseAudioDemuxer);\n    function MP3Demuxer() {\n      return _BaseAudioDemuxer.apply(this, arguments) || this;\n    }\n    var _proto = MP3Demuxer.prototype;\n    _proto.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec, trackDuration) {\n      _BaseAudioDemuxer.prototype.resetInitSegment.call(this, initSegment, audioCodec, videoCodec, trackDuration);\n      this._audioTrack = {\n        container: 'audio/mpeg',\n        type: 'audio',\n        id: 2,\n        pid: -1,\n        sequenceNumber: 0,\n        segmentCodec: 'mp3',\n        samples: [],\n        manifestCodec: audioCodec,\n        duration: trackDuration,\n        inputTimeScale: 90000,\n        dropped: 0\n      };\n    };\n    MP3Demuxer.probe = function probe$1(data) {\n      if (!data) {\n        return false;\n      }\n\n      // check if data contains ID3 timestamp and MPEG sync word\n      // Look for MPEG header | 1111 1111 | 111X XYZX | where X can be either 0 or 1 and Y or Z should be 1\n      // Layer bits (position 14 and 15) in header should be always different from 0 (Layer I or Layer II or Layer III)\n      // More info http://www.mp3-tech.org/programmer/frame_header.html\n      var id3Data = getID3Data(data, 0);\n      var offset = (id3Data == null ? void 0 : id3Data.length) || 0;\n\n      // Check for ac-3|ec-3 sync bytes and return false if present\n      if (id3Data && data[offset] === 0x0b && data[offset + 1] === 0x77 && getTimeStamp(id3Data) !== undefined &&\n      // check the bsid to confirm ac-3 or ec-3 (not mp3)\n      getAudioBSID(data, offset) <= 16) {\n        return false;\n      }\n      for (var length = data.length; offset < length; offset++) {\n        if (probe(data, offset)) {\n          logger.log('MPEG Audio sync word found !');\n          return true;\n        }\n      }\n      return false;\n    };\n    _proto.canParse = function canParse$1(data, offset) {\n      return canParse(data, offset);\n    };\n    _proto.appendFrame = function appendFrame$1(track, data, offset) {\n      if (this.basePTS === null) {\n        return;\n      }\n      return appendFrame(track, data, offset, this.basePTS, this.frameIndex);\n    };\n    return MP3Demuxer;\n  }(BaseAudioDemuxer);\n\n  /**\n   *  AAC helper\n   */\n  var AAC = /*#__PURE__*/function () {\n    function AAC() {}\n    AAC.getSilentFrame = function getSilentFrame(codec, channelCount) {\n      switch (codec) {\n        case 'mp4a.40.2':\n          if (channelCount === 1) {\n            return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x23, 0x80]);\n          } else if (channelCount === 2) {\n            return new Uint8Array([0x21, 0x00, 0x49, 0x90, 0x02, 0x19, 0x00, 0x23, 0x80]);\n          } else if (channelCount === 3) {\n            return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x8e]);\n          } else if (channelCount === 4) {\n            return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x80, 0x2c, 0x80, 0x08, 0x02, 0x38]);\n          } else if (channelCount === 5) {\n            return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x38]);\n          } else if (channelCount === 6) {\n            return new Uint8Array([0x00, 0xc8, 0x00, 0x80, 0x20, 0x84, 0x01, 0x26, 0x40, 0x08, 0x64, 0x00, 0x82, 0x30, 0x04, 0x99, 0x00, 0x21, 0x90, 0x02, 0x00, 0xb2, 0x00, 0x20, 0x08, 0xe0]);\n          }\n          break;\n        // handle HE-AAC below (mp4a.40.5 / mp4a.40.29)\n        default:\n          if (channelCount === 1) {\n            // ffmpeg -y -f lavfi -i \"aevalsrc=0:d=0.05\" -c:a libfdk_aac -profile:a aac_he -b:a 4k output.aac && hexdump -v -e '16/1 \"0x%x,\" \"\\n\"' -v output.aac\n            return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x4e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x1c, 0x6, 0xf1, 0xc1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\n          } else if (channelCount === 2) {\n            // ffmpeg -y -f lavfi -i \"aevalsrc=0|0:d=0.05\" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 \"0x%x,\" \"\\n\"' -v output.aac\n            return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\n          } else if (channelCount === 3) {\n            // ffmpeg -y -f lavfi -i \"aevalsrc=0|0|0:d=0.05\" -c:a libfdk_aac -profile:a aac_he_v2 -b:a 4k output.aac && hexdump -v -e '16/1 \"0x%x,\" \"\\n\"' -v output.aac\n            return new Uint8Array([0x1, 0x40, 0x22, 0x80, 0xa3, 0x5e, 0xe6, 0x80, 0xba, 0x8, 0x0, 0x0, 0x0, 0x0, 0x95, 0x0, 0x6, 0xf1, 0xa1, 0xa, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5a, 0x5e]);\n          }\n          break;\n      }\n      return undefined;\n    };\n    return AAC;\n  }();\n\n  /**\n   * Generate MP4 Box\n   */\n\n  var UINT32_MAX = Math.pow(2, 32) - 1;\n  var MP4 = /*#__PURE__*/function () {\n    function MP4() {}\n    MP4.init = function init() {\n      MP4.types = {\n        avc1: [],\n        // codingname\n        avcC: [],\n        btrt: [],\n        dinf: [],\n        dref: [],\n        esds: [],\n        ftyp: [],\n        hdlr: [],\n        mdat: [],\n        mdhd: [],\n        mdia: [],\n        mfhd: [],\n        minf: [],\n        moof: [],\n        moov: [],\n        mp4a: [],\n        '.mp3': [],\n        dac3: [],\n        'ac-3': [],\n        mvex: [],\n        mvhd: [],\n        pasp: [],\n        sdtp: [],\n        stbl: [],\n        stco: [],\n        stsc: [],\n        stsd: [],\n        stsz: [],\n        stts: [],\n        tfdt: [],\n        tfhd: [],\n        traf: [],\n        trak: [],\n        trun: [],\n        trex: [],\n        tkhd: [],\n        vmhd: [],\n        smhd: []\n      };\n      var i;\n      for (i in MP4.types) {\n        if (MP4.types.hasOwnProperty(i)) {\n          MP4.types[i] = [i.charCodeAt(0), i.charCodeAt(1), i.charCodeAt(2), i.charCodeAt(3)];\n        }\n      }\n      var videoHdlr = new Uint8Array([0x00,\n      // version 0\n      0x00, 0x00, 0x00,\n      // flags\n      0x00, 0x00, 0x00, 0x00,\n      // pre_defined\n      0x76, 0x69, 0x64, 0x65,\n      // handler_type: 'vide'\n      0x00, 0x00, 0x00, 0x00,\n      // reserved\n      0x00, 0x00, 0x00, 0x00,\n      // reserved\n      0x00, 0x00, 0x00, 0x00,\n      // reserved\n      0x56, 0x69, 0x64, 0x65, 0x6f, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'VideoHandler'\n      ]);\n      var audioHdlr = new Uint8Array([0x00,\n      // version 0\n      0x00, 0x00, 0x00,\n      // flags\n      0x00, 0x00, 0x00, 0x00,\n      // pre_defined\n      0x73, 0x6f, 0x75, 0x6e,\n      // handler_type: 'soun'\n      0x00, 0x00, 0x00, 0x00,\n      // reserved\n      0x00, 0x00, 0x00, 0x00,\n      // reserved\n      0x00, 0x00, 0x00, 0x00,\n      // reserved\n      0x53, 0x6f, 0x75, 0x6e, 0x64, 0x48, 0x61, 0x6e, 0x64, 0x6c, 0x65, 0x72, 0x00 // name: 'SoundHandler'\n      ]);\n      MP4.HDLR_TYPES = {\n        video: videoHdlr,\n        audio: audioHdlr\n      };\n      var dref = new Uint8Array([0x00,\n      // version 0\n      0x00, 0x00, 0x00,\n      // flags\n      0x00, 0x00, 0x00, 0x01,\n      // entry_count\n      0x00, 0x00, 0x00, 0x0c,\n      // entry_size\n      0x75, 0x72, 0x6c, 0x20,\n      // 'url' type\n      0x00,\n      // version 0\n      0x00, 0x00, 0x01 // entry_flags\n      ]);\n      var stco = new Uint8Array([0x00,\n      // version\n      0x00, 0x00, 0x00,\n      // flags\n      0x00, 0x00, 0x00, 0x00 // entry_count\n      ]);\n      MP4.STTS = MP4.STSC = MP4.STCO = stco;\n      MP4.STSZ = new Uint8Array([0x00,\n      // version\n      0x00, 0x00, 0x00,\n      // flags\n      0x00, 0x00, 0x00, 0x00,\n      // sample_size\n      0x00, 0x00, 0x00, 0x00 // sample_count\n      ]);\n      MP4.VMHD = new Uint8Array([0x00,\n      // version\n      0x00, 0x00, 0x01,\n      // flags\n      0x00, 0x00,\n      // graphicsmode\n      0x00, 0x00, 0x00, 0x00, 0x00, 0x00 // opcolor\n      ]);\n      MP4.SMHD = new Uint8Array([0x00,\n      // version\n      0x00, 0x00, 0x00,\n      // flags\n      0x00, 0x00,\n      // balance\n      0x00, 0x00 // reserved\n      ]);\n      MP4.STSD = new Uint8Array([0x00,\n      // version 0\n      0x00, 0x00, 0x00,\n      // flags\n      0x00, 0x00, 0x00, 0x01]); // entry_count\n\n      var majorBrand = new Uint8Array([105, 115, 111, 109]); // isom\n      var avc1Brand = new Uint8Array([97, 118, 99, 49]); // avc1\n      var minorVersion = new Uint8Array([0, 0, 0, 1]);\n      MP4.FTYP = MP4.box(MP4.types.ftyp, majorBrand, minorVersion, majorBrand, avc1Brand);\n      MP4.DINF = MP4.box(MP4.types.dinf, MP4.box(MP4.types.dref, dref));\n    };\n    MP4.box = function box(type) {\n      var size = 8;\n      for (var _len = arguments.length, payload = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n        payload[_key - 1] = arguments[_key];\n      }\n      var i = payload.length;\n      var len = i;\n      // calculate the total size we need to allocate\n      while (i--) {\n        size += payload[i].byteLength;\n      }\n      var result = new Uint8Array(size);\n      result[0] = size >> 24 & 0xff;\n      result[1] = size >> 16 & 0xff;\n      result[2] = size >> 8 & 0xff;\n      result[3] = size & 0xff;\n      result.set(type, 4);\n      // copy the payload into the result\n      for (i = 0, size = 8; i < len; i++) {\n        // copy payload[i] array @ offset size\n        result.set(payload[i], size);\n        size += payload[i].byteLength;\n      }\n      return result;\n    };\n    MP4.hdlr = function hdlr(type) {\n      return MP4.box(MP4.types.hdlr, MP4.HDLR_TYPES[type]);\n    };\n    MP4.mdat = function mdat(data) {\n      return MP4.box(MP4.types.mdat, data);\n    };\n    MP4.mdhd = function mdhd(timescale, duration) {\n      duration *= timescale;\n      var upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));\n      var lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));\n      return MP4.box(MP4.types.mdhd, new Uint8Array([0x01,\n      // version 1\n      0x00, 0x00, 0x00,\n      // flags\n      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,\n      // creation_time\n      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03,\n      // modification_time\n      timescale >> 24 & 0xff, timescale >> 16 & 0xff, timescale >> 8 & 0xff, timescale & 0xff,\n      // timescale\n      upperWordDuration >> 24, upperWordDuration >> 16 & 0xff, upperWordDuration >> 8 & 0xff, upperWordDuration & 0xff, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xff, lowerWordDuration >> 8 & 0xff, lowerWordDuration & 0xff, 0x55, 0xc4,\n      // 'und' language (undetermined)\n      0x00, 0x00]));\n    };\n    MP4.mdia = function mdia(track) {\n      return MP4.box(MP4.types.mdia, MP4.mdhd(track.timescale, track.duration), MP4.hdlr(track.type), MP4.minf(track));\n    };\n    MP4.mfhd = function mfhd(sequenceNumber) {\n      return MP4.box(MP4.types.mfhd, new Uint8Array([0x00, 0x00, 0x00, 0x00,\n      // flags\n      sequenceNumber >> 24, sequenceNumber >> 16 & 0xff, sequenceNumber >> 8 & 0xff, sequenceNumber & 0xff // sequence_number\n      ]));\n    };\n    MP4.minf = function minf(track) {\n      if (track.type === 'audio') {\n        return MP4.box(MP4.types.minf, MP4.box(MP4.types.smhd, MP4.SMHD), MP4.DINF, MP4.stbl(track));\n      } else {\n        return MP4.box(MP4.types.minf, MP4.box(MP4.types.vmhd, MP4.VMHD), MP4.DINF, MP4.stbl(track));\n      }\n    };\n    MP4.moof = function moof(sn, baseMediaDecodeTime, track) {\n      return MP4.box(MP4.types.moof, MP4.mfhd(sn), MP4.traf(track, baseMediaDecodeTime));\n    };\n    MP4.moov = function moov(tracks) {\n      var i = tracks.length;\n      var boxes = [];\n      while (i--) {\n        boxes[i] = MP4.trak(tracks[i]);\n      }\n      return MP4.box.apply(null, [MP4.types.moov, MP4.mvhd(tracks[0].timescale, tracks[0].duration)].concat(boxes).concat(MP4.mvex(tracks)));\n    };\n    MP4.mvex = function mvex(tracks) {\n      var i = tracks.length;\n      var boxes = [];\n      while (i--) {\n        boxes[i] = MP4.trex(tracks[i]);\n      }\n      return MP4.box.apply(null, [MP4.types.mvex].concat(boxes));\n    };\n    MP4.mvhd = function mvhd(timescale, duration) {\n      duration *= timescale;\n      var upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));\n      var lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));\n      var bytes = new Uint8Array([0x01,\n      // version 1\n      0x00, 0x00, 0x00,\n      // flags\n      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,\n      // creation_time\n      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03,\n      // modification_time\n      timescale >> 24 & 0xff, timescale >> 16 & 0xff, timescale >> 8 & 0xff, timescale & 0xff,\n      // timescale\n      upperWordDuration >> 24, upperWordDuration >> 16 & 0xff, upperWordDuration >> 8 & 0xff, upperWordDuration & 0xff, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xff, lowerWordDuration >> 8 & 0xff, lowerWordDuration & 0xff, 0x00, 0x01, 0x00, 0x00,\n      // 1.0 rate\n      0x01, 0x00,\n      // 1.0 volume\n      0x00, 0x00,\n      // reserved\n      0x00, 0x00, 0x00, 0x00,\n      // reserved\n      0x00, 0x00, 0x00, 0x00,\n      // reserved\n      0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00,\n      // transformation: unity matrix\n      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n      // pre_defined\n      0xff, 0xff, 0xff, 0xff // next_track_ID\n      ]);\n      return MP4.box(MP4.types.mvhd, bytes);\n    };\n    MP4.sdtp = function sdtp(track) {\n      var samples = track.samples || [];\n      var bytes = new Uint8Array(4 + samples.length);\n      var i;\n      var flags;\n      // leave the full box header (4 bytes) all zero\n      // write the sample table\n      for (i = 0; i < samples.length; i++) {\n        flags = samples[i].flags;\n        bytes[i + 4] = flags.dependsOn << 4 | flags.isDependedOn << 2 | flags.hasRedundancy;\n      }\n      return MP4.box(MP4.types.sdtp, bytes);\n    };\n    MP4.stbl = function stbl(track) {\n      return MP4.box(MP4.types.stbl, MP4.stsd(track), MP4.box(MP4.types.stts, MP4.STTS), MP4.box(MP4.types.stsc, MP4.STSC), MP4.box(MP4.types.stsz, MP4.STSZ), MP4.box(MP4.types.stco, MP4.STCO));\n    };\n    MP4.avc1 = function avc1(track) {\n      var sps = [];\n      var pps = [];\n      var i;\n      var data;\n      var len;\n      // assemble the SPSs\n\n      for (i = 0; i < track.sps.length; i++) {\n        data = track.sps[i];\n        len = data.byteLength;\n        sps.push(len >>> 8 & 0xff);\n        sps.push(len & 0xff);\n\n        // SPS\n        sps = sps.concat(Array.prototype.slice.call(data));\n      }\n\n      // assemble the PPSs\n      for (i = 0; i < track.pps.length; i++) {\n        data = track.pps[i];\n        len = data.byteLength;\n        pps.push(len >>> 8 & 0xff);\n        pps.push(len & 0xff);\n        pps = pps.concat(Array.prototype.slice.call(data));\n      }\n      var avcc = MP4.box(MP4.types.avcC, new Uint8Array([0x01,\n      // version\n      sps[3],\n      // profile\n      sps[4],\n      // profile compat\n      sps[5],\n      // level\n      0xfc | 3,\n      // lengthSizeMinusOne, hard-coded to 4 bytes\n      0xe0 | track.sps.length // 3bit reserved (111) + numOfSequenceParameterSets\n      ].concat(sps).concat([track.pps.length // numOfPictureParameterSets\n      ]).concat(pps))); // \"PPS\"\n      var width = track.width;\n      var height = track.height;\n      var hSpacing = track.pixelRatio[0];\n      var vSpacing = track.pixelRatio[1];\n      return MP4.box(MP4.types.avc1, new Uint8Array([0x00, 0x00, 0x00,\n      // reserved\n      0x00, 0x00, 0x00,\n      // reserved\n      0x00, 0x01,\n      // data_reference_index\n      0x00, 0x00,\n      // pre_defined\n      0x00, 0x00,\n      // reserved\n      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n      // pre_defined\n      width >> 8 & 0xff, width & 0xff,\n      // width\n      height >> 8 & 0xff, height & 0xff,\n      // height\n      0x00, 0x48, 0x00, 0x00,\n      // horizresolution\n      0x00, 0x48, 0x00, 0x00,\n      // vertresolution\n      0x00, 0x00, 0x00, 0x00,\n      // reserved\n      0x00, 0x01,\n      // frame_count\n      0x12, 0x64, 0x61, 0x69, 0x6c,\n      // dailymotion/hls.js\n      0x79, 0x6d, 0x6f, 0x74, 0x69, 0x6f, 0x6e, 0x2f, 0x68, 0x6c, 0x73, 0x2e, 0x6a, 0x73, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n      // compressorname\n      0x00, 0x18,\n      // depth = 24\n      0x11, 0x11]),\n      // pre_defined = -1\n      avcc, MP4.box(MP4.types.btrt, new Uint8Array([0x00, 0x1c, 0x9c, 0x80,\n      // bufferSizeDB\n      0x00, 0x2d, 0xc6, 0xc0,\n      // maxBitrate\n      0x00, 0x2d, 0xc6, 0xc0])),\n      // avgBitrate\n      MP4.box(MP4.types.pasp, new Uint8Array([hSpacing >> 24,\n      // hSpacing\n      hSpacing >> 16 & 0xff, hSpacing >> 8 & 0xff, hSpacing & 0xff, vSpacing >> 24,\n      // vSpacing\n      vSpacing >> 16 & 0xff, vSpacing >> 8 & 0xff, vSpacing & 0xff])));\n    };\n    MP4.esds = function esds(track) {\n      var configlen = track.config.length;\n      return new Uint8Array([0x00,\n      // version 0\n      0x00, 0x00, 0x00,\n      // flags\n\n      0x03,\n      // descriptor_type\n      0x17 + configlen,\n      // length\n      0x00, 0x01,\n      // es_id\n      0x00,\n      // stream_priority\n\n      0x04,\n      // descriptor_type\n      0x0f + configlen,\n      // length\n      0x40,\n      // codec : mpeg4_audio\n      0x15,\n      // stream_type\n      0x00, 0x00, 0x00,\n      // buffer_size\n      0x00, 0x00, 0x00, 0x00,\n      // maxBitrate\n      0x00, 0x00, 0x00, 0x00,\n      // avgBitrate\n\n      0x05 // descriptor_type\n      ].concat([configlen]).concat(track.config).concat([0x06, 0x01, 0x02])); // GASpecificConfig)); // length + audio config descriptor\n    };\n    MP4.audioStsd = function audioStsd(track) {\n      var samplerate = track.samplerate;\n      return new Uint8Array([0x00, 0x00, 0x00,\n      // reserved\n      0x00, 0x00, 0x00,\n      // reserved\n      0x00, 0x01,\n      // data_reference_index\n      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n      // reserved\n      0x00, track.channelCount,\n      // channelcount\n      0x00, 0x10,\n      // sampleSize:16bits\n      0x00, 0x00, 0x00, 0x00,\n      // reserved2\n      samplerate >> 8 & 0xff, samplerate & 0xff,\n      //\n      0x00, 0x00]);\n    };\n    MP4.mp4a = function mp4a(track) {\n      return MP4.box(MP4.types.mp4a, MP4.audioStsd(track), MP4.box(MP4.types.esds, MP4.esds(track)));\n    };\n    MP4.mp3 = function mp3(track) {\n      return MP4.box(MP4.types['.mp3'], MP4.audioStsd(track));\n    };\n    MP4.ac3 = function ac3(track) {\n      return MP4.box(MP4.types['ac-3'], MP4.audioStsd(track), MP4.box(MP4.types.dac3, track.config));\n    };\n    MP4.stsd = function stsd(track) {\n      if (track.type === 'audio') {\n        if (track.segmentCodec === 'mp3' && track.codec === 'mp3') {\n          return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp3(track));\n        }\n        if (track.segmentCodec === 'ac3') {\n          return MP4.box(MP4.types.stsd, MP4.STSD, MP4.ac3(track));\n        }\n        return MP4.box(MP4.types.stsd, MP4.STSD, MP4.mp4a(track));\n      } else {\n        return MP4.box(MP4.types.stsd, MP4.STSD, MP4.avc1(track));\n      }\n    };\n    MP4.tkhd = function tkhd(track) {\n      var id = track.id;\n      var duration = track.duration * track.timescale;\n      var width = track.width;\n      var height = track.height;\n      var upperWordDuration = Math.floor(duration / (UINT32_MAX + 1));\n      var lowerWordDuration = Math.floor(duration % (UINT32_MAX + 1));\n      return MP4.box(MP4.types.tkhd, new Uint8Array([0x01,\n      // version 1\n      0x00, 0x00, 0x07,\n      // flags\n      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02,\n      // creation_time\n      0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x03,\n      // modification_time\n      id >> 24 & 0xff, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff,\n      // track_ID\n      0x00, 0x00, 0x00, 0x00,\n      // reserved\n      upperWordDuration >> 24, upperWordDuration >> 16 & 0xff, upperWordDuration >> 8 & 0xff, upperWordDuration & 0xff, lowerWordDuration >> 24, lowerWordDuration >> 16 & 0xff, lowerWordDuration >> 8 & 0xff, lowerWordDuration & 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n      // reserved\n      0x00, 0x00,\n      // layer\n      0x00, 0x00,\n      // alternate_group\n      0x00, 0x00,\n      // non-audio track volume\n      0x00, 0x00,\n      // reserved\n      0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00,\n      // transformation: unity matrix\n      width >> 8 & 0xff, width & 0xff, 0x00, 0x00,\n      // width\n      height >> 8 & 0xff, height & 0xff, 0x00, 0x00 // height\n      ]));\n    };\n    MP4.traf = function traf(track, baseMediaDecodeTime) {\n      var sampleDependencyTable = MP4.sdtp(track);\n      var id = track.id;\n      var upperWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime / (UINT32_MAX + 1));\n      var lowerWordBaseMediaDecodeTime = Math.floor(baseMediaDecodeTime % (UINT32_MAX + 1));\n      return MP4.box(MP4.types.traf, MP4.box(MP4.types.tfhd, new Uint8Array([0x00,\n      // version 0\n      0x00, 0x00, 0x00,\n      // flags\n      id >> 24, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff // track_ID\n      ])), MP4.box(MP4.types.tfdt, new Uint8Array([0x01,\n      // version 1\n      0x00, 0x00, 0x00,\n      // flags\n      upperWordBaseMediaDecodeTime >> 24, upperWordBaseMediaDecodeTime >> 16 & 0xff, upperWordBaseMediaDecodeTime >> 8 & 0xff, upperWordBaseMediaDecodeTime & 0xff, lowerWordBaseMediaDecodeTime >> 24, lowerWordBaseMediaDecodeTime >> 16 & 0xff, lowerWordBaseMediaDecodeTime >> 8 & 0xff, lowerWordBaseMediaDecodeTime & 0xff])), MP4.trun(track, sampleDependencyTable.length + 16 +\n      // tfhd\n      20 +\n      // tfdt\n      8 +\n      // traf header\n      16 +\n      // mfhd\n      8 +\n      // moof header\n      8),\n      // mdat header\n      sampleDependencyTable);\n    }\n\n    /**\n     * Generate a track box.\n     * @param track a track definition\n     */;\n    MP4.trak = function trak(track) {\n      track.duration = track.duration || 0xffffffff;\n      return MP4.box(MP4.types.trak, MP4.tkhd(track), MP4.mdia(track));\n    };\n    MP4.trex = function trex(track) {\n      var id = track.id;\n      return MP4.box(MP4.types.trex, new Uint8Array([0x00,\n      // version 0\n      0x00, 0x00, 0x00,\n      // flags\n      id >> 24, id >> 16 & 0xff, id >> 8 & 0xff, id & 0xff,\n      // track_ID\n      0x00, 0x00, 0x00, 0x01,\n      // default_sample_description_index\n      0x00, 0x00, 0x00, 0x00,\n      // default_sample_duration\n      0x00, 0x00, 0x00, 0x00,\n      // default_sample_size\n      0x00, 0x01, 0x00, 0x01 // default_sample_flags\n      ]));\n    };\n    MP4.trun = function trun(track, offset) {\n      var samples = track.samples || [];\n      var len = samples.length;\n      var arraylen = 12 + 16 * len;\n      var array = new Uint8Array(arraylen);\n      var i;\n      var sample;\n      var duration;\n      var size;\n      var flags;\n      var cts;\n      offset += 8 + arraylen;\n      array.set([track.type === 'video' ? 0x01 : 0x00,\n      // version 1 for video with signed-int sample_composition_time_offset\n      0x00, 0x0f, 0x01,\n      // flags\n      len >>> 24 & 0xff, len >>> 16 & 0xff, len >>> 8 & 0xff, len & 0xff,\n      // sample_count\n      offset >>> 24 & 0xff, offset >>> 16 & 0xff, offset >>> 8 & 0xff, offset & 0xff // data_offset\n      ], 0);\n      for (i = 0; i < len; i++) {\n        sample = samples[i];\n        duration = sample.duration;\n        size = sample.size;\n        flags = sample.flags;\n        cts = sample.cts;\n        array.set([duration >>> 24 & 0xff, duration >>> 16 & 0xff, duration >>> 8 & 0xff, duration & 0xff,\n        // sample_duration\n        size >>> 24 & 0xff, size >>> 16 & 0xff, size >>> 8 & 0xff, size & 0xff,\n        // sample_size\n        flags.isLeading << 2 | flags.dependsOn, flags.isDependedOn << 6 | flags.hasRedundancy << 4 | flags.paddingValue << 1 | flags.isNonSync, flags.degradPrio & 0xf0 << 8, flags.degradPrio & 0x0f,\n        // sample_flags\n        cts >>> 24 & 0xff, cts >>> 16 & 0xff, cts >>> 8 & 0xff, cts & 0xff // sample_composition_time_offset\n        ], 12 + 16 * i);\n      }\n      return MP4.box(MP4.types.trun, array);\n    };\n    MP4.initSegment = function initSegment(tracks) {\n      if (!MP4.types) {\n        MP4.init();\n      }\n      var movie = MP4.moov(tracks);\n      var result = appendUint8Array(MP4.FTYP, movie);\n      return result;\n    };\n    return MP4;\n  }();\n  MP4.types = void 0;\n  MP4.HDLR_TYPES = void 0;\n  MP4.STTS = void 0;\n  MP4.STSC = void 0;\n  MP4.STCO = void 0;\n  MP4.STSZ = void 0;\n  MP4.VMHD = void 0;\n  MP4.SMHD = void 0;\n  MP4.STSD = void 0;\n  MP4.FTYP = void 0;\n  MP4.DINF = void 0;\n\n  var MPEG_TS_CLOCK_FREQ_HZ = 90000;\n  function toTimescaleFromBase(baseTime, destScale, srcBase, round) {\n    if (srcBase === void 0) {\n      srcBase = 1;\n    }\n    if (round === void 0) {\n      round = false;\n    }\n    var result = baseTime * destScale * srcBase; // equivalent to `(value * scale) / (1 / base)`\n    return round ? Math.round(result) : result;\n  }\n  function toTimescaleFromScale(baseTime, destScale, srcScale, round) {\n    if (srcScale === void 0) {\n      srcScale = 1;\n    }\n    if (round === void 0) {\n      round = false;\n    }\n    return toTimescaleFromBase(baseTime, destScale, 1 / srcScale, round);\n  }\n  function toMsFromMpegTsClock(baseTime, round) {\n    if (round === void 0) {\n      round = false;\n    }\n    return toTimescaleFromBase(baseTime, 1000, 1 / MPEG_TS_CLOCK_FREQ_HZ, round);\n  }\n  function toMpegTsClockFromTimescale(baseTime, srcScale) {\n    if (srcScale === void 0) {\n      srcScale = 1;\n    }\n    return toTimescaleFromBase(baseTime, MPEG_TS_CLOCK_FREQ_HZ, 1 / srcScale);\n  }\n\n  var MAX_SILENT_FRAME_DURATION = 10 * 1000; // 10 seconds\n  var AAC_SAMPLES_PER_FRAME = 1024;\n  var MPEG_AUDIO_SAMPLE_PER_FRAME = 1152;\n  var AC3_SAMPLES_PER_FRAME = 1536;\n  var chromeVersion = null;\n  var safariWebkitVersion = null;\n  var MP4Remuxer = /*#__PURE__*/function () {\n    function MP4Remuxer(observer, config, typeSupported, vendor) {\n      this.observer = void 0;\n      this.config = void 0;\n      this.typeSupported = void 0;\n      this.ISGenerated = false;\n      this._initPTS = null;\n      this._initDTS = null;\n      this.nextAvcDts = null;\n      this.nextAudioPts = null;\n      this.videoSampleDuration = null;\n      this.isAudioContiguous = false;\n      this.isVideoContiguous = false;\n      this.videoTrackConfig = void 0;\n      this.observer = observer;\n      this.config = config;\n      this.typeSupported = typeSupported;\n      this.ISGenerated = false;\n      if (chromeVersion === null) {\n        var userAgent = navigator.userAgent || '';\n        var result = userAgent.match(/Chrome\\/(\\d+)/i);\n        chromeVersion = result ? parseInt(result[1]) : 0;\n      }\n      if (safariWebkitVersion === null) {\n        var _result = navigator.userAgent.match(/Safari\\/(\\d+)/i);\n        safariWebkitVersion = _result ? parseInt(_result[1]) : 0;\n      }\n    }\n    var _proto = MP4Remuxer.prototype;\n    _proto.destroy = function destroy() {\n      // @ts-ignore\n      this.config = this.videoTrackConfig = this._initPTS = this._initDTS = null;\n    };\n    _proto.resetTimeStamp = function resetTimeStamp(defaultTimeStamp) {\n      logger.log('[mp4-remuxer]: initPTS & initDTS reset');\n      this._initPTS = this._initDTS = defaultTimeStamp;\n    };\n    _proto.resetNextTimestamp = function resetNextTimestamp() {\n      logger.log('[mp4-remuxer]: reset next timestamp');\n      this.isVideoContiguous = false;\n      this.isAudioContiguous = false;\n    };\n    _proto.resetInitSegment = function resetInitSegment() {\n      logger.log('[mp4-remuxer]: ISGenerated flag reset');\n      this.ISGenerated = false;\n      this.videoTrackConfig = undefined;\n    };\n    _proto.getVideoStartPts = function getVideoStartPts(videoSamples) {\n      var rolloverDetected = false;\n      var startPTS = videoSamples.reduce(function (minPTS, sample) {\n        var delta = sample.pts - minPTS;\n        if (delta < -4294967296) {\n          // 2^32, see PTSNormalize for reasoning, but we're hitting a rollover here, and we don't want that to impact the timeOffset calculation\n          rolloverDetected = true;\n          return normalizePts(minPTS, sample.pts);\n        } else if (delta > 0) {\n          return minPTS;\n        } else {\n          return sample.pts;\n        }\n      }, videoSamples[0].pts);\n      if (rolloverDetected) {\n        logger.debug('PTS rollover detected');\n      }\n      return startPTS;\n    };\n    _proto.remux = function remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, flush, playlistType) {\n      var video;\n      var audio;\n      var initSegment;\n      var text;\n      var id3;\n      var independent;\n      var audioTimeOffset = timeOffset;\n      var videoTimeOffset = timeOffset;\n\n      // If we're remuxing audio and video progressively, wait until we've received enough samples for each track before proceeding.\n      // This is done to synchronize the audio and video streams. We know if the current segment will have samples if the \"pid\"\n      // parameter is greater than -1. The pid is set when the PMT is parsed, which contains the tracks list.\n      // However, if the initSegment has already been generated, or we've reached the end of a segment (flush),\n      // then we can remux one track without waiting for the other.\n      var hasAudio = audioTrack.pid > -1;\n      var hasVideo = videoTrack.pid > -1;\n      var length = videoTrack.samples.length;\n      var enoughAudioSamples = audioTrack.samples.length > 0;\n      var enoughVideoSamples = flush && length > 0 || length > 1;\n      var canRemuxAvc = (!hasAudio || enoughAudioSamples) && (!hasVideo || enoughVideoSamples) || this.ISGenerated || flush;\n      if (canRemuxAvc) {\n        if (this.ISGenerated) {\n          var _videoTrack$pixelRati, _config$pixelRatio, _videoTrack$pixelRati2, _config$pixelRatio2;\n          var config = this.videoTrackConfig;\n          if (config && (videoTrack.width !== config.width || videoTrack.height !== config.height || ((_videoTrack$pixelRati = videoTrack.pixelRatio) == null ? void 0 : _videoTrack$pixelRati[0]) !== ((_config$pixelRatio = config.pixelRatio) == null ? void 0 : _config$pixelRatio[0]) || ((_videoTrack$pixelRati2 = videoTrack.pixelRatio) == null ? void 0 : _videoTrack$pixelRati2[1]) !== ((_config$pixelRatio2 = config.pixelRatio) == null ? void 0 : _config$pixelRatio2[1]))) {\n            this.resetInitSegment();\n          }\n        } else {\n          initSegment = this.generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset);\n        }\n        var isVideoContiguous = this.isVideoContiguous;\n        var firstKeyFrameIndex = -1;\n        var firstKeyFramePTS;\n        if (enoughVideoSamples) {\n          firstKeyFrameIndex = findKeyframeIndex(videoTrack.samples);\n          if (!isVideoContiguous && this.config.forceKeyFrameOnDiscontinuity) {\n            independent = true;\n            if (firstKeyFrameIndex > 0) {\n              logger.warn(\"[mp4-remuxer]: Dropped \" + firstKeyFrameIndex + \" out of \" + length + \" video samples due to a missing keyframe\");\n              var startPTS = this.getVideoStartPts(videoTrack.samples);\n              videoTrack.samples = videoTrack.samples.slice(firstKeyFrameIndex);\n              videoTrack.dropped += firstKeyFrameIndex;\n              videoTimeOffset += (videoTrack.samples[0].pts - startPTS) / videoTrack.inputTimeScale;\n              firstKeyFramePTS = videoTimeOffset;\n            } else if (firstKeyFrameIndex === -1) {\n              logger.warn(\"[mp4-remuxer]: No keyframe found out of \" + length + \" video samples\");\n              independent = false;\n            }\n          }\n        }\n        if (this.ISGenerated) {\n          if (enoughAudioSamples && enoughVideoSamples) {\n            // timeOffset is expected to be the offset of the first timestamp of this fragment (first DTS)\n            // if first audio DTS is not aligned with first video DTS then we need to take that into account\n            // when providing timeOffset to remuxAudio / remuxVideo. if we don't do that, there might be a permanent / small\n            // drift between audio and video streams\n            var _startPTS = this.getVideoStartPts(videoTrack.samples);\n            var tsDelta = normalizePts(audioTrack.samples[0].pts, _startPTS) - _startPTS;\n            var audiovideoTimestampDelta = tsDelta / videoTrack.inputTimeScale;\n            audioTimeOffset += Math.max(0, audiovideoTimestampDelta);\n            videoTimeOffset += Math.max(0, -audiovideoTimestampDelta);\n          }\n\n          // Purposefully remuxing audio before video, so that remuxVideo can use nextAudioPts, which is calculated in remuxAudio.\n          if (enoughAudioSamples) {\n            // if initSegment was generated without audio samples, regenerate it again\n            if (!audioTrack.samplerate) {\n              logger.warn('[mp4-remuxer]: regenerate InitSegment as audio detected');\n              initSegment = this.generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset);\n            }\n            audio = this.remuxAudio(audioTrack, audioTimeOffset, this.isAudioContiguous, accurateTimeOffset, hasVideo || enoughVideoSamples || playlistType === PlaylistLevelType.AUDIO ? videoTimeOffset : undefined);\n            if (enoughVideoSamples) {\n              var audioTrackLength = audio ? audio.endPTS - audio.startPTS : 0;\n              // if initSegment was generated without video samples, regenerate it again\n              if (!videoTrack.inputTimeScale) {\n                logger.warn('[mp4-remuxer]: regenerate InitSegment as video detected');\n                initSegment = this.generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset);\n              }\n              video = this.remuxVideo(videoTrack, videoTimeOffset, isVideoContiguous, audioTrackLength);\n            }\n          } else if (enoughVideoSamples) {\n            video = this.remuxVideo(videoTrack, videoTimeOffset, isVideoContiguous, 0);\n          }\n          if (video) {\n            video.firstKeyFrame = firstKeyFrameIndex;\n            video.independent = firstKeyFrameIndex !== -1;\n            video.firstKeyFramePTS = firstKeyFramePTS;\n          }\n        }\n      }\n\n      // Allow ID3 and text to remux, even if more audio/video samples are required\n      if (this.ISGenerated && this._initPTS && this._initDTS) {\n        if (id3Track.samples.length) {\n          id3 = flushTextTrackMetadataCueSamples(id3Track, timeOffset, this._initPTS, this._initDTS);\n        }\n        if (textTrack.samples.length) {\n          text = flushTextTrackUserdataCueSamples(textTrack, timeOffset, this._initPTS);\n        }\n      }\n      return {\n        audio: audio,\n        video: video,\n        initSegment: initSegment,\n        independent: independent,\n        text: text,\n        id3: id3\n      };\n    };\n    _proto.generateIS = function generateIS(audioTrack, videoTrack, timeOffset, accurateTimeOffset) {\n      var audioSamples = audioTrack.samples;\n      var videoSamples = videoTrack.samples;\n      var typeSupported = this.typeSupported;\n      var tracks = {};\n      var _initPTS = this._initPTS;\n      var computePTSDTS = !_initPTS || accurateTimeOffset;\n      var container = 'audio/mp4';\n      var initPTS;\n      var initDTS;\n      var timescale;\n      if (computePTSDTS) {\n        initPTS = initDTS = Infinity;\n      }\n      if (audioTrack.config && audioSamples.length) {\n        // let's use audio sampling rate as MP4 time scale.\n        // rationale is that there is a integer nb of audio frames per audio sample (1024 for AAC)\n        // using audio sampling rate here helps having an integer MP4 frame duration\n        // this avoids potential rounding issue and AV sync issue\n        audioTrack.timescale = audioTrack.samplerate;\n        switch (audioTrack.segmentCodec) {\n          case 'mp3':\n            if (typeSupported.mpeg) {\n              // Chrome and Safari\n              container = 'audio/mpeg';\n              audioTrack.codec = '';\n            } else if (typeSupported.mp3) {\n              // Firefox\n              audioTrack.codec = 'mp3';\n            }\n            break;\n          case 'ac3':\n            audioTrack.codec = 'ac-3';\n            break;\n        }\n        tracks.audio = {\n          id: 'audio',\n          container: container,\n          codec: audioTrack.codec,\n          initSegment: audioTrack.segmentCodec === 'mp3' && typeSupported.mpeg ? new Uint8Array(0) : MP4.initSegment([audioTrack]),\n          metadata: {\n            channelCount: audioTrack.channelCount\n          }\n        };\n        if (computePTSDTS) {\n          timescale = audioTrack.inputTimeScale;\n          if (!_initPTS || timescale !== _initPTS.timescale) {\n            // remember first PTS of this demuxing context. for audio, PTS = DTS\n            initPTS = initDTS = audioSamples[0].pts - Math.round(timescale * timeOffset);\n          } else {\n            computePTSDTS = false;\n          }\n        }\n      }\n      if (videoTrack.sps && videoTrack.pps && videoSamples.length) {\n        // let's use input time scale as MP4 video timescale\n        // we use input time scale straight away to avoid rounding issues on frame duration / cts computation\n        videoTrack.timescale = videoTrack.inputTimeScale;\n        tracks.video = {\n          id: 'main',\n          container: 'video/mp4',\n          codec: videoTrack.codec,\n          initSegment: MP4.initSegment([videoTrack]),\n          metadata: {\n            width: videoTrack.width,\n            height: videoTrack.height\n          }\n        };\n        if (computePTSDTS) {\n          timescale = videoTrack.inputTimeScale;\n          if (!_initPTS || timescale !== _initPTS.timescale) {\n            var startPTS = this.getVideoStartPts(videoSamples);\n            var startOffset = Math.round(timescale * timeOffset);\n            initDTS = Math.min(initDTS, normalizePts(videoSamples[0].dts, startPTS) - startOffset);\n            initPTS = Math.min(initPTS, startPTS - startOffset);\n          } else {\n            computePTSDTS = false;\n          }\n        }\n        this.videoTrackConfig = {\n          width: videoTrack.width,\n          height: videoTrack.height,\n          pixelRatio: videoTrack.pixelRatio\n        };\n      }\n      if (Object.keys(tracks).length) {\n        this.ISGenerated = true;\n        if (computePTSDTS) {\n          this._initPTS = {\n            baseTime: initPTS,\n            timescale: timescale\n          };\n          this._initDTS = {\n            baseTime: initDTS,\n            timescale: timescale\n          };\n        } else {\n          initPTS = timescale = undefined;\n        }\n        return {\n          tracks: tracks,\n          initPTS: initPTS,\n          timescale: timescale\n        };\n      }\n    };\n    _proto.remuxVideo = function remuxVideo(track, timeOffset, contiguous, audioTrackLength) {\n      var timeScale = track.inputTimeScale;\n      var inputSamples = track.samples;\n      var outputSamples = [];\n      var nbSamples = inputSamples.length;\n      var initPTS = this._initPTS;\n      var nextAvcDts = this.nextAvcDts;\n      var offset = 8;\n      var mp4SampleDuration = this.videoSampleDuration;\n      var firstDTS;\n      var lastDTS;\n      var minPTS = Number.POSITIVE_INFINITY;\n      var maxPTS = Number.NEGATIVE_INFINITY;\n      var sortSamples = false;\n\n      // if parsed fragment is contiguous with last one, let's use last DTS value as reference\n      if (!contiguous || nextAvcDts === null) {\n        var pts = timeOffset * timeScale;\n        var cts = inputSamples[0].pts - normalizePts(inputSamples[0].dts, inputSamples[0].pts);\n        if (chromeVersion && nextAvcDts !== null && Math.abs(pts - cts - nextAvcDts) < 15000) {\n          // treat as contigous to adjust samples that would otherwise produce video buffer gaps in Chrome\n          contiguous = true;\n        } else {\n          // if not contiguous, let's use target timeOffset\n          nextAvcDts = pts - cts;\n        }\n      }\n\n      // PTS is coded on 33bits, and can loop from -2^32 to 2^32\n      // PTSNormalize will make PTS/DTS value monotonic, we use last known DTS value as reference value\n      var initTime = initPTS.baseTime * timeScale / initPTS.timescale;\n      for (var i = 0; i < nbSamples; i++) {\n        var sample = inputSamples[i];\n        sample.pts = normalizePts(sample.pts - initTime, nextAvcDts);\n        sample.dts = normalizePts(sample.dts - initTime, nextAvcDts);\n        if (sample.dts < inputSamples[i > 0 ? i - 1 : i].dts) {\n          sortSamples = true;\n        }\n      }\n\n      // sort video samples by DTS then PTS then demux id order\n      if (sortSamples) {\n        inputSamples.sort(function (a, b) {\n          var deltadts = a.dts - b.dts;\n          var deltapts = a.pts - b.pts;\n          return deltadts || deltapts;\n        });\n      }\n\n      // Get first/last DTS\n      firstDTS = inputSamples[0].dts;\n      lastDTS = inputSamples[inputSamples.length - 1].dts;\n\n      // Sample duration (as expected by trun MP4 boxes), should be the delta between sample DTS\n      // set this constant duration as being the avg delta between consecutive DTS.\n      var inputDuration = lastDTS - firstDTS;\n      var averageSampleDuration = inputDuration ? Math.round(inputDuration / (nbSamples - 1)) : mp4SampleDuration || track.inputTimeScale / 30;\n\n      // if fragment are contiguous, detect hole/overlapping between fragments\n      if (contiguous) {\n        // check timestamp continuity across consecutive fragments (this is to remove inter-fragment gap/hole)\n        var delta = firstDTS - nextAvcDts;\n        var foundHole = delta > averageSampleDuration;\n        var foundOverlap = delta < -1;\n        if (foundHole || foundOverlap) {\n          if (foundHole) {\n            logger.warn(\"AVC: \" + toMsFromMpegTsClock(delta, true) + \" ms (\" + delta + \"dts) hole between fragments detected at \" + timeOffset.toFixed(3));\n          } else {\n            logger.warn(\"AVC: \" + toMsFromMpegTsClock(-delta, true) + \" ms (\" + delta + \"dts) overlapping between fragments detected at \" + timeOffset.toFixed(3));\n          }\n          if (!foundOverlap || nextAvcDts >= inputSamples[0].pts || chromeVersion) {\n            firstDTS = nextAvcDts;\n            var firstPTS = inputSamples[0].pts - delta;\n            if (foundHole) {\n              inputSamples[0].dts = firstDTS;\n              inputSamples[0].pts = firstPTS;\n            } else {\n              for (var _i = 0; _i < inputSamples.length; _i++) {\n                if (inputSamples[_i].dts > firstPTS) {\n                  break;\n                }\n                inputSamples[_i].dts -= delta;\n                inputSamples[_i].pts -= delta;\n              }\n            }\n            logger.log(\"Video: Initial PTS/DTS adjusted: \" + toMsFromMpegTsClock(firstPTS, true) + \"/\" + toMsFromMpegTsClock(firstDTS, true) + \", delta: \" + toMsFromMpegTsClock(delta, true) + \" ms\");\n          }\n        }\n      }\n      firstDTS = Math.max(0, firstDTS);\n      var nbNalu = 0;\n      var naluLen = 0;\n      var dtsStep = firstDTS;\n      for (var _i2 = 0; _i2 < nbSamples; _i2++) {\n        // compute total/avc sample length and nb of NAL units\n        var _sample = inputSamples[_i2];\n        var units = _sample.units;\n        var nbUnits = units.length;\n        var sampleLen = 0;\n        for (var j = 0; j < nbUnits; j++) {\n          sampleLen += units[j].data.length;\n        }\n        naluLen += sampleLen;\n        nbNalu += nbUnits;\n        _sample.length = sampleLen;\n\n        // ensure sample monotonic DTS\n        if (_sample.dts < dtsStep) {\n          _sample.dts = dtsStep;\n          dtsStep += averageSampleDuration / 4 | 0 || 1;\n        } else {\n          dtsStep = _sample.dts;\n        }\n        minPTS = Math.min(_sample.pts, minPTS);\n        maxPTS = Math.max(_sample.pts, maxPTS);\n      }\n      lastDTS = inputSamples[nbSamples - 1].dts;\n\n      /* concatenate the video data and construct the mdat in place\n        (need 8 more bytes to fill length and mpdat type) */\n      var mdatSize = naluLen + 4 * nbNalu + 8;\n      var mdat;\n      try {\n        mdat = new Uint8Array(mdatSize);\n      } catch (err) {\n        this.observer.emit(Events.ERROR, Events.ERROR, {\n          type: ErrorTypes.MUX_ERROR,\n          details: ErrorDetails.REMUX_ALLOC_ERROR,\n          fatal: false,\n          error: err,\n          bytes: mdatSize,\n          reason: \"fail allocating video mdat \" + mdatSize\n        });\n        return;\n      }\n      var view = new DataView(mdat.buffer);\n      view.setUint32(0, mdatSize);\n      mdat.set(MP4.types.mdat, 4);\n      var stretchedLastFrame = false;\n      var minDtsDelta = Number.POSITIVE_INFINITY;\n      var minPtsDelta = Number.POSITIVE_INFINITY;\n      var maxDtsDelta = Number.NEGATIVE_INFINITY;\n      var maxPtsDelta = Number.NEGATIVE_INFINITY;\n      for (var _i3 = 0; _i3 < nbSamples; _i3++) {\n        var _VideoSample = inputSamples[_i3];\n        var VideoSampleUnits = _VideoSample.units;\n        var mp4SampleLength = 0;\n        // convert NALU bitstream to MP4 format (prepend NALU with size field)\n        for (var _j = 0, _nbUnits = VideoSampleUnits.length; _j < _nbUnits; _j++) {\n          var unit = VideoSampleUnits[_j];\n          var unitData = unit.data;\n          var unitDataLen = unit.data.byteLength;\n          view.setUint32(offset, unitDataLen);\n          offset += 4;\n          mdat.set(unitData, offset);\n          offset += unitDataLen;\n          mp4SampleLength += 4 + unitDataLen;\n        }\n\n        // expected sample duration is the Decoding Timestamp diff of consecutive samples\n        var ptsDelta = void 0;\n        if (_i3 < nbSamples - 1) {\n          mp4SampleDuration = inputSamples[_i3 + 1].dts - _VideoSample.dts;\n          ptsDelta = inputSamples[_i3 + 1].pts - _VideoSample.pts;\n        } else {\n          var config = this.config;\n          var lastFrameDuration = _i3 > 0 ? _VideoSample.dts - inputSamples[_i3 - 1].dts : averageSampleDuration;\n          ptsDelta = _i3 > 0 ? _VideoSample.pts - inputSamples[_i3 - 1].pts : averageSampleDuration;\n          if (config.stretchShortVideoTrack && this.nextAudioPts !== null) {\n            // In some cases, a segment's audio track duration may exceed the video track duration.\n            // Since we've already remuxed audio, and we know how long the audio track is, we look to\n            // see if the delta to the next segment is longer than maxBufferHole.\n            // If so, playback would potentially get stuck, so we artificially inflate\n            // the duration of the last frame to minimize any potential gap between segments.\n            var gapTolerance = Math.floor(config.maxBufferHole * timeScale);\n            var deltaToFrameEnd = (audioTrackLength ? minPTS + audioTrackLength * timeScale : this.nextAudioPts) - _VideoSample.pts;\n            if (deltaToFrameEnd > gapTolerance) {\n              // We subtract lastFrameDuration from deltaToFrameEnd to try to prevent any video\n              // frame overlap. maxBufferHole should be >> lastFrameDuration anyway.\n              mp4SampleDuration = deltaToFrameEnd - lastFrameDuration;\n              if (mp4SampleDuration < 0) {\n                mp4SampleDuration = lastFrameDuration;\n              } else {\n                stretchedLastFrame = true;\n              }\n              logger.log(\"[mp4-remuxer]: It is approximately \" + deltaToFrameEnd / 90 + \" ms to the next segment; using duration \" + mp4SampleDuration / 90 + \" ms for the last video frame.\");\n            } else {\n              mp4SampleDuration = lastFrameDuration;\n            }\n          } else {\n            mp4SampleDuration = lastFrameDuration;\n          }\n        }\n        var compositionTimeOffset = Math.round(_VideoSample.pts - _VideoSample.dts);\n        minDtsDelta = Math.min(minDtsDelta, mp4SampleDuration);\n        maxDtsDelta = Math.max(maxDtsDelta, mp4SampleDuration);\n        minPtsDelta = Math.min(minPtsDelta, ptsDelta);\n        maxPtsDelta = Math.max(maxPtsDelta, ptsDelta);\n        outputSamples.push(new Mp4Sample(_VideoSample.key, mp4SampleDuration, mp4SampleLength, compositionTimeOffset));\n      }\n      if (outputSamples.length) {\n        if (chromeVersion) {\n          if (chromeVersion < 70) {\n            // Chrome workaround, mark first sample as being a Random Access Point (keyframe) to avoid sourcebuffer append issue\n            // https://code.google.com/p/chromium/issues/detail?id=229412\n            var flags = outputSamples[0].flags;\n            flags.dependsOn = 2;\n            flags.isNonSync = 0;\n          }\n        } else if (safariWebkitVersion) {\n          // Fix for \"CNN special report, with CC\" in test-streams (Safari browser only)\n          // Ignore DTS when frame durations are irregular. Safari MSE does not handle this leading to gaps.\n          if (maxPtsDelta - minPtsDelta < maxDtsDelta - minDtsDelta && averageSampleDuration / maxDtsDelta < 0.025 && outputSamples[0].cts === 0) {\n            logger.warn('Found irregular gaps in sample duration. Using PTS instead of DTS to determine MP4 sample duration.');\n            var dts = firstDTS;\n            for (var _i4 = 0, len = outputSamples.length; _i4 < len; _i4++) {\n              var nextDts = dts + outputSamples[_i4].duration;\n              var _pts = dts + outputSamples[_i4].cts;\n              if (_i4 < len - 1) {\n                var nextPts = nextDts + outputSamples[_i4 + 1].cts;\n                outputSamples[_i4].duration = nextPts - _pts;\n              } else {\n                outputSamples[_i4].duration = _i4 ? outputSamples[_i4 - 1].duration : averageSampleDuration;\n              }\n              outputSamples[_i4].cts = 0;\n              dts = nextDts;\n            }\n          }\n        }\n      }\n      // next AVC sample DTS should be equal to last sample DTS + last sample duration (in PES timescale)\n      mp4SampleDuration = stretchedLastFrame || !mp4SampleDuration ? averageSampleDuration : mp4SampleDuration;\n      this.nextAvcDts = nextAvcDts = lastDTS + mp4SampleDuration;\n      this.videoSampleDuration = mp4SampleDuration;\n      this.isVideoContiguous = true;\n      var moof = MP4.moof(track.sequenceNumber++, firstDTS, _extends({}, track, {\n        samples: outputSamples\n      }));\n      var type = 'video';\n      var data = {\n        data1: moof,\n        data2: mdat,\n        startPTS: minPTS / timeScale,\n        endPTS: (maxPTS + mp4SampleDuration) / timeScale,\n        startDTS: firstDTS / timeScale,\n        endDTS: nextAvcDts / timeScale,\n        type: type,\n        hasAudio: false,\n        hasVideo: true,\n        nb: outputSamples.length,\n        dropped: track.dropped\n      };\n      track.samples = [];\n      track.dropped = 0;\n      return data;\n    };\n    _proto.getSamplesPerFrame = function getSamplesPerFrame(track) {\n      switch (track.segmentCodec) {\n        case 'mp3':\n          return MPEG_AUDIO_SAMPLE_PER_FRAME;\n        case 'ac3':\n          return AC3_SAMPLES_PER_FRAME;\n        default:\n          return AAC_SAMPLES_PER_FRAME;\n      }\n    };\n    _proto.remuxAudio = function remuxAudio(track, timeOffset, contiguous, accurateTimeOffset, videoTimeOffset) {\n      var inputTimeScale = track.inputTimeScale;\n      var mp4timeScale = track.samplerate ? track.samplerate : inputTimeScale;\n      var scaleFactor = inputTimeScale / mp4timeScale;\n      var mp4SampleDuration = this.getSamplesPerFrame(track);\n      var inputSampleDuration = mp4SampleDuration * scaleFactor;\n      var initPTS = this._initPTS;\n      var rawMPEG = track.segmentCodec === 'mp3' && this.typeSupported.mpeg;\n      var outputSamples = [];\n      var alignedWithVideo = videoTimeOffset !== undefined;\n      var inputSamples = track.samples;\n      var offset = rawMPEG ? 0 : 8;\n      var nextAudioPts = this.nextAudioPts || -1;\n\n      // window.audioSamples ? window.audioSamples.push(inputSamples.map(s => s.pts)) : (window.audioSamples = [inputSamples.map(s => s.pts)]);\n\n      // for audio samples, also consider consecutive fragments as being contiguous (even if a level switch occurs),\n      // for sake of clarity:\n      // consecutive fragments are frags with\n      //  - less than 100ms gaps between new time offset (if accurate) and next expected PTS OR\n      //  - less than 20 audio frames distance\n      // contiguous fragments are consecutive fragments from same quality level (same level, new SN = old SN + 1)\n      // this helps ensuring audio continuity\n      // and this also avoids audio glitches/cut when switching quality, or reporting wrong duration on first audio frame\n      var timeOffsetMpegTS = timeOffset * inputTimeScale;\n      var initTime = initPTS.baseTime * inputTimeScale / initPTS.timescale;\n      this.isAudioContiguous = contiguous = contiguous || inputSamples.length && nextAudioPts > 0 && (accurateTimeOffset && Math.abs(timeOffsetMpegTS - nextAudioPts) < 9000 || Math.abs(normalizePts(inputSamples[0].pts - initTime, timeOffsetMpegTS) - nextAudioPts) < 20 * inputSampleDuration);\n\n      // compute normalized PTS\n      inputSamples.forEach(function (sample) {\n        sample.pts = normalizePts(sample.pts - initTime, timeOffsetMpegTS);\n      });\n      if (!contiguous || nextAudioPts < 0) {\n        // filter out sample with negative PTS that are not playable anyway\n        // if we don't remove these negative samples, they will shift all audio samples forward.\n        // leading to audio overlap between current / next fragment\n        inputSamples = inputSamples.filter(function (sample) {\n          return sample.pts >= 0;\n        });\n\n        // in case all samples have negative PTS, and have been filtered out, return now\n        if (!inputSamples.length) {\n          return;\n        }\n        if (videoTimeOffset === 0) {\n          // Set the start to 0 to match video so that start gaps larger than inputSampleDuration are filled with silence\n          nextAudioPts = 0;\n        } else if (accurateTimeOffset && !alignedWithVideo) {\n          // When not seeking, not live, and LevelDetails.PTSKnown, use fragment start as predicted next audio PTS\n          nextAudioPts = Math.max(0, timeOffsetMpegTS);\n        } else {\n          // if frags are not contiguous and if we cant trust time offset, let's use first sample PTS as next audio PTS\n          nextAudioPts = inputSamples[0].pts;\n        }\n      }\n\n      // If the audio track is missing samples, the frames seem to get \"left-shifted\" within the\n      // resulting mp4 segment, causing sync issues and leaving gaps at the end of the audio segment.\n      // In an effort to prevent this from happening, we inject frames here where there are gaps.\n      // When possible, we inject a silent frame; when that's not possible, we duplicate the last\n      // frame.\n\n      if (track.segmentCodec === 'aac') {\n        var maxAudioFramesDrift = this.config.maxAudioFramesDrift;\n        for (var i = 0, nextPts = nextAudioPts; i < inputSamples.length; i++) {\n          // First, let's see how far off this frame is from where we expect it to be\n          var sample = inputSamples[i];\n          var pts = sample.pts;\n          var delta = pts - nextPts;\n          var duration = Math.abs(1000 * delta / inputTimeScale);\n\n          // When remuxing with video, if we're overlapping by more than a duration, drop this sample to stay in sync\n          if (delta <= -maxAudioFramesDrift * inputSampleDuration && alignedWithVideo) {\n            if (i === 0) {\n              logger.warn(\"Audio frame @ \" + (pts / inputTimeScale).toFixed(3) + \"s overlaps nextAudioPts by \" + Math.round(1000 * delta / inputTimeScale) + \" ms.\");\n              this.nextAudioPts = nextAudioPts = nextPts = pts;\n            }\n          } // eslint-disable-line brace-style\n\n          // Insert missing frames if:\n          // 1: We're more than maxAudioFramesDrift frame away\n          // 2: Not more than MAX_SILENT_FRAME_DURATION away\n          // 3: currentTime (aka nextPtsNorm) is not 0\n          // 4: remuxing with video (videoTimeOffset !== undefined)\n          else if (delta >= maxAudioFramesDrift * inputSampleDuration && duration < MAX_SILENT_FRAME_DURATION && alignedWithVideo) {\n            var missing = Math.round(delta / inputSampleDuration);\n            // Adjust nextPts so that silent samples are aligned with media pts. This will prevent media samples from\n            // later being shifted if nextPts is based on timeOffset and delta is not a multiple of inputSampleDuration.\n            nextPts = pts - missing * inputSampleDuration;\n            if (nextPts < 0) {\n              missing--;\n              nextPts += inputSampleDuration;\n            }\n            if (i === 0) {\n              this.nextAudioPts = nextAudioPts = nextPts;\n            }\n            logger.warn(\"[mp4-remuxer]: Injecting \" + missing + \" audio frame @ \" + (nextPts / inputTimeScale).toFixed(3) + \"s due to \" + Math.round(1000 * delta / inputTimeScale) + \" ms gap.\");\n            for (var j = 0; j < missing; j++) {\n              var newStamp = Math.max(nextPts, 0);\n              var fillFrame = AAC.getSilentFrame(track.manifestCodec || track.codec, track.channelCount);\n              if (!fillFrame) {\n                logger.log('[mp4-remuxer]: Unable to get silent frame for given audio codec; duplicating last frame instead.');\n                fillFrame = sample.unit.subarray();\n              }\n              inputSamples.splice(i, 0, {\n                unit: fillFrame,\n                pts: newStamp\n              });\n              nextPts += inputSampleDuration;\n              i++;\n            }\n          }\n          sample.pts = nextPts;\n          nextPts += inputSampleDuration;\n        }\n      }\n      var firstPTS = null;\n      var lastPTS = null;\n      var mdat;\n      var mdatSize = 0;\n      var sampleLength = inputSamples.length;\n      while (sampleLength--) {\n        mdatSize += inputSamples[sampleLength].unit.byteLength;\n      }\n      for (var _j2 = 0, _nbSamples = inputSamples.length; _j2 < _nbSamples; _j2++) {\n        var audioSample = inputSamples[_j2];\n        var unit = audioSample.unit;\n        var _pts2 = audioSample.pts;\n        if (lastPTS !== null) {\n          // If we have more than one sample, set the duration of the sample to the \"real\" duration; the PTS diff with\n          // the previous sample\n          var prevSample = outputSamples[_j2 - 1];\n          prevSample.duration = Math.round((_pts2 - lastPTS) / scaleFactor);\n        } else {\n          if (contiguous && track.segmentCodec === 'aac') {\n            // set PTS/DTS to expected PTS/DTS\n            _pts2 = nextAudioPts;\n          }\n          // remember first PTS of our audioSamples\n          firstPTS = _pts2;\n          if (mdatSize > 0) {\n            /* concatenate the audio data and construct the mdat in place\n              (need 8 more bytes to fill length and mdat type) */\n            mdatSize += offset;\n            try {\n              mdat = new Uint8Array(mdatSize);\n            } catch (err) {\n              this.observer.emit(Events.ERROR, Events.ERROR, {\n                type: ErrorTypes.MUX_ERROR,\n                details: ErrorDetails.REMUX_ALLOC_ERROR,\n                fatal: false,\n                error: err,\n                bytes: mdatSize,\n                reason: \"fail allocating audio mdat \" + mdatSize\n              });\n              return;\n            }\n            if (!rawMPEG) {\n              var view = new DataView(mdat.buffer);\n              view.setUint32(0, mdatSize);\n              mdat.set(MP4.types.mdat, 4);\n            }\n          } else {\n            // no audio samples\n            return;\n          }\n        }\n        mdat.set(unit, offset);\n        var unitLen = unit.byteLength;\n        offset += unitLen;\n        // Default the sample's duration to the computed mp4SampleDuration, which will either be 1024 for AAC or 1152 for MPEG\n        // In the case that we have 1 sample, this will be the duration. If we have more than one sample, the duration\n        // becomes the PTS diff with the previous sample\n        outputSamples.push(new Mp4Sample(true, mp4SampleDuration, unitLen, 0));\n        lastPTS = _pts2;\n      }\n\n      // We could end up with no audio samples if all input samples were overlapping with the previously remuxed ones\n      var nbSamples = outputSamples.length;\n      if (!nbSamples) {\n        return;\n      }\n\n      // The next audio sample PTS should be equal to last sample PTS + duration\n      var lastSample = outputSamples[outputSamples.length - 1];\n      this.nextAudioPts = nextAudioPts = lastPTS + scaleFactor * lastSample.duration;\n\n      // Set the track samples from inputSamples to outputSamples before remuxing\n      var moof = rawMPEG ? new Uint8Array(0) : MP4.moof(track.sequenceNumber++, firstPTS / scaleFactor, _extends({}, track, {\n        samples: outputSamples\n      }));\n\n      // Clear the track samples. This also clears the samples array in the demuxer, since the reference is shared\n      track.samples = [];\n      var start = firstPTS / inputTimeScale;\n      var end = nextAudioPts / inputTimeScale;\n      var type = 'audio';\n      var audioData = {\n        data1: moof,\n        data2: mdat,\n        startPTS: start,\n        endPTS: end,\n        startDTS: start,\n        endDTS: end,\n        type: type,\n        hasAudio: true,\n        hasVideo: false,\n        nb: nbSamples\n      };\n      this.isAudioContiguous = true;\n      return audioData;\n    };\n    _proto.remuxEmptyAudio = function remuxEmptyAudio(track, timeOffset, contiguous, videoData) {\n      var inputTimeScale = track.inputTimeScale;\n      var mp4timeScale = track.samplerate ? track.samplerate : inputTimeScale;\n      var scaleFactor = inputTimeScale / mp4timeScale;\n      var nextAudioPts = this.nextAudioPts;\n      // sync with video's timestamp\n      var initDTS = this._initDTS;\n      var init90kHz = initDTS.baseTime * 90000 / initDTS.timescale;\n      var startDTS = (nextAudioPts !== null ? nextAudioPts : videoData.startDTS * inputTimeScale) + init90kHz;\n      var endDTS = videoData.endDTS * inputTimeScale + init90kHz;\n      // one sample's duration value\n      var frameDuration = scaleFactor * AAC_SAMPLES_PER_FRAME;\n      // samples count of this segment's duration\n      var nbSamples = Math.ceil((endDTS - startDTS) / frameDuration);\n      // silent frame\n      var silentFrame = AAC.getSilentFrame(track.manifestCodec || track.codec, track.channelCount);\n      logger.warn('[mp4-remuxer]: remux empty Audio');\n      // Can't remux if we can't generate a silent frame...\n      if (!silentFrame) {\n        logger.trace('[mp4-remuxer]: Unable to remuxEmptyAudio since we were unable to get a silent frame for given audio codec');\n        return;\n      }\n      var samples = [];\n      for (var i = 0; i < nbSamples; i++) {\n        var stamp = startDTS + i * frameDuration;\n        samples.push({\n          unit: silentFrame,\n          pts: stamp,\n          dts: stamp\n        });\n      }\n      track.samples = samples;\n      return this.remuxAudio(track, timeOffset, contiguous, false);\n    };\n    return MP4Remuxer;\n  }();\n  function normalizePts(value, reference) {\n    var offset;\n    if (reference === null) {\n      return value;\n    }\n    if (reference < value) {\n      // - 2^33\n      offset = -8589934592;\n    } else {\n      // + 2^33\n      offset = 8589934592;\n    }\n    /* PTS is 33bit (from 0 to 2^33 -1)\n      if diff between value and reference is bigger than half of the amplitude (2^32) then it means that\n      PTS looping occured. fill the gap */\n    while (Math.abs(value - reference) > 4294967296) {\n      value += offset;\n    }\n    return value;\n  }\n  function findKeyframeIndex(samples) {\n    for (var i = 0; i < samples.length; i++) {\n      if (samples[i].key) {\n        return i;\n      }\n    }\n    return -1;\n  }\n  function flushTextTrackMetadataCueSamples(track, timeOffset, initPTS, initDTS) {\n    var length = track.samples.length;\n    if (!length) {\n      return;\n    }\n    var inputTimeScale = track.inputTimeScale;\n    for (var index = 0; index < length; index++) {\n      var sample = track.samples[index];\n      // setting id3 pts, dts to relative time\n      // using this._initPTS and this._initDTS to calculate relative time\n      sample.pts = normalizePts(sample.pts - initPTS.baseTime * inputTimeScale / initPTS.timescale, timeOffset * inputTimeScale) / inputTimeScale;\n      sample.dts = normalizePts(sample.dts - initDTS.baseTime * inputTimeScale / initDTS.timescale, timeOffset * inputTimeScale) / inputTimeScale;\n    }\n    var samples = track.samples;\n    track.samples = [];\n    return {\n      samples: samples\n    };\n  }\n  function flushTextTrackUserdataCueSamples(track, timeOffset, initPTS) {\n    var length = track.samples.length;\n    if (!length) {\n      return;\n    }\n    var inputTimeScale = track.inputTimeScale;\n    for (var index = 0; index < length; index++) {\n      var sample = track.samples[index];\n      // setting text pts, dts to relative time\n      // using this._initPTS and this._initDTS to calculate relative time\n      sample.pts = normalizePts(sample.pts - initPTS.baseTime * inputTimeScale / initPTS.timescale, timeOffset * inputTimeScale) / inputTimeScale;\n    }\n    track.samples.sort(function (a, b) {\n      return a.pts - b.pts;\n    });\n    var samples = track.samples;\n    track.samples = [];\n    return {\n      samples: samples\n    };\n  }\n  var Mp4Sample = function Mp4Sample(isKeyframe, duration, size, cts) {\n    this.size = void 0;\n    this.duration = void 0;\n    this.cts = void 0;\n    this.flags = void 0;\n    this.duration = duration;\n    this.size = size;\n    this.cts = cts;\n    this.flags = {\n      isLeading: 0,\n      isDependedOn: 0,\n      hasRedundancy: 0,\n      degradPrio: 0,\n      dependsOn: isKeyframe ? 2 : 1,\n      isNonSync: isKeyframe ? 0 : 1\n    };\n  };\n\n  var PassThroughRemuxer = /*#__PURE__*/function () {\n    function PassThroughRemuxer() {\n      this.emitInitSegment = false;\n      this.audioCodec = void 0;\n      this.videoCodec = void 0;\n      this.initData = void 0;\n      this.initPTS = null;\n      this.initTracks = void 0;\n      this.lastEndTime = null;\n    }\n    var _proto = PassThroughRemuxer.prototype;\n    _proto.destroy = function destroy() {};\n    _proto.resetTimeStamp = function resetTimeStamp(defaultInitPTS) {\n      this.initPTS = defaultInitPTS;\n      this.lastEndTime = null;\n    };\n    _proto.resetNextTimestamp = function resetNextTimestamp() {\n      this.lastEndTime = null;\n    };\n    _proto.resetInitSegment = function resetInitSegment(initSegment, audioCodec, videoCodec, decryptdata) {\n      this.audioCodec = audioCodec;\n      this.videoCodec = videoCodec;\n      this.generateInitSegment(patchEncyptionData(initSegment, decryptdata));\n      this.emitInitSegment = true;\n    };\n    _proto.generateInitSegment = function generateInitSegment(initSegment) {\n      var audioCodec = this.audioCodec,\n        videoCodec = this.videoCodec;\n      if (!(initSegment != null && initSegment.byteLength)) {\n        this.initTracks = undefined;\n        this.initData = undefined;\n        return;\n      }\n      var initData = this.initData = parseInitSegment(initSegment);\n\n      // Get codec from initSegment or fallback to default\n      if (initData.audio) {\n        audioCodec = getParsedTrackCodec(initData.audio, ElementaryStreamTypes.AUDIO);\n      }\n      if (initData.video) {\n        videoCodec = getParsedTrackCodec(initData.video, ElementaryStreamTypes.VIDEO);\n      }\n      var tracks = {};\n      if (initData.audio && initData.video) {\n        tracks.audiovideo = {\n          container: 'video/mp4',\n          codec: audioCodec + ',' + videoCodec,\n          initSegment: initSegment,\n          id: 'main'\n        };\n      } else if (initData.audio) {\n        tracks.audio = {\n          container: 'audio/mp4',\n          codec: audioCodec,\n          initSegment: initSegment,\n          id: 'audio'\n        };\n      } else if (initData.video) {\n        tracks.video = {\n          container: 'video/mp4',\n          codec: videoCodec,\n          initSegment: initSegment,\n          id: 'main'\n        };\n      } else {\n        logger.warn('[passthrough-remuxer.ts]: initSegment does not contain moov or trak boxes.');\n      }\n      this.initTracks = tracks;\n    };\n    _proto.remux = function remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset) {\n      var _initData, _initData2;\n      var initPTS = this.initPTS,\n        lastEndTime = this.lastEndTime;\n      var result = {\n        audio: undefined,\n        video: undefined,\n        text: textTrack,\n        id3: id3Track,\n        initSegment: undefined\n      };\n\n      // If we haven't yet set a lastEndDTS, or it was reset, set it to the provided timeOffset. We want to use the\n      // lastEndDTS over timeOffset whenever possible; during progressive playback, the media source will not update\n      // the media duration (which is what timeOffset is provided as) before we need to process the next chunk.\n      if (!isFiniteNumber(lastEndTime)) {\n        lastEndTime = this.lastEndTime = timeOffset || 0;\n      }\n\n      // The binary segment data is added to the videoTrack in the mp4demuxer. We don't check to see if the data is only\n      // audio or video (or both); adding it to video was an arbitrary choice.\n      var data = videoTrack.samples;\n      if (!(data != null && data.length)) {\n        return result;\n      }\n      var initSegment = {\n        initPTS: undefined,\n        timescale: 1\n      };\n      var initData = this.initData;\n      if (!((_initData = initData) != null && _initData.length)) {\n        this.generateInitSegment(data);\n        initData = this.initData;\n      }\n      if (!((_initData2 = initData) != null && _initData2.length)) {\n        // We can't remux if the initSegment could not be generated\n        logger.warn('[passthrough-remuxer.ts]: Failed to generate initSegment.');\n        return result;\n      }\n      if (this.emitInitSegment) {\n        initSegment.tracks = this.initTracks;\n        this.emitInitSegment = false;\n      }\n      var duration = getDuration(data, initData);\n      var startDTS = getStartDTS(initData, data);\n      var decodeTime = startDTS === null ? timeOffset : startDTS;\n      if (isInvalidInitPts(initPTS, decodeTime, timeOffset, duration) || initSegment.timescale !== initPTS.timescale && accurateTimeOffset) {\n        initSegment.initPTS = decodeTime - timeOffset;\n        if (initPTS && initPTS.timescale === 1) {\n          logger.warn(\"Adjusting initPTS by \" + (initSegment.initPTS - initPTS.baseTime));\n        }\n        this.initPTS = initPTS = {\n          baseTime: initSegment.initPTS,\n          timescale: 1\n        };\n      }\n      var startTime = audioTrack ? decodeTime - initPTS.baseTime / initPTS.timescale : lastEndTime;\n      var endTime = startTime + duration;\n      offsetStartDTS(initData, data, initPTS.baseTime / initPTS.timescale);\n      if (duration > 0) {\n        this.lastEndTime = endTime;\n      } else {\n        logger.warn('Duration parsed from mp4 should be greater than zero');\n        this.resetNextTimestamp();\n      }\n      var hasAudio = !!initData.audio;\n      var hasVideo = !!initData.video;\n      var type = '';\n      if (hasAudio) {\n        type += 'audio';\n      }\n      if (hasVideo) {\n        type += 'video';\n      }\n      var track = {\n        data1: data,\n        startPTS: startTime,\n        startDTS: startTime,\n        endPTS: endTime,\n        endDTS: endTime,\n        type: type,\n        hasAudio: hasAudio,\n        hasVideo: hasVideo,\n        nb: 1,\n        dropped: 0\n      };\n      result.audio = track.type === 'audio' ? track : undefined;\n      result.video = track.type !== 'audio' ? track : undefined;\n      result.initSegment = initSegment;\n      result.id3 = flushTextTrackMetadataCueSamples(id3Track, timeOffset, initPTS, initPTS);\n      if (textTrack.samples.length) {\n        result.text = flushTextTrackUserdataCueSamples(textTrack, timeOffset, initPTS);\n      }\n      return result;\n    };\n    return PassThroughRemuxer;\n  }();\n  function isInvalidInitPts(initPTS, startDTS, timeOffset, duration) {\n    if (initPTS === null) {\n      return true;\n    }\n    // InitPTS is invalid when distance from program would be more than segment duration or a minimum of one second\n    var minDuration = Math.max(duration, 1);\n    var startTime = startDTS - initPTS.baseTime / initPTS.timescale;\n    return Math.abs(startTime - timeOffset) > minDuration;\n  }\n  function getParsedTrackCodec(track, type) {\n    var parsedCodec = track == null ? void 0 : track.codec;\n    if (parsedCodec && parsedCodec.length > 4) {\n      return parsedCodec;\n    }\n    if (type === ElementaryStreamTypes.AUDIO) {\n      if (parsedCodec === 'ec-3' || parsedCodec === 'ac-3' || parsedCodec === 'alac') {\n        return parsedCodec;\n      }\n      if (parsedCodec === 'fLaC' || parsedCodec === 'Opus') {\n        // Opting not to get `preferManagedMediaSource` from player config for isSupported() check for simplicity\n        var preferManagedMediaSource = false;\n        return getCodecCompatibleName(parsedCodec, preferManagedMediaSource);\n      }\n      var result = 'mp4a.40.5';\n      logger.info(\"Parsed audio codec \\\"\" + parsedCodec + \"\\\" or audio object type not handled. Using \\\"\" + result + \"\\\"\");\n      return result;\n    }\n    // Provide defaults based on codec type\n    // This allows for some playback of some fmp4 playlists without CODECS defined in manifest\n    logger.warn(\"Unhandled video codec \\\"\" + parsedCodec + \"\\\"\");\n    if (parsedCodec === 'hvc1' || parsedCodec === 'hev1') {\n      return 'hvc1.1.6.L120.90';\n    }\n    if (parsedCodec === 'av01') {\n      return 'av01.0.04M.08';\n    }\n    return 'avc1.42e01e';\n  }\n\n  var now;\n  // performance.now() not available on WebWorker, at least on Safari Desktop\n  try {\n    now = self.performance.now.bind(self.performance);\n  } catch (err) {\n    logger.debug('Unable to use Performance API on this environment');\n    now = optionalSelf == null ? void 0 : optionalSelf.Date.now;\n  }\n  var muxConfig = [{\n    demux: MP4Demuxer,\n    remux: PassThroughRemuxer\n  }, {\n    demux: TSDemuxer,\n    remux: MP4Remuxer\n  }, {\n    demux: AACDemuxer,\n    remux: MP4Remuxer\n  }, {\n    demux: MP3Demuxer,\n    remux: MP4Remuxer\n  }];\n  {\n    muxConfig.splice(2, 0, {\n      demux: AC3Demuxer,\n      remux: MP4Remuxer\n    });\n  }\n  var Transmuxer = /*#__PURE__*/function () {\n    function Transmuxer(observer, typeSupported, config, vendor, id) {\n      this.async = false;\n      this.observer = void 0;\n      this.typeSupported = void 0;\n      this.config = void 0;\n      this.vendor = void 0;\n      this.id = void 0;\n      this.demuxer = void 0;\n      this.remuxer = void 0;\n      this.decrypter = void 0;\n      this.probe = void 0;\n      this.decryptionPromise = null;\n      this.transmuxConfig = void 0;\n      this.currentTransmuxState = void 0;\n      this.observer = observer;\n      this.typeSupported = typeSupported;\n      this.config = config;\n      this.vendor = vendor;\n      this.id = id;\n    }\n    var _proto = Transmuxer.prototype;\n    _proto.configure = function configure(transmuxConfig) {\n      this.transmuxConfig = transmuxConfig;\n      if (this.decrypter) {\n        this.decrypter.reset();\n      }\n    };\n    _proto.push = function push(data, decryptdata, chunkMeta, state) {\n      var _this = this;\n      var stats = chunkMeta.transmuxing;\n      stats.executeStart = now();\n      var uintData = new Uint8Array(data);\n      var currentTransmuxState = this.currentTransmuxState,\n        transmuxConfig = this.transmuxConfig;\n      if (state) {\n        this.currentTransmuxState = state;\n      }\n      var _ref = state || currentTransmuxState,\n        contiguous = _ref.contiguous,\n        discontinuity = _ref.discontinuity,\n        trackSwitch = _ref.trackSwitch,\n        accurateTimeOffset = _ref.accurateTimeOffset,\n        timeOffset = _ref.timeOffset,\n        initSegmentChange = _ref.initSegmentChange;\n      var audioCodec = transmuxConfig.audioCodec,\n        videoCodec = transmuxConfig.videoCodec,\n        defaultInitPts = transmuxConfig.defaultInitPts,\n        duration = transmuxConfig.duration,\n        initSegmentData = transmuxConfig.initSegmentData;\n      var keyData = getEncryptionType(uintData, decryptdata);\n      if (keyData && keyData.method === 'AES-128') {\n        var decrypter = this.getDecrypter();\n        // Software decryption is synchronous; webCrypto is not\n        if (decrypter.isSync()) {\n          // Software decryption is progressive. Progressive decryption may not return a result on each call. Any cached\n          // data is handled in the flush() call\n          var decryptedData = decrypter.softwareDecrypt(uintData, keyData.key.buffer, keyData.iv.buffer);\n          // For Low-Latency HLS Parts, decrypt in place, since part parsing is expected on push progress\n          var loadingParts = chunkMeta.part > -1;\n          if (loadingParts) {\n            decryptedData = decrypter.flush();\n          }\n          if (!decryptedData) {\n            stats.executeEnd = now();\n            return emptyResult(chunkMeta);\n          }\n          uintData = new Uint8Array(decryptedData);\n        } else {\n          this.decryptionPromise = decrypter.webCryptoDecrypt(uintData, keyData.key.buffer, keyData.iv.buffer).then(function (decryptedData) {\n            // Calling push here is important; if flush() is called while this is still resolving, this ensures that\n            // the decrypted data has been transmuxed\n            var result = _this.push(decryptedData, null, chunkMeta);\n            _this.decryptionPromise = null;\n            return result;\n          });\n          return this.decryptionPromise;\n        }\n      }\n      var resetMuxers = this.needsProbing(discontinuity, trackSwitch);\n      if (resetMuxers) {\n        var error = this.configureTransmuxer(uintData);\n        if (error) {\n          logger.warn(\"[transmuxer] \" + error.message);\n          this.observer.emit(Events.ERROR, Events.ERROR, {\n            type: ErrorTypes.MEDIA_ERROR,\n            details: ErrorDetails.FRAG_PARSING_ERROR,\n            fatal: false,\n            error: error,\n            reason: error.message\n          });\n          stats.executeEnd = now();\n          return emptyResult(chunkMeta);\n        }\n      }\n      if (discontinuity || trackSwitch || initSegmentChange || resetMuxers) {\n        this.resetInitSegment(initSegmentData, audioCodec, videoCodec, duration, decryptdata);\n      }\n      if (discontinuity || initSegmentChange || resetMuxers) {\n        this.resetInitialTimestamp(defaultInitPts);\n      }\n      if (!contiguous) {\n        this.resetContiguity();\n      }\n      var result = this.transmux(uintData, keyData, timeOffset, accurateTimeOffset, chunkMeta);\n      var currentState = this.currentTransmuxState;\n      currentState.contiguous = true;\n      currentState.discontinuity = false;\n      currentState.trackSwitch = false;\n      stats.executeEnd = now();\n      return result;\n    }\n\n    // Due to data caching, flush calls can produce more than one TransmuxerResult (hence the Array type)\n    ;\n    _proto.flush = function flush(chunkMeta) {\n      var _this2 = this;\n      var stats = chunkMeta.transmuxing;\n      stats.executeStart = now();\n      var decrypter = this.decrypter,\n        currentTransmuxState = this.currentTransmuxState,\n        decryptionPromise = this.decryptionPromise;\n      if (decryptionPromise) {\n        // Upon resolution, the decryption promise calls push() and returns its TransmuxerResult up the stack. Therefore\n        // only flushing is required for async decryption\n        return decryptionPromise.then(function () {\n          return _this2.flush(chunkMeta);\n        });\n      }\n      var transmuxResults = [];\n      var timeOffset = currentTransmuxState.timeOffset;\n      if (decrypter) {\n        // The decrypter may have data cached, which needs to be demuxed. In this case we'll have two TransmuxResults\n        // This happens in the case that we receive only 1 push call for a segment (either for non-progressive downloads,\n        // or for progressive downloads with small segments)\n        var decryptedData = decrypter.flush();\n        if (decryptedData) {\n          // Push always returns a TransmuxerResult if decryptdata is null\n          transmuxResults.push(this.push(decryptedData, null, chunkMeta));\n        }\n      }\n      var demuxer = this.demuxer,\n        remuxer = this.remuxer;\n      if (!demuxer || !remuxer) {\n        // If probing failed, then Hls.js has been given content its not able to handle\n        stats.executeEnd = now();\n        return [emptyResult(chunkMeta)];\n      }\n      var demuxResultOrPromise = demuxer.flush(timeOffset);\n      if (isPromise(demuxResultOrPromise)) {\n        // Decrypt final SAMPLE-AES samples\n        return demuxResultOrPromise.then(function (demuxResult) {\n          _this2.flushRemux(transmuxResults, demuxResult, chunkMeta);\n          return transmuxResults;\n        });\n      }\n      this.flushRemux(transmuxResults, demuxResultOrPromise, chunkMeta);\n      return transmuxResults;\n    };\n    _proto.flushRemux = function flushRemux(transmuxResults, demuxResult, chunkMeta) {\n      var audioTrack = demuxResult.audioTrack,\n        videoTrack = demuxResult.videoTrack,\n        id3Track = demuxResult.id3Track,\n        textTrack = demuxResult.textTrack;\n      var _this$currentTransmux = this.currentTransmuxState,\n        accurateTimeOffset = _this$currentTransmux.accurateTimeOffset,\n        timeOffset = _this$currentTransmux.timeOffset;\n      logger.log(\"[transmuxer.ts]: Flushed fragment \" + chunkMeta.sn + (chunkMeta.part > -1 ? ' p: ' + chunkMeta.part : '') + \" of level \" + chunkMeta.level);\n      var remuxResult = this.remuxer.remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, true, this.id);\n      transmuxResults.push({\n        remuxResult: remuxResult,\n        chunkMeta: chunkMeta\n      });\n      chunkMeta.transmuxing.executeEnd = now();\n    };\n    _proto.resetInitialTimestamp = function resetInitialTimestamp(defaultInitPts) {\n      var demuxer = this.demuxer,\n        remuxer = this.remuxer;\n      if (!demuxer || !remuxer) {\n        return;\n      }\n      demuxer.resetTimeStamp(defaultInitPts);\n      remuxer.resetTimeStamp(defaultInitPts);\n    };\n    _proto.resetContiguity = function resetContiguity() {\n      var demuxer = this.demuxer,\n        remuxer = this.remuxer;\n      if (!demuxer || !remuxer) {\n        return;\n      }\n      demuxer.resetContiguity();\n      remuxer.resetNextTimestamp();\n    };\n    _proto.resetInitSegment = function resetInitSegment(initSegmentData, audioCodec, videoCodec, trackDuration, decryptdata) {\n      var demuxer = this.demuxer,\n        remuxer = this.remuxer;\n      if (!demuxer || !remuxer) {\n        return;\n      }\n      demuxer.resetInitSegment(initSegmentData, audioCodec, videoCodec, trackDuration);\n      remuxer.resetInitSegment(initSegmentData, audioCodec, videoCodec, decryptdata);\n    };\n    _proto.destroy = function destroy() {\n      if (this.demuxer) {\n        this.demuxer.destroy();\n        this.demuxer = undefined;\n      }\n      if (this.remuxer) {\n        this.remuxer.destroy();\n        this.remuxer = undefined;\n      }\n    };\n    _proto.transmux = function transmux(data, keyData, timeOffset, accurateTimeOffset, chunkMeta) {\n      var result;\n      if (keyData && keyData.method === 'SAMPLE-AES') {\n        result = this.transmuxSampleAes(data, keyData, timeOffset, accurateTimeOffset, chunkMeta);\n      } else {\n        result = this.transmuxUnencrypted(data, timeOffset, accurateTimeOffset, chunkMeta);\n      }\n      return result;\n    };\n    _proto.transmuxUnencrypted = function transmuxUnencrypted(data, timeOffset, accurateTimeOffset, chunkMeta) {\n      var _demux = this.demuxer.demux(data, timeOffset, false, !this.config.progressive),\n        audioTrack = _demux.audioTrack,\n        videoTrack = _demux.videoTrack,\n        id3Track = _demux.id3Track,\n        textTrack = _demux.textTrack;\n      var remuxResult = this.remuxer.remux(audioTrack, videoTrack, id3Track, textTrack, timeOffset, accurateTimeOffset, false, this.id);\n      return {\n        remuxResult: remuxResult,\n        chunkMeta: chunkMeta\n      };\n    };\n    _proto.transmuxSampleAes = function transmuxSampleAes(data, decryptData, timeOffset, accurateTimeOffset, chunkMeta) {\n      var _this3 = this;\n      return this.demuxer.demuxSampleAes(data, decryptData, timeOffset).then(function (demuxResult) {\n        var remuxResult = _this3.remuxer.remux(demuxResult.audioTrack, demuxResult.videoTrack, demuxResult.id3Track, demuxResult.textTrack, timeOffset, accurateTimeOffset, false, _this3.id);\n        return {\n          remuxResult: remuxResult,\n          chunkMeta: chunkMeta\n        };\n      });\n    };\n    _proto.configureTransmuxer = function configureTransmuxer(data) {\n      var config = this.config,\n        observer = this.observer,\n        typeSupported = this.typeSupported,\n        vendor = this.vendor;\n      // probe for content type\n      var mux;\n      for (var i = 0, len = muxConfig.length; i < len; i++) {\n        var _muxConfig$i$demux;\n        if ((_muxConfig$i$demux = muxConfig[i].demux) != null && _muxConfig$i$demux.probe(data)) {\n          mux = muxConfig[i];\n          break;\n        }\n      }\n      if (!mux) {\n        return new Error('Failed to find demuxer by probing fragment data');\n      }\n      // so let's check that current remuxer and demuxer are still valid\n      var demuxer = this.demuxer;\n      var remuxer = this.remuxer;\n      var Remuxer = mux.remux;\n      var Demuxer = mux.demux;\n      if (!remuxer || !(remuxer instanceof Remuxer)) {\n        this.remuxer = new Remuxer(observer, config, typeSupported, vendor);\n      }\n      if (!demuxer || !(demuxer instanceof Demuxer)) {\n        this.demuxer = new Demuxer(observer, config, typeSupported);\n        this.probe = Demuxer.probe;\n      }\n    };\n    _proto.needsProbing = function needsProbing(discontinuity, trackSwitch) {\n      // in case of continuity change, or track switch\n      // we might switch from content type (AAC container to TS container, or TS to fmp4 for example)\n      return !this.demuxer || !this.remuxer || discontinuity || trackSwitch;\n    };\n    _proto.getDecrypter = function getDecrypter() {\n      var decrypter = this.decrypter;\n      if (!decrypter) {\n        decrypter = this.decrypter = new Decrypter(this.config);\n      }\n      return decrypter;\n    };\n    return Transmuxer;\n  }();\n  function getEncryptionType(data, decryptData) {\n    var encryptionType = null;\n    if (data.byteLength > 0 && (decryptData == null ? void 0 : decryptData.key) != null && decryptData.iv !== null && decryptData.method != null) {\n      encryptionType = decryptData;\n    }\n    return encryptionType;\n  }\n  var emptyResult = function emptyResult(chunkMeta) {\n    return {\n      remuxResult: {},\n      chunkMeta: chunkMeta\n    };\n  };\n  function isPromise(p) {\n    return 'then' in p && p.then instanceof Function;\n  }\n  var TransmuxConfig = function TransmuxConfig(audioCodec, videoCodec, initSegmentData, duration, defaultInitPts) {\n    this.audioCodec = void 0;\n    this.videoCodec = void 0;\n    this.initSegmentData = void 0;\n    this.duration = void 0;\n    this.defaultInitPts = void 0;\n    this.audioCodec = audioCodec;\n    this.videoCodec = videoCodec;\n    this.initSegmentData = initSegmentData;\n    this.duration = duration;\n    this.defaultInitPts = defaultInitPts || null;\n  };\n  var TransmuxState = function TransmuxState(discontinuity, contiguous, accurateTimeOffset, trackSwitch, timeOffset, initSegmentChange) {\n    this.discontinuity = void 0;\n    this.contiguous = void 0;\n    this.accurateTimeOffset = void 0;\n    this.trackSwitch = void 0;\n    this.timeOffset = void 0;\n    this.initSegmentChange = void 0;\n    this.discontinuity = discontinuity;\n    this.contiguous = contiguous;\n    this.accurateTimeOffset = accurateTimeOffset;\n    this.trackSwitch = trackSwitch;\n    this.timeOffset = timeOffset;\n    this.initSegmentChange = initSegmentChange;\n  };\n\n  var eventemitter3 = {exports: {}};\n\n  (function (module) {\n\n  \tvar has = Object.prototype.hasOwnProperty\n  \t  , prefix = '~';\n\n  \t/**\n  \t * Constructor to create a storage for our `EE` objects.\n  \t * An `Events` instance is a plain object whose properties are event names.\n  \t *\n  \t * @constructor\n  \t * @private\n  \t */\n  \tfunction Events() {}\n\n  \t//\n  \t// We try to not inherit from `Object.prototype`. In some engines creating an\n  \t// instance in this way is faster than calling `Object.create(null)` directly.\n  \t// If `Object.create(null)` is not supported we prefix the event names with a\n  \t// character to make sure that the built-in object properties are not\n  \t// overridden or used as an attack vector.\n  \t//\n  \tif (Object.create) {\n  \t  Events.prototype = Object.create(null);\n\n  \t  //\n  \t  // This hack is needed because the `__proto__` property is still inherited in\n  \t  // some old browsers like Android 4, iPhone 5.1, Opera 11 and Safari 5.\n  \t  //\n  \t  if (!new Events().__proto__) prefix = false;\n  \t}\n\n  \t/**\n  \t * Representation of a single event listener.\n  \t *\n  \t * @param {Function} fn The listener function.\n  \t * @param {*} context The context to invoke the listener with.\n  \t * @param {Boolean} [once=false] Specify if the listener is a one-time listener.\n  \t * @constructor\n  \t * @private\n  \t */\n  \tfunction EE(fn, context, once) {\n  \t  this.fn = fn;\n  \t  this.context = context;\n  \t  this.once = once || false;\n  \t}\n\n  \t/**\n  \t * Add a listener for a given event.\n  \t *\n  \t * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.\n  \t * @param {(String|Symbol)} event The event name.\n  \t * @param {Function} fn The listener function.\n  \t * @param {*} context The context to invoke the listener with.\n  \t * @param {Boolean} once Specify if the listener is a one-time listener.\n  \t * @returns {EventEmitter}\n  \t * @private\n  \t */\n  \tfunction addListener(emitter, event, fn, context, once) {\n  \t  if (typeof fn !== 'function') {\n  \t    throw new TypeError('The listener must be a function');\n  \t  }\n\n  \t  var listener = new EE(fn, context || emitter, once)\n  \t    , evt = prefix ? prefix + event : event;\n\n  \t  if (!emitter._events[evt]) emitter._events[evt] = listener, emitter._eventsCount++;\n  \t  else if (!emitter._events[evt].fn) emitter._events[evt].push(listener);\n  \t  else emitter._events[evt] = [emitter._events[evt], listener];\n\n  \t  return emitter;\n  \t}\n\n  \t/**\n  \t * Clear event by name.\n  \t *\n  \t * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.\n  \t * @param {(String|Symbol)} evt The Event name.\n  \t * @private\n  \t */\n  \tfunction clearEvent(emitter, evt) {\n  \t  if (--emitter._eventsCount === 0) emitter._events = new Events();\n  \t  else delete emitter._events[evt];\n  \t}\n\n  \t/**\n  \t * Minimal `EventEmitter` interface that is molded against the Node.js\n  \t * `EventEmitter` interface.\n  \t *\n  \t * @constructor\n  \t * @public\n  \t */\n  \tfunction EventEmitter() {\n  \t  this._events = new Events();\n  \t  this._eventsCount = 0;\n  \t}\n\n  \t/**\n  \t * Return an array listing the events for which the emitter has registered\n  \t * listeners.\n  \t *\n  \t * @returns {Array}\n  \t * @public\n  \t */\n  \tEventEmitter.prototype.eventNames = function eventNames() {\n  \t  var names = []\n  \t    , events\n  \t    , name;\n\n  \t  if (this._eventsCount === 0) return names;\n\n  \t  for (name in (events = this._events)) {\n  \t    if (has.call(events, name)) names.push(prefix ? name.slice(1) : name);\n  \t  }\n\n  \t  if (Object.getOwnPropertySymbols) {\n  \t    return names.concat(Object.getOwnPropertySymbols(events));\n  \t  }\n\n  \t  return names;\n  \t};\n\n  \t/**\n  \t * Return the listeners registered for a given event.\n  \t *\n  \t * @param {(String|Symbol)} event The event name.\n  \t * @returns {Array} The registered listeners.\n  \t * @public\n  \t */\n  \tEventEmitter.prototype.listeners = function listeners(event) {\n  \t  var evt = prefix ? prefix + event : event\n  \t    , handlers = this._events[evt];\n\n  \t  if (!handlers) return [];\n  \t  if (handlers.fn) return [handlers.fn];\n\n  \t  for (var i = 0, l = handlers.length, ee = new Array(l); i < l; i++) {\n  \t    ee[i] = handlers[i].fn;\n  \t  }\n\n  \t  return ee;\n  \t};\n\n  \t/**\n  \t * Return the number of listeners listening to a given event.\n  \t *\n  \t * @param {(String|Symbol)} event The event name.\n  \t * @returns {Number} The number of listeners.\n  \t * @public\n  \t */\n  \tEventEmitter.prototype.listenerCount = function listenerCount(event) {\n  \t  var evt = prefix ? prefix + event : event\n  \t    , listeners = this._events[evt];\n\n  \t  if (!listeners) return 0;\n  \t  if (listeners.fn) return 1;\n  \t  return listeners.length;\n  \t};\n\n  \t/**\n  \t * Calls each of the listeners registered for a given event.\n  \t *\n  \t * @param {(String|Symbol)} event The event name.\n  \t * @returns {Boolean} `true` if the event had listeners, else `false`.\n  \t * @public\n  \t */\n  \tEventEmitter.prototype.emit = function emit(event, a1, a2, a3, a4, a5) {\n  \t  var evt = prefix ? prefix + event : event;\n\n  \t  if (!this._events[evt]) return false;\n\n  \t  var listeners = this._events[evt]\n  \t    , len = arguments.length\n  \t    , args\n  \t    , i;\n\n  \t  if (listeners.fn) {\n  \t    if (listeners.once) this.removeListener(event, listeners.fn, undefined, true);\n\n  \t    switch (len) {\n  \t      case 1: return listeners.fn.call(listeners.context), true;\n  \t      case 2: return listeners.fn.call(listeners.context, a1), true;\n  \t      case 3: return listeners.fn.call(listeners.context, a1, a2), true;\n  \t      case 4: return listeners.fn.call(listeners.context, a1, a2, a3), true;\n  \t      case 5: return listeners.fn.call(listeners.context, a1, a2, a3, a4), true;\n  \t      case 6: return listeners.fn.call(listeners.context, a1, a2, a3, a4, a5), true;\n  \t    }\n\n  \t    for (i = 1, args = new Array(len -1); i < len; i++) {\n  \t      args[i - 1] = arguments[i];\n  \t    }\n\n  \t    listeners.fn.apply(listeners.context, args);\n  \t  } else {\n  \t    var length = listeners.length\n  \t      , j;\n\n  \t    for (i = 0; i < length; i++) {\n  \t      if (listeners[i].once) this.removeListener(event, listeners[i].fn, undefined, true);\n\n  \t      switch (len) {\n  \t        case 1: listeners[i].fn.call(listeners[i].context); break;\n  \t        case 2: listeners[i].fn.call(listeners[i].context, a1); break;\n  \t        case 3: listeners[i].fn.call(listeners[i].context, a1, a2); break;\n  \t        case 4: listeners[i].fn.call(listeners[i].context, a1, a2, a3); break;\n  \t        default:\n  \t          if (!args) for (j = 1, args = new Array(len -1); j < len; j++) {\n  \t            args[j - 1] = arguments[j];\n  \t          }\n\n  \t          listeners[i].fn.apply(listeners[i].context, args);\n  \t      }\n  \t    }\n  \t  }\n\n  \t  return true;\n  \t};\n\n  \t/**\n  \t * Add a listener for a given event.\n  \t *\n  \t * @param {(String|Symbol)} event The event name.\n  \t * @param {Function} fn The listener function.\n  \t * @param {*} [context=this] The context to invoke the listener with.\n  \t * @returns {EventEmitter} `this`.\n  \t * @public\n  \t */\n  \tEventEmitter.prototype.on = function on(event, fn, context) {\n  \t  return addListener(this, event, fn, context, false);\n  \t};\n\n  \t/**\n  \t * Add a one-time listener for a given event.\n  \t *\n  \t * @param {(String|Symbol)} event The event name.\n  \t * @param {Function} fn The listener function.\n  \t * @param {*} [context=this] The context to invoke the listener with.\n  \t * @returns {EventEmitter} `this`.\n  \t * @public\n  \t */\n  \tEventEmitter.prototype.once = function once(event, fn, context) {\n  \t  return addListener(this, event, fn, context, true);\n  \t};\n\n  \t/**\n  \t * Remove the listeners of a given event.\n  \t *\n  \t * @param {(String|Symbol)} event The event name.\n  \t * @param {Function} fn Only remove the listeners that match this function.\n  \t * @param {*} context Only remove the listeners that have this context.\n  \t * @param {Boolean} once Only remove one-time listeners.\n  \t * @returns {EventEmitter} `this`.\n  \t * @public\n  \t */\n  \tEventEmitter.prototype.removeListener = function removeListener(event, fn, context, once) {\n  \t  var evt = prefix ? prefix + event : event;\n\n  \t  if (!this._events[evt]) return this;\n  \t  if (!fn) {\n  \t    clearEvent(this, evt);\n  \t    return this;\n  \t  }\n\n  \t  var listeners = this._events[evt];\n\n  \t  if (listeners.fn) {\n  \t    if (\n  \t      listeners.fn === fn &&\n  \t      (!once || listeners.once) &&\n  \t      (!context || listeners.context === context)\n  \t    ) {\n  \t      clearEvent(this, evt);\n  \t    }\n  \t  } else {\n  \t    for (var i = 0, events = [], length = listeners.length; i < length; i++) {\n  \t      if (\n  \t        listeners[i].fn !== fn ||\n  \t        (once && !listeners[i].once) ||\n  \t        (context && listeners[i].context !== context)\n  \t      ) {\n  \t        events.push(listeners[i]);\n  \t      }\n  \t    }\n\n  \t    //\n  \t    // Reset the array, or remove it completely if we have no more listeners.\n  \t    //\n  \t    if (events.length) this._events[evt] = events.length === 1 ? events[0] : events;\n  \t    else clearEvent(this, evt);\n  \t  }\n\n  \t  return this;\n  \t};\n\n  \t/**\n  \t * Remove all listeners, or those of the specified event.\n  \t *\n  \t * @param {(String|Symbol)} [event] The event name.\n  \t * @returns {EventEmitter} `this`.\n  \t * @public\n  \t */\n  \tEventEmitter.prototype.removeAllListeners = function removeAllListeners(event) {\n  \t  var evt;\n\n  \t  if (event) {\n  \t    evt = prefix ? prefix + event : event;\n  \t    if (this._events[evt]) clearEvent(this, evt);\n  \t  } else {\n  \t    this._events = new Events();\n  \t    this._eventsCount = 0;\n  \t  }\n\n  \t  return this;\n  \t};\n\n  \t//\n  \t// Alias methods names because people roll like that.\n  \t//\n  \tEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n  \tEventEmitter.prototype.addListener = EventEmitter.prototype.on;\n\n  \t//\n  \t// Expose the prefix.\n  \t//\n  \tEventEmitter.prefixed = prefix;\n\n  \t//\n  \t// Allow `EventEmitter` to be imported as module namespace.\n  \t//\n  \tEventEmitter.EventEmitter = EventEmitter;\n\n  \t//\n  \t// Expose the module.\n  \t//\n  \t{\n  \t  module.exports = EventEmitter;\n  \t} \n  } (eventemitter3));\n\n  var eventemitter3Exports = eventemitter3.exports;\n  var EventEmitter = /*@__PURE__*/getDefaultExportFromCjs(eventemitter3Exports);\n\n  if (typeof __IN_WORKER__ !== 'undefined' && __IN_WORKER__) {\n    startWorker(self);\n  }\n  function startWorker(self) {\n    var observer = new EventEmitter();\n    var forwardMessage = function forwardMessage(ev, data) {\n      self.postMessage({\n        event: ev,\n        data: data\n      });\n    };\n\n    // forward events to main thread\n    observer.on(Events.FRAG_DECRYPTED, forwardMessage);\n    observer.on(Events.ERROR, forwardMessage);\n\n    // forward logger events to main thread\n    var forwardWorkerLogs = function forwardWorkerLogs() {\n      var _loop = function _loop(logFn) {\n        var func = function func(message) {\n          forwardMessage('workerLog', {\n            logType: logFn,\n            message: message\n          });\n        };\n        logger[logFn] = func;\n      };\n      for (var logFn in logger) {\n        _loop(logFn);\n      }\n    };\n    self.addEventListener('message', function (ev) {\n      var data = ev.data;\n      switch (data.cmd) {\n        case 'init':\n          {\n            var config = JSON.parse(data.config);\n            self.transmuxer = new Transmuxer(observer, data.typeSupported, config, '', data.id);\n            enableLogs(config.debug, data.id);\n            forwardWorkerLogs();\n            forwardMessage('init', null);\n            break;\n          }\n        case 'configure':\n          {\n            self.transmuxer.configure(data.config);\n            break;\n          }\n        case 'demux':\n          {\n            var transmuxResult = self.transmuxer.push(data.data, data.decryptdata, data.chunkMeta, data.state);\n            if (isPromise(transmuxResult)) {\n              self.transmuxer.async = true;\n              transmuxResult.then(function (data) {\n                emitTransmuxComplete(self, data);\n              }).catch(function (error) {\n                forwardMessage(Events.ERROR, {\n                  type: ErrorTypes.MEDIA_ERROR,\n                  details: ErrorDetails.FRAG_PARSING_ERROR,\n                  chunkMeta: data.chunkMeta,\n                  fatal: false,\n                  error: error,\n                  err: error,\n                  reason: \"transmuxer-worker push error\"\n                });\n              });\n            } else {\n              self.transmuxer.async = false;\n              emitTransmuxComplete(self, transmuxResult);\n            }\n            break;\n          }\n        case 'flush':\n          {\n            var id = data.chunkMeta;\n            var _transmuxResult = self.transmuxer.flush(id);\n            var asyncFlush = isPromise(_transmuxResult);\n            if (asyncFlush || self.transmuxer.async) {\n              if (!isPromise(_transmuxResult)) {\n                _transmuxResult = Promise.resolve(_transmuxResult);\n              }\n              _transmuxResult.then(function (results) {\n                handleFlushResult(self, results, id);\n              }).catch(function (error) {\n                forwardMessage(Events.ERROR, {\n                  type: ErrorTypes.MEDIA_ERROR,\n                  details: ErrorDetails.FRAG_PARSING_ERROR,\n                  chunkMeta: data.chunkMeta,\n                  fatal: false,\n                  error: error,\n                  err: error,\n                  reason: \"transmuxer-worker flush error\"\n                });\n              });\n            } else {\n              handleFlushResult(self, _transmuxResult, id);\n            }\n            break;\n          }\n      }\n    });\n  }\n  function emitTransmuxComplete(self, transmuxResult) {\n    if (isEmptyResult(transmuxResult.remuxResult)) {\n      return false;\n    }\n    var transferable = [];\n    var _transmuxResult$remux = transmuxResult.remuxResult,\n      audio = _transmuxResult$remux.audio,\n      video = _transmuxResult$remux.video;\n    if (audio) {\n      addToTransferable(transferable, audio);\n    }\n    if (video) {\n      addToTransferable(transferable, video);\n    }\n    self.postMessage({\n      event: 'transmuxComplete',\n      data: transmuxResult\n    }, transferable);\n    return true;\n  }\n\n  // Converts data to a transferable object https://developers.google.com/web/updates/2011/12/Transferable-Objects-Lightning-Fast)\n  // in order to minimize message passing overhead\n  function addToTransferable(transferable, track) {\n    if (track.data1) {\n      transferable.push(track.data1.buffer);\n    }\n    if (track.data2) {\n      transferable.push(track.data2.buffer);\n    }\n  }\n  function handleFlushResult(self, results, chunkMeta) {\n    var parsed = results.reduce(function (parsed, result) {\n      return emitTransmuxComplete(self, result) || parsed;\n    }, false);\n    if (!parsed) {\n      // Emit at least one \"transmuxComplete\" message even if media is not found to update stream-controller state to PARSING\n      self.postMessage({\n        event: 'transmuxComplete',\n        data: results[0]\n      });\n    }\n    self.postMessage({\n      event: 'flush',\n      data: chunkMeta\n    });\n  }\n  function isEmptyResult(remuxResult) {\n    return !remuxResult.audio && !remuxResult.video && !remuxResult.text && !remuxResult.id3 && !remuxResult.initSegment;\n  }\n\n  // ensure the worker ends up in the bundle\n  // If the worker should not be included this gets aliased to empty.js\n  function hasUMDWorker() {\n    return typeof __HLS_WORKER_BUNDLE__ === 'function';\n  }\n  function injectWorker() {\n    var blob = new self.Blob([\"var exports={};var module={exports:exports};function define(f){f()};define.amd=true;(\" + __HLS_WORKER_BUNDLE__.toString() + \")(true);\"], {\n      type: 'text/javascript'\n    });\n    var objectURL = self.URL.createObjectURL(blob);\n    var worker = new self.Worker(objectURL);\n    return {\n      worker: worker,\n      objectURL: objectURL\n    };\n  }\n  function loadWorker(path) {\n    var scriptURL = new self.URL(path, self.location.href).href;\n    var worker = new self.Worker(scriptURL);\n    return {\n      worker: worker,\n      scriptURL: scriptURL\n    };\n  }\n\n  var TransmuxerInterface = /*#__PURE__*/function () {\n    function TransmuxerInterface(hls, id, onTransmuxComplete, onFlush) {\n      var _this = this;\n      this.error = null;\n      this.hls = void 0;\n      this.id = void 0;\n      this.observer = void 0;\n      this.frag = null;\n      this.part = null;\n      this.useWorker = void 0;\n      this.workerContext = null;\n      this.onwmsg = void 0;\n      this.transmuxer = null;\n      this.onTransmuxComplete = void 0;\n      this.onFlush = void 0;\n      var config = hls.config;\n      this.hls = hls;\n      this.id = id;\n      this.useWorker = !!config.enableWorker;\n      this.onTransmuxComplete = onTransmuxComplete;\n      this.onFlush = onFlush;\n      var forwardMessage = function forwardMessage(ev, data) {\n        data = data || {};\n        data.frag = _this.frag;\n        data.id = _this.id;\n        if (ev === Events.ERROR) {\n          _this.error = data.error;\n        }\n        _this.hls.trigger(ev, data);\n      };\n\n      // forward events to main thread\n      this.observer = new EventEmitter();\n      this.observer.on(Events.FRAG_DECRYPTED, forwardMessage);\n      this.observer.on(Events.ERROR, forwardMessage);\n      var MediaSource = getMediaSource(config.preferManagedMediaSource) || {\n        isTypeSupported: function isTypeSupported() {\n          return false;\n        }\n      };\n      var m2tsTypeSupported = {\n        mpeg: MediaSource.isTypeSupported('audio/mpeg'),\n        mp3: MediaSource.isTypeSupported('audio/mp4; codecs=\"mp3\"'),\n        ac3: MediaSource.isTypeSupported('audio/mp4; codecs=\"ac-3\"') \n      };\n      if (this.useWorker && typeof Worker !== 'undefined') {\n        var canCreateWorker = config.workerPath || hasUMDWorker();\n        if (canCreateWorker) {\n          try {\n            if (config.workerPath) {\n              logger.log(\"loading Web Worker \" + config.workerPath + \" for \\\"\" + id + \"\\\"\");\n              this.workerContext = loadWorker(config.workerPath);\n            } else {\n              logger.log(\"injecting Web Worker for \\\"\" + id + \"\\\"\");\n              this.workerContext = injectWorker();\n            }\n            this.onwmsg = function (event) {\n              return _this.onWorkerMessage(event);\n            };\n            var worker = this.workerContext.worker;\n            worker.addEventListener('message', this.onwmsg);\n            worker.onerror = function (event) {\n              var error = new Error(event.message + \"  (\" + event.filename + \":\" + event.lineno + \")\");\n              config.enableWorker = false;\n              logger.warn(\"Error in \\\"\" + id + \"\\\" Web Worker, fallback to inline\");\n              _this.hls.trigger(Events.ERROR, {\n                type: ErrorTypes.OTHER_ERROR,\n                details: ErrorDetails.INTERNAL_EXCEPTION,\n                fatal: false,\n                event: 'demuxerWorker',\n                error: error\n              });\n            };\n            worker.postMessage({\n              cmd: 'init',\n              typeSupported: m2tsTypeSupported,\n              vendor: '',\n              id: id,\n              config: JSON.stringify(config)\n            });\n          } catch (err) {\n            logger.warn(\"Error setting up \\\"\" + id + \"\\\" Web Worker, fallback to inline\", err);\n            this.resetWorker();\n            this.error = null;\n            this.transmuxer = new Transmuxer(this.observer, m2tsTypeSupported, config, '', id);\n          }\n          return;\n        }\n      }\n      this.transmuxer = new Transmuxer(this.observer, m2tsTypeSupported, config, '', id);\n    }\n    var _proto = TransmuxerInterface.prototype;\n    _proto.resetWorker = function resetWorker() {\n      if (this.workerContext) {\n        var _this$workerContext = this.workerContext,\n          worker = _this$workerContext.worker,\n          objectURL = _this$workerContext.objectURL;\n        if (objectURL) {\n          // revoke the Object URL that was used to create transmuxer worker, so as not to leak it\n          self.URL.revokeObjectURL(objectURL);\n        }\n        worker.removeEventListener('message', this.onwmsg);\n        worker.onerror = null;\n        worker.terminate();\n        this.workerContext = null;\n      }\n    };\n    _proto.destroy = function destroy() {\n      if (this.workerContext) {\n        this.resetWorker();\n        this.onwmsg = undefined;\n      } else {\n        var transmuxer = this.transmuxer;\n        if (transmuxer) {\n          transmuxer.destroy();\n          this.transmuxer = null;\n        }\n      }\n      var observer = this.observer;\n      if (observer) {\n        observer.removeAllListeners();\n      }\n      this.frag = null;\n      // @ts-ignore\n      this.observer = null;\n      // @ts-ignore\n      this.hls = null;\n    };\n    _proto.push = function push(data, initSegmentData, audioCodec, videoCodec, frag, part, duration, accurateTimeOffset, chunkMeta, defaultInitPTS) {\n      var _frag$initSegment,\n        _lastFrag$initSegment,\n        _this2 = this;\n      chunkMeta.transmuxing.start = self.performance.now();\n      var transmuxer = this.transmuxer;\n      var timeOffset = part ? part.start : frag.start;\n      // TODO: push \"clear-lead\" decrypt data for unencrypted fragments in streams with encrypted ones\n      var decryptdata = frag.decryptdata;\n      var lastFrag = this.frag;\n      var discontinuity = !(lastFrag && frag.cc === lastFrag.cc);\n      var trackSwitch = !(lastFrag && chunkMeta.level === lastFrag.level);\n      var snDiff = lastFrag ? chunkMeta.sn - lastFrag.sn : -1;\n      var partDiff = this.part ? chunkMeta.part - this.part.index : -1;\n      var progressive = snDiff === 0 && chunkMeta.id > 1 && chunkMeta.id === (lastFrag == null ? void 0 : lastFrag.stats.chunkCount);\n      var contiguous = !trackSwitch && (snDiff === 1 || snDiff === 0 && (partDiff === 1 || progressive && partDiff <= 0));\n      var now = self.performance.now();\n      if (trackSwitch || snDiff || frag.stats.parsing.start === 0) {\n        frag.stats.parsing.start = now;\n      }\n      if (part && (partDiff || !contiguous)) {\n        part.stats.parsing.start = now;\n      }\n      var initSegmentChange = !(lastFrag && ((_frag$initSegment = frag.initSegment) == null ? void 0 : _frag$initSegment.url) === ((_lastFrag$initSegment = lastFrag.initSegment) == null ? void 0 : _lastFrag$initSegment.url));\n      var state = new TransmuxState(discontinuity, contiguous, accurateTimeOffset, trackSwitch, timeOffset, initSegmentChange);\n      if (!contiguous || discontinuity || initSegmentChange) {\n        logger.log(\"[transmuxer-interface, \" + frag.type + \"]: Starting new transmux session for sn: \" + chunkMeta.sn + \" p: \" + chunkMeta.part + \" level: \" + chunkMeta.level + \" id: \" + chunkMeta.id + \"\\n        discontinuity: \" + discontinuity + \"\\n        trackSwitch: \" + trackSwitch + \"\\n        contiguous: \" + contiguous + \"\\n        accurateTimeOffset: \" + accurateTimeOffset + \"\\n        timeOffset: \" + timeOffset + \"\\n        initSegmentChange: \" + initSegmentChange);\n        var config = new TransmuxConfig(audioCodec, videoCodec, initSegmentData, duration, defaultInitPTS);\n        this.configureTransmuxer(config);\n      }\n      this.frag = frag;\n      this.part = part;\n\n      // Frags with sn of 'initSegment' are not transmuxed\n      if (this.workerContext) {\n        // post fragment payload as transferable objects for ArrayBuffer (no copy)\n        this.workerContext.worker.postMessage({\n          cmd: 'demux',\n          data: data,\n          decryptdata: decryptdata,\n          chunkMeta: chunkMeta,\n          state: state\n        }, data instanceof ArrayBuffer ? [data] : []);\n      } else if (transmuxer) {\n        var _transmuxResult = transmuxer.push(data, decryptdata, chunkMeta, state);\n        if (isPromise(_transmuxResult)) {\n          transmuxer.async = true;\n          _transmuxResult.then(function (data) {\n            _this2.handleTransmuxComplete(data);\n          }).catch(function (error) {\n            _this2.transmuxerError(error, chunkMeta, 'transmuxer-interface push error');\n          });\n        } else {\n          transmuxer.async = false;\n          this.handleTransmuxComplete(_transmuxResult);\n        }\n      }\n    };\n    _proto.flush = function flush(chunkMeta) {\n      var _this3 = this;\n      chunkMeta.transmuxing.start = self.performance.now();\n      var transmuxer = this.transmuxer;\n      if (this.workerContext) {\n        this.workerContext.worker.postMessage({\n          cmd: 'flush',\n          chunkMeta: chunkMeta\n        });\n      } else if (transmuxer) {\n        var _transmuxResult2 = transmuxer.flush(chunkMeta);\n        var asyncFlush = isPromise(_transmuxResult2);\n        if (asyncFlush || transmuxer.async) {\n          if (!isPromise(_transmuxResult2)) {\n            _transmuxResult2 = Promise.resolve(_transmuxResult2);\n          }\n          _transmuxResult2.then(function (data) {\n            _this3.handleFlushResult(data, chunkMeta);\n          }).catch(function (error) {\n            _this3.transmuxerError(error, chunkMeta, 'transmuxer-interface flush error');\n          });\n        } else {\n          this.handleFlushResult(_transmuxResult2, chunkMeta);\n        }\n      }\n    };\n    _proto.transmuxerError = function transmuxerError(error, chunkMeta, reason) {\n      if (!this.hls) {\n        return;\n      }\n      this.error = error;\n      this.hls.trigger(Events.ERROR, {\n        type: ErrorTypes.MEDIA_ERROR,\n        details: ErrorDetails.FRAG_PARSING_ERROR,\n        chunkMeta: chunkMeta,\n        frag: this.frag || undefined,\n        fatal: false,\n        error: error,\n        err: error,\n        reason: reason\n      });\n    };\n    _proto.handleFlushResult = function handleFlushResult(results, chunkMeta) {\n      var _this4 = this;\n      results.forEach(function (result) {\n        _this4.handleTransmuxComplete(result);\n      });\n      this.onFlush(chunkMeta);\n    };\n    _proto.onWorkerMessage = function onWorkerMessage(event) {\n      var data = event.data;\n      if (!(data != null && data.event)) {\n        logger.warn(\"worker message received with no \" + (data ? 'event name' : 'data'));\n        return;\n      }\n      var hls = this.hls;\n      if (!this.hls) {\n        return;\n      }\n      switch (data.event) {\n        case 'init':\n          {\n            var _this$workerContext2;\n            var objectURL = (_this$workerContext2 = this.workerContext) == null ? void 0 : _this$workerContext2.objectURL;\n            if (objectURL) {\n              // revoke the Object URL that was used to create transmuxer worker, so as not to leak it\n              self.URL.revokeObjectURL(objectURL);\n            }\n            break;\n          }\n        case 'transmuxComplete':\n          {\n            this.handleTransmuxComplete(data.data);\n            break;\n          }\n        case 'flush':\n          {\n            this.onFlush(data.data);\n            break;\n          }\n\n        // pass logs from the worker thread to the main logger\n        case 'workerLog':\n          if (logger[data.data.logType]) {\n            logger[data.data.logType](data.data.message);\n          }\n          break;\n        default:\n          {\n            data.data = data.data || {};\n            data.data.frag = this.frag;\n            data.data.id = this.id;\n            hls.trigger(data.event, data.data);\n            break;\n          }\n      }\n    };\n    _proto.configureTransmuxer = function configureTransmuxer(config) {\n      var transmuxer = this.transmuxer;\n      if (this.workerContext) {\n        this.workerContext.worker.postMessage({\n          cmd: 'configure',\n          config: config\n        });\n      } else if (transmuxer) {\n        transmuxer.configure(config);\n      }\n    };\n    _proto.handleTransmuxComplete = function handleTransmuxComplete(result) {\n      result.chunkMeta.transmuxing.end = self.performance.now();\n      this.onTransmuxComplete(result);\n    };\n    return TransmuxerInterface;\n  }();\n\n  function subtitleOptionsIdentical(trackList1, trackList2) {\n    if (trackList1.length !== trackList2.length) {\n      return false;\n    }\n    for (var i = 0; i < trackList1.length; i++) {\n      if (!mediaAttributesIdentical(trackList1[i].attrs, trackList2[i].attrs)) {\n        return false;\n      }\n    }\n    return true;\n  }\n  function mediaAttributesIdentical(attrs1, attrs2, customAttributes) {\n    // Media options with the same rendition ID must be bit identical\n    var stableRenditionId = attrs1['STABLE-RENDITION-ID'];\n    if (stableRenditionId && !customAttributes) {\n      return stableRenditionId === attrs2['STABLE-RENDITION-ID'];\n    }\n    // When rendition ID is not present, compare attributes\n    return !(customAttributes || ['LANGUAGE', 'NAME', 'CHARACTERISTICS', 'AUTOSELECT', 'DEFAULT', 'FORCED', 'ASSOC-LANGUAGE']).some(function (subtitleAttribute) {\n      return attrs1[subtitleAttribute] !== attrs2[subtitleAttribute];\n    });\n  }\n  function subtitleTrackMatchesTextTrack(subtitleTrack, textTrack) {\n    return textTrack.label.toLowerCase() === subtitleTrack.name.toLowerCase() && (!textTrack.language || textTrack.language.toLowerCase() === (subtitleTrack.lang || '').toLowerCase());\n  }\n\n  var TICK_INTERVAL$2 = 100; // how often to tick in ms\n  var AudioStreamController = /*#__PURE__*/function (_BaseStreamController) {\n    _inheritsLoose(AudioStreamController, _BaseStreamController);\n    function AudioStreamController(hls, fragmentTracker, keyLoader) {\n      var _this;\n      _this = _BaseStreamController.call(this, hls, fragmentTracker, keyLoader, '[audio-stream-controller]', PlaylistLevelType.AUDIO) || this;\n      _this.videoBuffer = null;\n      _this.videoTrackCC = -1;\n      _this.waitingVideoCC = -1;\n      _this.bufferedTrack = null;\n      _this.switchingTrack = null;\n      _this.trackId = -1;\n      _this.waitingData = null;\n      _this.mainDetails = null;\n      _this.flushing = false;\n      _this.bufferFlushed = false;\n      _this.cachedTrackLoadedData = null;\n      _this._registerListeners();\n      return _this;\n    }\n    var _proto = AudioStreamController.prototype;\n    _proto.onHandlerDestroying = function onHandlerDestroying() {\n      this._unregisterListeners();\n      _BaseStreamController.prototype.onHandlerDestroying.call(this);\n      this.mainDetails = null;\n      this.bufferedTrack = null;\n      this.switchingTrack = null;\n    };\n    _proto._registerListeners = function _registerListeners() {\n      var hls = this.hls;\n      hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n      hls.on(Events.AUDIO_TRACKS_UPDATED, this.onAudioTracksUpdated, this);\n      hls.on(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);\n      hls.on(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);\n      hls.on(Events.ERROR, this.onError, this);\n      hls.on(Events.BUFFER_RESET, this.onBufferReset, this);\n      hls.on(Events.BUFFER_CREATED, this.onBufferCreated, this);\n      hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n      hls.on(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);\n      hls.on(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);\n      hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    };\n    _proto._unregisterListeners = function _unregisterListeners() {\n      var hls = this.hls;\n      hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n      hls.off(Events.AUDIO_TRACKS_UPDATED, this.onAudioTracksUpdated, this);\n      hls.off(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);\n      hls.off(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);\n      hls.off(Events.ERROR, this.onError, this);\n      hls.off(Events.BUFFER_RESET, this.onBufferReset, this);\n      hls.off(Events.BUFFER_CREATED, this.onBufferCreated, this);\n      hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n      hls.off(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);\n      hls.off(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);\n      hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    }\n\n    // INIT_PTS_FOUND is triggered when the video track parsed in the stream-controller has a new PTS value\n    ;\n    _proto.onInitPtsFound = function onInitPtsFound(event, _ref) {\n      var frag = _ref.frag,\n        id = _ref.id,\n        initPTS = _ref.initPTS,\n        timescale = _ref.timescale;\n      // Always update the new INIT PTS\n      // Can change due level switch\n      if (id === 'main') {\n        var cc = frag.cc;\n        this.initPTS[frag.cc] = {\n          baseTime: initPTS,\n          timescale: timescale\n        };\n        this.log(\"InitPTS for cc: \" + cc + \" found from main: \" + initPTS);\n        this.videoTrackCC = cc;\n        // If we are waiting, tick immediately to unblock audio fragment transmuxing\n        if (this.state === State.WAITING_INIT_PTS) {\n          this.tick();\n        }\n      }\n    };\n    _proto.startLoad = function startLoad(startPosition) {\n      if (!this.levels) {\n        this.startPosition = startPosition;\n        this.state = State.STOPPED;\n        return;\n      }\n      var lastCurrentTime = this.lastCurrentTime;\n      this.stopLoad();\n      this.setInterval(TICK_INTERVAL$2);\n      if (lastCurrentTime > 0 && startPosition === -1) {\n        this.log(\"Override startPosition with lastCurrentTime @\" + lastCurrentTime.toFixed(3));\n        startPosition = lastCurrentTime;\n        this.state = State.IDLE;\n      } else {\n        this.loadedmetadata = false;\n        this.state = State.WAITING_TRACK;\n      }\n      this.nextLoadPosition = this.startPosition = this.lastCurrentTime = startPosition;\n      this.tick();\n    };\n    _proto.doTick = function doTick() {\n      switch (this.state) {\n        case State.IDLE:\n          this.doTickIdle();\n          break;\n        case State.WAITING_TRACK:\n          {\n            var _levels$trackId;\n            var levels = this.levels,\n              trackId = this.trackId;\n            var details = levels == null ? void 0 : (_levels$trackId = levels[trackId]) == null ? void 0 : _levels$trackId.details;\n            if (details) {\n              if (this.waitForCdnTuneIn(details)) {\n                break;\n              }\n              this.state = State.WAITING_INIT_PTS;\n            }\n            break;\n          }\n        case State.FRAG_LOADING_WAITING_RETRY:\n          {\n            var _this$media;\n            var now = performance.now();\n            var retryDate = this.retryDate;\n            // if current time is gt than retryDate, or if media seeking let's switch to IDLE state to retry loading\n            if (!retryDate || now >= retryDate || (_this$media = this.media) != null && _this$media.seeking) {\n              var _levels = this.levels,\n                _trackId = this.trackId;\n              this.log('RetryDate reached, switch back to IDLE state');\n              this.resetStartWhenNotLoaded((_levels == null ? void 0 : _levels[_trackId]) || null);\n              this.state = State.IDLE;\n            }\n            break;\n          }\n        case State.WAITING_INIT_PTS:\n          {\n            // Ensure we don't get stuck in the WAITING_INIT_PTS state if the waiting frag CC doesn't match any initPTS\n            var waitingData = this.waitingData;\n            if (waitingData) {\n              var frag = waitingData.frag,\n                part = waitingData.part,\n                cache = waitingData.cache,\n                complete = waitingData.complete;\n              if (this.initPTS[frag.cc] !== undefined) {\n                this.waitingData = null;\n                this.waitingVideoCC = -1;\n                this.state = State.FRAG_LOADING;\n                var payload = cache.flush();\n                var data = {\n                  frag: frag,\n                  part: part,\n                  payload: payload,\n                  networkDetails: null\n                };\n                this._handleFragmentLoadProgress(data);\n                if (complete) {\n                  _BaseStreamController.prototype._handleFragmentLoadComplete.call(this, data);\n                }\n              } else if (this.videoTrackCC !== this.waitingVideoCC) {\n                // Drop waiting fragment if videoTrackCC has changed since waitingFragment was set and initPTS was not found\n                this.log(\"Waiting fragment cc (\" + frag.cc + \") cancelled because video is at cc \" + this.videoTrackCC);\n                this.clearWaitingFragment();\n              } else {\n                // Drop waiting fragment if an earlier fragment is needed\n                var pos = this.getLoadPosition();\n                var bufferInfo = BufferHelper.bufferInfo(this.mediaBuffer, pos, this.config.maxBufferHole);\n                var waitingFragmentAtPosition = fragmentWithinToleranceTest(bufferInfo.end, this.config.maxFragLookUpTolerance, frag);\n                if (waitingFragmentAtPosition < 0) {\n                  this.log(\"Waiting fragment cc (\" + frag.cc + \") @ \" + frag.start + \" cancelled because another fragment at \" + bufferInfo.end + \" is needed\");\n                  this.clearWaitingFragment();\n                }\n              }\n            } else {\n              this.state = State.IDLE;\n            }\n          }\n      }\n      this.onTickEnd();\n    };\n    _proto.clearWaitingFragment = function clearWaitingFragment() {\n      var waitingData = this.waitingData;\n      if (waitingData) {\n        this.fragmentTracker.removeFragment(waitingData.frag);\n        this.waitingData = null;\n        this.waitingVideoCC = -1;\n        this.state = State.IDLE;\n      }\n    };\n    _proto.resetLoadingState = function resetLoadingState() {\n      this.clearWaitingFragment();\n      _BaseStreamController.prototype.resetLoadingState.call(this);\n    };\n    _proto.onTickEnd = function onTickEnd() {\n      var media = this.media;\n      if (!(media != null && media.readyState)) {\n        // Exit early if we don't have media or if the media hasn't buffered anything yet (readyState 0)\n        return;\n      }\n      this.lastCurrentTime = media.currentTime;\n    };\n    _proto.doTickIdle = function doTickIdle() {\n      var hls = this.hls,\n        levels = this.levels,\n        media = this.media,\n        trackId = this.trackId;\n      var config = hls.config;\n\n      // 1. if video not attached AND\n      //    start fragment already requested OR start frag prefetch not enabled\n      // 2. if tracks or track not loaded and selected\n      // then exit loop\n      // => if media not attached but start frag prefetch is enabled and start frag not requested yet, we will not exit loop\n      if (!media && (this.startFragRequested || !config.startFragPrefetch) || !(levels != null && levels[trackId])) {\n        return;\n      }\n      var levelInfo = levels[trackId];\n      var trackDetails = levelInfo.details;\n      if (!trackDetails || trackDetails.live && this.levelLastLoaded !== levelInfo || this.waitForCdnTuneIn(trackDetails)) {\n        this.state = State.WAITING_TRACK;\n        return;\n      }\n      var bufferable = this.mediaBuffer ? this.mediaBuffer : this.media;\n      if (this.bufferFlushed && bufferable) {\n        this.bufferFlushed = false;\n        this.afterBufferFlushed(bufferable, ElementaryStreamTypes.AUDIO, PlaylistLevelType.AUDIO);\n      }\n      var bufferInfo = this.getFwdBufferInfo(bufferable, PlaylistLevelType.AUDIO);\n      if (bufferInfo === null) {\n        return;\n      }\n      var bufferedTrack = this.bufferedTrack,\n        switchingTrack = this.switchingTrack;\n      if (!switchingTrack && this._streamEnded(bufferInfo, trackDetails)) {\n        hls.trigger(Events.BUFFER_EOS, {\n          type: 'audio'\n        });\n        this.state = State.ENDED;\n        return;\n      }\n      var mainBufferInfo = this.getFwdBufferInfo(this.videoBuffer ? this.videoBuffer : this.media, PlaylistLevelType.MAIN);\n      var bufferLen = bufferInfo.len;\n      var maxBufLen = this.getMaxBufferLength(mainBufferInfo == null ? void 0 : mainBufferInfo.len);\n      var fragments = trackDetails.fragments;\n      var start = fragments[0].start;\n      var targetBufferTime = this.flushing ? this.getLoadPosition() : bufferInfo.end;\n      if (switchingTrack && media) {\n        var pos = this.getLoadPosition();\n        // STABLE\n        if (bufferedTrack && !mediaAttributesIdentical(switchingTrack.attrs, bufferedTrack.attrs)) {\n          targetBufferTime = pos;\n        }\n        // if currentTime (pos) is less than alt audio playlist start time, it means that alt audio is ahead of currentTime\n        if (trackDetails.PTSKnown && pos < start) {\n          // if everything is buffered from pos to start or if audio buffer upfront, let's seek to start\n          if (bufferInfo.end > start || bufferInfo.nextStart) {\n            this.log('Alt audio track ahead of main track, seek to start of alt audio track');\n            media.currentTime = start + 0.05;\n          }\n        }\n      }\n\n      // if buffer length is less than maxBufLen, or near the end, find a fragment to load\n      if (bufferLen >= maxBufLen && !switchingTrack && targetBufferTime < fragments[fragments.length - 1].start) {\n        return;\n      }\n      var frag = this.getNextFragment(targetBufferTime, trackDetails);\n      var atGap = false;\n      // Avoid loop loading by using nextLoadPosition set for backtracking and skipping consecutive GAP tags\n      if (frag && this.isLoopLoading(frag, targetBufferTime)) {\n        atGap = !!frag.gap;\n        frag = this.getNextFragmentLoopLoading(frag, trackDetails, bufferInfo, PlaylistLevelType.MAIN, maxBufLen);\n      }\n      if (!frag) {\n        this.bufferFlushed = true;\n        return;\n      }\n\n      // Buffer audio up to one target duration ahead of main buffer\n      var atBufferSyncLimit = mainBufferInfo && frag.start > mainBufferInfo.end + trackDetails.targetduration;\n      if (atBufferSyncLimit ||\n      // Or wait for main buffer after buffing some audio\n      !(mainBufferInfo != null && mainBufferInfo.len) && bufferInfo.len) {\n        // Check fragment-tracker for main fragments since GAP segments do not show up in bufferInfo\n        var mainFrag = this.getAppendedFrag(frag.start, PlaylistLevelType.MAIN);\n        if (mainFrag === null) {\n          return;\n        }\n        // Bridge gaps in main buffer\n        atGap || (atGap = !!mainFrag.gap || !!atBufferSyncLimit && mainBufferInfo.len === 0);\n        if (atBufferSyncLimit && !atGap || atGap && bufferInfo.nextStart && bufferInfo.nextStart < mainFrag.end) {\n          return;\n        }\n      }\n      this.loadFragment(frag, levelInfo, targetBufferTime);\n    };\n    _proto.getMaxBufferLength = function getMaxBufferLength(mainBufferLength) {\n      var maxConfigBuffer = _BaseStreamController.prototype.getMaxBufferLength.call(this);\n      if (!mainBufferLength) {\n        return maxConfigBuffer;\n      }\n      return Math.min(Math.max(maxConfigBuffer, mainBufferLength), this.config.maxMaxBufferLength);\n    };\n    _proto.onMediaDetaching = function onMediaDetaching() {\n      this.videoBuffer = null;\n      this.bufferFlushed = this.flushing = false;\n      _BaseStreamController.prototype.onMediaDetaching.call(this);\n    };\n    _proto.onAudioTracksUpdated = function onAudioTracksUpdated(event, _ref2) {\n      var audioTracks = _ref2.audioTracks;\n      // Reset tranxmuxer is essential for large context switches (Content Steering)\n      this.resetTransmuxer();\n      this.levels = audioTracks.map(function (mediaPlaylist) {\n        return new Level(mediaPlaylist);\n      });\n    };\n    _proto.onAudioTrackSwitching = function onAudioTrackSwitching(event, data) {\n      // if any URL found on new audio track, it is an alternate audio track\n      var altAudio = !!data.url;\n      this.trackId = data.id;\n      var fragCurrent = this.fragCurrent;\n      if (fragCurrent) {\n        fragCurrent.abortRequests();\n        this.removeUnbufferedFrags(fragCurrent.start);\n      }\n      this.resetLoadingState();\n      // destroy useless transmuxer when switching audio to main\n      if (!altAudio) {\n        this.resetTransmuxer();\n      } else {\n        // switching to audio track, start timer if not already started\n        this.setInterval(TICK_INTERVAL$2);\n      }\n\n      // should we switch tracks ?\n      if (altAudio) {\n        this.switchingTrack = data;\n        // main audio track are handled by stream-controller, just do something if switching to alt audio track\n        this.state = State.IDLE;\n        this.flushAudioIfNeeded(data);\n      } else {\n        this.switchingTrack = null;\n        this.bufferedTrack = data;\n        this.state = State.STOPPED;\n      }\n      this.tick();\n    };\n    _proto.onManifestLoading = function onManifestLoading() {\n      this.fragmentTracker.removeAllFragments();\n      this.startPosition = this.lastCurrentTime = 0;\n      this.bufferFlushed = this.flushing = false;\n      this.levels = this.mainDetails = this.waitingData = this.bufferedTrack = this.cachedTrackLoadedData = this.switchingTrack = null;\n      this.startFragRequested = false;\n      this.trackId = this.videoTrackCC = this.waitingVideoCC = -1;\n    };\n    _proto.onLevelLoaded = function onLevelLoaded(event, data) {\n      this.mainDetails = data.details;\n      if (this.cachedTrackLoadedData !== null) {\n        this.hls.trigger(Events.AUDIO_TRACK_LOADED, this.cachedTrackLoadedData);\n        this.cachedTrackLoadedData = null;\n      }\n    };\n    _proto.onAudioTrackLoaded = function onAudioTrackLoaded(event, data) {\n      var _track$details;\n      if (this.mainDetails == null) {\n        this.cachedTrackLoadedData = data;\n        return;\n      }\n      var levels = this.levels;\n      var newDetails = data.details,\n        trackId = data.id;\n      if (!levels) {\n        this.warn(\"Audio tracks were reset while loading level \" + trackId);\n        return;\n      }\n      this.log(\"Audio track \" + trackId + \" loaded [\" + newDetails.startSN + \",\" + newDetails.endSN + \"]\" + (newDetails.lastPartSn ? \"[part-\" + newDetails.lastPartSn + \"-\" + newDetails.lastPartIndex + \"]\" : '') + \",duration:\" + newDetails.totalduration);\n      var track = levels[trackId];\n      var sliding = 0;\n      if (newDetails.live || (_track$details = track.details) != null && _track$details.live) {\n        this.checkLiveUpdate(newDetails);\n        var mainDetails = this.mainDetails;\n        if (newDetails.deltaUpdateFailed || !mainDetails) {\n          return;\n        }\n        if (!track.details && newDetails.hasProgramDateTime && mainDetails.hasProgramDateTime) {\n          // Make sure our audio rendition is aligned with the \"main\" rendition, using\n          // pdt as our reference times.\n          alignMediaPlaylistByPDT(newDetails, mainDetails);\n          sliding = newDetails.fragments[0].start;\n        } else {\n          var _this$levelLastLoaded;\n          sliding = this.alignPlaylists(newDetails, track.details, (_this$levelLastLoaded = this.levelLastLoaded) == null ? void 0 : _this$levelLastLoaded.details);\n        }\n      }\n      track.details = newDetails;\n      this.levelLastLoaded = track;\n\n      // compute start position if we are aligned with the main playlist\n      if (!this.startFragRequested && (this.mainDetails || !newDetails.live)) {\n        this.setStartPosition(this.mainDetails || newDetails, sliding);\n      }\n      // only switch back to IDLE state if we were waiting for track to start downloading a new fragment\n      if (this.state === State.WAITING_TRACK && !this.waitForCdnTuneIn(newDetails)) {\n        this.state = State.IDLE;\n      }\n\n      // trigger handler right now\n      this.tick();\n    };\n    _proto._handleFragmentLoadProgress = function _handleFragmentLoadProgress(data) {\n      var _frag$initSegment;\n      var frag = data.frag,\n        part = data.part,\n        payload = data.payload;\n      var config = this.config,\n        trackId = this.trackId,\n        levels = this.levels;\n      if (!levels) {\n        this.warn(\"Audio tracks were reset while fragment load was in progress. Fragment \" + frag.sn + \" of level \" + frag.level + \" will not be buffered\");\n        return;\n      }\n      var track = levels[trackId];\n      if (!track) {\n        this.warn('Audio track is undefined on fragment load progress');\n        return;\n      }\n      var details = track.details;\n      if (!details) {\n        this.warn('Audio track details undefined on fragment load progress');\n        this.removeUnbufferedFrags(frag.start);\n        return;\n      }\n      var audioCodec = config.defaultAudioCodec || track.audioCodec || 'mp4a.40.2';\n      var transmuxer = this.transmuxer;\n      if (!transmuxer) {\n        transmuxer = this.transmuxer = new TransmuxerInterface(this.hls, PlaylistLevelType.AUDIO, this._handleTransmuxComplete.bind(this), this._handleTransmuxerFlush.bind(this));\n      }\n\n      // Check if we have video initPTS\n      // If not we need to wait for it\n      var initPTS = this.initPTS[frag.cc];\n      var initSegmentData = (_frag$initSegment = frag.initSegment) == null ? void 0 : _frag$initSegment.data;\n      if (initPTS !== undefined) {\n        // this.log(`Transmuxing ${sn} of [${details.startSN} ,${details.endSN}],track ${trackId}`);\n        // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live)\n        var accurateTimeOffset = false; // details.PTSKnown || !details.live;\n        var partIndex = part ? part.index : -1;\n        var partial = partIndex !== -1;\n        var chunkMeta = new ChunkMetadata(frag.level, frag.sn, frag.stats.chunkCount, payload.byteLength, partIndex, partial);\n        transmuxer.push(payload, initSegmentData, audioCodec, '', frag, part, details.totalduration, accurateTimeOffset, chunkMeta, initPTS);\n      } else {\n        this.log(\"Unknown video PTS for cc \" + frag.cc + \", waiting for video PTS before demuxing audio frag \" + frag.sn + \" of [\" + details.startSN + \" ,\" + details.endSN + \"],track \" + trackId);\n        var _this$waitingData = this.waitingData = this.waitingData || {\n            frag: frag,\n            part: part,\n            cache: new ChunkCache(),\n            complete: false\n          },\n          cache = _this$waitingData.cache;\n        cache.push(new Uint8Array(payload));\n        this.waitingVideoCC = this.videoTrackCC;\n        this.state = State.WAITING_INIT_PTS;\n      }\n    };\n    _proto._handleFragmentLoadComplete = function _handleFragmentLoadComplete(fragLoadedData) {\n      if (this.waitingData) {\n        this.waitingData.complete = true;\n        return;\n      }\n      _BaseStreamController.prototype._handleFragmentLoadComplete.call(this, fragLoadedData);\n    };\n    _proto.onBufferReset = function onBufferReset( /* event: Events.BUFFER_RESET */\n    ) {\n      // reset reference to sourcebuffers\n      this.mediaBuffer = this.videoBuffer = null;\n      this.loadedmetadata = false;\n    };\n    _proto.onBufferCreated = function onBufferCreated(event, data) {\n      var audioTrack = data.tracks.audio;\n      if (audioTrack) {\n        this.mediaBuffer = audioTrack.buffer || null;\n      }\n      if (data.tracks.video) {\n        this.videoBuffer = data.tracks.video.buffer || null;\n      }\n    };\n    _proto.onFragBuffered = function onFragBuffered(event, data) {\n      var frag = data.frag,\n        part = data.part;\n      if (frag.type !== PlaylistLevelType.AUDIO) {\n        if (!this.loadedmetadata && frag.type === PlaylistLevelType.MAIN) {\n          var bufferable = this.videoBuffer || this.media;\n          if (bufferable) {\n            var bufferedTimeRanges = BufferHelper.getBuffered(bufferable);\n            if (bufferedTimeRanges.length) {\n              this.loadedmetadata = true;\n            }\n          }\n        }\n        return;\n      }\n      if (this.fragContextChanged(frag)) {\n        // If a level switch was requested while a fragment was buffering, it will emit the FRAG_BUFFERED event upon completion\n        // Avoid setting state back to IDLE or concluding the audio switch; otherwise, the switched-to track will not buffer\n        this.warn(\"Fragment \" + frag.sn + (part ? ' p: ' + part.index : '') + \" of level \" + frag.level + \" finished buffering, but was aborted. state: \" + this.state + \", audioSwitch: \" + (this.switchingTrack ? this.switchingTrack.name : 'false'));\n        return;\n      }\n      if (frag.sn !== 'initSegment') {\n        this.fragPrevious = frag;\n        var track = this.switchingTrack;\n        if (track) {\n          this.bufferedTrack = track;\n          this.switchingTrack = null;\n          this.hls.trigger(Events.AUDIO_TRACK_SWITCHED, _objectSpread2({}, track));\n        }\n      }\n      this.fragBufferedComplete(frag, part);\n    };\n    _proto.onError = function onError(event, data) {\n      var _data$context;\n      if (data.fatal) {\n        this.state = State.ERROR;\n        return;\n      }\n      switch (data.details) {\n        case ErrorDetails.FRAG_GAP:\n        case ErrorDetails.FRAG_PARSING_ERROR:\n        case ErrorDetails.FRAG_DECRYPT_ERROR:\n        case ErrorDetails.FRAG_LOAD_ERROR:\n        case ErrorDetails.FRAG_LOAD_TIMEOUT:\n        case ErrorDetails.KEY_LOAD_ERROR:\n        case ErrorDetails.KEY_LOAD_TIMEOUT:\n          this.onFragmentOrKeyLoadError(PlaylistLevelType.AUDIO, data);\n          break;\n        case ErrorDetails.AUDIO_TRACK_LOAD_ERROR:\n        case ErrorDetails.AUDIO_TRACK_LOAD_TIMEOUT:\n        case ErrorDetails.LEVEL_PARSING_ERROR:\n          // in case of non fatal error while loading track, if not retrying to load track, switch back to IDLE\n          if (!data.levelRetry && this.state === State.WAITING_TRACK && ((_data$context = data.context) == null ? void 0 : _data$context.type) === PlaylistContextType.AUDIO_TRACK) {\n            this.state = State.IDLE;\n          }\n          break;\n        case ErrorDetails.BUFFER_APPEND_ERROR:\n        case ErrorDetails.BUFFER_FULL_ERROR:\n          if (!data.parent || data.parent !== 'audio') {\n            return;\n          }\n          if (data.details === ErrorDetails.BUFFER_APPEND_ERROR) {\n            this.resetLoadingState();\n            return;\n          }\n          if (this.reduceLengthAndFlushBuffer(data)) {\n            this.bufferedTrack = null;\n            _BaseStreamController.prototype.flushMainBuffer.call(this, 0, Number.POSITIVE_INFINITY, 'audio');\n          }\n          break;\n        case ErrorDetails.INTERNAL_EXCEPTION:\n          this.recoverWorkerError(data);\n          break;\n      }\n    };\n    _proto.onBufferFlushing = function onBufferFlushing(event, _ref3) {\n      var type = _ref3.type;\n      if (type !== ElementaryStreamTypes.VIDEO) {\n        this.flushing = true;\n      }\n    };\n    _proto.onBufferFlushed = function onBufferFlushed(event, _ref4) {\n      var type = _ref4.type;\n      if (type !== ElementaryStreamTypes.VIDEO) {\n        this.flushing = false;\n        this.bufferFlushed = true;\n        if (this.state === State.ENDED) {\n          this.state = State.IDLE;\n        }\n        var mediaBuffer = this.mediaBuffer || this.media;\n        if (mediaBuffer) {\n          this.afterBufferFlushed(mediaBuffer, type, PlaylistLevelType.AUDIO);\n          this.tick();\n        }\n      }\n    };\n    _proto._handleTransmuxComplete = function _handleTransmuxComplete(transmuxResult) {\n      var _id3$samples;\n      var id = 'audio';\n      var hls = this.hls;\n      var remuxResult = transmuxResult.remuxResult,\n        chunkMeta = transmuxResult.chunkMeta;\n      var context = this.getCurrentContext(chunkMeta);\n      if (!context) {\n        this.resetWhenMissingContext(chunkMeta);\n        return;\n      }\n      var frag = context.frag,\n        part = context.part,\n        level = context.level;\n      var details = level.details;\n      var audio = remuxResult.audio,\n        text = remuxResult.text,\n        id3 = remuxResult.id3,\n        initSegment = remuxResult.initSegment;\n\n      // Check if the current fragment has been aborted. We check this by first seeing if we're still playing the current level.\n      // If we are, subsequently check if the currently loading fragment (fragCurrent) has changed.\n      if (this.fragContextChanged(frag) || !details) {\n        this.fragmentTracker.removeFragment(frag);\n        return;\n      }\n      this.state = State.PARSING;\n      if (this.switchingTrack && audio) {\n        this.completeAudioSwitch(this.switchingTrack);\n      }\n      if (initSegment != null && initSegment.tracks) {\n        var mapFragment = frag.initSegment || frag;\n        this._bufferInitSegment(level, initSegment.tracks, mapFragment, chunkMeta);\n        hls.trigger(Events.FRAG_PARSING_INIT_SEGMENT, {\n          frag: mapFragment,\n          id: id,\n          tracks: initSegment.tracks\n        });\n        // Only flush audio from old audio tracks when PTS is known on new audio track\n      }\n      if (audio) {\n        var startPTS = audio.startPTS,\n          endPTS = audio.endPTS,\n          startDTS = audio.startDTS,\n          endDTS = audio.endDTS;\n        if (part) {\n          part.elementaryStreams[ElementaryStreamTypes.AUDIO] = {\n            startPTS: startPTS,\n            endPTS: endPTS,\n            startDTS: startDTS,\n            endDTS: endDTS\n          };\n        }\n        frag.setElementaryStreamInfo(ElementaryStreamTypes.AUDIO, startPTS, endPTS, startDTS, endDTS);\n        this.bufferFragmentData(audio, frag, part, chunkMeta);\n      }\n      if (id3 != null && (_id3$samples = id3.samples) != null && _id3$samples.length) {\n        var emittedID3 = _extends({\n          id: id,\n          frag: frag,\n          details: details\n        }, id3);\n        hls.trigger(Events.FRAG_PARSING_METADATA, emittedID3);\n      }\n      if (text) {\n        var emittedText = _extends({\n          id: id,\n          frag: frag,\n          details: details\n        }, text);\n        hls.trigger(Events.FRAG_PARSING_USERDATA, emittedText);\n      }\n    };\n    _proto._bufferInitSegment = function _bufferInitSegment(currentLevel, tracks, frag, chunkMeta) {\n      if (this.state !== State.PARSING) {\n        return;\n      }\n      // delete any video track found on audio transmuxer\n      if (tracks.video) {\n        delete tracks.video;\n      }\n\n      // include levelCodec in audio and video tracks\n      var track = tracks.audio;\n      if (!track) {\n        return;\n      }\n      track.id = 'audio';\n      var variantAudioCodecs = currentLevel.audioCodec;\n      this.log(\"Init audio buffer, container:\" + track.container + \", codecs[level/parsed]=[\" + variantAudioCodecs + \"/\" + track.codec + \"]\");\n      // SourceBuffer will use track.levelCodec if defined\n      if (variantAudioCodecs && variantAudioCodecs.split(',').length === 1) {\n        track.levelCodec = variantAudioCodecs;\n      }\n      this.hls.trigger(Events.BUFFER_CODECS, tracks);\n      var initSegment = track.initSegment;\n      if (initSegment != null && initSegment.byteLength) {\n        var segment = {\n          type: 'audio',\n          frag: frag,\n          part: null,\n          chunkMeta: chunkMeta,\n          parent: frag.type,\n          data: initSegment\n        };\n        this.hls.trigger(Events.BUFFER_APPENDING, segment);\n      }\n      // trigger handler right now\n      this.tickImmediate();\n    };\n    _proto.loadFragment = function loadFragment(frag, track, targetBufferTime) {\n      // only load if fragment is not loaded or if in audio switch\n      var fragState = this.fragmentTracker.getState(frag);\n      this.fragCurrent = frag;\n\n      // we force a frag loading in audio switch as fragment tracker might not have evicted previous frags in case of quick audio switch\n      if (this.switchingTrack || fragState === FragmentState.NOT_LOADED || fragState === FragmentState.PARTIAL) {\n        var _track$details2;\n        if (frag.sn === 'initSegment') {\n          this._loadInitSegment(frag, track);\n        } else if ((_track$details2 = track.details) != null && _track$details2.live && !this.initPTS[frag.cc]) {\n          this.log(\"Waiting for video PTS in continuity counter \" + frag.cc + \" of live stream before loading audio fragment \" + frag.sn + \" of level \" + this.trackId);\n          this.state = State.WAITING_INIT_PTS;\n          var mainDetails = this.mainDetails;\n          if (mainDetails && mainDetails.fragments[0].start !== track.details.fragments[0].start) {\n            alignMediaPlaylistByPDT(track.details, mainDetails);\n          }\n        } else {\n          this.startFragRequested = true;\n          _BaseStreamController.prototype.loadFragment.call(this, frag, track, targetBufferTime);\n        }\n      } else {\n        this.clearTrackerIfNeeded(frag);\n      }\n    };\n    _proto.flushAudioIfNeeded = function flushAudioIfNeeded(switchingTrack) {\n      var media = this.media,\n        bufferedTrack = this.bufferedTrack;\n      var bufferedAttributes = bufferedTrack == null ? void 0 : bufferedTrack.attrs;\n      var switchAttributes = switchingTrack.attrs;\n      if (media && bufferedAttributes && (bufferedAttributes.CHANNELS !== switchAttributes.CHANNELS || bufferedTrack.name !== switchingTrack.name || bufferedTrack.lang !== switchingTrack.lang)) {\n        this.log('Switching audio track : flushing all audio');\n        _BaseStreamController.prototype.flushMainBuffer.call(this, 0, Number.POSITIVE_INFINITY, 'audio');\n        this.bufferedTrack = null;\n      }\n    };\n    _proto.completeAudioSwitch = function completeAudioSwitch(switchingTrack) {\n      var hls = this.hls;\n      this.flushAudioIfNeeded(switchingTrack);\n      this.bufferedTrack = switchingTrack;\n      this.switchingTrack = null;\n      hls.trigger(Events.AUDIO_TRACK_SWITCHED, _objectSpread2({}, switchingTrack));\n    };\n    return AudioStreamController;\n  }(BaseStreamController);\n\n  var AudioTrackController = /*#__PURE__*/function (_BasePlaylistControll) {\n    _inheritsLoose(AudioTrackController, _BasePlaylistControll);\n    function AudioTrackController(hls) {\n      var _this;\n      _this = _BasePlaylistControll.call(this, hls, '[audio-track-controller]') || this;\n      _this.tracks = [];\n      _this.groupIds = null;\n      _this.tracksInGroup = [];\n      _this.trackId = -1;\n      _this.currentTrack = null;\n      _this.selectDefaultTrack = true;\n      _this.registerListeners();\n      return _this;\n    }\n    var _proto = AudioTrackController.prototype;\n    _proto.registerListeners = function registerListeners() {\n      var hls = this.hls;\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n      hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);\n      hls.on(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n      hls.on(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);\n      hls.on(Events.ERROR, this.onError, this);\n    };\n    _proto.unregisterListeners = function unregisterListeners() {\n      var hls = this.hls;\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n      hls.off(Events.LEVEL_LOADING, this.onLevelLoading, this);\n      hls.off(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n      hls.off(Events.AUDIO_TRACK_LOADED, this.onAudioTrackLoaded, this);\n      hls.off(Events.ERROR, this.onError, this);\n    };\n    _proto.destroy = function destroy() {\n      this.unregisterListeners();\n      this.tracks.length = 0;\n      this.tracksInGroup.length = 0;\n      this.currentTrack = null;\n      _BasePlaylistControll.prototype.destroy.call(this);\n    };\n    _proto.onManifestLoading = function onManifestLoading() {\n      this.tracks = [];\n      this.tracksInGroup = [];\n      this.groupIds = null;\n      this.currentTrack = null;\n      this.trackId = -1;\n      this.selectDefaultTrack = true;\n    };\n    _proto.onManifestParsed = function onManifestParsed(event, data) {\n      this.tracks = data.audioTracks || [];\n    };\n    _proto.onAudioTrackLoaded = function onAudioTrackLoaded(event, data) {\n      var id = data.id,\n        groupId = data.groupId,\n        details = data.details;\n      var trackInActiveGroup = this.tracksInGroup[id];\n      if (!trackInActiveGroup || trackInActiveGroup.groupId !== groupId) {\n        this.warn(\"Audio track with id:\" + id + \" and group:\" + groupId + \" not found in active group \" + (trackInActiveGroup == null ? void 0 : trackInActiveGroup.groupId));\n        return;\n      }\n      var curDetails = trackInActiveGroup.details;\n      trackInActiveGroup.details = data.details;\n      this.log(\"Audio track \" + id + \" \\\"\" + trackInActiveGroup.name + \"\\\" lang:\" + trackInActiveGroup.lang + \" group:\" + groupId + \" loaded [\" + details.startSN + \"-\" + details.endSN + \"]\");\n      if (id === this.trackId) {\n        this.playlistLoaded(id, data, curDetails);\n      }\n    };\n    _proto.onLevelLoading = function onLevelLoading(event, data) {\n      this.switchLevel(data.level);\n    };\n    _proto.onLevelSwitching = function onLevelSwitching(event, data) {\n      this.switchLevel(data.level);\n    };\n    _proto.switchLevel = function switchLevel(levelIndex) {\n      var levelInfo = this.hls.levels[levelIndex];\n      if (!levelInfo) {\n        return;\n      }\n      var audioGroups = levelInfo.audioGroups || null;\n      var currentGroups = this.groupIds;\n      var currentTrack = this.currentTrack;\n      if (!audioGroups || (currentGroups == null ? void 0 : currentGroups.length) !== (audioGroups == null ? void 0 : audioGroups.length) || audioGroups != null && audioGroups.some(function (groupId) {\n        return (currentGroups == null ? void 0 : currentGroups.indexOf(groupId)) === -1;\n      })) {\n        this.groupIds = audioGroups;\n        this.trackId = -1;\n        this.currentTrack = null;\n        var audioTracks = this.tracks.filter(function (track) {\n          return !audioGroups || audioGroups.indexOf(track.groupId) !== -1;\n        });\n        if (audioTracks.length) {\n          // Disable selectDefaultTrack if there are no default tracks\n          if (this.selectDefaultTrack && !audioTracks.some(function (track) {\n            return track.default;\n          })) {\n            this.selectDefaultTrack = false;\n          }\n          // track.id should match hls.audioTracks index\n          audioTracks.forEach(function (track, i) {\n            track.id = i;\n          });\n        } else if (!currentTrack && !this.tracksInGroup.length) {\n          // Do not dispatch AUDIO_TRACKS_UPDATED when there were and are no tracks\n          return;\n        }\n        this.tracksInGroup = audioTracks;\n\n        // Find preferred track\n        var audioPreference = this.hls.config.audioPreference;\n        if (!currentTrack && audioPreference) {\n          var groupIndex = findMatchingOption(audioPreference, audioTracks, audioMatchPredicate);\n          if (groupIndex > -1) {\n            currentTrack = audioTracks[groupIndex];\n          } else {\n            var allIndex = findMatchingOption(audioPreference, this.tracks);\n            currentTrack = this.tracks[allIndex];\n          }\n        }\n\n        // Select initial track\n        var trackId = this.findTrackId(currentTrack);\n        if (trackId === -1 && currentTrack) {\n          trackId = this.findTrackId(null);\n        }\n\n        // Dispatch events and load track if needed\n        var audioTracksUpdated = {\n          audioTracks: audioTracks\n        };\n        this.log(\"Updating audio tracks, \" + audioTracks.length + \" track(s) found in group(s): \" + (audioGroups == null ? void 0 : audioGroups.join(',')));\n        this.hls.trigger(Events.AUDIO_TRACKS_UPDATED, audioTracksUpdated);\n        var selectedTrackId = this.trackId;\n        if (trackId !== -1 && selectedTrackId === -1) {\n          this.setAudioTrack(trackId);\n        } else if (audioTracks.length && selectedTrackId === -1) {\n          var _this$groupIds;\n          var error = new Error(\"No audio track selected for current audio group-ID(s): \" + ((_this$groupIds = this.groupIds) == null ? void 0 : _this$groupIds.join(',')) + \" track count: \" + audioTracks.length);\n          this.warn(error.message);\n          this.hls.trigger(Events.ERROR, {\n            type: ErrorTypes.MEDIA_ERROR,\n            details: ErrorDetails.AUDIO_TRACK_LOAD_ERROR,\n            fatal: true,\n            error: error\n          });\n        }\n      } else if (this.shouldReloadPlaylist(currentTrack)) {\n        // Retry playlist loading if no playlist is or has been loaded yet\n        this.setAudioTrack(this.trackId);\n      }\n    };\n    _proto.onError = function onError(event, data) {\n      if (data.fatal || !data.context) {\n        return;\n      }\n      if (data.context.type === PlaylistContextType.AUDIO_TRACK && data.context.id === this.trackId && (!this.groupIds || this.groupIds.indexOf(data.context.groupId) !== -1)) {\n        this.requestScheduled = -1;\n        this.checkRetry(data);\n      }\n    };\n    _proto.setAudioOption = function setAudioOption(audioOption) {\n      var hls = this.hls;\n      hls.config.audioPreference = audioOption;\n      if (audioOption) {\n        var allAudioTracks = this.allAudioTracks;\n        this.selectDefaultTrack = false;\n        if (allAudioTracks.length) {\n          // First see if current option matches (no switch op)\n          var currentTrack = this.currentTrack;\n          if (currentTrack && matchesOption(audioOption, currentTrack, audioMatchPredicate)) {\n            return currentTrack;\n          }\n          // Find option in available tracks (tracksInGroup)\n          var groupIndex = findMatchingOption(audioOption, this.tracksInGroup, audioMatchPredicate);\n          if (groupIndex > -1) {\n            var track = this.tracksInGroup[groupIndex];\n            this.setAudioTrack(groupIndex);\n            return track;\n          } else if (currentTrack) {\n            // Find option in nearest level audio group\n            var searchIndex = hls.loadLevel;\n            if (searchIndex === -1) {\n              searchIndex = hls.firstAutoLevel;\n            }\n            var switchIndex = findClosestLevelWithAudioGroup(audioOption, hls.levels, allAudioTracks, searchIndex, audioMatchPredicate);\n            if (switchIndex === -1) {\n              // could not find matching variant\n              return null;\n            }\n            // and switch level to acheive the audio group switch\n            hls.nextLoadLevel = switchIndex;\n          }\n          if (audioOption.channels || audioOption.audioCodec) {\n            // Could not find a match with codec / channels predicate\n            // Find a match without channels or codec\n            var withoutCodecAndChannelsMatch = findMatchingOption(audioOption, allAudioTracks);\n            if (withoutCodecAndChannelsMatch > -1) {\n              return allAudioTracks[withoutCodecAndChannelsMatch];\n            }\n          }\n        }\n      }\n      return null;\n    };\n    _proto.setAudioTrack = function setAudioTrack(newId) {\n      var tracks = this.tracksInGroup;\n\n      // check if level idx is valid\n      if (newId < 0 || newId >= tracks.length) {\n        this.warn(\"Invalid audio track id: \" + newId);\n        return;\n      }\n\n      // stopping live reloading timer if any\n      this.clearTimer();\n      this.selectDefaultTrack = false;\n      var lastTrack = this.currentTrack;\n      var track = tracks[newId];\n      var trackLoaded = track.details && !track.details.live;\n      if (newId === this.trackId && track === lastTrack && trackLoaded) {\n        return;\n      }\n      this.log(\"Switching to audio-track \" + newId + \" \\\"\" + track.name + \"\\\" lang:\" + track.lang + \" group:\" + track.groupId + \" channels:\" + track.channels);\n      this.trackId = newId;\n      this.currentTrack = track;\n      this.hls.trigger(Events.AUDIO_TRACK_SWITCHING, _objectSpread2({}, track));\n      // Do not reload track unless live\n      if (trackLoaded) {\n        return;\n      }\n      var hlsUrlParameters = this.switchParams(track.url, lastTrack == null ? void 0 : lastTrack.details, track.details);\n      this.loadPlaylist(hlsUrlParameters);\n    };\n    _proto.findTrackId = function findTrackId(currentTrack) {\n      var audioTracks = this.tracksInGroup;\n      for (var i = 0; i < audioTracks.length; i++) {\n        var track = audioTracks[i];\n        if (this.selectDefaultTrack && !track.default) {\n          continue;\n        }\n        if (!currentTrack || matchesOption(currentTrack, track, audioMatchPredicate)) {\n          return i;\n        }\n      }\n      if (currentTrack) {\n        var name = currentTrack.name,\n          lang = currentTrack.lang,\n          assocLang = currentTrack.assocLang,\n          characteristics = currentTrack.characteristics,\n          audioCodec = currentTrack.audioCodec,\n          channels = currentTrack.channels;\n        for (var _i = 0; _i < audioTracks.length; _i++) {\n          var _track = audioTracks[_i];\n          if (matchesOption({\n            name: name,\n            lang: lang,\n            assocLang: assocLang,\n            characteristics: characteristics,\n            audioCodec: audioCodec,\n            channels: channels\n          }, _track, audioMatchPredicate)) {\n            return _i;\n          }\n        }\n        for (var _i2 = 0; _i2 < audioTracks.length; _i2++) {\n          var _track2 = audioTracks[_i2];\n          if (mediaAttributesIdentical(currentTrack.attrs, _track2.attrs, ['LANGUAGE', 'ASSOC-LANGUAGE', 'CHARACTERISTICS'])) {\n            return _i2;\n          }\n        }\n        for (var _i3 = 0; _i3 < audioTracks.length; _i3++) {\n          var _track3 = audioTracks[_i3];\n          if (mediaAttributesIdentical(currentTrack.attrs, _track3.attrs, ['LANGUAGE'])) {\n            return _i3;\n          }\n        }\n      }\n      return -1;\n    };\n    _proto.loadPlaylist = function loadPlaylist(hlsUrlParameters) {\n      var audioTrack = this.currentTrack;\n      if (this.shouldLoadPlaylist(audioTrack) && audioTrack) {\n        _BasePlaylistControll.prototype.loadPlaylist.call(this);\n        var id = audioTrack.id;\n        var groupId = audioTrack.groupId;\n        var url = audioTrack.url;\n        if (hlsUrlParameters) {\n          try {\n            url = hlsUrlParameters.addDirectives(url);\n          } catch (error) {\n            this.warn(\"Could not construct new URL with HLS Delivery Directives: \" + error);\n          }\n        }\n        // track not retrieved yet, or live playlist we need to (re)load it\n        this.log(\"loading audio-track playlist \" + id + \" \\\"\" + audioTrack.name + \"\\\" lang:\" + audioTrack.lang + \" group:\" + groupId);\n        this.clearTimer();\n        this.hls.trigger(Events.AUDIO_TRACK_LOADING, {\n          url: url,\n          id: id,\n          groupId: groupId,\n          deliveryDirectives: hlsUrlParameters || null\n        });\n      }\n    };\n    _createClass(AudioTrackController, [{\n      key: \"allAudioTracks\",\n      get: function get() {\n        return this.tracks;\n      }\n    }, {\n      key: \"audioTracks\",\n      get: function get() {\n        return this.tracksInGroup;\n      }\n    }, {\n      key: \"audioTrack\",\n      get: function get() {\n        return this.trackId;\n      },\n      set: function set(newId) {\n        // If audio track is selected from API then don't choose from the manifest default track\n        this.selectDefaultTrack = false;\n        this.setAudioTrack(newId);\n      }\n    }]);\n    return AudioTrackController;\n  }(BasePlaylistController);\n\n  var TICK_INTERVAL$1 = 500; // how often to tick in ms\n\n  var SubtitleStreamController = /*#__PURE__*/function (_BaseStreamController) {\n    _inheritsLoose(SubtitleStreamController, _BaseStreamController);\n    function SubtitleStreamController(hls, fragmentTracker, keyLoader) {\n      var _this;\n      _this = _BaseStreamController.call(this, hls, fragmentTracker, keyLoader, '[subtitle-stream-controller]', PlaylistLevelType.SUBTITLE) || this;\n      _this.currentTrackId = -1;\n      _this.tracksBuffered = [];\n      _this.mainDetails = null;\n      _this._registerListeners();\n      return _this;\n    }\n    var _proto = SubtitleStreamController.prototype;\n    _proto.onHandlerDestroying = function onHandlerDestroying() {\n      this._unregisterListeners();\n      _BaseStreamController.prototype.onHandlerDestroying.call(this);\n      this.mainDetails = null;\n    };\n    _proto._registerListeners = function _registerListeners() {\n      var hls = this.hls;\n      hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n      hls.on(Events.ERROR, this.onError, this);\n      hls.on(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);\n      hls.on(Events.SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);\n      hls.on(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);\n      hls.on(Events.SUBTITLE_FRAG_PROCESSED, this.onSubtitleFragProcessed, this);\n      hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n      hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    };\n    _proto._unregisterListeners = function _unregisterListeners() {\n      var hls = this.hls;\n      hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n      hls.off(Events.ERROR, this.onError, this);\n      hls.off(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);\n      hls.off(Events.SUBTITLE_TRACK_SWITCH, this.onSubtitleTrackSwitch, this);\n      hls.off(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);\n      hls.off(Events.SUBTITLE_FRAG_PROCESSED, this.onSubtitleFragProcessed, this);\n      hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n      hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    };\n    _proto.startLoad = function startLoad(startPosition) {\n      this.stopLoad();\n      this.state = State.IDLE;\n      this.setInterval(TICK_INTERVAL$1);\n      this.nextLoadPosition = this.startPosition = this.lastCurrentTime = startPosition;\n      this.tick();\n    };\n    _proto.onManifestLoading = function onManifestLoading() {\n      this.mainDetails = null;\n      this.fragmentTracker.removeAllFragments();\n    };\n    _proto.onMediaDetaching = function onMediaDetaching() {\n      this.tracksBuffered = [];\n      _BaseStreamController.prototype.onMediaDetaching.call(this);\n    };\n    _proto.onLevelLoaded = function onLevelLoaded(event, data) {\n      this.mainDetails = data.details;\n    };\n    _proto.onSubtitleFragProcessed = function onSubtitleFragProcessed(event, data) {\n      var frag = data.frag,\n        success = data.success;\n      this.fragPrevious = frag;\n      this.state = State.IDLE;\n      if (!success) {\n        return;\n      }\n      var buffered = this.tracksBuffered[this.currentTrackId];\n      if (!buffered) {\n        return;\n      }\n\n      // Create/update a buffered array matching the interface used by BufferHelper.bufferedInfo\n      // so we can re-use the logic used to detect how much has been buffered\n      var timeRange;\n      var fragStart = frag.start;\n      for (var i = 0; i < buffered.length; i++) {\n        if (fragStart >= buffered[i].start && fragStart <= buffered[i].end) {\n          timeRange = buffered[i];\n          break;\n        }\n      }\n      var fragEnd = frag.start + frag.duration;\n      if (timeRange) {\n        timeRange.end = fragEnd;\n      } else {\n        timeRange = {\n          start: fragStart,\n          end: fragEnd\n        };\n        buffered.push(timeRange);\n      }\n      this.fragmentTracker.fragBuffered(frag);\n      this.fragBufferedComplete(frag, null);\n    };\n    _proto.onBufferFlushing = function onBufferFlushing(event, data) {\n      var startOffset = data.startOffset,\n        endOffset = data.endOffset;\n      if (startOffset === 0 && endOffset !== Number.POSITIVE_INFINITY) {\n        var endOffsetSubtitles = endOffset - 1;\n        if (endOffsetSubtitles <= 0) {\n          return;\n        }\n        data.endOffsetSubtitles = Math.max(0, endOffsetSubtitles);\n        this.tracksBuffered.forEach(function (buffered) {\n          for (var i = 0; i < buffered.length;) {\n            if (buffered[i].end <= endOffsetSubtitles) {\n              buffered.shift();\n              continue;\n            } else if (buffered[i].start < endOffsetSubtitles) {\n              buffered[i].start = endOffsetSubtitles;\n            } else {\n              break;\n            }\n            i++;\n          }\n        });\n        this.fragmentTracker.removeFragmentsInRange(startOffset, endOffsetSubtitles, PlaylistLevelType.SUBTITLE);\n      }\n    };\n    _proto.onFragBuffered = function onFragBuffered(event, data) {\n      if (!this.loadedmetadata && data.frag.type === PlaylistLevelType.MAIN) {\n        var _this$media;\n        if ((_this$media = this.media) != null && _this$media.buffered.length) {\n          this.loadedmetadata = true;\n        }\n      }\n    }\n\n    // If something goes wrong, proceed to next frag, if we were processing one.\n    ;\n    _proto.onError = function onError(event, data) {\n      var frag = data.frag;\n      if ((frag == null ? void 0 : frag.type) === PlaylistLevelType.SUBTITLE) {\n        if (data.details === ErrorDetails.FRAG_GAP) {\n          this.fragmentTracker.fragBuffered(frag, true);\n        }\n        if (this.fragCurrent) {\n          this.fragCurrent.abortRequests();\n        }\n        if (this.state !== State.STOPPED) {\n          this.state = State.IDLE;\n        }\n      }\n    }\n\n    // Got all new subtitle levels.\n    ;\n    _proto.onSubtitleTracksUpdated = function onSubtitleTracksUpdated(event, _ref) {\n      var _this2 = this;\n      var subtitleTracks = _ref.subtitleTracks;\n      if (this.levels && subtitleOptionsIdentical(this.levels, subtitleTracks)) {\n        this.levels = subtitleTracks.map(function (mediaPlaylist) {\n          return new Level(mediaPlaylist);\n        });\n        return;\n      }\n      this.tracksBuffered = [];\n      this.levels = subtitleTracks.map(function (mediaPlaylist) {\n        var level = new Level(mediaPlaylist);\n        _this2.tracksBuffered[level.id] = [];\n        return level;\n      });\n      this.fragmentTracker.removeFragmentsInRange(0, Number.POSITIVE_INFINITY, PlaylistLevelType.SUBTITLE);\n      this.fragPrevious = null;\n      this.mediaBuffer = null;\n    };\n    _proto.onSubtitleTrackSwitch = function onSubtitleTrackSwitch(event, data) {\n      var _this$levels;\n      this.currentTrackId = data.id;\n      if (!((_this$levels = this.levels) != null && _this$levels.length) || this.currentTrackId === -1) {\n        this.clearInterval();\n        return;\n      }\n\n      // Check if track has the necessary details to load fragments\n      var currentTrack = this.levels[this.currentTrackId];\n      if (currentTrack != null && currentTrack.details) {\n        this.mediaBuffer = this.mediaBufferTimeRanges;\n      } else {\n        this.mediaBuffer = null;\n      }\n      if (currentTrack) {\n        this.setInterval(TICK_INTERVAL$1);\n      }\n    }\n\n    // Got a new set of subtitle fragments.\n    ;\n    _proto.onSubtitleTrackLoaded = function onSubtitleTrackLoaded(event, data) {\n      var _track$details;\n      var currentTrackId = this.currentTrackId,\n        levels = this.levels;\n      var newDetails = data.details,\n        trackId = data.id;\n      if (!levels) {\n        this.warn(\"Subtitle tracks were reset while loading level \" + trackId);\n        return;\n      }\n      var track = levels[trackId];\n      if (trackId >= levels.length || !track) {\n        return;\n      }\n      this.log(\"Subtitle track \" + trackId + \" loaded [\" + newDetails.startSN + \",\" + newDetails.endSN + \"]\" + (newDetails.lastPartSn ? \"[part-\" + newDetails.lastPartSn + \"-\" + newDetails.lastPartIndex + \"]\" : '') + \",duration:\" + newDetails.totalduration);\n      this.mediaBuffer = this.mediaBufferTimeRanges;\n      var sliding = 0;\n      if (newDetails.live || (_track$details = track.details) != null && _track$details.live) {\n        var mainDetails = this.mainDetails;\n        if (newDetails.deltaUpdateFailed || !mainDetails) {\n          return;\n        }\n        var mainSlidingStartFragment = mainDetails.fragments[0];\n        if (!track.details) {\n          if (newDetails.hasProgramDateTime && mainDetails.hasProgramDateTime) {\n            alignMediaPlaylistByPDT(newDetails, mainDetails);\n            sliding = newDetails.fragments[0].start;\n          } else if (mainSlidingStartFragment) {\n            // line up live playlist with main so that fragments in range are loaded\n            sliding = mainSlidingStartFragment.start;\n            addSliding(newDetails, sliding);\n          }\n        } else {\n          var _this$levelLastLoaded;\n          sliding = this.alignPlaylists(newDetails, track.details, (_this$levelLastLoaded = this.levelLastLoaded) == null ? void 0 : _this$levelLastLoaded.details);\n          if (sliding === 0 && mainSlidingStartFragment) {\n            // realign with main when there is no overlap with last refresh\n            sliding = mainSlidingStartFragment.start;\n            addSliding(newDetails, sliding);\n          }\n        }\n      }\n      track.details = newDetails;\n      this.levelLastLoaded = track;\n      if (trackId !== currentTrackId) {\n        return;\n      }\n      if (!this.startFragRequested && (this.mainDetails || !newDetails.live)) {\n        this.setStartPosition(this.mainDetails || newDetails, sliding);\n      }\n\n      // trigger handler right now\n      this.tick();\n\n      // If playlist is misaligned because of bad PDT or drift, delete details to resync with main on reload\n      if (newDetails.live && !this.fragCurrent && this.media && this.state === State.IDLE) {\n        var foundFrag = findFragmentByPTS(null, newDetails.fragments, this.media.currentTime, 0);\n        if (!foundFrag) {\n          this.warn('Subtitle playlist not aligned with playback');\n          track.details = undefined;\n        }\n      }\n    };\n    _proto._handleFragmentLoadComplete = function _handleFragmentLoadComplete(fragLoadedData) {\n      var _this3 = this;\n      var frag = fragLoadedData.frag,\n        payload = fragLoadedData.payload;\n      var decryptData = frag.decryptdata;\n      var hls = this.hls;\n      if (this.fragContextChanged(frag)) {\n        return;\n      }\n      // check to see if the payload needs to be decrypted\n      if (payload && payload.byteLength > 0 && decryptData != null && decryptData.key && decryptData.iv && decryptData.method === 'AES-128') {\n        var startTime = performance.now();\n        // decrypt the subtitles\n        this.decrypter.decrypt(new Uint8Array(payload), decryptData.key.buffer, decryptData.iv.buffer).catch(function (err) {\n          hls.trigger(Events.ERROR, {\n            type: ErrorTypes.MEDIA_ERROR,\n            details: ErrorDetails.FRAG_DECRYPT_ERROR,\n            fatal: false,\n            error: err,\n            reason: err.message,\n            frag: frag\n          });\n          throw err;\n        }).then(function (decryptedData) {\n          var endTime = performance.now();\n          hls.trigger(Events.FRAG_DECRYPTED, {\n            frag: frag,\n            payload: decryptedData,\n            stats: {\n              tstart: startTime,\n              tdecrypt: endTime\n            }\n          });\n        }).catch(function (err) {\n          _this3.warn(err.name + \": \" + err.message);\n          _this3.state = State.IDLE;\n        });\n      }\n    };\n    _proto.doTick = function doTick() {\n      if (!this.media) {\n        this.state = State.IDLE;\n        return;\n      }\n      if (this.state === State.IDLE) {\n        var currentTrackId = this.currentTrackId,\n          levels = this.levels;\n        var track = levels == null ? void 0 : levels[currentTrackId];\n        if (!track || !levels.length || !track.details) {\n          return;\n        }\n        var config = this.config;\n        var currentTime = this.getLoadPosition();\n        var bufferedInfo = BufferHelper.bufferedInfo(this.tracksBuffered[this.currentTrackId] || [], currentTime, config.maxBufferHole);\n        var targetBufferTime = bufferedInfo.end,\n          bufferLen = bufferedInfo.len;\n        var mainBufferInfo = this.getFwdBufferInfo(this.media, PlaylistLevelType.MAIN);\n        var trackDetails = track.details;\n        var maxBufLen = this.getMaxBufferLength(mainBufferInfo == null ? void 0 : mainBufferInfo.len) + trackDetails.levelTargetDuration;\n        if (bufferLen > maxBufLen) {\n          return;\n        }\n        var fragments = trackDetails.fragments;\n        var fragLen = fragments.length;\n        var end = trackDetails.edge;\n        var foundFrag = null;\n        var fragPrevious = this.fragPrevious;\n        if (targetBufferTime < end) {\n          var tolerance = config.maxFragLookUpTolerance;\n          var lookupTolerance = targetBufferTime > end - tolerance ? 0 : tolerance;\n          foundFrag = findFragmentByPTS(fragPrevious, fragments, Math.max(fragments[0].start, targetBufferTime), lookupTolerance);\n          if (!foundFrag && fragPrevious && fragPrevious.start < fragments[0].start) {\n            foundFrag = fragments[0];\n          }\n        } else {\n          foundFrag = fragments[fragLen - 1];\n        }\n        if (!foundFrag) {\n          return;\n        }\n        foundFrag = this.mapToInitFragWhenRequired(foundFrag);\n        if (foundFrag.sn !== 'initSegment') {\n          // Load earlier fragment in same discontinuity to make up for misaligned playlists and cues that extend beyond end of segment\n          var curSNIdx = foundFrag.sn - trackDetails.startSN;\n          var prevFrag = fragments[curSNIdx - 1];\n          if (prevFrag && prevFrag.cc === foundFrag.cc && this.fragmentTracker.getState(prevFrag) === FragmentState.NOT_LOADED) {\n            foundFrag = prevFrag;\n          }\n        }\n        if (this.fragmentTracker.getState(foundFrag) === FragmentState.NOT_LOADED) {\n          // only load if fragment is not loaded\n          this.loadFragment(foundFrag, track, targetBufferTime);\n        }\n      }\n    };\n    _proto.getMaxBufferLength = function getMaxBufferLength(mainBufferLength) {\n      var maxConfigBuffer = _BaseStreamController.prototype.getMaxBufferLength.call(this);\n      if (!mainBufferLength) {\n        return maxConfigBuffer;\n      }\n      return Math.max(maxConfigBuffer, mainBufferLength);\n    };\n    _proto.loadFragment = function loadFragment(frag, level, targetBufferTime) {\n      this.fragCurrent = frag;\n      if (frag.sn === 'initSegment') {\n        this._loadInitSegment(frag, level);\n      } else {\n        this.startFragRequested = true;\n        _BaseStreamController.prototype.loadFragment.call(this, frag, level, targetBufferTime);\n      }\n    };\n    _createClass(SubtitleStreamController, [{\n      key: \"mediaBufferTimeRanges\",\n      get: function get() {\n        return new BufferableInstance(this.tracksBuffered[this.currentTrackId] || []);\n      }\n    }]);\n    return SubtitleStreamController;\n  }(BaseStreamController);\n  var BufferableInstance = function BufferableInstance(timeranges) {\n    this.buffered = void 0;\n    var getRange = function getRange(name, index, length) {\n      index = index >>> 0;\n      if (index > length - 1) {\n        throw new DOMException(\"Failed to execute '\" + name + \"' on 'TimeRanges': The index provided (\" + index + \") is greater than the maximum bound (\" + length + \")\");\n      }\n      return timeranges[index][name];\n    };\n    this.buffered = {\n      get length() {\n        return timeranges.length;\n      },\n      end: function end(index) {\n        return getRange('end', index, timeranges.length);\n      },\n      start: function start(index) {\n        return getRange('start', index, timeranges.length);\n      }\n    };\n  };\n\n  var SubtitleTrackController = /*#__PURE__*/function (_BasePlaylistControll) {\n    _inheritsLoose(SubtitleTrackController, _BasePlaylistControll);\n    function SubtitleTrackController(hls) {\n      var _this;\n      _this = _BasePlaylistControll.call(this, hls, '[subtitle-track-controller]') || this;\n      _this.media = null;\n      _this.tracks = [];\n      _this.groupIds = null;\n      _this.tracksInGroup = [];\n      _this.trackId = -1;\n      _this.currentTrack = null;\n      _this.selectDefaultTrack = true;\n      _this.queuedDefaultTrack = -1;\n      _this.asyncPollTrackChange = function () {\n        return _this.pollTrackChange(0);\n      };\n      _this.useTextTrackPolling = false;\n      _this.subtitlePollingInterval = -1;\n      _this._subtitleDisplay = true;\n      _this.onTextTracksChanged = function () {\n        if (!_this.useTextTrackPolling) {\n          self.clearInterval(_this.subtitlePollingInterval);\n        }\n        // Media is undefined when switching streams via loadSource()\n        if (!_this.media || !_this.hls.config.renderTextTracksNatively) {\n          return;\n        }\n        var textTrack = null;\n        var tracks = filterSubtitleTracks(_this.media.textTracks);\n        for (var i = 0; i < tracks.length; i++) {\n          if (tracks[i].mode === 'hidden') {\n            // Do not break in case there is a following track with showing.\n            textTrack = tracks[i];\n          } else if (tracks[i].mode === 'showing') {\n            textTrack = tracks[i];\n            break;\n          }\n        }\n\n        // Find internal track index for TextTrack\n        var trackId = _this.findTrackForTextTrack(textTrack);\n        if (_this.subtitleTrack !== trackId) {\n          _this.setSubtitleTrack(trackId);\n        }\n      };\n      _this.registerListeners();\n      return _this;\n    }\n    var _proto = SubtitleTrackController.prototype;\n    _proto.destroy = function destroy() {\n      this.unregisterListeners();\n      this.tracks.length = 0;\n      this.tracksInGroup.length = 0;\n      this.currentTrack = null;\n      this.onTextTracksChanged = this.asyncPollTrackChange = null;\n      _BasePlaylistControll.prototype.destroy.call(this);\n    };\n    _proto.registerListeners = function registerListeners() {\n      var hls = this.hls;\n      hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n      hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);\n      hls.on(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n      hls.on(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);\n      hls.on(Events.ERROR, this.onError, this);\n    };\n    _proto.unregisterListeners = function unregisterListeners() {\n      var hls = this.hls;\n      hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n      hls.off(Events.LEVEL_LOADING, this.onLevelLoading, this);\n      hls.off(Events.LEVEL_SWITCHING, this.onLevelSwitching, this);\n      hls.off(Events.SUBTITLE_TRACK_LOADED, this.onSubtitleTrackLoaded, this);\n      hls.off(Events.ERROR, this.onError, this);\n    }\n\n    // Listen for subtitle track change, then extract the current track ID.\n    ;\n    _proto.onMediaAttached = function onMediaAttached(event, data) {\n      this.media = data.media;\n      if (!this.media) {\n        return;\n      }\n      if (this.queuedDefaultTrack > -1) {\n        this.subtitleTrack = this.queuedDefaultTrack;\n        this.queuedDefaultTrack = -1;\n      }\n      this.useTextTrackPolling = !(this.media.textTracks && 'onchange' in this.media.textTracks);\n      if (this.useTextTrackPolling) {\n        this.pollTrackChange(500);\n      } else {\n        this.media.textTracks.addEventListener('change', this.asyncPollTrackChange);\n      }\n    };\n    _proto.pollTrackChange = function pollTrackChange(timeout) {\n      self.clearInterval(this.subtitlePollingInterval);\n      this.subtitlePollingInterval = self.setInterval(this.onTextTracksChanged, timeout);\n    };\n    _proto.onMediaDetaching = function onMediaDetaching() {\n      if (!this.media) {\n        return;\n      }\n      self.clearInterval(this.subtitlePollingInterval);\n      if (!this.useTextTrackPolling) {\n        this.media.textTracks.removeEventListener('change', this.asyncPollTrackChange);\n      }\n      if (this.trackId > -1) {\n        this.queuedDefaultTrack = this.trackId;\n      }\n      var textTracks = filterSubtitleTracks(this.media.textTracks);\n      // Clear loaded cues on media detachment from tracks\n      textTracks.forEach(function (track) {\n        clearCurrentCues(track);\n      });\n      // Disable all subtitle tracks before detachment so when reattached only tracks in that content are enabled.\n      this.subtitleTrack = -1;\n      this.media = null;\n    };\n    _proto.onManifestLoading = function onManifestLoading() {\n      this.tracks = [];\n      this.groupIds = null;\n      this.tracksInGroup = [];\n      this.trackId = -1;\n      this.currentTrack = null;\n      this.selectDefaultTrack = true;\n    }\n\n    // Fired whenever a new manifest is loaded.\n    ;\n    _proto.onManifestParsed = function onManifestParsed(event, data) {\n      this.tracks = data.subtitleTracks;\n    };\n    _proto.onSubtitleTrackLoaded = function onSubtitleTrackLoaded(event, data) {\n      var id = data.id,\n        groupId = data.groupId,\n        details = data.details;\n      var trackInActiveGroup = this.tracksInGroup[id];\n      if (!trackInActiveGroup || trackInActiveGroup.groupId !== groupId) {\n        this.warn(\"Subtitle track with id:\" + id + \" and group:\" + groupId + \" not found in active group \" + (trackInActiveGroup == null ? void 0 : trackInActiveGroup.groupId));\n        return;\n      }\n      var curDetails = trackInActiveGroup.details;\n      trackInActiveGroup.details = data.details;\n      this.log(\"Subtitle track \" + id + \" \\\"\" + trackInActiveGroup.name + \"\\\" lang:\" + trackInActiveGroup.lang + \" group:\" + groupId + \" loaded [\" + details.startSN + \"-\" + details.endSN + \"]\");\n      if (id === this.trackId) {\n        this.playlistLoaded(id, data, curDetails);\n      }\n    };\n    _proto.onLevelLoading = function onLevelLoading(event, data) {\n      this.switchLevel(data.level);\n    };\n    _proto.onLevelSwitching = function onLevelSwitching(event, data) {\n      this.switchLevel(data.level);\n    };\n    _proto.switchLevel = function switchLevel(levelIndex) {\n      var levelInfo = this.hls.levels[levelIndex];\n      if (!levelInfo) {\n        return;\n      }\n      var subtitleGroups = levelInfo.subtitleGroups || null;\n      var currentGroups = this.groupIds;\n      var currentTrack = this.currentTrack;\n      if (!subtitleGroups || (currentGroups == null ? void 0 : currentGroups.length) !== (subtitleGroups == null ? void 0 : subtitleGroups.length) || subtitleGroups != null && subtitleGroups.some(function (groupId) {\n        return (currentGroups == null ? void 0 : currentGroups.indexOf(groupId)) === -1;\n      })) {\n        this.groupIds = subtitleGroups;\n        this.trackId = -1;\n        this.currentTrack = null;\n        var subtitleTracks = this.tracks.filter(function (track) {\n          return !subtitleGroups || subtitleGroups.indexOf(track.groupId) !== -1;\n        });\n        if (subtitleTracks.length) {\n          // Disable selectDefaultTrack if there are no default tracks\n          if (this.selectDefaultTrack && !subtitleTracks.some(function (track) {\n            return track.default;\n          })) {\n            this.selectDefaultTrack = false;\n          }\n          // track.id should match hls.audioTracks index\n          subtitleTracks.forEach(function (track, i) {\n            track.id = i;\n          });\n        } else if (!currentTrack && !this.tracksInGroup.length) {\n          // Do not dispatch SUBTITLE_TRACKS_UPDATED when there were and are no tracks\n          return;\n        }\n        this.tracksInGroup = subtitleTracks;\n\n        // Find preferred track\n        var subtitlePreference = this.hls.config.subtitlePreference;\n        if (!currentTrack && subtitlePreference) {\n          this.selectDefaultTrack = false;\n          var groupIndex = findMatchingOption(subtitlePreference, subtitleTracks);\n          if (groupIndex > -1) {\n            currentTrack = subtitleTracks[groupIndex];\n          } else {\n            var allIndex = findMatchingOption(subtitlePreference, this.tracks);\n            currentTrack = this.tracks[allIndex];\n          }\n        }\n\n        // Select initial track\n        var trackId = this.findTrackId(currentTrack);\n        if (trackId === -1 && currentTrack) {\n          trackId = this.findTrackId(null);\n        }\n\n        // Dispatch events and load track if needed\n        var subtitleTracksUpdated = {\n          subtitleTracks: subtitleTracks\n        };\n        this.log(\"Updating subtitle tracks, \" + subtitleTracks.length + \" track(s) found in \\\"\" + (subtitleGroups == null ? void 0 : subtitleGroups.join(',')) + \"\\\" group-id\");\n        this.hls.trigger(Events.SUBTITLE_TRACKS_UPDATED, subtitleTracksUpdated);\n        if (trackId !== -1 && this.trackId === -1) {\n          this.setSubtitleTrack(trackId);\n        }\n      } else if (this.shouldReloadPlaylist(currentTrack)) {\n        // Retry playlist loading if no playlist is or has been loaded yet\n        this.setSubtitleTrack(this.trackId);\n      }\n    };\n    _proto.findTrackId = function findTrackId(currentTrack) {\n      var tracks = this.tracksInGroup;\n      var selectDefault = this.selectDefaultTrack;\n      for (var i = 0; i < tracks.length; i++) {\n        var track = tracks[i];\n        if (selectDefault && !track.default || !selectDefault && !currentTrack) {\n          continue;\n        }\n        if (!currentTrack || matchesOption(track, currentTrack)) {\n          return i;\n        }\n      }\n      if (currentTrack) {\n        for (var _i = 0; _i < tracks.length; _i++) {\n          var _track = tracks[_i];\n          if (mediaAttributesIdentical(currentTrack.attrs, _track.attrs, ['LANGUAGE', 'ASSOC-LANGUAGE', 'CHARACTERISTICS'])) {\n            return _i;\n          }\n        }\n        for (var _i2 = 0; _i2 < tracks.length; _i2++) {\n          var _track2 = tracks[_i2];\n          if (mediaAttributesIdentical(currentTrack.attrs, _track2.attrs, ['LANGUAGE'])) {\n            return _i2;\n          }\n        }\n      }\n      return -1;\n    };\n    _proto.findTrackForTextTrack = function findTrackForTextTrack(textTrack) {\n      if (textTrack) {\n        var tracks = this.tracksInGroup;\n        for (var i = 0; i < tracks.length; i++) {\n          var track = tracks[i];\n          if (subtitleTrackMatchesTextTrack(track, textTrack)) {\n            return i;\n          }\n        }\n      }\n      return -1;\n    };\n    _proto.onError = function onError(event, data) {\n      if (data.fatal || !data.context) {\n        return;\n      }\n      if (data.context.type === PlaylistContextType.SUBTITLE_TRACK && data.context.id === this.trackId && (!this.groupIds || this.groupIds.indexOf(data.context.groupId) !== -1)) {\n        this.checkRetry(data);\n      }\n    };\n    _proto.setSubtitleOption = function setSubtitleOption(subtitleOption) {\n      this.hls.config.subtitlePreference = subtitleOption;\n      if (subtitleOption) {\n        var allSubtitleTracks = this.allSubtitleTracks;\n        this.selectDefaultTrack = false;\n        if (allSubtitleTracks.length) {\n          // First see if current option matches (no switch op)\n          var currentTrack = this.currentTrack;\n          if (currentTrack && matchesOption(subtitleOption, currentTrack)) {\n            return currentTrack;\n          }\n          // Find option in current group\n          var groupIndex = findMatchingOption(subtitleOption, this.tracksInGroup);\n          if (groupIndex > -1) {\n            var track = this.tracksInGroup[groupIndex];\n            this.setSubtitleTrack(groupIndex);\n            return track;\n          } else if (currentTrack) {\n            // If this is not the initial selection return null\n            // option should have matched one in active group\n            return null;\n          } else {\n            // Find the option in all tracks for initial selection\n            var allIndex = findMatchingOption(subtitleOption, allSubtitleTracks);\n            if (allIndex > -1) {\n              return allSubtitleTracks[allIndex];\n            }\n          }\n        }\n      }\n      return null;\n    };\n    _proto.loadPlaylist = function loadPlaylist(hlsUrlParameters) {\n      _BasePlaylistControll.prototype.loadPlaylist.call(this);\n      var currentTrack = this.currentTrack;\n      if (this.shouldLoadPlaylist(currentTrack) && currentTrack) {\n        var id = currentTrack.id;\n        var groupId = currentTrack.groupId;\n        var url = currentTrack.url;\n        if (hlsUrlParameters) {\n          try {\n            url = hlsUrlParameters.addDirectives(url);\n          } catch (error) {\n            this.warn(\"Could not construct new URL with HLS Delivery Directives: \" + error);\n          }\n        }\n        this.log(\"Loading subtitle playlist for id \" + id);\n        this.hls.trigger(Events.SUBTITLE_TRACK_LOADING, {\n          url: url,\n          id: id,\n          groupId: groupId,\n          deliveryDirectives: hlsUrlParameters || null\n        });\n      }\n    }\n\n    /**\n     * Disables the old subtitleTrack and sets current mode on the next subtitleTrack.\n     * This operates on the DOM textTracks.\n     * A value of -1 will disable all subtitle tracks.\n     */;\n    _proto.toggleTrackModes = function toggleTrackModes() {\n      var media = this.media;\n      if (!media) {\n        return;\n      }\n      var textTracks = filterSubtitleTracks(media.textTracks);\n      var currentTrack = this.currentTrack;\n      var nextTrack;\n      if (currentTrack) {\n        nextTrack = textTracks.filter(function (textTrack) {\n          return subtitleTrackMatchesTextTrack(currentTrack, textTrack);\n        })[0];\n        if (!nextTrack) {\n          this.warn(\"Unable to find subtitle TextTrack with name \\\"\" + currentTrack.name + \"\\\" and language \\\"\" + currentTrack.lang + \"\\\"\");\n        }\n      }\n      [].slice.call(textTracks).forEach(function (track) {\n        if (track.mode !== 'disabled' && track !== nextTrack) {\n          track.mode = 'disabled';\n        }\n      });\n      if (nextTrack) {\n        var mode = this.subtitleDisplay ? 'showing' : 'hidden';\n        if (nextTrack.mode !== mode) {\n          nextTrack.mode = mode;\n        }\n      }\n    }\n\n    /**\n     * This method is responsible for validating the subtitle index and periodically reloading if live.\n     * Dispatches the SUBTITLE_TRACK_SWITCH event, which instructs the subtitle-stream-controller to load the selected track.\n     */;\n    _proto.setSubtitleTrack = function setSubtitleTrack(newId) {\n      var tracks = this.tracksInGroup;\n\n      // setting this.subtitleTrack will trigger internal logic\n      // if media has not been attached yet, it will fail\n      // we keep a reference to the default track id\n      // and we'll set subtitleTrack when onMediaAttached is triggered\n      if (!this.media) {\n        this.queuedDefaultTrack = newId;\n        return;\n      }\n\n      // exit if track id as already set or invalid\n      if (newId < -1 || newId >= tracks.length || !isFiniteNumber(newId)) {\n        this.warn(\"Invalid subtitle track id: \" + newId);\n        return;\n      }\n\n      // stopping live reloading timer if any\n      this.clearTimer();\n      this.selectDefaultTrack = false;\n      var lastTrack = this.currentTrack;\n      var track = tracks[newId] || null;\n      this.trackId = newId;\n      this.currentTrack = track;\n      this.toggleTrackModes();\n      if (!track) {\n        // switch to -1\n        this.hls.trigger(Events.SUBTITLE_TRACK_SWITCH, {\n          id: newId\n        });\n        return;\n      }\n      var trackLoaded = !!track.details && !track.details.live;\n      if (newId === this.trackId && track === lastTrack && trackLoaded) {\n        return;\n      }\n      this.log(\"Switching to subtitle-track \" + newId + (track ? \" \\\"\" + track.name + \"\\\" lang:\" + track.lang + \" group:\" + track.groupId : ''));\n      var id = track.id,\n        _track$groupId = track.groupId,\n        groupId = _track$groupId === void 0 ? '' : _track$groupId,\n        name = track.name,\n        type = track.type,\n        url = track.url;\n      this.hls.trigger(Events.SUBTITLE_TRACK_SWITCH, {\n        id: id,\n        groupId: groupId,\n        name: name,\n        type: type,\n        url: url\n      });\n      var hlsUrlParameters = this.switchParams(track.url, lastTrack == null ? void 0 : lastTrack.details, track.details);\n      this.loadPlaylist(hlsUrlParameters);\n    };\n    _createClass(SubtitleTrackController, [{\n      key: \"subtitleDisplay\",\n      get: function get() {\n        return this._subtitleDisplay;\n      },\n      set: function set(value) {\n        this._subtitleDisplay = value;\n        if (this.trackId > -1) {\n          this.toggleTrackModes();\n        }\n      }\n    }, {\n      key: \"allSubtitleTracks\",\n      get: function get() {\n        return this.tracks;\n      }\n\n      /** get alternate subtitle tracks list from playlist **/\n    }, {\n      key: \"subtitleTracks\",\n      get: function get() {\n        return this.tracksInGroup;\n      }\n\n      /** get/set index of the selected subtitle track (based on index in subtitle track lists) **/\n    }, {\n      key: \"subtitleTrack\",\n      get: function get() {\n        return this.trackId;\n      },\n      set: function set(newId) {\n        this.selectDefaultTrack = false;\n        this.setSubtitleTrack(newId);\n      }\n    }]);\n    return SubtitleTrackController;\n  }(BasePlaylistController);\n\n  var BufferOperationQueue = /*#__PURE__*/function () {\n    function BufferOperationQueue(sourceBufferReference) {\n      this.buffers = void 0;\n      this.queues = {\n        video: [],\n        audio: [],\n        audiovideo: []\n      };\n      this.buffers = sourceBufferReference;\n    }\n    var _proto = BufferOperationQueue.prototype;\n    _proto.append = function append(operation, type, pending) {\n      var queue = this.queues[type];\n      queue.push(operation);\n      if (queue.length === 1 && !pending) {\n        this.executeNext(type);\n      }\n    };\n    _proto.insertAbort = function insertAbort(operation, type) {\n      var queue = this.queues[type];\n      queue.unshift(operation);\n      this.executeNext(type);\n    };\n    _proto.appendBlocker = function appendBlocker(type) {\n      var execute;\n      var promise = new Promise(function (resolve) {\n        execute = resolve;\n      });\n      var operation = {\n        execute: execute,\n        onStart: function onStart() {},\n        onComplete: function onComplete() {},\n        onError: function onError() {}\n      };\n      this.append(operation, type);\n      return promise;\n    };\n    _proto.executeNext = function executeNext(type) {\n      var queue = this.queues[type];\n      if (queue.length) {\n        var operation = queue[0];\n        try {\n          // Operations are expected to result in an 'updateend' event being fired. If not, the queue will lock. Operations\n          // which do not end with this event must call _onSBUpdateEnd manually\n          operation.execute();\n        } catch (error) {\n          logger.warn(\"[buffer-operation-queue]: Exception executing \\\"\" + type + \"\\\" SourceBuffer operation: \" + error);\n          operation.onError(error);\n\n          // Only shift the current operation off, otherwise the updateend handler will do this for us\n          var sb = this.buffers[type];\n          if (!(sb != null && sb.updating)) {\n            this.shiftAndExecuteNext(type);\n          }\n        }\n      }\n    };\n    _proto.shiftAndExecuteNext = function shiftAndExecuteNext(type) {\n      this.queues[type].shift();\n      this.executeNext(type);\n    };\n    _proto.current = function current(type) {\n      return this.queues[type][0];\n    };\n    return BufferOperationQueue;\n  }();\n\n  var VIDEO_CODEC_PROFILE_REPLACE = /(avc[1234]|hvc1|hev1|dvh[1e]|vp09|av01)(?:\\.[^.,]+)+/;\n  var BufferController = /*#__PURE__*/function () {\n    function BufferController(hls) {\n      var _this = this;\n      // The level details used to determine duration, target-duration and live\n      this.details = null;\n      // cache the self generated object url to detect hijack of video tag\n      this._objectUrl = null;\n      // A queue of buffer operations which require the SourceBuffer to not be updating upon execution\n      this.operationQueue = void 0;\n      // References to event listeners for each SourceBuffer, so that they can be referenced for event removal\n      this.listeners = void 0;\n      this.hls = void 0;\n      // The number of BUFFER_CODEC events received before any sourceBuffers are created\n      this.bufferCodecEventsExpected = 0;\n      // The total number of BUFFER_CODEC events received\n      this._bufferCodecEventsTotal = 0;\n      // A reference to the attached media element\n      this.media = null;\n      // A reference to the active media source\n      this.mediaSource = null;\n      // Last MP3 audio chunk appended\n      this.lastMpegAudioChunk = null;\n      this.appendSource = void 0;\n      // counters\n      this.appendErrors = {\n        audio: 0,\n        video: 0,\n        audiovideo: 0\n      };\n      this.tracks = {};\n      this.pendingTracks = {};\n      this.sourceBuffer = void 0;\n      this.log = void 0;\n      this.warn = void 0;\n      this.error = void 0;\n      this._onEndStreaming = function (event) {\n        if (!_this.hls) {\n          return;\n        }\n        _this.hls.pauseBuffering();\n      };\n      this._onStartStreaming = function (event) {\n        if (!_this.hls) {\n          return;\n        }\n        _this.hls.resumeBuffering();\n      };\n      // Keep as arrow functions so that we can directly reference these functions directly as event listeners\n      this._onMediaSourceOpen = function () {\n        var media = _this.media,\n          mediaSource = _this.mediaSource;\n        _this.log('Media source opened');\n        if (media) {\n          media.removeEventListener('emptied', _this._onMediaEmptied);\n          _this.updateMediaElementDuration();\n          _this.hls.trigger(Events.MEDIA_ATTACHED, {\n            media: media,\n            mediaSource: mediaSource\n          });\n        }\n        if (mediaSource) {\n          // once received, don't listen anymore to sourceopen event\n          mediaSource.removeEventListener('sourceopen', _this._onMediaSourceOpen);\n        }\n        _this.checkPendingTracks();\n      };\n      this._onMediaSourceClose = function () {\n        _this.log('Media source closed');\n      };\n      this._onMediaSourceEnded = function () {\n        _this.log('Media source ended');\n      };\n      this._onMediaEmptied = function () {\n        var mediaSrc = _this.mediaSrc,\n          _objectUrl = _this._objectUrl;\n        if (mediaSrc !== _objectUrl) {\n          logger.error(\"Media element src was set while attaching MediaSource (\" + _objectUrl + \" > \" + mediaSrc + \")\");\n        }\n      };\n      this.hls = hls;\n      var logPrefix = '[buffer-controller]';\n      this.appendSource = isManagedMediaSource(getMediaSource(hls.config.preferManagedMediaSource));\n      this.log = logger.log.bind(logger, logPrefix);\n      this.warn = logger.warn.bind(logger, logPrefix);\n      this.error = logger.error.bind(logger, logPrefix);\n      this._initSourceBuffer();\n      this.registerListeners();\n    }\n    var _proto = BufferController.prototype;\n    _proto.hasSourceTypes = function hasSourceTypes() {\n      return this.getSourceBufferTypes().length > 0 || Object.keys(this.pendingTracks).length > 0;\n    };\n    _proto.destroy = function destroy() {\n      this.unregisterListeners();\n      this.details = null;\n      this.lastMpegAudioChunk = null;\n      // @ts-ignore\n      this.hls = null;\n    };\n    _proto.registerListeners = function registerListeners() {\n      var hls = this.hls;\n      hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n      hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n      hls.on(Events.BUFFER_RESET, this.onBufferReset, this);\n      hls.on(Events.BUFFER_APPENDING, this.onBufferAppending, this);\n      hls.on(Events.BUFFER_CODECS, this.onBufferCodecs, this);\n      hls.on(Events.BUFFER_EOS, this.onBufferEos, this);\n      hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n      hls.on(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n      hls.on(Events.FRAG_PARSED, this.onFragParsed, this);\n      hls.on(Events.FRAG_CHANGED, this.onFragChanged, this);\n    };\n    _proto.unregisterListeners = function unregisterListeners() {\n      var hls = this.hls;\n      hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n      hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n      hls.off(Events.BUFFER_RESET, this.onBufferReset, this);\n      hls.off(Events.BUFFER_APPENDING, this.onBufferAppending, this);\n      hls.off(Events.BUFFER_CODECS, this.onBufferCodecs, this);\n      hls.off(Events.BUFFER_EOS, this.onBufferEos, this);\n      hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n      hls.off(Events.LEVEL_UPDATED, this.onLevelUpdated, this);\n      hls.off(Events.FRAG_PARSED, this.onFragParsed, this);\n      hls.off(Events.FRAG_CHANGED, this.onFragChanged, this);\n    };\n    _proto._initSourceBuffer = function _initSourceBuffer() {\n      this.sourceBuffer = {};\n      this.operationQueue = new BufferOperationQueue(this.sourceBuffer);\n      this.listeners = {\n        audio: [],\n        video: [],\n        audiovideo: []\n      };\n      this.appendErrors = {\n        audio: 0,\n        video: 0,\n        audiovideo: 0\n      };\n      this.lastMpegAudioChunk = null;\n    };\n    _proto.onManifestLoading = function onManifestLoading() {\n      this.bufferCodecEventsExpected = this._bufferCodecEventsTotal = 0;\n      this.details = null;\n    };\n    _proto.onManifestParsed = function onManifestParsed(event, data) {\n      // in case of alt audio 2 BUFFER_CODECS events will be triggered, one per stream controller\n      // sourcebuffers will be created all at once when the expected nb of tracks will be reached\n      // in case alt audio is not used, only one BUFFER_CODEC event will be fired from main stream controller\n      // it will contain the expected nb of source buffers, no need to compute it\n      var codecEvents = 2;\n      if (data.audio && !data.video || !data.altAudio || !true) {\n        codecEvents = 1;\n      }\n      this.bufferCodecEventsExpected = this._bufferCodecEventsTotal = codecEvents;\n      this.log(this.bufferCodecEventsExpected + \" bufferCodec event(s) expected\");\n    };\n    _proto.onMediaAttaching = function onMediaAttaching(event, data) {\n      var media = this.media = data.media;\n      var MediaSource = getMediaSource(this.appendSource);\n      if (media && MediaSource) {\n        var _ms$constructor;\n        var ms = this.mediaSource = new MediaSource();\n        this.log(\"created media source: \" + ((_ms$constructor = ms.constructor) == null ? void 0 : _ms$constructor.name));\n        // MediaSource listeners are arrow functions with a lexical scope, and do not need to be bound\n        ms.addEventListener('sourceopen', this._onMediaSourceOpen);\n        ms.addEventListener('sourceended', this._onMediaSourceEnded);\n        ms.addEventListener('sourceclose', this._onMediaSourceClose);\n        if (this.appendSource) {\n          ms.addEventListener('startstreaming', this._onStartStreaming);\n          ms.addEventListener('endstreaming', this._onEndStreaming);\n        }\n\n        // cache the locally generated object url\n        var objectUrl = this._objectUrl = self.URL.createObjectURL(ms);\n        // link video and media Source\n        if (this.appendSource) {\n          try {\n            media.removeAttribute('src');\n            // ManagedMediaSource will not open without disableRemotePlayback set to false or source alternatives\n            var MMS = self.ManagedMediaSource;\n            media.disableRemotePlayback = media.disableRemotePlayback || MMS && ms instanceof MMS;\n            removeSourceChildren(media);\n            addSource(media, objectUrl);\n            media.load();\n          } catch (error) {\n            media.src = objectUrl;\n          }\n        } else {\n          media.src = objectUrl;\n        }\n        media.addEventListener('emptied', this._onMediaEmptied);\n      }\n    };\n    _proto.onMediaDetaching = function onMediaDetaching() {\n      var media = this.media,\n        mediaSource = this.mediaSource,\n        _objectUrl = this._objectUrl;\n      if (mediaSource) {\n        this.log('media source detaching');\n        if (mediaSource.readyState === 'open') {\n          try {\n            // endOfStream could trigger exception if any sourcebuffer is in updating state\n            // we don't really care about checking sourcebuffer state here,\n            // as we are anyway detaching the MediaSource\n            // let's just avoid this exception to propagate\n            mediaSource.endOfStream();\n          } catch (err) {\n            this.warn(\"onMediaDetaching: \" + err.message + \" while calling endOfStream\");\n          }\n        }\n        // Clean up the SourceBuffers by invoking onBufferReset\n        this.onBufferReset();\n        mediaSource.removeEventListener('sourceopen', this._onMediaSourceOpen);\n        mediaSource.removeEventListener('sourceended', this._onMediaSourceEnded);\n        mediaSource.removeEventListener('sourceclose', this._onMediaSourceClose);\n        if (this.appendSource) {\n          mediaSource.removeEventListener('startstreaming', this._onStartStreaming);\n          mediaSource.removeEventListener('endstreaming', this._onEndStreaming);\n        }\n\n        // Detach properly the MediaSource from the HTMLMediaElement as\n        // suggested in https://github.com/w3c/media-source/issues/53.\n        if (media) {\n          media.removeEventListener('emptied', this._onMediaEmptied);\n          if (_objectUrl) {\n            self.URL.revokeObjectURL(_objectUrl);\n          }\n\n          // clean up video tag src only if it's our own url. some external libraries might\n          // hijack the video tag and change its 'src' without destroying the Hls instance first\n          if (this.mediaSrc === _objectUrl) {\n            media.removeAttribute('src');\n            if (this.appendSource) {\n              removeSourceChildren(media);\n            }\n            media.load();\n          } else {\n            this.warn('media|source.src was changed by a third party - skip cleanup');\n          }\n        }\n        this.mediaSource = null;\n        this.media = null;\n        this._objectUrl = null;\n        this.bufferCodecEventsExpected = this._bufferCodecEventsTotal;\n        this.pendingTracks = {};\n        this.tracks = {};\n      }\n      this.hls.trigger(Events.MEDIA_DETACHED, undefined);\n    };\n    _proto.onBufferReset = function onBufferReset() {\n      var _this2 = this;\n      this.getSourceBufferTypes().forEach(function (type) {\n        _this2.resetBuffer(type);\n      });\n      this._initSourceBuffer();\n    };\n    _proto.resetBuffer = function resetBuffer(type) {\n      var sb = this.sourceBuffer[type];\n      try {\n        if (sb) {\n          var _this$mediaSource;\n          this.removeBufferListeners(type);\n          // Synchronously remove the SB from the map before the next call in order to prevent an async function from\n          // accessing it\n          this.sourceBuffer[type] = undefined;\n          if ((_this$mediaSource = this.mediaSource) != null && _this$mediaSource.sourceBuffers.length) {\n            this.mediaSource.removeSourceBuffer(sb);\n          }\n        }\n      } catch (err) {\n        this.warn(\"onBufferReset \" + type, err);\n      }\n    };\n    _proto.onBufferCodecs = function onBufferCodecs(event, data) {\n      var _this3 = this;\n      var sourceBufferCount = this.getSourceBufferTypes().length;\n      var trackNames = Object.keys(data);\n      trackNames.forEach(function (trackName) {\n        if (sourceBufferCount) {\n          // check if SourceBuffer codec needs to change\n          var track = _this3.tracks[trackName];\n          if (track && typeof track.buffer.changeType === 'function') {\n            var _trackCodec;\n            var _data$trackName = data[trackName],\n              id = _data$trackName.id,\n              codec = _data$trackName.codec,\n              levelCodec = _data$trackName.levelCodec,\n              container = _data$trackName.container,\n              metadata = _data$trackName.metadata;\n            var currentCodecFull = pickMostCompleteCodecName(track.codec, track.levelCodec);\n            var currentCodec = currentCodecFull == null ? void 0 : currentCodecFull.replace(VIDEO_CODEC_PROFILE_REPLACE, '$1');\n            var trackCodec = pickMostCompleteCodecName(codec, levelCodec);\n            var nextCodec = (_trackCodec = trackCodec) == null ? void 0 : _trackCodec.replace(VIDEO_CODEC_PROFILE_REPLACE, '$1');\n            if (trackCodec && currentCodec !== nextCodec) {\n              if (trackName.slice(0, 5) === 'audio') {\n                trackCodec = getCodecCompatibleName(trackCodec, _this3.appendSource);\n              }\n              var mimeType = container + \";codecs=\" + trackCodec;\n              _this3.appendChangeType(trackName, mimeType);\n              _this3.log(\"switching codec \" + currentCodecFull + \" to \" + trackCodec);\n              _this3.tracks[trackName] = {\n                buffer: track.buffer,\n                codec: codec,\n                container: container,\n                levelCodec: levelCodec,\n                metadata: metadata,\n                id: id\n              };\n            }\n          }\n        } else {\n          // if source buffer(s) not created yet, appended buffer tracks in this.pendingTracks\n          _this3.pendingTracks[trackName] = data[trackName];\n        }\n      });\n\n      // if sourcebuffers already created, do nothing ...\n      if (sourceBufferCount) {\n        return;\n      }\n      var bufferCodecEventsExpected = Math.max(this.bufferCodecEventsExpected - 1, 0);\n      if (this.bufferCodecEventsExpected !== bufferCodecEventsExpected) {\n        this.log(bufferCodecEventsExpected + \" bufferCodec event(s) expected \" + trackNames.join(','));\n        this.bufferCodecEventsExpected = bufferCodecEventsExpected;\n      }\n      if (this.mediaSource && this.mediaSource.readyState === 'open') {\n        this.checkPendingTracks();\n      }\n    };\n    _proto.appendChangeType = function appendChangeType(type, mimeType) {\n      var _this4 = this;\n      var operationQueue = this.operationQueue;\n      var operation = {\n        execute: function execute() {\n          var sb = _this4.sourceBuffer[type];\n          if (sb) {\n            _this4.log(\"changing \" + type + \" sourceBuffer type to \" + mimeType);\n            sb.changeType(mimeType);\n          }\n          operationQueue.shiftAndExecuteNext(type);\n        },\n        onStart: function onStart() {},\n        onComplete: function onComplete() {},\n        onError: function onError(error) {\n          _this4.warn(\"Failed to change \" + type + \" SourceBuffer type\", error);\n        }\n      };\n      operationQueue.append(operation, type, !!this.pendingTracks[type]);\n    };\n    _proto.onBufferAppending = function onBufferAppending(event, eventData) {\n      var _this5 = this;\n      var hls = this.hls,\n        operationQueue = this.operationQueue,\n        tracks = this.tracks;\n      var data = eventData.data,\n        type = eventData.type,\n        frag = eventData.frag,\n        part = eventData.part,\n        chunkMeta = eventData.chunkMeta;\n      var chunkStats = chunkMeta.buffering[type];\n      var bufferAppendingStart = self.performance.now();\n      chunkStats.start = bufferAppendingStart;\n      var fragBuffering = frag.stats.buffering;\n      var partBuffering = part ? part.stats.buffering : null;\n      if (fragBuffering.start === 0) {\n        fragBuffering.start = bufferAppendingStart;\n      }\n      if (partBuffering && partBuffering.start === 0) {\n        partBuffering.start = bufferAppendingStart;\n      }\n\n      // TODO: Only update timestampOffset when audio/mpeg fragment or part is not contiguous with previously appended\n      // Adjusting `SourceBuffer.timestampOffset` (desired point in the timeline where the next frames should be appended)\n      // in Chrome browser when we detect MPEG audio container and time delta between level PTS and `SourceBuffer.timestampOffset`\n      // is greater than 100ms (this is enough to handle seek for VOD or level change for LIVE videos).\n      // More info here: https://github.com/video-dev/hls.js/issues/332#issuecomment-257986486\n      var audioTrack = tracks.audio;\n      var checkTimestampOffset = false;\n      if (type === 'audio' && (audioTrack == null ? void 0 : audioTrack.container) === 'audio/mpeg') {\n        checkTimestampOffset = !this.lastMpegAudioChunk || chunkMeta.id === 1 || this.lastMpegAudioChunk.sn !== chunkMeta.sn;\n        this.lastMpegAudioChunk = chunkMeta;\n      }\n      var fragStart = frag.start;\n      var operation = {\n        execute: function execute() {\n          chunkStats.executeStart = self.performance.now();\n          if (checkTimestampOffset) {\n            var sb = _this5.sourceBuffer[type];\n            if (sb) {\n              var delta = fragStart - sb.timestampOffset;\n              if (Math.abs(delta) >= 0.1) {\n                _this5.log(\"Updating audio SourceBuffer timestampOffset to \" + fragStart + \" (delta: \" + delta + \") sn: \" + frag.sn + \")\");\n                sb.timestampOffset = fragStart;\n              }\n            }\n          }\n          _this5.appendExecutor(data, type);\n        },\n        onStart: function onStart() {\n          // logger.debug(`[buffer-controller]: ${type} SourceBuffer updatestart`);\n        },\n        onComplete: function onComplete() {\n          // logger.debug(`[buffer-controller]: ${type} SourceBuffer updateend`);\n          var end = self.performance.now();\n          chunkStats.executeEnd = chunkStats.end = end;\n          if (fragBuffering.first === 0) {\n            fragBuffering.first = end;\n          }\n          if (partBuffering && partBuffering.first === 0) {\n            partBuffering.first = end;\n          }\n          var sourceBuffer = _this5.sourceBuffer;\n          var timeRanges = {};\n          for (var _type in sourceBuffer) {\n            timeRanges[_type] = BufferHelper.getBuffered(sourceBuffer[_type]);\n          }\n          _this5.appendErrors[type] = 0;\n          if (type === 'audio' || type === 'video') {\n            _this5.appendErrors.audiovideo = 0;\n          } else {\n            _this5.appendErrors.audio = 0;\n            _this5.appendErrors.video = 0;\n          }\n          _this5.hls.trigger(Events.BUFFER_APPENDED, {\n            type: type,\n            frag: frag,\n            part: part,\n            chunkMeta: chunkMeta,\n            parent: frag.type,\n            timeRanges: timeRanges\n          });\n        },\n        onError: function onError(error) {\n          // in case any error occured while appending, put back segment in segments table\n          var event = {\n            type: ErrorTypes.MEDIA_ERROR,\n            parent: frag.type,\n            details: ErrorDetails.BUFFER_APPEND_ERROR,\n            sourceBufferName: type,\n            frag: frag,\n            part: part,\n            chunkMeta: chunkMeta,\n            error: error,\n            err: error,\n            fatal: false\n          };\n          if (error.code === DOMException.QUOTA_EXCEEDED_ERR) {\n            // QuotaExceededError: http://www.w3.org/TR/html5/infrastructure.html#quotaexceedederror\n            // let's stop appending any segments, and report BUFFER_FULL_ERROR error\n            event.details = ErrorDetails.BUFFER_FULL_ERROR;\n          } else {\n            var appendErrorCount = ++_this5.appendErrors[type];\n            event.details = ErrorDetails.BUFFER_APPEND_ERROR;\n            /* with UHD content, we could get loop of quota exceeded error until\n              browser is able to evict some data from sourcebuffer. Retrying can help recover.\n            */\n            _this5.warn(\"Failed \" + appendErrorCount + \"/\" + hls.config.appendErrorMaxRetry + \" times to append segment in \\\"\" + type + \"\\\" sourceBuffer\");\n            if (appendErrorCount >= hls.config.appendErrorMaxRetry) {\n              event.fatal = true;\n            }\n          }\n          hls.trigger(Events.ERROR, event);\n        }\n      };\n      operationQueue.append(operation, type, !!this.pendingTracks[type]);\n    };\n    _proto.onBufferFlushing = function onBufferFlushing(event, data) {\n      var _this6 = this;\n      var operationQueue = this.operationQueue;\n      var flushOperation = function flushOperation(type) {\n        return {\n          execute: _this6.removeExecutor.bind(_this6, type, data.startOffset, data.endOffset),\n          onStart: function onStart() {\n            // logger.debug(`[buffer-controller]: Started flushing ${data.startOffset} -> ${data.endOffset} for ${type} Source Buffer`);\n          },\n          onComplete: function onComplete() {\n            // logger.debug(`[buffer-controller]: Finished flushing ${data.startOffset} -> ${data.endOffset} for ${type} Source Buffer`);\n            _this6.hls.trigger(Events.BUFFER_FLUSHED, {\n              type: type\n            });\n          },\n          onError: function onError(error) {\n            _this6.warn(\"Failed to remove from \" + type + \" SourceBuffer\", error);\n          }\n        };\n      };\n      if (data.type) {\n        operationQueue.append(flushOperation(data.type), data.type);\n      } else {\n        this.getSourceBufferTypes().forEach(function (type) {\n          operationQueue.append(flushOperation(type), type);\n        });\n      }\n    };\n    _proto.onFragParsed = function onFragParsed(event, data) {\n      var _this7 = this;\n      var frag = data.frag,\n        part = data.part;\n      var buffersAppendedTo = [];\n      var elementaryStreams = part ? part.elementaryStreams : frag.elementaryStreams;\n      if (elementaryStreams[ElementaryStreamTypes.AUDIOVIDEO]) {\n        buffersAppendedTo.push('audiovideo');\n      } else {\n        if (elementaryStreams[ElementaryStreamTypes.AUDIO]) {\n          buffersAppendedTo.push('audio');\n        }\n        if (elementaryStreams[ElementaryStreamTypes.VIDEO]) {\n          buffersAppendedTo.push('video');\n        }\n      }\n      var onUnblocked = function onUnblocked() {\n        var now = self.performance.now();\n        frag.stats.buffering.end = now;\n        if (part) {\n          part.stats.buffering.end = now;\n        }\n        var stats = part ? part.stats : frag.stats;\n        _this7.hls.trigger(Events.FRAG_BUFFERED, {\n          frag: frag,\n          part: part,\n          stats: stats,\n          id: frag.type\n        });\n      };\n      if (buffersAppendedTo.length === 0) {\n        this.warn(\"Fragments must have at least one ElementaryStreamType set. type: \" + frag.type + \" level: \" + frag.level + \" sn: \" + frag.sn);\n      }\n      this.blockBuffers(onUnblocked, buffersAppendedTo);\n    };\n    _proto.onFragChanged = function onFragChanged(event, data) {\n      this.trimBuffers();\n    }\n\n    // on BUFFER_EOS mark matching sourcebuffer(s) as ended and trigger checkEos()\n    // an undefined data.type will mark all buffers as EOS.\n    ;\n    _proto.onBufferEos = function onBufferEos(event, data) {\n      var _this8 = this;\n      var ended = this.getSourceBufferTypes().reduce(function (acc, type) {\n        var sb = _this8.sourceBuffer[type];\n        if (sb && (!data.type || data.type === type)) {\n          sb.ending = true;\n          if (!sb.ended) {\n            sb.ended = true;\n            _this8.log(type + \" sourceBuffer now EOS\");\n          }\n        }\n        return acc && !!(!sb || sb.ended);\n      }, true);\n      if (ended) {\n        this.log(\"Queueing mediaSource.endOfStream()\");\n        this.blockBuffers(function () {\n          _this8.getSourceBufferTypes().forEach(function (type) {\n            var sb = _this8.sourceBuffer[type];\n            if (sb) {\n              sb.ending = false;\n            }\n          });\n          var mediaSource = _this8.mediaSource;\n          if (!mediaSource || mediaSource.readyState !== 'open') {\n            if (mediaSource) {\n              _this8.log(\"Could not call mediaSource.endOfStream(). mediaSource.readyState: \" + mediaSource.readyState);\n            }\n            return;\n          }\n          _this8.log(\"Calling mediaSource.endOfStream()\");\n          // Allow this to throw and be caught by the enqueueing function\n          mediaSource.endOfStream();\n        });\n      }\n    };\n    _proto.onLevelUpdated = function onLevelUpdated(event, _ref) {\n      var details = _ref.details;\n      if (!details.fragments.length) {\n        return;\n      }\n      this.details = details;\n      if (this.getSourceBufferTypes().length) {\n        this.blockBuffers(this.updateMediaElementDuration.bind(this));\n      } else {\n        this.updateMediaElementDuration();\n      }\n    };\n    _proto.trimBuffers = function trimBuffers() {\n      var hls = this.hls,\n        details = this.details,\n        media = this.media;\n      if (!media || details === null) {\n        return;\n      }\n      var sourceBufferTypes = this.getSourceBufferTypes();\n      if (!sourceBufferTypes.length) {\n        return;\n      }\n      var config = hls.config;\n      var currentTime = media.currentTime;\n      var targetDuration = details.levelTargetDuration;\n\n      // Support for deprecated liveBackBufferLength\n      var backBufferLength = details.live && config.liveBackBufferLength !== null ? config.liveBackBufferLength : config.backBufferLength;\n      if (isFiniteNumber(backBufferLength) && backBufferLength > 0) {\n        var maxBackBufferLength = Math.max(backBufferLength, targetDuration);\n        var targetBackBufferPosition = Math.floor(currentTime / targetDuration) * targetDuration - maxBackBufferLength;\n        this.flushBackBuffer(currentTime, targetDuration, targetBackBufferPosition);\n      }\n      if (isFiniteNumber(config.frontBufferFlushThreshold) && config.frontBufferFlushThreshold > 0) {\n        var frontBufferLength = Math.max(config.maxBufferLength, config.frontBufferFlushThreshold);\n        var maxFrontBufferLength = Math.max(frontBufferLength, targetDuration);\n        var targetFrontBufferPosition = Math.floor(currentTime / targetDuration) * targetDuration + maxFrontBufferLength;\n        this.flushFrontBuffer(currentTime, targetDuration, targetFrontBufferPosition);\n      }\n    };\n    _proto.flushBackBuffer = function flushBackBuffer(currentTime, targetDuration, targetBackBufferPosition) {\n      var _this9 = this;\n      var details = this.details,\n        sourceBuffer = this.sourceBuffer;\n      var sourceBufferTypes = this.getSourceBufferTypes();\n      sourceBufferTypes.forEach(function (type) {\n        var sb = sourceBuffer[type];\n        if (sb) {\n          var buffered = BufferHelper.getBuffered(sb);\n          // when target buffer start exceeds actual buffer start\n          if (buffered.length > 0 && targetBackBufferPosition > buffered.start(0)) {\n            _this9.hls.trigger(Events.BACK_BUFFER_REACHED, {\n              bufferEnd: targetBackBufferPosition\n            });\n\n            // Support for deprecated event:\n            if (details != null && details.live) {\n              _this9.hls.trigger(Events.LIVE_BACK_BUFFER_REACHED, {\n                bufferEnd: targetBackBufferPosition\n              });\n            } else if (sb.ended && buffered.end(buffered.length - 1) - currentTime < targetDuration * 2) {\n              _this9.log(\"Cannot flush \" + type + \" back buffer while SourceBuffer is in ended state\");\n              return;\n            }\n            _this9.hls.trigger(Events.BUFFER_FLUSHING, {\n              startOffset: 0,\n              endOffset: targetBackBufferPosition,\n              type: type\n            });\n          }\n        }\n      });\n    };\n    _proto.flushFrontBuffer = function flushFrontBuffer(currentTime, targetDuration, targetFrontBufferPosition) {\n      var _this10 = this;\n      var sourceBuffer = this.sourceBuffer;\n      var sourceBufferTypes = this.getSourceBufferTypes();\n      sourceBufferTypes.forEach(function (type) {\n        var sb = sourceBuffer[type];\n        if (sb) {\n          var buffered = BufferHelper.getBuffered(sb);\n          var numBufferedRanges = buffered.length;\n          // The buffer is either empty or contiguous\n          if (numBufferedRanges < 2) {\n            return;\n          }\n          var bufferStart = buffered.start(numBufferedRanges - 1);\n          var bufferEnd = buffered.end(numBufferedRanges - 1);\n          // No flush if we can tolerate the current buffer length or the current buffer range we would flush is contiguous with current position\n          if (targetFrontBufferPosition > bufferStart || currentTime >= bufferStart && currentTime <= bufferEnd) {\n            return;\n          } else if (sb.ended && currentTime - bufferEnd < 2 * targetDuration) {\n            _this10.log(\"Cannot flush \" + type + \" front buffer while SourceBuffer is in ended state\");\n            return;\n          }\n          _this10.hls.trigger(Events.BUFFER_FLUSHING, {\n            startOffset: bufferStart,\n            endOffset: Infinity,\n            type: type\n          });\n        }\n      });\n    }\n\n    /**\n     * Update Media Source duration to current level duration or override to Infinity if configuration parameter\n     * 'liveDurationInfinity` is set to `true`\n     * More details: https://github.com/video-dev/hls.js/issues/355\n     */;\n    _proto.updateMediaElementDuration = function updateMediaElementDuration() {\n      if (!this.details || !this.media || !this.mediaSource || this.mediaSource.readyState !== 'open') {\n        return;\n      }\n      var details = this.details,\n        hls = this.hls,\n        media = this.media,\n        mediaSource = this.mediaSource;\n      var levelDuration = details.fragments[0].start + details.totalduration;\n      var mediaDuration = media.duration;\n      var msDuration = isFiniteNumber(mediaSource.duration) ? mediaSource.duration : 0;\n      if (details.live && hls.config.liveDurationInfinity) {\n        // Override duration to Infinity\n        mediaSource.duration = Infinity;\n        this.updateSeekableRange(details);\n      } else if (levelDuration > msDuration && levelDuration > mediaDuration || !isFiniteNumber(mediaDuration)) {\n        // levelDuration was the last value we set.\n        // not using mediaSource.duration as the browser may tweak this value\n        // only update Media Source duration if its value increase, this is to avoid\n        // flushing already buffered portion when switching between quality level\n        this.log(\"Updating Media Source duration to \" + levelDuration.toFixed(3));\n        mediaSource.duration = levelDuration;\n      }\n    };\n    _proto.updateSeekableRange = function updateSeekableRange(levelDetails) {\n      var mediaSource = this.mediaSource;\n      var fragments = levelDetails.fragments;\n      var len = fragments.length;\n      if (len && levelDetails.live && mediaSource != null && mediaSource.setLiveSeekableRange) {\n        var start = Math.max(0, fragments[0].start);\n        var end = Math.max(start, start + levelDetails.totalduration);\n        this.log(\"Media Source duration is set to \" + mediaSource.duration + \". Setting seekable range to \" + start + \"-\" + end + \".\");\n        mediaSource.setLiveSeekableRange(start, end);\n      }\n    };\n    _proto.checkPendingTracks = function checkPendingTracks() {\n      var bufferCodecEventsExpected = this.bufferCodecEventsExpected,\n        operationQueue = this.operationQueue,\n        pendingTracks = this.pendingTracks;\n\n      // Check if we've received all of the expected bufferCodec events. When none remain, create all the sourceBuffers at once.\n      // This is important because the MSE spec allows implementations to throw QuotaExceededErrors if creating new sourceBuffers after\n      // data has been appended to existing ones.\n      // 2 tracks is the max (one for audio, one for video). If we've reach this max go ahead and create the buffers.\n      var pendingTracksCount = Object.keys(pendingTracks).length;\n      if (pendingTracksCount && (!bufferCodecEventsExpected || pendingTracksCount === 2 || 'audiovideo' in pendingTracks)) {\n        // ok, let's create them now !\n        this.createSourceBuffers(pendingTracks);\n        this.pendingTracks = {};\n        // append any pending segments now !\n        var buffers = this.getSourceBufferTypes();\n        if (buffers.length) {\n          this.hls.trigger(Events.BUFFER_CREATED, {\n            tracks: this.tracks\n          });\n          buffers.forEach(function (type) {\n            operationQueue.executeNext(type);\n          });\n        } else {\n          var error = new Error('could not create source buffer for media codec(s)');\n          this.hls.trigger(Events.ERROR, {\n            type: ErrorTypes.MEDIA_ERROR,\n            details: ErrorDetails.BUFFER_INCOMPATIBLE_CODECS_ERROR,\n            fatal: true,\n            error: error,\n            reason: error.message\n          });\n        }\n      }\n    };\n    _proto.createSourceBuffers = function createSourceBuffers(tracks) {\n      var _this11 = this;\n      var sourceBuffer = this.sourceBuffer,\n        mediaSource = this.mediaSource;\n      if (!mediaSource) {\n        throw Error('createSourceBuffers called when mediaSource was null');\n      }\n      var _loop = function _loop(trackName) {\n        if (!sourceBuffer[trackName]) {\n          var _track$levelCodec;\n          var track = tracks[trackName];\n          if (!track) {\n            throw Error(\"source buffer exists for track \" + trackName + \", however track does not\");\n          }\n          // use levelCodec as first priority unless it contains multiple comma-separated codec values\n          var codec = ((_track$levelCodec = track.levelCodec) == null ? void 0 : _track$levelCodec.indexOf(',')) === -1 ? track.levelCodec : track.codec;\n          if (codec) {\n            if (trackName.slice(0, 5) === 'audio') {\n              codec = getCodecCompatibleName(codec, _this11.appendSource);\n            }\n          }\n          var mimeType = track.container + \";codecs=\" + codec;\n          _this11.log(\"creating sourceBuffer(\" + mimeType + \")\");\n          try {\n            var sb = sourceBuffer[trackName] = mediaSource.addSourceBuffer(mimeType);\n            var sbName = trackName;\n            _this11.addBufferListener(sbName, 'updatestart', _this11._onSBUpdateStart);\n            _this11.addBufferListener(sbName, 'updateend', _this11._onSBUpdateEnd);\n            _this11.addBufferListener(sbName, 'error', _this11._onSBUpdateError);\n            // ManagedSourceBuffer bufferedchange event\n            if (_this11.appendSource) {\n              _this11.addBufferListener(sbName, 'bufferedchange', function (type, event) {\n                // If media was ejected check for a change. Added ranges are redundant with changes on 'updateend' event.\n                var removedRanges = event.removedRanges;\n                if (removedRanges != null && removedRanges.length) {\n                  _this11.hls.trigger(Events.BUFFER_FLUSHED, {\n                    type: trackName\n                  });\n                }\n              });\n            }\n            _this11.tracks[trackName] = {\n              buffer: sb,\n              codec: codec,\n              container: track.container,\n              levelCodec: track.levelCodec,\n              metadata: track.metadata,\n              id: track.id\n            };\n          } catch (err) {\n            _this11.error(\"error while trying to add sourceBuffer: \" + err.message);\n            _this11.hls.trigger(Events.ERROR, {\n              type: ErrorTypes.MEDIA_ERROR,\n              details: ErrorDetails.BUFFER_ADD_CODEC_ERROR,\n              fatal: false,\n              error: err,\n              sourceBufferName: trackName,\n              mimeType: mimeType\n            });\n          }\n        }\n      };\n      for (var trackName in tracks) {\n        _loop(trackName);\n      }\n    };\n    _proto._onSBUpdateStart = function _onSBUpdateStart(type) {\n      var operationQueue = this.operationQueue;\n      var operation = operationQueue.current(type);\n      operation.onStart();\n    };\n    _proto._onSBUpdateEnd = function _onSBUpdateEnd(type) {\n      var _this$mediaSource2;\n      if (((_this$mediaSource2 = this.mediaSource) == null ? void 0 : _this$mediaSource2.readyState) === 'closed') {\n        this.resetBuffer(type);\n        return;\n      }\n      var operationQueue = this.operationQueue;\n      var operation = operationQueue.current(type);\n      operation.onComplete();\n      operationQueue.shiftAndExecuteNext(type);\n    };\n    _proto._onSBUpdateError = function _onSBUpdateError(type, event) {\n      var _this$mediaSource3;\n      var error = new Error(type + \" SourceBuffer error. MediaSource readyState: \" + ((_this$mediaSource3 = this.mediaSource) == null ? void 0 : _this$mediaSource3.readyState));\n      this.error(\"\" + error, event);\n      // according to http://www.w3.org/TR/media-source/#sourcebuffer-append-error\n      // SourceBuffer errors are not necessarily fatal; if so, the HTMLMediaElement will fire an error event\n      this.hls.trigger(Events.ERROR, {\n        type: ErrorTypes.MEDIA_ERROR,\n        details: ErrorDetails.BUFFER_APPENDING_ERROR,\n        sourceBufferName: type,\n        error: error,\n        fatal: false\n      });\n      // updateend is always fired after error, so we'll allow that to shift the current operation off of the queue\n      var operation = this.operationQueue.current(type);\n      if (operation) {\n        operation.onError(error);\n      }\n    }\n\n    // This method must result in an updateend event; if remove is not called, _onSBUpdateEnd must be called manually\n    ;\n    _proto.removeExecutor = function removeExecutor(type, startOffset, endOffset) {\n      var media = this.media,\n        mediaSource = this.mediaSource,\n        operationQueue = this.operationQueue,\n        sourceBuffer = this.sourceBuffer;\n      var sb = sourceBuffer[type];\n      if (!media || !mediaSource || !sb) {\n        this.warn(\"Attempting to remove from the \" + type + \" SourceBuffer, but it does not exist\");\n        operationQueue.shiftAndExecuteNext(type);\n        return;\n      }\n      var mediaDuration = isFiniteNumber(media.duration) ? media.duration : Infinity;\n      var msDuration = isFiniteNumber(mediaSource.duration) ? mediaSource.duration : Infinity;\n      var removeStart = Math.max(0, startOffset);\n      var removeEnd = Math.min(endOffset, mediaDuration, msDuration);\n      if (removeEnd > removeStart && (!sb.ending || sb.ended)) {\n        sb.ended = false;\n        this.log(\"Removing [\" + removeStart + \",\" + removeEnd + \"] from the \" + type + \" SourceBuffer\");\n        sb.remove(removeStart, removeEnd);\n      } else {\n        // Cycle the queue\n        operationQueue.shiftAndExecuteNext(type);\n      }\n    }\n\n    // This method must result in an updateend event; if append is not called, _onSBUpdateEnd must be called manually\n    ;\n    _proto.appendExecutor = function appendExecutor(data, type) {\n      var sb = this.sourceBuffer[type];\n      if (!sb) {\n        if (!this.pendingTracks[type]) {\n          throw new Error(\"Attempting to append to the \" + type + \" SourceBuffer, but it does not exist\");\n        }\n        return;\n      }\n      sb.ended = false;\n      sb.appendBuffer(data);\n    }\n\n    // Enqueues an operation to each SourceBuffer queue which, upon execution, resolves a promise. When all promises\n    // resolve, the onUnblocked function is executed. Functions calling this method do not need to unblock the queue\n    // upon completion, since we already do it here\n    ;\n    _proto.blockBuffers = function blockBuffers(onUnblocked, buffers) {\n      var _this12 = this;\n      if (buffers === void 0) {\n        buffers = this.getSourceBufferTypes();\n      }\n      if (!buffers.length) {\n        this.log('Blocking operation requested, but no SourceBuffers exist');\n        Promise.resolve().then(onUnblocked);\n        return;\n      }\n      var operationQueue = this.operationQueue;\n\n      // logger.debug(`[buffer-controller]: Blocking ${buffers} SourceBuffer`);\n      var blockingOperations = buffers.map(function (type) {\n        return operationQueue.appendBlocker(type);\n      });\n      Promise.all(blockingOperations).then(function () {\n        // logger.debug(`[buffer-controller]: Blocking operation resolved; unblocking ${buffers} SourceBuffer`);\n        onUnblocked();\n        buffers.forEach(function (type) {\n          var sb = _this12.sourceBuffer[type];\n          // Only cycle the queue if the SB is not updating. There's a bug in Chrome which sets the SB updating flag to\n          // true when changing the MediaSource duration (https://bugs.chromium.org/p/chromium/issues/detail?id=959359&can=2&q=mediasource%20duration)\n          // While this is a workaround, it's probably useful to have around\n          if (!(sb != null && sb.updating)) {\n            operationQueue.shiftAndExecuteNext(type);\n          }\n        });\n      });\n    };\n    _proto.getSourceBufferTypes = function getSourceBufferTypes() {\n      return Object.keys(this.sourceBuffer);\n    };\n    _proto.addBufferListener = function addBufferListener(type, event, fn) {\n      var buffer = this.sourceBuffer[type];\n      if (!buffer) {\n        return;\n      }\n      var listener = fn.bind(this, type);\n      this.listeners[type].push({\n        event: event,\n        listener: listener\n      });\n      buffer.addEventListener(event, listener);\n    };\n    _proto.removeBufferListeners = function removeBufferListeners(type) {\n      var buffer = this.sourceBuffer[type];\n      if (!buffer) {\n        return;\n      }\n      this.listeners[type].forEach(function (l) {\n        buffer.removeEventListener(l.event, l.listener);\n      });\n    };\n    _createClass(BufferController, [{\n      key: \"mediaSrc\",\n      get: function get() {\n        var _this$media, _this$media$querySele;\n        var media = ((_this$media = this.media) == null ? void 0 : (_this$media$querySele = _this$media.querySelector) == null ? void 0 : _this$media$querySele.call(_this$media, 'source')) || this.media;\n        return media == null ? void 0 : media.src;\n      }\n    }]);\n    return BufferController;\n  }();\n  function removeSourceChildren(node) {\n    var sourceChildren = node.querySelectorAll('source');\n    [].slice.call(sourceChildren).forEach(function (source) {\n      node.removeChild(source);\n    });\n  }\n  function addSource(media, url) {\n    var source = self.document.createElement('source');\n    source.type = 'video/mp4';\n    source.src = url;\n    media.appendChild(source);\n  }\n\n  /**\n   *\n   * This code was ported from the dash.js project at:\n   *   https://github.com/Dash-Industry-Forum/dash.js/blob/development/externals/cea608-parser.js\n   *   https://github.com/Dash-Industry-Forum/dash.js/commit/8269b26a761e0853bb21d78780ed945144ecdd4d#diff-71bc295a2d6b6b7093a1d3290d53a4b2\n   *\n   * The original copyright appears below:\n   *\n   * The copyright in this software is being made available under the BSD License,\n   * included below. This software may be subject to other third party and contributor\n   * rights, including patent rights, and no such rights are granted under this license.\n   *\n   * Copyright (c) 2015-2016, DASH Industry Forum.\n   * All rights reserved.\n   *\n   * Redistribution and use in source and binary forms, with or without modification,\n   * are permitted provided that the following conditions are met:\n   *  1. Redistributions of source code must retain the above copyright notice, this\n   *  list of conditions and the following disclaimer.\n   *  * Redistributions in binary form must reproduce the above copyright notice,\n   *  this list of conditions and the following disclaimer in the documentation and/or\n   *  other materials provided with the distribution.\n   *  2. Neither the name of Dash Industry Forum nor the names of its\n   *  contributors may be used to endorse or promote products derived from this software\n   *  without specific prior written permission.\n   *\n   *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS AS IS AND ANY\n   *  EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n   *  WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n   *  IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,\n   *  INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n   *  NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n   *  PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\n   *  WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n   *  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n   *  POSSIBILITY OF SUCH DAMAGE.\n   */\n  /**\n   *  Exceptions from regular ASCII. CodePoints are mapped to UTF-16 codes\n   */\n\n  var specialCea608CharsCodes = {\n    0x2a: 0xe1,\n    // lowercase a, acute accent\n    0x5c: 0xe9,\n    // lowercase e, acute accent\n    0x5e: 0xed,\n    // lowercase i, acute accent\n    0x5f: 0xf3,\n    // lowercase o, acute accent\n    0x60: 0xfa,\n    // lowercase u, acute accent\n    0x7b: 0xe7,\n    // lowercase c with cedilla\n    0x7c: 0xf7,\n    // division symbol\n    0x7d: 0xd1,\n    // uppercase N tilde\n    0x7e: 0xf1,\n    // lowercase n tilde\n    0x7f: 0x2588,\n    // Full block\n    // THIS BLOCK INCLUDES THE 16 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS\n    // THAT COME FROM HI BYTE=0x11 AND LOW BETWEEN 0x30 AND 0x3F\n    // THIS MEANS THAT \\x50 MUST BE ADDED TO THE VALUES\n    0x80: 0xae,\n    // Registered symbol (R)\n    0x81: 0xb0,\n    // degree sign\n    0x82: 0xbd,\n    // 1/2 symbol\n    0x83: 0xbf,\n    // Inverted (open) question mark\n    0x84: 0x2122,\n    // Trademark symbol (TM)\n    0x85: 0xa2,\n    // Cents symbol\n    0x86: 0xa3,\n    // Pounds sterling\n    0x87: 0x266a,\n    // Music 8'th note\n    0x88: 0xe0,\n    // lowercase a, grave accent\n    0x89: 0x20,\n    // transparent space (regular)\n    0x8a: 0xe8,\n    // lowercase e, grave accent\n    0x8b: 0xe2,\n    // lowercase a, circumflex accent\n    0x8c: 0xea,\n    // lowercase e, circumflex accent\n    0x8d: 0xee,\n    // lowercase i, circumflex accent\n    0x8e: 0xf4,\n    // lowercase o, circumflex accent\n    0x8f: 0xfb,\n    // lowercase u, circumflex accent\n    // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS\n    // THAT COME FROM HI BYTE=0x12 AND LOW BETWEEN 0x20 AND 0x3F\n    0x90: 0xc1,\n    // capital letter A with acute\n    0x91: 0xc9,\n    // capital letter E with acute\n    0x92: 0xd3,\n    // capital letter O with acute\n    0x93: 0xda,\n    // capital letter U with acute\n    0x94: 0xdc,\n    // capital letter U with diaresis\n    0x95: 0xfc,\n    // lowercase letter U with diaeresis\n    0x96: 0x2018,\n    // opening single quote\n    0x97: 0xa1,\n    // inverted exclamation mark\n    0x98: 0x2a,\n    // asterisk\n    0x99: 0x2019,\n    // closing single quote\n    0x9a: 0x2501,\n    // box drawings heavy horizontal\n    0x9b: 0xa9,\n    // copyright sign\n    0x9c: 0x2120,\n    // Service mark\n    0x9d: 0x2022,\n    // (round) bullet\n    0x9e: 0x201c,\n    // Left double quotation mark\n    0x9f: 0x201d,\n    // Right double quotation mark\n    0xa0: 0xc0,\n    // uppercase A, grave accent\n    0xa1: 0xc2,\n    // uppercase A, circumflex\n    0xa2: 0xc7,\n    // uppercase C with cedilla\n    0xa3: 0xc8,\n    // uppercase E, grave accent\n    0xa4: 0xca,\n    // uppercase E, circumflex\n    0xa5: 0xcb,\n    // capital letter E with diaresis\n    0xa6: 0xeb,\n    // lowercase letter e with diaresis\n    0xa7: 0xce,\n    // uppercase I, circumflex\n    0xa8: 0xcf,\n    // uppercase I, with diaresis\n    0xa9: 0xef,\n    // lowercase i, with diaresis\n    0xaa: 0xd4,\n    // uppercase O, circumflex\n    0xab: 0xd9,\n    // uppercase U, grave accent\n    0xac: 0xf9,\n    // lowercase u, grave accent\n    0xad: 0xdb,\n    // uppercase U, circumflex\n    0xae: 0xab,\n    // left-pointing double angle quotation mark\n    0xaf: 0xbb,\n    // right-pointing double angle quotation mark\n    // THIS BLOCK INCLUDES THE 32 EXTENDED (TWO-BYTE) LINE 21 CHARACTERS\n    // THAT COME FROM HI BYTE=0x13 AND LOW BETWEEN 0x20 AND 0x3F\n    0xb0: 0xc3,\n    // Uppercase A, tilde\n    0xb1: 0xe3,\n    // Lowercase a, tilde\n    0xb2: 0xcd,\n    // Uppercase I, acute accent\n    0xb3: 0xcc,\n    // Uppercase I, grave accent\n    0xb4: 0xec,\n    // Lowercase i, grave accent\n    0xb5: 0xd2,\n    // Uppercase O, grave accent\n    0xb6: 0xf2,\n    // Lowercase o, grave accent\n    0xb7: 0xd5,\n    // Uppercase O, tilde\n    0xb8: 0xf5,\n    // Lowercase o, tilde\n    0xb9: 0x7b,\n    // Open curly brace\n    0xba: 0x7d,\n    // Closing curly brace\n    0xbb: 0x5c,\n    // Backslash\n    0xbc: 0x5e,\n    // Caret\n    0xbd: 0x5f,\n    // Underscore\n    0xbe: 0x7c,\n    // Pipe (vertical line)\n    0xbf: 0x223c,\n    // Tilde operator\n    0xc0: 0xc4,\n    // Uppercase A, umlaut\n    0xc1: 0xe4,\n    // Lowercase A, umlaut\n    0xc2: 0xd6,\n    // Uppercase O, umlaut\n    0xc3: 0xf6,\n    // Lowercase o, umlaut\n    0xc4: 0xdf,\n    // Esszett (sharp S)\n    0xc5: 0xa5,\n    // Yen symbol\n    0xc6: 0xa4,\n    // Generic currency sign\n    0xc7: 0x2503,\n    // Box drawings heavy vertical\n    0xc8: 0xc5,\n    // Uppercase A, ring\n    0xc9: 0xe5,\n    // Lowercase A, ring\n    0xca: 0xd8,\n    // Uppercase O, stroke\n    0xcb: 0xf8,\n    // Lowercase o, strok\n    0xcc: 0x250f,\n    // Box drawings heavy down and right\n    0xcd: 0x2513,\n    // Box drawings heavy down and left\n    0xce: 0x2517,\n    // Box drawings heavy up and right\n    0xcf: 0x251b // Box drawings heavy up and left\n  };\n\n  /**\n   * Utils\n   */\n  var getCharForByte = function getCharForByte(_byte) {\n    return String.fromCharCode(specialCea608CharsCodes[_byte] || _byte);\n  };\n  var NR_ROWS = 15;\n  var NR_COLS = 100;\n  // Tables to look up row from PAC data\n  var rowsLowCh1 = {\n    0x11: 1,\n    0x12: 3,\n    0x15: 5,\n    0x16: 7,\n    0x17: 9,\n    0x10: 11,\n    0x13: 12,\n    0x14: 14\n  };\n  var rowsHighCh1 = {\n    0x11: 2,\n    0x12: 4,\n    0x15: 6,\n    0x16: 8,\n    0x17: 10,\n    0x13: 13,\n    0x14: 15\n  };\n  var rowsLowCh2 = {\n    0x19: 1,\n    0x1a: 3,\n    0x1d: 5,\n    0x1e: 7,\n    0x1f: 9,\n    0x18: 11,\n    0x1b: 12,\n    0x1c: 14\n  };\n  var rowsHighCh2 = {\n    0x19: 2,\n    0x1a: 4,\n    0x1d: 6,\n    0x1e: 8,\n    0x1f: 10,\n    0x1b: 13,\n    0x1c: 15\n  };\n  var backgroundColors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'black', 'transparent'];\n  var CaptionsLogger = /*#__PURE__*/function () {\n    function CaptionsLogger() {\n      this.time = null;\n      this.verboseLevel = 0;\n    }\n    var _proto = CaptionsLogger.prototype;\n    _proto.log = function log(severity, msg) {\n      if (this.verboseLevel >= severity) {\n        var m = typeof msg === 'function' ? msg() : msg;\n        logger.log(this.time + \" [\" + severity + \"] \" + m);\n      }\n    };\n    return CaptionsLogger;\n  }();\n  var numArrayToHexArray = function numArrayToHexArray(numArray) {\n    var hexArray = [];\n    for (var j = 0; j < numArray.length; j++) {\n      hexArray.push(numArray[j].toString(16));\n    }\n    return hexArray;\n  };\n  var PenState = /*#__PURE__*/function () {\n    function PenState() {\n      this.foreground = 'white';\n      this.underline = false;\n      this.italics = false;\n      this.background = 'black';\n      this.flash = false;\n    }\n    var _proto2 = PenState.prototype;\n    _proto2.reset = function reset() {\n      this.foreground = 'white';\n      this.underline = false;\n      this.italics = false;\n      this.background = 'black';\n      this.flash = false;\n    };\n    _proto2.setStyles = function setStyles(styles) {\n      var attribs = ['foreground', 'underline', 'italics', 'background', 'flash'];\n      for (var i = 0; i < attribs.length; i++) {\n        var style = attribs[i];\n        if (styles.hasOwnProperty(style)) {\n          this[style] = styles[style];\n        }\n      }\n    };\n    _proto2.isDefault = function isDefault() {\n      return this.foreground === 'white' && !this.underline && !this.italics && this.background === 'black' && !this.flash;\n    };\n    _proto2.equals = function equals(other) {\n      return this.foreground === other.foreground && this.underline === other.underline && this.italics === other.italics && this.background === other.background && this.flash === other.flash;\n    };\n    _proto2.copy = function copy(newPenState) {\n      this.foreground = newPenState.foreground;\n      this.underline = newPenState.underline;\n      this.italics = newPenState.italics;\n      this.background = newPenState.background;\n      this.flash = newPenState.flash;\n    };\n    _proto2.toString = function toString() {\n      return 'color=' + this.foreground + ', underline=' + this.underline + ', italics=' + this.italics + ', background=' + this.background + ', flash=' + this.flash;\n    };\n    return PenState;\n  }();\n  /**\n   * Unicode character with styling and background.\n   * @constructor\n   */\n  var StyledUnicodeChar = /*#__PURE__*/function () {\n    function StyledUnicodeChar() {\n      this.uchar = ' ';\n      this.penState = new PenState();\n    }\n    var _proto3 = StyledUnicodeChar.prototype;\n    _proto3.reset = function reset() {\n      this.uchar = ' ';\n      this.penState.reset();\n    };\n    _proto3.setChar = function setChar(uchar, newPenState) {\n      this.uchar = uchar;\n      this.penState.copy(newPenState);\n    };\n    _proto3.setPenState = function setPenState(newPenState) {\n      this.penState.copy(newPenState);\n    };\n    _proto3.equals = function equals(other) {\n      return this.uchar === other.uchar && this.penState.equals(other.penState);\n    };\n    _proto3.copy = function copy(newChar) {\n      this.uchar = newChar.uchar;\n      this.penState.copy(newChar.penState);\n    };\n    _proto3.isEmpty = function isEmpty() {\n      return this.uchar === ' ' && this.penState.isDefault();\n    };\n    return StyledUnicodeChar;\n  }();\n  /**\n   * CEA-608 row consisting of NR_COLS instances of StyledUnicodeChar.\n   * @constructor\n   */\n  var Row = /*#__PURE__*/function () {\n    function Row(logger) {\n      this.chars = [];\n      this.pos = 0;\n      this.currPenState = new PenState();\n      this.cueStartTime = null;\n      this.logger = void 0;\n      for (var i = 0; i < NR_COLS; i++) {\n        this.chars.push(new StyledUnicodeChar());\n      }\n      this.logger = logger;\n    }\n    var _proto4 = Row.prototype;\n    _proto4.equals = function equals(other) {\n      for (var i = 0; i < NR_COLS; i++) {\n        if (!this.chars[i].equals(other.chars[i])) {\n          return false;\n        }\n      }\n      return true;\n    };\n    _proto4.copy = function copy(other) {\n      for (var i = 0; i < NR_COLS; i++) {\n        this.chars[i].copy(other.chars[i]);\n      }\n    };\n    _proto4.isEmpty = function isEmpty() {\n      var empty = true;\n      for (var i = 0; i < NR_COLS; i++) {\n        if (!this.chars[i].isEmpty()) {\n          empty = false;\n          break;\n        }\n      }\n      return empty;\n    }\n\n    /**\n     *  Set the cursor to a valid column.\n     */;\n    _proto4.setCursor = function setCursor(absPos) {\n      if (this.pos !== absPos) {\n        this.pos = absPos;\n      }\n      if (this.pos < 0) {\n        this.logger.log(3, 'Negative cursor position ' + this.pos);\n        this.pos = 0;\n      } else if (this.pos > NR_COLS) {\n        this.logger.log(3, 'Too large cursor position ' + this.pos);\n        this.pos = NR_COLS;\n      }\n    }\n\n    /**\n     * Move the cursor relative to current position.\n     */;\n    _proto4.moveCursor = function moveCursor(relPos) {\n      var newPos = this.pos + relPos;\n      if (relPos > 1) {\n        for (var i = this.pos + 1; i < newPos + 1; i++) {\n          this.chars[i].setPenState(this.currPenState);\n        }\n      }\n      this.setCursor(newPos);\n    }\n\n    /**\n     * Backspace, move one step back and clear character.\n     */;\n    _proto4.backSpace = function backSpace() {\n      this.moveCursor(-1);\n      this.chars[this.pos].setChar(' ', this.currPenState);\n    };\n    _proto4.insertChar = function insertChar(_byte2) {\n      var _this = this;\n      if (_byte2 >= 0x90) {\n        // Extended char\n        this.backSpace();\n      }\n      var _char = getCharForByte(_byte2);\n      if (this.pos >= NR_COLS) {\n        this.logger.log(0, function () {\n          return 'Cannot insert ' + _byte2.toString(16) + ' (' + _char + ') at position ' + _this.pos + '. Skipping it!';\n        });\n        return;\n      }\n      this.chars[this.pos].setChar(_char, this.currPenState);\n      this.moveCursor(1);\n    };\n    _proto4.clearFromPos = function clearFromPos(startPos) {\n      var i;\n      for (i = startPos; i < NR_COLS; i++) {\n        this.chars[i].reset();\n      }\n    };\n    _proto4.clear = function clear() {\n      this.clearFromPos(0);\n      this.pos = 0;\n      this.currPenState.reset();\n    };\n    _proto4.clearToEndOfRow = function clearToEndOfRow() {\n      this.clearFromPos(this.pos);\n    };\n    _proto4.getTextString = function getTextString() {\n      var chars = [];\n      var empty = true;\n      for (var i = 0; i < NR_COLS; i++) {\n        var _char2 = this.chars[i].uchar;\n        if (_char2 !== ' ') {\n          empty = false;\n        }\n        chars.push(_char2);\n      }\n      if (empty) {\n        return '';\n      } else {\n        return chars.join('');\n      }\n    };\n    _proto4.setPenStyles = function setPenStyles(styles) {\n      this.currPenState.setStyles(styles);\n      var currChar = this.chars[this.pos];\n      currChar.setPenState(this.currPenState);\n    };\n    return Row;\n  }();\n\n  /**\n   * Keep a CEA-608 screen of 32x15 styled characters\n   * @constructor\n   */\n  var CaptionScreen = /*#__PURE__*/function () {\n    function CaptionScreen(logger) {\n      this.rows = [];\n      this.currRow = NR_ROWS - 1;\n      this.nrRollUpRows = null;\n      this.lastOutputScreen = null;\n      this.logger = void 0;\n      for (var i = 0; i < NR_ROWS; i++) {\n        this.rows.push(new Row(logger));\n      }\n      this.logger = logger;\n    }\n    var _proto5 = CaptionScreen.prototype;\n    _proto5.reset = function reset() {\n      for (var i = 0; i < NR_ROWS; i++) {\n        this.rows[i].clear();\n      }\n      this.currRow = NR_ROWS - 1;\n    };\n    _proto5.equals = function equals(other) {\n      var equal = true;\n      for (var i = 0; i < NR_ROWS; i++) {\n        if (!this.rows[i].equals(other.rows[i])) {\n          equal = false;\n          break;\n        }\n      }\n      return equal;\n    };\n    _proto5.copy = function copy(other) {\n      for (var i = 0; i < NR_ROWS; i++) {\n        this.rows[i].copy(other.rows[i]);\n      }\n    };\n    _proto5.isEmpty = function isEmpty() {\n      var empty = true;\n      for (var i = 0; i < NR_ROWS; i++) {\n        if (!this.rows[i].isEmpty()) {\n          empty = false;\n          break;\n        }\n      }\n      return empty;\n    };\n    _proto5.backSpace = function backSpace() {\n      var row = this.rows[this.currRow];\n      row.backSpace();\n    };\n    _proto5.clearToEndOfRow = function clearToEndOfRow() {\n      var row = this.rows[this.currRow];\n      row.clearToEndOfRow();\n    }\n\n    /**\n     * Insert a character (without styling) in the current row.\n     */;\n    _proto5.insertChar = function insertChar(_char3) {\n      var row = this.rows[this.currRow];\n      row.insertChar(_char3);\n    };\n    _proto5.setPen = function setPen(styles) {\n      var row = this.rows[this.currRow];\n      row.setPenStyles(styles);\n    };\n    _proto5.moveCursor = function moveCursor(relPos) {\n      var row = this.rows[this.currRow];\n      row.moveCursor(relPos);\n    };\n    _proto5.setCursor = function setCursor(absPos) {\n      this.logger.log(2, 'setCursor: ' + absPos);\n      var row = this.rows[this.currRow];\n      row.setCursor(absPos);\n    };\n    _proto5.setPAC = function setPAC(pacData) {\n      this.logger.log(2, function () {\n        return 'pacData = ' + JSON.stringify(pacData);\n      });\n      var newRow = pacData.row - 1;\n      if (this.nrRollUpRows && newRow < this.nrRollUpRows - 1) {\n        newRow = this.nrRollUpRows - 1;\n      }\n\n      // Make sure this only affects Roll-up Captions by checking this.nrRollUpRows\n      if (this.nrRollUpRows && this.currRow !== newRow) {\n        // clear all rows first\n        for (var i = 0; i < NR_ROWS; i++) {\n          this.rows[i].clear();\n        }\n\n        // Copy this.nrRollUpRows rows from lastOutputScreen and place it in the newRow location\n        // topRowIndex - the start of rows to copy (inclusive index)\n        var topRowIndex = this.currRow + 1 - this.nrRollUpRows;\n        // We only copy if the last position was already shown.\n        // We use the cueStartTime value to check this.\n        var lastOutputScreen = this.lastOutputScreen;\n        if (lastOutputScreen) {\n          var prevLineTime = lastOutputScreen.rows[topRowIndex].cueStartTime;\n          var time = this.logger.time;\n          if (prevLineTime !== null && time !== null && prevLineTime < time) {\n            for (var _i = 0; _i < this.nrRollUpRows; _i++) {\n              this.rows[newRow - this.nrRollUpRows + _i + 1].copy(lastOutputScreen.rows[topRowIndex + _i]);\n            }\n          }\n        }\n      }\n      this.currRow = newRow;\n      var row = this.rows[this.currRow];\n      if (pacData.indent !== null) {\n        var indent = pacData.indent;\n        var prevPos = Math.max(indent - 1, 0);\n        row.setCursor(pacData.indent);\n        pacData.color = row.chars[prevPos].penState.foreground;\n      }\n      var styles = {\n        foreground: pacData.color,\n        underline: pacData.underline,\n        italics: pacData.italics,\n        background: 'black',\n        flash: false\n      };\n      this.setPen(styles);\n    }\n\n    /**\n     * Set background/extra foreground, but first do back_space, and then insert space (backwards compatibility).\n     */;\n    _proto5.setBkgData = function setBkgData(bkgData) {\n      this.logger.log(2, function () {\n        return 'bkgData = ' + JSON.stringify(bkgData);\n      });\n      this.backSpace();\n      this.setPen(bkgData);\n      this.insertChar(0x20); // Space\n    };\n    _proto5.setRollUpRows = function setRollUpRows(nrRows) {\n      this.nrRollUpRows = nrRows;\n    };\n    _proto5.rollUp = function rollUp() {\n      var _this2 = this;\n      if (this.nrRollUpRows === null) {\n        this.logger.log(3, 'roll_up but nrRollUpRows not set yet');\n        return; // Not properly setup\n      }\n      this.logger.log(1, function () {\n        return _this2.getDisplayText();\n      });\n      var topRowIndex = this.currRow + 1 - this.nrRollUpRows;\n      var topRow = this.rows.splice(topRowIndex, 1)[0];\n      topRow.clear();\n      this.rows.splice(this.currRow, 0, topRow);\n      this.logger.log(2, 'Rolling up');\n      // this.logger.log(VerboseLevel.TEXT, this.get_display_text())\n    }\n\n    /**\n     * Get all non-empty rows with as unicode text.\n     */;\n    _proto5.getDisplayText = function getDisplayText(asOneRow) {\n      asOneRow = asOneRow || false;\n      var displayText = [];\n      var text = '';\n      var rowNr = -1;\n      for (var i = 0; i < NR_ROWS; i++) {\n        var rowText = this.rows[i].getTextString();\n        if (rowText) {\n          rowNr = i + 1;\n          if (asOneRow) {\n            displayText.push('Row ' + rowNr + \": '\" + rowText + \"'\");\n          } else {\n            displayText.push(rowText.trim());\n          }\n        }\n      }\n      if (displayText.length > 0) {\n        if (asOneRow) {\n          text = '[' + displayText.join(' | ') + ']';\n        } else {\n          text = displayText.join('\\n');\n        }\n      }\n      return text;\n    };\n    _proto5.getTextAndFormat = function getTextAndFormat() {\n      return this.rows;\n    };\n    return CaptionScreen;\n  }();\n\n  // var modes = ['MODE_ROLL-UP', 'MODE_POP-ON', 'MODE_PAINT-ON', 'MODE_TEXT'];\n  var Cea608Channel = /*#__PURE__*/function () {\n    function Cea608Channel(channelNumber, outputFilter, logger) {\n      this.chNr = void 0;\n      this.outputFilter = void 0;\n      this.mode = void 0;\n      this.verbose = void 0;\n      this.displayedMemory = void 0;\n      this.nonDisplayedMemory = void 0;\n      this.lastOutputScreen = void 0;\n      this.currRollUpRow = void 0;\n      this.writeScreen = void 0;\n      this.cueStartTime = void 0;\n      this.logger = void 0;\n      this.chNr = channelNumber;\n      this.outputFilter = outputFilter;\n      this.mode = null;\n      this.verbose = 0;\n      this.displayedMemory = new CaptionScreen(logger);\n      this.nonDisplayedMemory = new CaptionScreen(logger);\n      this.lastOutputScreen = new CaptionScreen(logger);\n      this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];\n      this.writeScreen = this.displayedMemory;\n      this.mode = null;\n      this.cueStartTime = null; // Keeps track of where a cue started.\n      this.logger = logger;\n    }\n    var _proto6 = Cea608Channel.prototype;\n    _proto6.reset = function reset() {\n      this.mode = null;\n      this.displayedMemory.reset();\n      this.nonDisplayedMemory.reset();\n      this.lastOutputScreen.reset();\n      this.outputFilter.reset();\n      this.currRollUpRow = this.displayedMemory.rows[NR_ROWS - 1];\n      this.writeScreen = this.displayedMemory;\n      this.mode = null;\n      this.cueStartTime = null;\n    };\n    _proto6.getHandler = function getHandler() {\n      return this.outputFilter;\n    };\n    _proto6.setHandler = function setHandler(newHandler) {\n      this.outputFilter = newHandler;\n    };\n    _proto6.setPAC = function setPAC(pacData) {\n      this.writeScreen.setPAC(pacData);\n    };\n    _proto6.setBkgData = function setBkgData(bkgData) {\n      this.writeScreen.setBkgData(bkgData);\n    };\n    _proto6.setMode = function setMode(newMode) {\n      if (newMode === this.mode) {\n        return;\n      }\n      this.mode = newMode;\n      this.logger.log(2, function () {\n        return 'MODE=' + newMode;\n      });\n      if (this.mode === 'MODE_POP-ON') {\n        this.writeScreen = this.nonDisplayedMemory;\n      } else {\n        this.writeScreen = this.displayedMemory;\n        this.writeScreen.reset();\n      }\n      if (this.mode !== 'MODE_ROLL-UP') {\n        this.displayedMemory.nrRollUpRows = null;\n        this.nonDisplayedMemory.nrRollUpRows = null;\n      }\n      this.mode = newMode;\n    };\n    _proto6.insertChars = function insertChars(chars) {\n      var _this3 = this;\n      for (var i = 0; i < chars.length; i++) {\n        this.writeScreen.insertChar(chars[i]);\n      }\n      var screen = this.writeScreen === this.displayedMemory ? 'DISP' : 'NON_DISP';\n      this.logger.log(2, function () {\n        return screen + ': ' + _this3.writeScreen.getDisplayText(true);\n      });\n      if (this.mode === 'MODE_PAINT-ON' || this.mode === 'MODE_ROLL-UP') {\n        this.logger.log(1, function () {\n          return 'DISPLAYED: ' + _this3.displayedMemory.getDisplayText(true);\n        });\n        this.outputDataUpdate();\n      }\n    };\n    _proto6.ccRCL = function ccRCL() {\n      // Resume Caption Loading (switch mode to Pop On)\n      this.logger.log(2, 'RCL - Resume Caption Loading');\n      this.setMode('MODE_POP-ON');\n    };\n    _proto6.ccBS = function ccBS() {\n      // BackSpace\n      this.logger.log(2, 'BS - BackSpace');\n      if (this.mode === 'MODE_TEXT') {\n        return;\n      }\n      this.writeScreen.backSpace();\n      if (this.writeScreen === this.displayedMemory) {\n        this.outputDataUpdate();\n      }\n    };\n    _proto6.ccAOF = function ccAOF() {\n      // Reserved (formerly Alarm Off)\n    };\n    _proto6.ccAON = function ccAON() {\n      // Reserved (formerly Alarm On)\n    };\n    _proto6.ccDER = function ccDER() {\n      // Delete to End of Row\n      this.logger.log(2, 'DER- Delete to End of Row');\n      this.writeScreen.clearToEndOfRow();\n      this.outputDataUpdate();\n    };\n    _proto6.ccRU = function ccRU(nrRows) {\n      // Roll-Up Captions-2,3,or 4 Rows\n      this.logger.log(2, 'RU(' + nrRows + ') - Roll Up');\n      this.writeScreen = this.displayedMemory;\n      this.setMode('MODE_ROLL-UP');\n      this.writeScreen.setRollUpRows(nrRows);\n    };\n    _proto6.ccFON = function ccFON() {\n      // Flash On\n      this.logger.log(2, 'FON - Flash On');\n      this.writeScreen.setPen({\n        flash: true\n      });\n    };\n    _proto6.ccRDC = function ccRDC() {\n      // Resume Direct Captioning (switch mode to PaintOn)\n      this.logger.log(2, 'RDC - Resume Direct Captioning');\n      this.setMode('MODE_PAINT-ON');\n    };\n    _proto6.ccTR = function ccTR() {\n      // Text Restart in text mode (not supported, however)\n      this.logger.log(2, 'TR');\n      this.setMode('MODE_TEXT');\n    };\n    _proto6.ccRTD = function ccRTD() {\n      // Resume Text Display in Text mode (not supported, however)\n      this.logger.log(2, 'RTD');\n      this.setMode('MODE_TEXT');\n    };\n    _proto6.ccEDM = function ccEDM() {\n      // Erase Displayed Memory\n      this.logger.log(2, 'EDM - Erase Displayed Memory');\n      this.displayedMemory.reset();\n      this.outputDataUpdate(true);\n    };\n    _proto6.ccCR = function ccCR() {\n      // Carriage Return\n      this.logger.log(2, 'CR - Carriage Return');\n      this.writeScreen.rollUp();\n      this.outputDataUpdate(true);\n    };\n    _proto6.ccENM = function ccENM() {\n      // Erase Non-Displayed Memory\n      this.logger.log(2, 'ENM - Erase Non-displayed Memory');\n      this.nonDisplayedMemory.reset();\n    };\n    _proto6.ccEOC = function ccEOC() {\n      var _this4 = this;\n      // End of Caption (Flip Memories)\n      this.logger.log(2, 'EOC - End Of Caption');\n      if (this.mode === 'MODE_POP-ON') {\n        var tmp = this.displayedMemory;\n        this.displayedMemory = this.nonDisplayedMemory;\n        this.nonDisplayedMemory = tmp;\n        this.writeScreen = this.nonDisplayedMemory;\n        this.logger.log(1, function () {\n          return 'DISP: ' + _this4.displayedMemory.getDisplayText();\n        });\n      }\n      this.outputDataUpdate(true);\n    };\n    _proto6.ccTO = function ccTO(nrCols) {\n      // Tab Offset 1,2, or 3 columns\n      this.logger.log(2, 'TO(' + nrCols + ') - Tab Offset');\n      this.writeScreen.moveCursor(nrCols);\n    };\n    _proto6.ccMIDROW = function ccMIDROW(secondByte) {\n      // Parse MIDROW command\n      var styles = {\n        flash: false\n      };\n      styles.underline = secondByte % 2 === 1;\n      styles.italics = secondByte >= 0x2e;\n      if (!styles.italics) {\n        var colorIndex = Math.floor(secondByte / 2) - 0x10;\n        var colors = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta'];\n        styles.foreground = colors[colorIndex];\n      } else {\n        styles.foreground = 'white';\n      }\n      this.logger.log(2, 'MIDROW: ' + JSON.stringify(styles));\n      this.writeScreen.setPen(styles);\n    };\n    _proto6.outputDataUpdate = function outputDataUpdate(dispatch) {\n      if (dispatch === void 0) {\n        dispatch = false;\n      }\n      var time = this.logger.time;\n      if (time === null) {\n        return;\n      }\n      if (this.outputFilter) {\n        if (this.cueStartTime === null && !this.displayedMemory.isEmpty()) {\n          // Start of a new cue\n          this.cueStartTime = time;\n        } else {\n          if (!this.displayedMemory.equals(this.lastOutputScreen)) {\n            this.outputFilter.newCue(this.cueStartTime, time, this.lastOutputScreen);\n            if (dispatch && this.outputFilter.dispatchCue) {\n              this.outputFilter.dispatchCue();\n            }\n            this.cueStartTime = this.displayedMemory.isEmpty() ? null : time;\n          }\n        }\n        this.lastOutputScreen.copy(this.displayedMemory);\n      }\n    };\n    _proto6.cueSplitAtTime = function cueSplitAtTime(t) {\n      if (this.outputFilter) {\n        if (!this.displayedMemory.isEmpty()) {\n          if (this.outputFilter.newCue) {\n            this.outputFilter.newCue(this.cueStartTime, t, this.displayedMemory);\n          }\n          this.cueStartTime = t;\n        }\n      }\n    };\n    return Cea608Channel;\n  }(); // Will be 1 or 2 when parsing captions\n  var Cea608Parser = /*#__PURE__*/function () {\n    function Cea608Parser(field, out1, out2) {\n      this.channels = void 0;\n      this.currentChannel = 0;\n      this.cmdHistory = createCmdHistory();\n      this.logger = void 0;\n      var logger = this.logger = new CaptionsLogger();\n      this.channels = [null, new Cea608Channel(field, out1, logger), new Cea608Channel(field + 1, out2, logger)];\n    }\n    var _proto7 = Cea608Parser.prototype;\n    _proto7.getHandler = function getHandler(channel) {\n      return this.channels[channel].getHandler();\n    };\n    _proto7.setHandler = function setHandler(channel, newHandler) {\n      this.channels[channel].setHandler(newHandler);\n    }\n\n    /**\n     * Add data for time t in forms of list of bytes (unsigned ints). The bytes are treated as pairs.\n     */;\n    _proto7.addData = function addData(time, byteList) {\n      var _this5 = this;\n      this.logger.time = time;\n      var _loop = function _loop(i) {\n          var a = byteList[i] & 0x7f;\n          var b = byteList[i + 1] & 0x7f;\n          var cmdFound = false;\n          var charsFound = null;\n          if (a === 0 && b === 0) {\n            return 0; // continue\n          } else {\n            _this5.logger.log(3, function () {\n              return '[' + numArrayToHexArray([byteList[i], byteList[i + 1]]) + '] -> (' + numArrayToHexArray([a, b]) + ')';\n            });\n          }\n          var cmdHistory = _this5.cmdHistory;\n          var isControlCode = a >= 0x10 && a <= 0x1f;\n          if (isControlCode) {\n            // Skip redundant control codes\n            if (hasCmdRepeated(a, b, cmdHistory)) {\n              setLastCmd(null, null, cmdHistory);\n              _this5.logger.log(3, function () {\n                return 'Repeated command (' + numArrayToHexArray([a, b]) + ') is dropped';\n              });\n              return 0; // continue\n            }\n            setLastCmd(a, b, _this5.cmdHistory);\n            cmdFound = _this5.parseCmd(a, b);\n            if (!cmdFound) {\n              cmdFound = _this5.parseMidrow(a, b);\n            }\n            if (!cmdFound) {\n              cmdFound = _this5.parsePAC(a, b);\n            }\n            if (!cmdFound) {\n              cmdFound = _this5.parseBackgroundAttributes(a, b);\n            }\n          } else {\n            setLastCmd(null, null, cmdHistory);\n          }\n          if (!cmdFound) {\n            charsFound = _this5.parseChars(a, b);\n            if (charsFound) {\n              var currChNr = _this5.currentChannel;\n              if (currChNr && currChNr > 0) {\n                var channel = _this5.channels[currChNr];\n                channel.insertChars(charsFound);\n              } else {\n                _this5.logger.log(2, 'No channel found yet. TEXT-MODE?');\n              }\n            }\n          }\n          if (!cmdFound && !charsFound) {\n            _this5.logger.log(2, function () {\n              return \"Couldn't parse cleaned data \" + numArrayToHexArray([a, b]) + ' orig: ' + numArrayToHexArray([byteList[i], byteList[i + 1]]);\n            });\n          }\n        },\n        _ret;\n      for (var i = 0; i < byteList.length; i += 2) {\n        _ret = _loop(i);\n        if (_ret === 0) continue;\n      }\n    }\n\n    /**\n     * Parse Command.\n     * @returns True if a command was found\n     */;\n    _proto7.parseCmd = function parseCmd(a, b) {\n      var cond1 = (a === 0x14 || a === 0x1c || a === 0x15 || a === 0x1d) && b >= 0x20 && b <= 0x2f;\n      var cond2 = (a === 0x17 || a === 0x1f) && b >= 0x21 && b <= 0x23;\n      if (!(cond1 || cond2)) {\n        return false;\n      }\n      var chNr = a === 0x14 || a === 0x15 || a === 0x17 ? 1 : 2;\n      var channel = this.channels[chNr];\n      if (a === 0x14 || a === 0x15 || a === 0x1c || a === 0x1d) {\n        if (b === 0x20) {\n          channel.ccRCL();\n        } else if (b === 0x21) {\n          channel.ccBS();\n        } else if (b === 0x22) {\n          channel.ccAOF();\n        } else if (b === 0x23) {\n          channel.ccAON();\n        } else if (b === 0x24) {\n          channel.ccDER();\n        } else if (b === 0x25) {\n          channel.ccRU(2);\n        } else if (b === 0x26) {\n          channel.ccRU(3);\n        } else if (b === 0x27) {\n          channel.ccRU(4);\n        } else if (b === 0x28) {\n          channel.ccFON();\n        } else if (b === 0x29) {\n          channel.ccRDC();\n        } else if (b === 0x2a) {\n          channel.ccTR();\n        } else if (b === 0x2b) {\n          channel.ccRTD();\n        } else if (b === 0x2c) {\n          channel.ccEDM();\n        } else if (b === 0x2d) {\n          channel.ccCR();\n        } else if (b === 0x2e) {\n          channel.ccENM();\n        } else if (b === 0x2f) {\n          channel.ccEOC();\n        }\n      } else {\n        // a == 0x17 || a == 0x1F\n        channel.ccTO(b - 0x20);\n      }\n      this.currentChannel = chNr;\n      return true;\n    }\n\n    /**\n     * Parse midrow styling command\n     */;\n    _proto7.parseMidrow = function parseMidrow(a, b) {\n      var chNr = 0;\n      if ((a === 0x11 || a === 0x19) && b >= 0x20 && b <= 0x2f) {\n        if (a === 0x11) {\n          chNr = 1;\n        } else {\n          chNr = 2;\n        }\n        if (chNr !== this.currentChannel) {\n          this.logger.log(0, 'Mismatch channel in midrow parsing');\n          return false;\n        }\n        var channel = this.channels[chNr];\n        if (!channel) {\n          return false;\n        }\n        channel.ccMIDROW(b);\n        this.logger.log(3, function () {\n          return 'MIDROW (' + numArrayToHexArray([a, b]) + ')';\n        });\n        return true;\n      }\n      return false;\n    }\n\n    /**\n     * Parse Preable Access Codes (Table 53).\n     * @returns {Boolean} Tells if PAC found\n     */;\n    _proto7.parsePAC = function parsePAC(a, b) {\n      var row;\n      var case1 = (a >= 0x11 && a <= 0x17 || a >= 0x19 && a <= 0x1f) && b >= 0x40 && b <= 0x7f;\n      var case2 = (a === 0x10 || a === 0x18) && b >= 0x40 && b <= 0x5f;\n      if (!(case1 || case2)) {\n        return false;\n      }\n      var chNr = a <= 0x17 ? 1 : 2;\n      if (b >= 0x40 && b <= 0x5f) {\n        row = chNr === 1 ? rowsLowCh1[a] : rowsLowCh2[a];\n      } else {\n        // 0x60 <= b <= 0x7F\n        row = chNr === 1 ? rowsHighCh1[a] : rowsHighCh2[a];\n      }\n      var channel = this.channels[chNr];\n      if (!channel) {\n        return false;\n      }\n      channel.setPAC(this.interpretPAC(row, b));\n      this.currentChannel = chNr;\n      return true;\n    }\n\n    /**\n     * Interpret the second byte of the pac, and return the information.\n     * @returns pacData with style parameters\n     */;\n    _proto7.interpretPAC = function interpretPAC(row, _byte3) {\n      var pacIndex;\n      var pacData = {\n        color: null,\n        italics: false,\n        indent: null,\n        underline: false,\n        row: row\n      };\n      if (_byte3 > 0x5f) {\n        pacIndex = _byte3 - 0x60;\n      } else {\n        pacIndex = _byte3 - 0x40;\n      }\n      pacData.underline = (pacIndex & 1) === 1;\n      if (pacIndex <= 0xd) {\n        pacData.color = ['white', 'green', 'blue', 'cyan', 'red', 'yellow', 'magenta', 'white'][Math.floor(pacIndex / 2)];\n      } else if (pacIndex <= 0xf) {\n        pacData.italics = true;\n        pacData.color = 'white';\n      } else {\n        pacData.indent = Math.floor((pacIndex - 0x10) / 2) * 4;\n      }\n      return pacData; // Note that row has zero offset. The spec uses 1.\n    }\n\n    /**\n     * Parse characters.\n     * @returns An array with 1 to 2 codes corresponding to chars, if found. null otherwise.\n     */;\n    _proto7.parseChars = function parseChars(a, b) {\n      var channelNr;\n      var charCodes = null;\n      var charCode1 = null;\n      if (a >= 0x19) {\n        channelNr = 2;\n        charCode1 = a - 8;\n      } else {\n        channelNr = 1;\n        charCode1 = a;\n      }\n      if (charCode1 >= 0x11 && charCode1 <= 0x13) {\n        // Special character\n        var oneCode;\n        if (charCode1 === 0x11) {\n          oneCode = b + 0x50;\n        } else if (charCode1 === 0x12) {\n          oneCode = b + 0x70;\n        } else {\n          oneCode = b + 0x90;\n        }\n        this.logger.log(2, function () {\n          return \"Special char '\" + getCharForByte(oneCode) + \"' in channel \" + channelNr;\n        });\n        charCodes = [oneCode];\n      } else if (a >= 0x20 && a <= 0x7f) {\n        charCodes = b === 0 ? [a] : [a, b];\n      }\n      if (charCodes) {\n        this.logger.log(3, function () {\n          return 'Char codes =  ' + numArrayToHexArray(charCodes).join(',');\n        });\n      }\n      return charCodes;\n    }\n\n    /**\n     * Parse extended background attributes as well as new foreground color black.\n     * @returns True if background attributes are found\n     */;\n    _proto7.parseBackgroundAttributes = function parseBackgroundAttributes(a, b) {\n      var case1 = (a === 0x10 || a === 0x18) && b >= 0x20 && b <= 0x2f;\n      var case2 = (a === 0x17 || a === 0x1f) && b >= 0x2d && b <= 0x2f;\n      if (!(case1 || case2)) {\n        return false;\n      }\n      var index;\n      var bkgData = {};\n      if (a === 0x10 || a === 0x18) {\n        index = Math.floor((b - 0x20) / 2);\n        bkgData.background = backgroundColors[index];\n        if (b % 2 === 1) {\n          bkgData.background = bkgData.background + '_semi';\n        }\n      } else if (b === 0x2d) {\n        bkgData.background = 'transparent';\n      } else {\n        bkgData.foreground = 'black';\n        if (b === 0x2f) {\n          bkgData.underline = true;\n        }\n      }\n      var chNr = a <= 0x17 ? 1 : 2;\n      var channel = this.channels[chNr];\n      channel.setBkgData(bkgData);\n      return true;\n    }\n\n    /**\n     * Reset state of parser and its channels.\n     */;\n    _proto7.reset = function reset() {\n      for (var i = 0; i < Object.keys(this.channels).length; i++) {\n        var channel = this.channels[i];\n        if (channel) {\n          channel.reset();\n        }\n      }\n      setLastCmd(null, null, this.cmdHistory);\n    }\n\n    /**\n     * Trigger the generation of a cue, and the start of a new one if displayScreens are not empty.\n     */;\n    _proto7.cueSplitAtTime = function cueSplitAtTime(t) {\n      for (var i = 0; i < this.channels.length; i++) {\n        var channel = this.channels[i];\n        if (channel) {\n          channel.cueSplitAtTime(t);\n        }\n      }\n    };\n    return Cea608Parser;\n  }();\n  function setLastCmd(a, b, cmdHistory) {\n    cmdHistory.a = a;\n    cmdHistory.b = b;\n  }\n  function hasCmdRepeated(a, b, cmdHistory) {\n    return cmdHistory.a === a && cmdHistory.b === b;\n  }\n  function createCmdHistory() {\n    return {\n      a: null,\n      b: null\n    };\n  }\n\n  var OutputFilter = /*#__PURE__*/function () {\n    function OutputFilter(timelineController, trackName) {\n      this.timelineController = void 0;\n      this.cueRanges = [];\n      this.trackName = void 0;\n      this.startTime = null;\n      this.endTime = null;\n      this.screen = null;\n      this.timelineController = timelineController;\n      this.trackName = trackName;\n    }\n    var _proto = OutputFilter.prototype;\n    _proto.dispatchCue = function dispatchCue() {\n      if (this.startTime === null) {\n        return;\n      }\n      this.timelineController.addCues(this.trackName, this.startTime, this.endTime, this.screen, this.cueRanges);\n      this.startTime = null;\n    };\n    _proto.newCue = function newCue(startTime, endTime, screen) {\n      if (this.startTime === null || this.startTime > startTime) {\n        this.startTime = startTime;\n      }\n      this.endTime = endTime;\n      this.screen = screen;\n      this.timelineController.createCaptionsTrack(this.trackName);\n    };\n    _proto.reset = function reset() {\n      this.cueRanges = [];\n      this.startTime = null;\n    };\n    return OutputFilter;\n  }();\n\n  /**\n   * Copyright 2013 vtt.js Contributors\n   *\n   * Licensed under the Apache License, Version 2.0 (the 'License');\n   * you may not use this file except in compliance with the License.\n   * You may obtain a copy of the License at\n   *\n   *   http://www.apache.org/licenses/LICENSE-2.0\n   *\n   * Unless required by applicable law or agreed to in writing, software\n   * distributed under the License is distributed on an 'AS IS' BASIS,\n   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   * See the License for the specific language governing permissions and\n   * limitations under the License.\n   */\n\n  var VTTCue = (function () {\n    if (optionalSelf != null && optionalSelf.VTTCue) {\n      return self.VTTCue;\n    }\n    var AllowedDirections = ['', 'lr', 'rl'];\n    var AllowedAlignments = ['start', 'middle', 'end', 'left', 'right'];\n    function isAllowedValue(allowed, value) {\n      if (typeof value !== 'string') {\n        return false;\n      }\n      // necessary for assuring the generic conforms to the Array interface\n      if (!Array.isArray(allowed)) {\n        return false;\n      }\n      // reset the type so that the next narrowing works well\n      var lcValue = value.toLowerCase();\n      // use the allow list to narrow the type to a specific subset of strings\n      if (~allowed.indexOf(lcValue)) {\n        return lcValue;\n      }\n      return false;\n    }\n    function findDirectionSetting(value) {\n      return isAllowedValue(AllowedDirections, value);\n    }\n    function findAlignSetting(value) {\n      return isAllowedValue(AllowedAlignments, value);\n    }\n    function extend(obj) {\n      for (var _len = arguments.length, rest = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {\n        rest[_key - 1] = arguments[_key];\n      }\n      var i = 1;\n      for (; i < arguments.length; i++) {\n        var cobj = arguments[i];\n        for (var p in cobj) {\n          obj[p] = cobj[p];\n        }\n      }\n      return obj;\n    }\n    function VTTCue(startTime, endTime, text) {\n      var cue = this;\n      var baseObj = {\n        enumerable: true\n      };\n      /**\n       * Shim implementation specific properties. These properties are not in\n       * the spec.\n       */\n\n      // Lets us know when the VTTCue's data has changed in such a way that we need\n      // to recompute its display state. This lets us compute its display state\n      // lazily.\n      cue.hasBeenReset = false;\n\n      /**\n       * VTTCue and TextTrackCue properties\n       * http://dev.w3.org/html5/webvtt/#vttcue-interface\n       */\n\n      var _id = '';\n      var _pauseOnExit = false;\n      var _startTime = startTime;\n      var _endTime = endTime;\n      var _text = text;\n      var _region = null;\n      var _vertical = '';\n      var _snapToLines = true;\n      var _line = 'auto';\n      var _lineAlign = 'start';\n      var _position = 50;\n      var _positionAlign = 'middle';\n      var _size = 50;\n      var _align = 'middle';\n      Object.defineProperty(cue, 'id', extend({}, baseObj, {\n        get: function get() {\n          return _id;\n        },\n        set: function set(value) {\n          _id = '' + value;\n        }\n      }));\n      Object.defineProperty(cue, 'pauseOnExit', extend({}, baseObj, {\n        get: function get() {\n          return _pauseOnExit;\n        },\n        set: function set(value) {\n          _pauseOnExit = !!value;\n        }\n      }));\n      Object.defineProperty(cue, 'startTime', extend({}, baseObj, {\n        get: function get() {\n          return _startTime;\n        },\n        set: function set(value) {\n          if (typeof value !== 'number') {\n            throw new TypeError('Start time must be set to a number.');\n          }\n          _startTime = value;\n          this.hasBeenReset = true;\n        }\n      }));\n      Object.defineProperty(cue, 'endTime', extend({}, baseObj, {\n        get: function get() {\n          return _endTime;\n        },\n        set: function set(value) {\n          if (typeof value !== 'number') {\n            throw new TypeError('End time must be set to a number.');\n          }\n          _endTime = value;\n          this.hasBeenReset = true;\n        }\n      }));\n      Object.defineProperty(cue, 'text', extend({}, baseObj, {\n        get: function get() {\n          return _text;\n        },\n        set: function set(value) {\n          _text = '' + value;\n          this.hasBeenReset = true;\n        }\n      }));\n\n      // todo: implement VTTRegion polyfill?\n      Object.defineProperty(cue, 'region', extend({}, baseObj, {\n        get: function get() {\n          return _region;\n        },\n        set: function set(value) {\n          _region = value;\n          this.hasBeenReset = true;\n        }\n      }));\n      Object.defineProperty(cue, 'vertical', extend({}, baseObj, {\n        get: function get() {\n          return _vertical;\n        },\n        set: function set(value) {\n          var setting = findDirectionSetting(value);\n          // Have to check for false because the setting an be an empty string.\n          if (setting === false) {\n            throw new SyntaxError('An invalid or illegal string was specified.');\n          }\n          _vertical = setting;\n          this.hasBeenReset = true;\n        }\n      }));\n      Object.defineProperty(cue, 'snapToLines', extend({}, baseObj, {\n        get: function get() {\n          return _snapToLines;\n        },\n        set: function set(value) {\n          _snapToLines = !!value;\n          this.hasBeenReset = true;\n        }\n      }));\n      Object.defineProperty(cue, 'line', extend({}, baseObj, {\n        get: function get() {\n          return _line;\n        },\n        set: function set(value) {\n          if (typeof value !== 'number' && value !== 'auto') {\n            throw new SyntaxError('An invalid number or illegal string was specified.');\n          }\n          _line = value;\n          this.hasBeenReset = true;\n        }\n      }));\n      Object.defineProperty(cue, 'lineAlign', extend({}, baseObj, {\n        get: function get() {\n          return _lineAlign;\n        },\n        set: function set(value) {\n          var setting = findAlignSetting(value);\n          if (!setting) {\n            throw new SyntaxError('An invalid or illegal string was specified.');\n          }\n          _lineAlign = setting;\n          this.hasBeenReset = true;\n        }\n      }));\n      Object.defineProperty(cue, 'position', extend({}, baseObj, {\n        get: function get() {\n          return _position;\n        },\n        set: function set(value) {\n          if (value < 0 || value > 100) {\n            throw new Error('Position must be between 0 and 100.');\n          }\n          _position = value;\n          this.hasBeenReset = true;\n        }\n      }));\n      Object.defineProperty(cue, 'positionAlign', extend({}, baseObj, {\n        get: function get() {\n          return _positionAlign;\n        },\n        set: function set(value) {\n          var setting = findAlignSetting(value);\n          if (!setting) {\n            throw new SyntaxError('An invalid or illegal string was specified.');\n          }\n          _positionAlign = setting;\n          this.hasBeenReset = true;\n        }\n      }));\n      Object.defineProperty(cue, 'size', extend({}, baseObj, {\n        get: function get() {\n          return _size;\n        },\n        set: function set(value) {\n          if (value < 0 || value > 100) {\n            throw new Error('Size must be between 0 and 100.');\n          }\n          _size = value;\n          this.hasBeenReset = true;\n        }\n      }));\n      Object.defineProperty(cue, 'align', extend({}, baseObj, {\n        get: function get() {\n          return _align;\n        },\n        set: function set(value) {\n          var setting = findAlignSetting(value);\n          if (!setting) {\n            throw new SyntaxError('An invalid or illegal string was specified.');\n          }\n          _align = setting;\n          this.hasBeenReset = true;\n        }\n      }));\n\n      /**\n       * Other <track> spec defined properties\n       */\n\n      // http://www.whatwg.org/specs/web-apps/current-work/multipage/the-video-element.html#text-track-cue-display-state\n      cue.displayState = undefined;\n    }\n\n    /**\n     * VTTCue methods\n     */\n\n    VTTCue.prototype.getCueAsHTML = function () {\n      // Assume WebVTT.convertCueToDOMTree is on the global.\n      var WebVTT = self.WebVTT;\n      return WebVTT.convertCueToDOMTree(self, this.text);\n    };\n    // this is a polyfill hack\n    return VTTCue;\n  })();\n\n  /*\n   * Source: https://github.com/mozilla/vtt.js/blob/master/dist/vtt.js\n   */\n\n  var StringDecoder = /*#__PURE__*/function () {\n    function StringDecoder() {}\n    var _proto = StringDecoder.prototype;\n    // eslint-disable-next-line @typescript-eslint/no-unused-vars\n    _proto.decode = function decode(data, options) {\n      if (!data) {\n        return '';\n      }\n      if (typeof data !== 'string') {\n        throw new Error('Error - expected string data.');\n      }\n      return decodeURIComponent(encodeURIComponent(data));\n    };\n    return StringDecoder;\n  }(); // Try to parse input as a time stamp.\n  function parseTimeStamp(input) {\n    function computeSeconds(h, m, s, f) {\n      return (h | 0) * 3600 + (m | 0) * 60 + (s | 0) + parseFloat(f || 0);\n    }\n    var m = input.match(/^(?:(\\d+):)?(\\d{2}):(\\d{2})(\\.\\d+)?/);\n    if (!m) {\n      return null;\n    }\n    if (parseFloat(m[2]) > 59) {\n      // Timestamp takes the form of [hours]:[minutes].[milliseconds]\n      // First position is hours as it's over 59.\n      return computeSeconds(m[2], m[3], 0, m[4]);\n    }\n    // Timestamp takes the form of [hours (optional)]:[minutes]:[seconds].[milliseconds]\n    return computeSeconds(m[1], m[2], m[3], m[4]);\n  }\n\n  // A settings object holds key/value pairs and will ignore anything but the first\n  // assignment to a specific key.\n  var Settings = /*#__PURE__*/function () {\n    function Settings() {\n      this.values = Object.create(null);\n    }\n    var _proto2 = Settings.prototype;\n    // Only accept the first assignment to any key.\n    _proto2.set = function set(k, v) {\n      if (!this.get(k) && v !== '') {\n        this.values[k] = v;\n      }\n    }\n    // Return the value for a key, or a default value.\n    // If 'defaultKey' is passed then 'dflt' is assumed to be an object with\n    // a number of possible default values as properties where 'defaultKey' is\n    // the key of the property that will be chosen; otherwise it's assumed to be\n    // a single value.\n    ;\n    _proto2.get = function get(k, dflt, defaultKey) {\n      if (defaultKey) {\n        return this.has(k) ? this.values[k] : dflt[defaultKey];\n      }\n      return this.has(k) ? this.values[k] : dflt;\n    }\n    // Check whether we have a value for a key.\n    ;\n    _proto2.has = function has(k) {\n      return k in this.values;\n    }\n    // Accept a setting if its one of the given alternatives.\n    ;\n    _proto2.alt = function alt(k, v, a) {\n      for (var n = 0; n < a.length; ++n) {\n        if (v === a[n]) {\n          this.set(k, v);\n          break;\n        }\n      }\n    }\n    // Accept a setting if its a valid (signed) integer.\n    ;\n    _proto2.integer = function integer(k, v) {\n      if (/^-?\\d+$/.test(v)) {\n        // integer\n        this.set(k, parseInt(v, 10));\n      }\n    }\n    // Accept a setting if its a valid percentage.\n    ;\n    _proto2.percent = function percent(k, v) {\n      if (/^([\\d]{1,3})(\\.[\\d]*)?%$/.test(v)) {\n        var percent = parseFloat(v);\n        if (percent >= 0 && percent <= 100) {\n          this.set(k, percent);\n          return true;\n        }\n      }\n      return false;\n    };\n    return Settings;\n  }(); // Helper function to parse input into groups separated by 'groupDelim', and\n  // interpret each group as a key/value pair separated by 'keyValueDelim'.\n  function parseOptions(input, callback, keyValueDelim, groupDelim) {\n    var groups = groupDelim ? input.split(groupDelim) : [input];\n    for (var i in groups) {\n      if (typeof groups[i] !== 'string') {\n        continue;\n      }\n      var kv = groups[i].split(keyValueDelim);\n      if (kv.length !== 2) {\n        continue;\n      }\n      var _k = kv[0];\n      var _v = kv[1];\n      callback(_k, _v);\n    }\n  }\n  var defaults = new VTTCue(0, 0, '');\n  // 'middle' was changed to 'center' in the spec: https://github.com/w3c/webvtt/pull/244\n  //  Safari doesn't yet support this change, but FF and Chrome do.\n  var center = defaults.align === 'middle' ? 'middle' : 'center';\n  function parseCue(input, cue, regionList) {\n    // Remember the original input if we need to throw an error.\n    var oInput = input;\n    // 4.1 WebVTT timestamp\n    function consumeTimeStamp() {\n      var ts = parseTimeStamp(input);\n      if (ts === null) {\n        throw new Error('Malformed timestamp: ' + oInput);\n      }\n\n      // Remove time stamp from input.\n      input = input.replace(/^[^\\sa-zA-Z-]+/, '');\n      return ts;\n    }\n\n    // 4.4.2 WebVTT cue settings\n    function consumeCueSettings(input, cue) {\n      var settings = new Settings();\n      parseOptions(input, function (k, v) {\n        var vals;\n        switch (k) {\n          case 'region':\n            // Find the last region we parsed with the same region id.\n            for (var i = regionList.length - 1; i >= 0; i--) {\n              if (regionList[i].id === v) {\n                settings.set(k, regionList[i].region);\n                break;\n              }\n            }\n            break;\n          case 'vertical':\n            settings.alt(k, v, ['rl', 'lr']);\n            break;\n          case 'line':\n            vals = v.split(',');\n            settings.integer(k, vals[0]);\n            if (settings.percent(k, vals[0])) {\n              settings.set('snapToLines', false);\n            }\n            settings.alt(k, vals[0], ['auto']);\n            if (vals.length === 2) {\n              settings.alt('lineAlign', vals[1], ['start', center, 'end']);\n            }\n            break;\n          case 'position':\n            vals = v.split(',');\n            settings.percent(k, vals[0]);\n            if (vals.length === 2) {\n              settings.alt('positionAlign', vals[1], ['start', center, 'end', 'line-left', 'line-right', 'auto']);\n            }\n            break;\n          case 'size':\n            settings.percent(k, v);\n            break;\n          case 'align':\n            settings.alt(k, v, ['start', center, 'end', 'left', 'right']);\n            break;\n        }\n      }, /:/, /\\s/);\n\n      // Apply default values for any missing fields.\n      cue.region = settings.get('region', null);\n      cue.vertical = settings.get('vertical', '');\n      var line = settings.get('line', 'auto');\n      if (line === 'auto' && defaults.line === -1) {\n        // set numeric line number for Safari\n        line = -1;\n      }\n      cue.line = line;\n      cue.lineAlign = settings.get('lineAlign', 'start');\n      cue.snapToLines = settings.get('snapToLines', true);\n      cue.size = settings.get('size', 100);\n      cue.align = settings.get('align', center);\n      var position = settings.get('position', 'auto');\n      if (position === 'auto' && defaults.position === 50) {\n        // set numeric position for Safari\n        position = cue.align === 'start' || cue.align === 'left' ? 0 : cue.align === 'end' || cue.align === 'right' ? 100 : 50;\n      }\n      cue.position = position;\n    }\n    function skipWhitespace() {\n      input = input.replace(/^\\s+/, '');\n    }\n\n    // 4.1 WebVTT cue timings.\n    skipWhitespace();\n    cue.startTime = consumeTimeStamp(); // (1) collect cue start time\n    skipWhitespace();\n    if (input.slice(0, 3) !== '--\x3e') {\n      // (3) next characters must match '--\x3e'\n      throw new Error(\"Malformed time stamp (time stamps must be separated by '--\x3e'): \" + oInput);\n    }\n    input = input.slice(3);\n    skipWhitespace();\n    cue.endTime = consumeTimeStamp(); // (5) collect cue end time\n\n    // 4.1 WebVTT cue settings list.\n    skipWhitespace();\n    consumeCueSettings(input, cue);\n  }\n  function fixLineBreaks(input) {\n    return input.replace(/<br(?: \\/)?>/gi, '\\n');\n  }\n  var VTTParser = /*#__PURE__*/function () {\n    function VTTParser() {\n      this.state = 'INITIAL';\n      this.buffer = '';\n      this.decoder = new StringDecoder();\n      this.regionList = [];\n      this.cue = null;\n      this.oncue = void 0;\n      this.onparsingerror = void 0;\n      this.onflush = void 0;\n    }\n    var _proto3 = VTTParser.prototype;\n    _proto3.parse = function parse(data) {\n      var _this = this;\n\n      // If there is no data then we won't decode it, but will just try to parse\n      // whatever is in buffer already. This may occur in circumstances, for\n      // example when flush() is called.\n      if (data) {\n        // Try to decode the data that we received.\n        _this.buffer += _this.decoder.decode(data, {\n          stream: true\n        });\n      }\n      function collectNextLine() {\n        var buffer = _this.buffer;\n        var pos = 0;\n        buffer = fixLineBreaks(buffer);\n        while (pos < buffer.length && buffer[pos] !== '\\r' && buffer[pos] !== '\\n') {\n          ++pos;\n        }\n        var line = buffer.slice(0, pos);\n        // Advance the buffer early in case we fail below.\n        if (buffer[pos] === '\\r') {\n          ++pos;\n        }\n        if (buffer[pos] === '\\n') {\n          ++pos;\n        }\n        _this.buffer = buffer.slice(pos);\n        return line;\n      }\n\n      // 3.2 WebVTT metadata header syntax\n      function parseHeader(input) {\n        parseOptions(input, function (k, v) {\n          // switch (k) {\n          // case 'region':\n          // 3.3 WebVTT region metadata header syntax\n          // console.log('parse region', v);\n          // parseRegion(v);\n          // break;\n          // }\n        }, /:/);\n      }\n\n      // 5.1 WebVTT file parsing.\n      try {\n        var line = '';\n        if (_this.state === 'INITIAL') {\n          // We can't start parsing until we have the first line.\n          if (!/\\r\\n|\\n/.test(_this.buffer)) {\n            return this;\n          }\n          line = collectNextLine();\n          // strip of UTF-8 BOM if any\n          // https://en.wikipedia.org/wiki/Byte_order_mark#UTF-8\n          var m = line.match(/^()?WEBVTT([ \\t].*)?$/);\n          if (!(m != null && m[0])) {\n            throw new Error('Malformed WebVTT signature.');\n          }\n          _this.state = 'HEADER';\n        }\n        var alreadyCollectedLine = false;\n        while (_this.buffer) {\n          // We can't parse a line until we have the full line.\n          if (!/\\r\\n|\\n/.test(_this.buffer)) {\n            return this;\n          }\n          if (!alreadyCollectedLine) {\n            line = collectNextLine();\n          } else {\n            alreadyCollectedLine = false;\n          }\n          switch (_this.state) {\n            case 'HEADER':\n              // 13-18 - Allow a header (metadata) under the WEBVTT line.\n              if (/:/.test(line)) {\n                parseHeader(line);\n              } else if (!line) {\n                // An empty line terminates the header and starts the body (cues).\n                _this.state = 'ID';\n              }\n              continue;\n            case 'NOTE':\n              // Ignore NOTE blocks.\n              if (!line) {\n                _this.state = 'ID';\n              }\n              continue;\n            case 'ID':\n              // Check for the start of NOTE blocks.\n              if (/^NOTE($|[ \\t])/.test(line)) {\n                _this.state = 'NOTE';\n                break;\n              }\n              // 19-29 - Allow any number of line terminators, then initialize new cue values.\n              if (!line) {\n                continue;\n              }\n              _this.cue = new VTTCue(0, 0, '');\n              _this.state = 'CUE';\n              // 30-39 - Check if self line contains an optional identifier or timing data.\n              if (line.indexOf('--\x3e') === -1) {\n                _this.cue.id = line;\n                continue;\n              }\n            // Process line as start of a cue.\n            /* falls through */\n            case 'CUE':\n              // 40 - Collect cue timings and settings.\n              if (!_this.cue) {\n                _this.state = 'BADCUE';\n                continue;\n              }\n              try {\n                parseCue(line, _this.cue, _this.regionList);\n              } catch (e) {\n                // In case of an error ignore rest of the cue.\n                _this.cue = null;\n                _this.state = 'BADCUE';\n                continue;\n              }\n              _this.state = 'CUETEXT';\n              continue;\n            case 'CUETEXT':\n              {\n                var hasSubstring = line.indexOf('--\x3e') !== -1;\n                // 34 - If we have an empty line then report the cue.\n                // 35 - If we have the special substring '--\x3e' then report the cue,\n                // but do not collect the line as we need to process the current\n                // one as a new cue.\n                if (!line || hasSubstring && (alreadyCollectedLine = true)) {\n                  // We are done parsing self cue.\n                  if (_this.oncue && _this.cue) {\n                    _this.oncue(_this.cue);\n                  }\n                  _this.cue = null;\n                  _this.state = 'ID';\n                  continue;\n                }\n                if (_this.cue === null) {\n                  continue;\n                }\n                if (_this.cue.text) {\n                  _this.cue.text += '\\n';\n                }\n                _this.cue.text += line;\n              }\n              continue;\n            case 'BADCUE':\n              // 54-62 - Collect and discard the remaining cue.\n              if (!line) {\n                _this.state = 'ID';\n              }\n          }\n        }\n      } catch (e) {\n        // If we are currently parsing a cue, report what we have.\n        if (_this.state === 'CUETEXT' && _this.cue && _this.oncue) {\n          _this.oncue(_this.cue);\n        }\n        _this.cue = null;\n        // Enter BADWEBVTT state if header was not parsed correctly otherwise\n        // another exception occurred so enter BADCUE state.\n        _this.state = _this.state === 'INITIAL' ? 'BADWEBVTT' : 'BADCUE';\n      }\n      return this;\n    };\n    _proto3.flush = function flush() {\n      var _this = this;\n      try {\n        // Finish decoding the stream.\n        // _this.buffer += _this.decoder.decode();\n        // Synthesize the end of the current cue or region.\n        if (_this.cue || _this.state === 'HEADER') {\n          _this.buffer += '\\n\\n';\n          _this.parse();\n        }\n        // If we've flushed, parsed, and we're still on the INITIAL state then\n        // that means we don't have enough of the stream to parse the first\n        // line.\n        if (_this.state === 'INITIAL' || _this.state === 'BADWEBVTT') {\n          throw new Error('Malformed WebVTT signature.');\n        }\n      } catch (e) {\n        if (_this.onparsingerror) {\n          _this.onparsingerror(e);\n        }\n      }\n      if (_this.onflush) {\n        _this.onflush();\n      }\n      return this;\n    };\n    return VTTParser;\n  }();\n\n  var LINEBREAKS = /\\r\\n|\\n\\r|\\n|\\r/g;\n\n  // String.prototype.startsWith is not supported in IE11\n  var startsWith = function startsWith(inputString, searchString, position) {\n    if (position === void 0) {\n      position = 0;\n    }\n    return inputString.slice(position, position + searchString.length) === searchString;\n  };\n  var cueString2millis = function cueString2millis(timeString) {\n    var ts = parseInt(timeString.slice(-3));\n    var secs = parseInt(timeString.slice(-6, -4));\n    var mins = parseInt(timeString.slice(-9, -7));\n    var hours = timeString.length > 9 ? parseInt(timeString.substring(0, timeString.indexOf(':'))) : 0;\n    if (!isFiniteNumber(ts) || !isFiniteNumber(secs) || !isFiniteNumber(mins) || !isFiniteNumber(hours)) {\n      throw Error(\"Malformed X-TIMESTAMP-MAP: Local:\" + timeString);\n    }\n    ts += 1000 * secs;\n    ts += 60 * 1000 * mins;\n    ts += 60 * 60 * 1000 * hours;\n    return ts;\n  };\n\n  // From https://github.com/darkskyapp/string-hash\n  var hash = function hash(text) {\n    var hash = 5381;\n    var i = text.length;\n    while (i) {\n      hash = hash * 33 ^ text.charCodeAt(--i);\n    }\n    return (hash >>> 0).toString();\n  };\n\n  // Create a unique hash id for a cue based on start/end times and text.\n  // This helps timeline-controller to avoid showing repeated captions.\n  function generateCueId(startTime, endTime, text) {\n    return hash(startTime.toString()) + hash(endTime.toString()) + hash(text);\n  }\n  var calculateOffset = function calculateOffset(vttCCs, cc, presentationTime) {\n    var currCC = vttCCs[cc];\n    var prevCC = vttCCs[currCC.prevCC];\n\n    // This is the first discontinuity or cues have been processed since the last discontinuity\n    // Offset = current discontinuity time\n    if (!prevCC || !prevCC.new && currCC.new) {\n      vttCCs.ccOffset = vttCCs.presentationOffset = currCC.start;\n      currCC.new = false;\n      return;\n    }\n\n    // There have been discontinuities since cues were last parsed.\n    // Offset = time elapsed\n    while ((_prevCC = prevCC) != null && _prevCC.new) {\n      var _prevCC;\n      vttCCs.ccOffset += currCC.start - prevCC.start;\n      currCC.new = false;\n      currCC = prevCC;\n      prevCC = vttCCs[currCC.prevCC];\n    }\n    vttCCs.presentationOffset = presentationTime;\n  };\n  function parseWebVTT(vttByteArray, initPTS, vttCCs, cc, timeOffset, callBack, errorCallBack) {\n    var parser = new VTTParser();\n    // Convert byteArray into string, replacing any somewhat exotic linefeeds with \"\\n\", then split on that character.\n    // Uint8Array.prototype.reduce is not implemented in IE11\n    var vttLines = utf8ArrayToStr(new Uint8Array(vttByteArray)).trim().replace(LINEBREAKS, '\\n').split('\\n');\n    var cues = [];\n    var init90kHz = initPTS ? toMpegTsClockFromTimescale(initPTS.baseTime, initPTS.timescale) : 0;\n    var cueTime = '00:00.000';\n    var timestampMapMPEGTS = 0;\n    var timestampMapLOCAL = 0;\n    var parsingError;\n    var inHeader = true;\n    parser.oncue = function (cue) {\n      // Adjust cue timing; clamp cues to start no earlier than - and drop cues that don't end after - 0 on timeline.\n      var currCC = vttCCs[cc];\n      var cueOffset = vttCCs.ccOffset;\n\n      // Calculate subtitle PTS offset\n      var webVttMpegTsMapOffset = (timestampMapMPEGTS - init90kHz) / 90000;\n\n      // Update offsets for new discontinuities\n      if (currCC != null && currCC.new) {\n        if (timestampMapLOCAL !== undefined) {\n          // When local time is provided, offset = discontinuity start time - local time\n          cueOffset = vttCCs.ccOffset = currCC.start;\n        } else {\n          calculateOffset(vttCCs, cc, webVttMpegTsMapOffset);\n        }\n      }\n      if (webVttMpegTsMapOffset) {\n        if (!initPTS) {\n          parsingError = new Error('Missing initPTS for VTT MPEGTS');\n          return;\n        }\n        // If we have MPEGTS, offset = presentation time + discontinuity offset\n        cueOffset = webVttMpegTsMapOffset - vttCCs.presentationOffset;\n      }\n      var duration = cue.endTime - cue.startTime;\n      var startTime = normalizePts((cue.startTime + cueOffset - timestampMapLOCAL) * 90000, timeOffset * 90000) / 90000;\n      cue.startTime = Math.max(startTime, 0);\n      cue.endTime = Math.max(startTime + duration, 0);\n\n      //trim trailing webvtt block whitespaces\n      var text = cue.text.trim();\n\n      // Fix encoding of special characters\n      cue.text = decodeURIComponent(encodeURIComponent(text));\n\n      // If the cue was not assigned an id from the VTT file (line above the content), create one.\n      if (!cue.id) {\n        cue.id = generateCueId(cue.startTime, cue.endTime, text);\n      }\n      if (cue.endTime > 0) {\n        cues.push(cue);\n      }\n    };\n    parser.onparsingerror = function (error) {\n      parsingError = error;\n    };\n    parser.onflush = function () {\n      if (parsingError) {\n        errorCallBack(parsingError);\n        return;\n      }\n      callBack(cues);\n    };\n\n    // Go through contents line by line.\n    vttLines.forEach(function (line) {\n      if (inHeader) {\n        // Look for X-TIMESTAMP-MAP in header.\n        if (startsWith(line, 'X-TIMESTAMP-MAP=')) {\n          // Once found, no more are allowed anyway, so stop searching.\n          inHeader = false;\n          // Extract LOCAL and MPEGTS.\n          line.slice(16).split(',').forEach(function (timestamp) {\n            if (startsWith(timestamp, 'LOCAL:')) {\n              cueTime = timestamp.slice(6);\n            } else if (startsWith(timestamp, 'MPEGTS:')) {\n              timestampMapMPEGTS = parseInt(timestamp.slice(7));\n            }\n          });\n          try {\n            // Convert cue time to seconds\n            timestampMapLOCAL = cueString2millis(cueTime) / 1000;\n          } catch (error) {\n            parsingError = error;\n          }\n          // Return without parsing X-TIMESTAMP-MAP line.\n          return;\n        } else if (line === '') {\n          inHeader = false;\n        }\n      }\n      // Parse line by default.\n      parser.parse(line + '\\n');\n    });\n    parser.flush();\n  }\n\n  var IMSC1_CODEC = 'stpp.ttml.im1t';\n\n  // Time format: h:m:s:frames(.subframes)\n  var HMSF_REGEX = /^(\\d{2,}):(\\d{2}):(\\d{2}):(\\d{2})\\.?(\\d+)?$/;\n\n  // Time format: hours, minutes, seconds, milliseconds, frames, ticks\n  var TIME_UNIT_REGEX = /^(\\d*(?:\\.\\d*)?)(h|m|s|ms|f|t)$/;\n  var textAlignToLineAlign = {\n    left: 'start',\n    center: 'center',\n    right: 'end',\n    start: 'start',\n    end: 'end'\n  };\n  function parseIMSC1(payload, initPTS, callBack, errorCallBack) {\n    var results = findBox(new Uint8Array(payload), ['mdat']);\n    if (results.length === 0) {\n      errorCallBack(new Error('Could not parse IMSC1 mdat'));\n      return;\n    }\n    var ttmlList = results.map(function (mdat) {\n      return utf8ArrayToStr(mdat);\n    });\n    var syncTime = toTimescaleFromScale(initPTS.baseTime, 1, initPTS.timescale);\n    try {\n      ttmlList.forEach(function (ttml) {\n        return callBack(parseTTML(ttml, syncTime));\n      });\n    } catch (error) {\n      errorCallBack(error);\n    }\n  }\n  function parseTTML(ttml, syncTime) {\n    var parser = new DOMParser();\n    var xmlDoc = parser.parseFromString(ttml, 'text/xml');\n    var tt = xmlDoc.getElementsByTagName('tt')[0];\n    if (!tt) {\n      throw new Error('Invalid ttml');\n    }\n    var defaultRateInfo = {\n      frameRate: 30,\n      subFrameRate: 1,\n      frameRateMultiplier: 0,\n      tickRate: 0\n    };\n    var rateInfo = Object.keys(defaultRateInfo).reduce(function (result, key) {\n      result[key] = tt.getAttribute(\"ttp:\" + key) || defaultRateInfo[key];\n      return result;\n    }, {});\n    var trim = tt.getAttribute('xml:space') !== 'preserve';\n    var styleElements = collectionToDictionary(getElementCollection(tt, 'styling', 'style'));\n    var regionElements = collectionToDictionary(getElementCollection(tt, 'layout', 'region'));\n    var cueElements = getElementCollection(tt, 'body', '[begin]');\n    return [].map.call(cueElements, function (cueElement) {\n      var cueText = getTextContent(cueElement, trim);\n      if (!cueText || !cueElement.hasAttribute('begin')) {\n        return null;\n      }\n      var startTime = parseTtmlTime(cueElement.getAttribute('begin'), rateInfo);\n      var duration = parseTtmlTime(cueElement.getAttribute('dur'), rateInfo);\n      var endTime = parseTtmlTime(cueElement.getAttribute('end'), rateInfo);\n      if (startTime === null) {\n        throw timestampParsingError(cueElement);\n      }\n      if (endTime === null) {\n        if (duration === null) {\n          throw timestampParsingError(cueElement);\n        }\n        endTime = startTime + duration;\n      }\n      var cue = new VTTCue(startTime - syncTime, endTime - syncTime, cueText);\n      cue.id = generateCueId(cue.startTime, cue.endTime, cue.text);\n      var region = regionElements[cueElement.getAttribute('region')];\n      var style = styleElements[cueElement.getAttribute('style')];\n\n      // Apply styles to cue\n      var styles = getTtmlStyles(region, style, styleElements);\n      var textAlign = styles.textAlign;\n      if (textAlign) {\n        // cue.positionAlign not settable in FF~2016\n        var lineAlign = textAlignToLineAlign[textAlign];\n        if (lineAlign) {\n          cue.lineAlign = lineAlign;\n        }\n        cue.align = textAlign;\n      }\n      _extends(cue, styles);\n      return cue;\n    }).filter(function (cue) {\n      return cue !== null;\n    });\n  }\n  function getElementCollection(fromElement, parentName, childName) {\n    var parent = fromElement.getElementsByTagName(parentName)[0];\n    if (parent) {\n      return [].slice.call(parent.querySelectorAll(childName));\n    }\n    return [];\n  }\n  function collectionToDictionary(elementsWithId) {\n    return elementsWithId.reduce(function (dict, element) {\n      var id = element.getAttribute('xml:id');\n      if (id) {\n        dict[id] = element;\n      }\n      return dict;\n    }, {});\n  }\n  function getTextContent(element, trim) {\n    return [].slice.call(element.childNodes).reduce(function (str, node, i) {\n      var _node$childNodes;\n      if (node.nodeName === 'br' && i) {\n        return str + '\\n';\n      }\n      if ((_node$childNodes = node.childNodes) != null && _node$childNodes.length) {\n        return getTextContent(node, trim);\n      } else if (trim) {\n        return str + node.textContent.trim().replace(/\\s+/g, ' ');\n      }\n      return str + node.textContent;\n    }, '');\n  }\n  function getTtmlStyles(region, style, styleElements) {\n    var ttsNs = 'http://www.w3.org/ns/ttml#styling';\n    var regionStyle = null;\n    var styleAttributes = ['displayAlign', 'textAlign', 'color', 'backgroundColor', 'fontSize', 'fontFamily'\n    // 'fontWeight',\n    // 'lineHeight',\n    // 'wrapOption',\n    // 'fontStyle',\n    // 'direction',\n    // 'writingMode'\n    ];\n    var regionStyleName = region != null && region.hasAttribute('style') ? region.getAttribute('style') : null;\n    if (regionStyleName && styleElements.hasOwnProperty(regionStyleName)) {\n      regionStyle = styleElements[regionStyleName];\n    }\n    return styleAttributes.reduce(function (styles, name) {\n      var value = getAttributeNS(style, ttsNs, name) || getAttributeNS(region, ttsNs, name) || getAttributeNS(regionStyle, ttsNs, name);\n      if (value) {\n        styles[name] = value;\n      }\n      return styles;\n    }, {});\n  }\n  function getAttributeNS(element, ns, name) {\n    if (!element) {\n      return null;\n    }\n    return element.hasAttributeNS(ns, name) ? element.getAttributeNS(ns, name) : null;\n  }\n  function timestampParsingError(node) {\n    return new Error(\"Could not parse ttml timestamp \" + node);\n  }\n  function parseTtmlTime(timeAttributeValue, rateInfo) {\n    if (!timeAttributeValue) {\n      return null;\n    }\n    var seconds = parseTimeStamp(timeAttributeValue);\n    if (seconds === null) {\n      if (HMSF_REGEX.test(timeAttributeValue)) {\n        seconds = parseHoursMinutesSecondsFrames(timeAttributeValue, rateInfo);\n      } else if (TIME_UNIT_REGEX.test(timeAttributeValue)) {\n        seconds = parseTimeUnits(timeAttributeValue, rateInfo);\n      }\n    }\n    return seconds;\n  }\n  function parseHoursMinutesSecondsFrames(timeAttributeValue, rateInfo) {\n    var m = HMSF_REGEX.exec(timeAttributeValue);\n    var frames = (m[4] | 0) + (m[5] | 0) / rateInfo.subFrameRate;\n    return (m[1] | 0) * 3600 + (m[2] | 0) * 60 + (m[3] | 0) + frames / rateInfo.frameRate;\n  }\n  function parseTimeUnits(timeAttributeValue, rateInfo) {\n    var m = TIME_UNIT_REGEX.exec(timeAttributeValue);\n    var value = Number(m[1]);\n    var unit = m[2];\n    switch (unit) {\n      case 'h':\n        return value * 3600;\n      case 'm':\n        return value * 60;\n      case 'ms':\n        return value * 1000;\n      case 'f':\n        return value / rateInfo.frameRate;\n      case 't':\n        return value / rateInfo.tickRate;\n    }\n    return value;\n  }\n\n  var TimelineController = /*#__PURE__*/function () {\n    function TimelineController(hls) {\n      this.hls = void 0;\n      this.media = null;\n      this.config = void 0;\n      this.enabled = true;\n      this.Cues = void 0;\n      this.textTracks = [];\n      this.tracks = [];\n      this.initPTS = [];\n      this.unparsedVttFrags = [];\n      this.captionsTracks = {};\n      this.nonNativeCaptionsTracks = {};\n      this.cea608Parser1 = void 0;\n      this.cea608Parser2 = void 0;\n      this.lastCc = -1;\n      // Last video (CEA-608) fragment CC\n      this.lastSn = -1;\n      // Last video (CEA-608) fragment MSN\n      this.lastPartIndex = -1;\n      // Last video (CEA-608) fragment Part Index\n      this.prevCC = -1;\n      // Last subtitle fragment CC\n      this.vttCCs = newVTTCCs();\n      this.captionsProperties = void 0;\n      this.hls = hls;\n      this.config = hls.config;\n      this.Cues = hls.config.cueHandler;\n      this.captionsProperties = {\n        textTrack1: {\n          label: this.config.captionsTextTrack1Label,\n          languageCode: this.config.captionsTextTrack1LanguageCode\n        },\n        textTrack2: {\n          label: this.config.captionsTextTrack2Label,\n          languageCode: this.config.captionsTextTrack2LanguageCode\n        },\n        textTrack3: {\n          label: this.config.captionsTextTrack3Label,\n          languageCode: this.config.captionsTextTrack3LanguageCode\n        },\n        textTrack4: {\n          label: this.config.captionsTextTrack4Label,\n          languageCode: this.config.captionsTextTrack4LanguageCode\n        }\n      };\n      hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n      hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n      hls.on(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);\n      hls.on(Events.FRAG_LOADING, this.onFragLoading, this);\n      hls.on(Events.FRAG_LOADED, this.onFragLoaded, this);\n      hls.on(Events.FRAG_PARSING_USERDATA, this.onFragParsingUserdata, this);\n      hls.on(Events.FRAG_DECRYPTED, this.onFragDecrypted, this);\n      hls.on(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);\n      hls.on(Events.SUBTITLE_TRACKS_CLEARED, this.onSubtitleTracksCleared, this);\n      hls.on(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n    }\n    var _proto = TimelineController.prototype;\n    _proto.destroy = function destroy() {\n      var hls = this.hls;\n      hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n      hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n      hls.off(Events.SUBTITLE_TRACKS_UPDATED, this.onSubtitleTracksUpdated, this);\n      hls.off(Events.FRAG_LOADING, this.onFragLoading, this);\n      hls.off(Events.FRAG_LOADED, this.onFragLoaded, this);\n      hls.off(Events.FRAG_PARSING_USERDATA, this.onFragParsingUserdata, this);\n      hls.off(Events.FRAG_DECRYPTED, this.onFragDecrypted, this);\n      hls.off(Events.INIT_PTS_FOUND, this.onInitPtsFound, this);\n      hls.off(Events.SUBTITLE_TRACKS_CLEARED, this.onSubtitleTracksCleared, this);\n      hls.off(Events.BUFFER_FLUSHING, this.onBufferFlushing, this);\n      // @ts-ignore\n      this.hls = this.config = null;\n      this.cea608Parser1 = this.cea608Parser2 = undefined;\n    };\n    _proto.initCea608Parsers = function initCea608Parsers() {\n      if (this.config.enableCEA708Captions && (!this.cea608Parser1 || !this.cea608Parser2)) {\n        var channel1 = new OutputFilter(this, 'textTrack1');\n        var channel2 = new OutputFilter(this, 'textTrack2');\n        var channel3 = new OutputFilter(this, 'textTrack3');\n        var channel4 = new OutputFilter(this, 'textTrack4');\n        this.cea608Parser1 = new Cea608Parser(1, channel1, channel2);\n        this.cea608Parser2 = new Cea608Parser(3, channel3, channel4);\n      }\n    };\n    _proto.addCues = function addCues(trackName, startTime, endTime, screen, cueRanges) {\n      // skip cues which overlap more than 50% with previously parsed time ranges\n      var merged = false;\n      for (var i = cueRanges.length; i--;) {\n        var cueRange = cueRanges[i];\n        var overlap = intersection(cueRange[0], cueRange[1], startTime, endTime);\n        if (overlap >= 0) {\n          cueRange[0] = Math.min(cueRange[0], startTime);\n          cueRange[1] = Math.max(cueRange[1], endTime);\n          merged = true;\n          if (overlap / (endTime - startTime) > 0.5) {\n            return;\n          }\n        }\n      }\n      if (!merged) {\n        cueRanges.push([startTime, endTime]);\n      }\n      if (this.config.renderTextTracksNatively) {\n        var track = this.captionsTracks[trackName];\n        this.Cues.newCue(track, startTime, endTime, screen);\n      } else {\n        var cues = this.Cues.newCue(null, startTime, endTime, screen);\n        this.hls.trigger(Events.CUES_PARSED, {\n          type: 'captions',\n          cues: cues,\n          track: trackName\n        });\n      }\n    }\n\n    // Triggered when an initial PTS is found; used for synchronisation of WebVTT.\n    ;\n    _proto.onInitPtsFound = function onInitPtsFound(event, _ref) {\n      var _this = this;\n      var frag = _ref.frag,\n        id = _ref.id,\n        initPTS = _ref.initPTS,\n        timescale = _ref.timescale;\n      var unparsedVttFrags = this.unparsedVttFrags;\n      if (id === 'main') {\n        this.initPTS[frag.cc] = {\n          baseTime: initPTS,\n          timescale: timescale\n        };\n      }\n\n      // Due to asynchronous processing, initial PTS may arrive later than the first VTT fragments are loaded.\n      // Parse any unparsed fragments upon receiving the initial PTS.\n      if (unparsedVttFrags.length) {\n        this.unparsedVttFrags = [];\n        unparsedVttFrags.forEach(function (frag) {\n          _this.onFragLoaded(Events.FRAG_LOADED, frag);\n        });\n      }\n    };\n    _proto.getExistingTrack = function getExistingTrack(label, language) {\n      var media = this.media;\n      if (media) {\n        for (var i = 0; i < media.textTracks.length; i++) {\n          var textTrack = media.textTracks[i];\n          if (canReuseVttTextTrack(textTrack, {\n            name: label,\n            lang: language,\n            attrs: {}\n          })) {\n            return textTrack;\n          }\n        }\n      }\n      return null;\n    };\n    _proto.createCaptionsTrack = function createCaptionsTrack(trackName) {\n      if (this.config.renderTextTracksNatively) {\n        this.createNativeTrack(trackName);\n      } else {\n        this.createNonNativeTrack(trackName);\n      }\n    };\n    _proto.createNativeTrack = function createNativeTrack(trackName) {\n      if (this.captionsTracks[trackName]) {\n        return;\n      }\n      var captionsProperties = this.captionsProperties,\n        captionsTracks = this.captionsTracks,\n        media = this.media;\n      var _captionsProperties$t = captionsProperties[trackName],\n        label = _captionsProperties$t.label,\n        languageCode = _captionsProperties$t.languageCode;\n      // Enable reuse of existing text track.\n      var existingTrack = this.getExistingTrack(label, languageCode);\n      if (!existingTrack) {\n        var textTrack = this.createTextTrack('captions', label, languageCode);\n        if (textTrack) {\n          // Set a special property on the track so we know it's managed by Hls.js\n          textTrack[trackName] = true;\n          captionsTracks[trackName] = textTrack;\n        }\n      } else {\n        captionsTracks[trackName] = existingTrack;\n        clearCurrentCues(captionsTracks[trackName]);\n        sendAddTrackEvent(captionsTracks[trackName], media);\n      }\n    };\n    _proto.createNonNativeTrack = function createNonNativeTrack(trackName) {\n      if (this.nonNativeCaptionsTracks[trackName]) {\n        return;\n      }\n      // Create a list of a single track for the provider to consume\n      var trackProperties = this.captionsProperties[trackName];\n      if (!trackProperties) {\n        return;\n      }\n      var label = trackProperties.label;\n      var track = {\n        _id: trackName,\n        label: label,\n        kind: 'captions',\n        default: trackProperties.media ? !!trackProperties.media.default : false,\n        closedCaptions: trackProperties.media\n      };\n      this.nonNativeCaptionsTracks[trackName] = track;\n      this.hls.trigger(Events.NON_NATIVE_TEXT_TRACKS_FOUND, {\n        tracks: [track]\n      });\n    };\n    _proto.createTextTrack = function createTextTrack(kind, label, lang) {\n      var media = this.media;\n      if (!media) {\n        return;\n      }\n      return media.addTextTrack(kind, label, lang);\n    };\n    _proto.onMediaAttaching = function onMediaAttaching(event, data) {\n      this.media = data.media;\n      this._cleanTracks();\n    };\n    _proto.onMediaDetaching = function onMediaDetaching() {\n      var captionsTracks = this.captionsTracks;\n      Object.keys(captionsTracks).forEach(function (trackName) {\n        clearCurrentCues(captionsTracks[trackName]);\n        delete captionsTracks[trackName];\n      });\n      this.nonNativeCaptionsTracks = {};\n    };\n    _proto.onManifestLoading = function onManifestLoading() {\n      // Detect discontinuity in video fragment (CEA-608) parsing\n      this.lastCc = -1;\n      this.lastSn = -1;\n      this.lastPartIndex = -1;\n      // Detect discontinuity in subtitle manifests\n      this.prevCC = -1;\n      this.vttCCs = newVTTCCs();\n      // Reset tracks\n      this._cleanTracks();\n      this.tracks = [];\n      this.captionsTracks = {};\n      this.nonNativeCaptionsTracks = {};\n      this.textTracks = [];\n      this.unparsedVttFrags = [];\n      this.initPTS = [];\n      if (this.cea608Parser1 && this.cea608Parser2) {\n        this.cea608Parser1.reset();\n        this.cea608Parser2.reset();\n      }\n    };\n    _proto._cleanTracks = function _cleanTracks() {\n      // clear outdated subtitles\n      var media = this.media;\n      if (!media) {\n        return;\n      }\n      var textTracks = media.textTracks;\n      if (textTracks) {\n        for (var i = 0; i < textTracks.length; i++) {\n          clearCurrentCues(textTracks[i]);\n        }\n      }\n    };\n    _proto.onSubtitleTracksUpdated = function onSubtitleTracksUpdated(event, data) {\n      var _this2 = this;\n      var tracks = data.subtitleTracks || [];\n      var hasIMSC1 = tracks.some(function (track) {\n        return track.textCodec === IMSC1_CODEC;\n      });\n      if (this.config.enableWebVTT || hasIMSC1 && this.config.enableIMSC1) {\n        var listIsIdentical = subtitleOptionsIdentical(this.tracks, tracks);\n        if (listIsIdentical) {\n          this.tracks = tracks;\n          return;\n        }\n        this.textTracks = [];\n        this.tracks = tracks;\n        if (this.config.renderTextTracksNatively) {\n          var media = this.media;\n          var inUseTracks = media ? filterSubtitleTracks(media.textTracks) : null;\n          this.tracks.forEach(function (track, index) {\n            // Reuse tracks with the same label and lang, but do not reuse 608/708 tracks\n            var textTrack;\n            if (inUseTracks) {\n              var inUseTrack = null;\n              for (var i = 0; i < inUseTracks.length; i++) {\n                if (inUseTracks[i] && canReuseVttTextTrack(inUseTracks[i], track)) {\n                  inUseTrack = inUseTracks[i];\n                  inUseTracks[i] = null;\n                  break;\n                }\n              }\n              if (inUseTrack) {\n                textTrack = inUseTrack;\n              }\n            }\n            if (textTrack) {\n              clearCurrentCues(textTrack);\n            } else {\n              var textTrackKind = captionsOrSubtitlesFromCharacteristics(track);\n              textTrack = _this2.createTextTrack(textTrackKind, track.name, track.lang);\n              if (textTrack) {\n                textTrack.mode = 'disabled';\n              }\n            }\n            if (textTrack) {\n              _this2.textTracks.push(textTrack);\n            }\n          });\n          // Warn when video element has captions or subtitle TextTracks carried over from another source\n          if (inUseTracks != null && inUseTracks.length) {\n            var unusedTextTracks = inUseTracks.filter(function (t) {\n              return t !== null;\n            }).map(function (t) {\n              return t.label;\n            });\n            if (unusedTextTracks.length) {\n              logger.warn(\"Media element contains unused subtitle tracks: \" + unusedTextTracks.join(', ') + \". Replace media element for each source to clear TextTracks and captions menu.\");\n            }\n          }\n        } else if (this.tracks.length) {\n          // Create a list of tracks for the provider to consume\n          var tracksList = this.tracks.map(function (track) {\n            return {\n              label: track.name,\n              kind: track.type.toLowerCase(),\n              default: track.default,\n              subtitleTrack: track\n            };\n          });\n          this.hls.trigger(Events.NON_NATIVE_TEXT_TRACKS_FOUND, {\n            tracks: tracksList\n          });\n        }\n      }\n    };\n    _proto.onManifestLoaded = function onManifestLoaded(event, data) {\n      var _this3 = this;\n      if (this.config.enableCEA708Captions && data.captions) {\n        data.captions.forEach(function (captionsTrack) {\n          var instreamIdMatch = /(?:CC|SERVICE)([1-4])/.exec(captionsTrack.instreamId);\n          if (!instreamIdMatch) {\n            return;\n          }\n          var trackName = \"textTrack\" + instreamIdMatch[1];\n          var trackProperties = _this3.captionsProperties[trackName];\n          if (!trackProperties) {\n            return;\n          }\n          trackProperties.label = captionsTrack.name;\n          if (captionsTrack.lang) {\n            // optional attribute\n            trackProperties.languageCode = captionsTrack.lang;\n          }\n          trackProperties.media = captionsTrack;\n        });\n      }\n    };\n    _proto.closedCaptionsForLevel = function closedCaptionsForLevel(frag) {\n      var level = this.hls.levels[frag.level];\n      return level == null ? void 0 : level.attrs['CLOSED-CAPTIONS'];\n    };\n    _proto.onFragLoading = function onFragLoading(event, data) {\n      // if this frag isn't contiguous, clear the parser so cues with bad start/end times aren't added to the textTrack\n      if (this.enabled && data.frag.type === PlaylistLevelType.MAIN) {\n        var _data$part$index, _data$part;\n        var cea608Parser1 = this.cea608Parser1,\n          cea608Parser2 = this.cea608Parser2,\n          lastSn = this.lastSn;\n        var _data$frag = data.frag,\n          cc = _data$frag.cc,\n          sn = _data$frag.sn;\n        var partIndex = (_data$part$index = (_data$part = data.part) == null ? void 0 : _data$part.index) != null ? _data$part$index : -1;\n        if (cea608Parser1 && cea608Parser2) {\n          if (sn !== lastSn + 1 || sn === lastSn && partIndex !== this.lastPartIndex + 1 || cc !== this.lastCc) {\n            cea608Parser1.reset();\n            cea608Parser2.reset();\n          }\n        }\n        this.lastCc = cc;\n        this.lastSn = sn;\n        this.lastPartIndex = partIndex;\n      }\n    };\n    _proto.onFragLoaded = function onFragLoaded(event, data) {\n      var frag = data.frag,\n        payload = data.payload;\n      if (frag.type === PlaylistLevelType.SUBTITLE) {\n        // If fragment is subtitle type, parse as WebVTT.\n        if (payload.byteLength) {\n          var decryptData = frag.decryptdata;\n          // fragment after decryption has a stats object\n          var decrypted = ('stats' in data);\n          // If the subtitles are not encrypted, parse VTTs now. Otherwise, we need to wait.\n          if (decryptData == null || !decryptData.encrypted || decrypted) {\n            var trackPlaylistMedia = this.tracks[frag.level];\n            var vttCCs = this.vttCCs;\n            if (!vttCCs[frag.cc]) {\n              vttCCs[frag.cc] = {\n                start: frag.start,\n                prevCC: this.prevCC,\n                new: true\n              };\n              this.prevCC = frag.cc;\n            }\n            if (trackPlaylistMedia && trackPlaylistMedia.textCodec === IMSC1_CODEC) {\n              this._parseIMSC1(frag, payload);\n            } else {\n              this._parseVTTs(data);\n            }\n          }\n        } else {\n          // In case there is no payload, finish unsuccessfully.\n          this.hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n            success: false,\n            frag: frag,\n            error: new Error('Empty subtitle payload')\n          });\n        }\n      }\n    };\n    _proto._parseIMSC1 = function _parseIMSC1(frag, payload) {\n      var _this4 = this;\n      var hls = this.hls;\n      parseIMSC1(payload, this.initPTS[frag.cc], function (cues) {\n        _this4._appendCues(cues, frag.level);\n        hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n          success: true,\n          frag: frag\n        });\n      }, function (error) {\n        logger.log(\"Failed to parse IMSC1: \" + error);\n        hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n          success: false,\n          frag: frag,\n          error: error\n        });\n      });\n    };\n    _proto._parseVTTs = function _parseVTTs(data) {\n      var _frag$initSegment,\n        _this5 = this;\n      var frag = data.frag,\n        payload = data.payload;\n      // We need an initial synchronisation PTS. Store fragments as long as none has arrived\n      var initPTS = this.initPTS,\n        unparsedVttFrags = this.unparsedVttFrags;\n      var maxAvCC = initPTS.length - 1;\n      if (!initPTS[frag.cc] && maxAvCC === -1) {\n        unparsedVttFrags.push(data);\n        return;\n      }\n      var hls = this.hls;\n      // Parse the WebVTT file contents.\n      var payloadWebVTT = (_frag$initSegment = frag.initSegment) != null && _frag$initSegment.data ? appendUint8Array(frag.initSegment.data, new Uint8Array(payload)) : payload;\n      parseWebVTT(payloadWebVTT, this.initPTS[frag.cc], this.vttCCs, frag.cc, frag.start, function (cues) {\n        _this5._appendCues(cues, frag.level);\n        hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n          success: true,\n          frag: frag\n        });\n      }, function (error) {\n        var missingInitPTS = error.message === 'Missing initPTS for VTT MPEGTS';\n        if (missingInitPTS) {\n          unparsedVttFrags.push(data);\n        } else {\n          _this5._fallbackToIMSC1(frag, payload);\n        }\n        // Something went wrong while parsing. Trigger event with success false.\n        logger.log(\"Failed to parse VTT cue: \" + error);\n        if (missingInitPTS && maxAvCC > frag.cc) {\n          return;\n        }\n        hls.trigger(Events.SUBTITLE_FRAG_PROCESSED, {\n          success: false,\n          frag: frag,\n          error: error\n        });\n      });\n    };\n    _proto._fallbackToIMSC1 = function _fallbackToIMSC1(frag, payload) {\n      var _this6 = this;\n      // If textCodec is unknown, try parsing as IMSC1. Set textCodec based on the result\n      var trackPlaylistMedia = this.tracks[frag.level];\n      if (!trackPlaylistMedia.textCodec) {\n        parseIMSC1(payload, this.initPTS[frag.cc], function () {\n          trackPlaylistMedia.textCodec = IMSC1_CODEC;\n          _this6._parseIMSC1(frag, payload);\n        }, function () {\n          trackPlaylistMedia.textCodec = 'wvtt';\n        });\n      }\n    };\n    _proto._appendCues = function _appendCues(cues, fragLevel) {\n      var hls = this.hls;\n      if (this.config.renderTextTracksNatively) {\n        var textTrack = this.textTracks[fragLevel];\n        // WebVTTParser.parse is an async method and if the currently selected text track mode is set to \"disabled\"\n        // before parsing is done then don't try to access currentTrack.cues.getCueById as cues will be null\n        // and trying to access getCueById method of cues will throw an exception\n        // Because we check if the mode is disabled, we can force check `cues` below. They can't be null.\n        if (!textTrack || textTrack.mode === 'disabled') {\n          return;\n        }\n        cues.forEach(function (cue) {\n          return addCueToTrack(textTrack, cue);\n        });\n      } else {\n        var currentTrack = this.tracks[fragLevel];\n        if (!currentTrack) {\n          return;\n        }\n        var track = currentTrack.default ? 'default' : 'subtitles' + fragLevel;\n        hls.trigger(Events.CUES_PARSED, {\n          type: 'subtitles',\n          cues: cues,\n          track: track\n        });\n      }\n    };\n    _proto.onFragDecrypted = function onFragDecrypted(event, data) {\n      var frag = data.frag;\n      if (frag.type === PlaylistLevelType.SUBTITLE) {\n        this.onFragLoaded(Events.FRAG_LOADED, data);\n      }\n    };\n    _proto.onSubtitleTracksCleared = function onSubtitleTracksCleared() {\n      this.tracks = [];\n      this.captionsTracks = {};\n    };\n    _proto.onFragParsingUserdata = function onFragParsingUserdata(event, data) {\n      this.initCea608Parsers();\n      var cea608Parser1 = this.cea608Parser1,\n        cea608Parser2 = this.cea608Parser2;\n      if (!this.enabled || !cea608Parser1 || !cea608Parser2) {\n        return;\n      }\n      var frag = data.frag,\n        samples = data.samples;\n      if (frag.type === PlaylistLevelType.MAIN && this.closedCaptionsForLevel(frag) === 'NONE') {\n        return;\n      }\n      // If the event contains captions (found in the bytes property), push all bytes into the parser immediately\n      // It will create the proper timestamps based on the PTS value\n      for (var i = 0; i < samples.length; i++) {\n        var ccBytes = samples[i].bytes;\n        if (ccBytes) {\n          var ccdatas = this.extractCea608Data(ccBytes);\n          cea608Parser1.addData(samples[i].pts, ccdatas[0]);\n          cea608Parser2.addData(samples[i].pts, ccdatas[1]);\n        }\n      }\n    };\n    _proto.onBufferFlushing = function onBufferFlushing(event, _ref2) {\n      var startOffset = _ref2.startOffset,\n        endOffset = _ref2.endOffset,\n        endOffsetSubtitles = _ref2.endOffsetSubtitles,\n        type = _ref2.type;\n      var media = this.media;\n      if (!media || media.currentTime < endOffset) {\n        return;\n      }\n      // Clear 608 caption cues from the captions TextTracks when the video back buffer is flushed\n      // Forward cues are never removed because we can loose streamed 608 content from recent fragments\n      if (!type || type === 'video') {\n        var captionsTracks = this.captionsTracks;\n        Object.keys(captionsTracks).forEach(function (trackName) {\n          return removeCuesInRange(captionsTracks[trackName], startOffset, endOffset);\n        });\n      }\n      if (this.config.renderTextTracksNatively) {\n        // Clear VTT/IMSC1 subtitle cues from the subtitle TextTracks when the back buffer is flushed\n        if (startOffset === 0 && endOffsetSubtitles !== undefined) {\n          var textTracks = this.textTracks;\n          Object.keys(textTracks).forEach(function (trackName) {\n            return removeCuesInRange(textTracks[trackName], startOffset, endOffsetSubtitles);\n          });\n        }\n      }\n    };\n    _proto.extractCea608Data = function extractCea608Data(byteArray) {\n      var actualCCBytes = [[], []];\n      var count = byteArray[0] & 0x1f;\n      var position = 2;\n      for (var j = 0; j < count; j++) {\n        var tmpByte = byteArray[position++];\n        var ccbyte1 = 0x7f & byteArray[position++];\n        var ccbyte2 = 0x7f & byteArray[position++];\n        if (ccbyte1 === 0 && ccbyte2 === 0) {\n          continue;\n        }\n        var ccValid = (0x04 & tmpByte) !== 0; // Support all four channels\n        if (ccValid) {\n          var ccType = 0x03 & tmpByte;\n          if (0x00 /* CEA608 field1*/ === ccType || 0x01 /* CEA608 field2*/ === ccType) {\n            // Exclude CEA708 CC data.\n            actualCCBytes[ccType].push(ccbyte1);\n            actualCCBytes[ccType].push(ccbyte2);\n          }\n        }\n      }\n      return actualCCBytes;\n    };\n    return TimelineController;\n  }();\n  function captionsOrSubtitlesFromCharacteristics(track) {\n    if (track.characteristics) {\n      if (/transcribes-spoken-dialog/gi.test(track.characteristics) && /describes-music-and-sound/gi.test(track.characteristics)) {\n        return 'captions';\n      }\n    }\n    return 'subtitles';\n  }\n  function canReuseVttTextTrack(inUseTrack, manifestTrack) {\n    return !!inUseTrack && inUseTrack.kind === captionsOrSubtitlesFromCharacteristics(manifestTrack) && subtitleTrackMatchesTextTrack(manifestTrack, inUseTrack);\n  }\n  function intersection(x1, x2, y1, y2) {\n    return Math.min(x2, y2) - Math.max(x1, y1);\n  }\n  function newVTTCCs() {\n    return {\n      ccOffset: 0,\n      presentationOffset: 0,\n      0: {\n        start: 0,\n        prevCC: -1,\n        new: true\n      }\n    };\n  }\n\n  var CapLevelController = /*#__PURE__*/function () {\n    function CapLevelController(hls) {\n      this.hls = void 0;\n      this.autoLevelCapping = void 0;\n      this.firstLevel = void 0;\n      this.media = void 0;\n      this.restrictedLevels = void 0;\n      this.timer = void 0;\n      this.clientRect = void 0;\n      this.streamController = void 0;\n      this.hls = hls;\n      this.autoLevelCapping = Number.POSITIVE_INFINITY;\n      this.firstLevel = -1;\n      this.media = null;\n      this.restrictedLevels = [];\n      this.timer = undefined;\n      this.clientRect = null;\n      this.registerListeners();\n    }\n    var _proto = CapLevelController.prototype;\n    _proto.setStreamController = function setStreamController(streamController) {\n      this.streamController = streamController;\n    };\n    _proto.destroy = function destroy() {\n      if (this.hls) {\n        this.unregisterListener();\n      }\n      if (this.timer) {\n        this.stopCapping();\n      }\n      this.media = null;\n      this.clientRect = null;\n      // @ts-ignore\n      this.hls = this.streamController = null;\n    };\n    _proto.registerListeners = function registerListeners() {\n      var hls = this.hls;\n      hls.on(Events.FPS_DROP_LEVEL_CAPPING, this.onFpsDropLevelCapping, this);\n      hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n      hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n      hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n      hls.on(Events.BUFFER_CODECS, this.onBufferCodecs, this);\n      hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    };\n    _proto.unregisterListener = function unregisterListener() {\n      var hls = this.hls;\n      hls.off(Events.FPS_DROP_LEVEL_CAPPING, this.onFpsDropLevelCapping, this);\n      hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n      hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n      hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n      hls.off(Events.BUFFER_CODECS, this.onBufferCodecs, this);\n      hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n    };\n    _proto.onFpsDropLevelCapping = function onFpsDropLevelCapping(event, data) {\n      // Don't add a restricted level more than once\n      var level = this.hls.levels[data.droppedLevel];\n      if (this.isLevelAllowed(level)) {\n        this.restrictedLevels.push({\n          bitrate: level.bitrate,\n          height: level.height,\n          width: level.width\n        });\n      }\n    };\n    _proto.onMediaAttaching = function onMediaAttaching(event, data) {\n      this.media = data.media instanceof HTMLVideoElement ? data.media : null;\n      this.clientRect = null;\n      if (this.timer && this.hls.levels.length) {\n        this.detectPlayerSize();\n      }\n    };\n    _proto.onManifestParsed = function onManifestParsed(event, data) {\n      var hls = this.hls;\n      this.restrictedLevels = [];\n      this.firstLevel = data.firstLevel;\n      if (hls.config.capLevelToPlayerSize && data.video) {\n        // Start capping immediately if the manifest has signaled video codecs\n        this.startCapping();\n      }\n    };\n    _proto.onLevelsUpdated = function onLevelsUpdated(event, data) {\n      if (this.timer && isFiniteNumber(this.autoLevelCapping)) {\n        this.detectPlayerSize();\n      }\n    }\n\n    // Only activate capping when playing a video stream; otherwise, multi-bitrate audio-only streams will be restricted\n    // to the first level\n    ;\n    _proto.onBufferCodecs = function onBufferCodecs(event, data) {\n      var hls = this.hls;\n      if (hls.config.capLevelToPlayerSize && data.video) {\n        // If the manifest did not signal a video codec capping has been deferred until we're certain video is present\n        this.startCapping();\n      }\n    };\n    _proto.onMediaDetaching = function onMediaDetaching() {\n      this.stopCapping();\n    };\n    _proto.detectPlayerSize = function detectPlayerSize() {\n      if (this.media) {\n        if (this.mediaHeight <= 0 || this.mediaWidth <= 0) {\n          this.clientRect = null;\n          return;\n        }\n        var levels = this.hls.levels;\n        if (levels.length) {\n          var hls = this.hls;\n          var maxLevel = this.getMaxLevel(levels.length - 1);\n          if (maxLevel !== this.autoLevelCapping) {\n            logger.log(\"Setting autoLevelCapping to \" + maxLevel + \": \" + levels[maxLevel].height + \"p@\" + levels[maxLevel].bitrate + \" for media \" + this.mediaWidth + \"x\" + this.mediaHeight);\n          }\n          hls.autoLevelCapping = maxLevel;\n          if (hls.autoLevelCapping > this.autoLevelCapping && this.streamController) {\n            // if auto level capping has a higher value for the previous one, flush the buffer using nextLevelSwitch\n            // usually happen when the user go to the fullscreen mode.\n            this.streamController.nextLevelSwitch();\n          }\n          this.autoLevelCapping = hls.autoLevelCapping;\n        }\n      }\n    }\n\n    /*\n     * returns level should be the one with the dimensions equal or greater than the media (player) dimensions (so the video will be downscaled)\n     */;\n    _proto.getMaxLevel = function getMaxLevel(capLevelIndex) {\n      var _this = this;\n      var levels = this.hls.levels;\n      if (!levels.length) {\n        return -1;\n      }\n      var validLevels = levels.filter(function (level, index) {\n        return _this.isLevelAllowed(level) && index <= capLevelIndex;\n      });\n      this.clientRect = null;\n      return CapLevelController.getMaxLevelByMediaSize(validLevels, this.mediaWidth, this.mediaHeight);\n    };\n    _proto.startCapping = function startCapping() {\n      if (this.timer) {\n        // Don't reset capping if started twice; this can happen if the manifest signals a video codec\n        return;\n      }\n      this.autoLevelCapping = Number.POSITIVE_INFINITY;\n      self.clearInterval(this.timer);\n      this.timer = self.setInterval(this.detectPlayerSize.bind(this), 1000);\n      this.detectPlayerSize();\n    };\n    _proto.stopCapping = function stopCapping() {\n      this.restrictedLevels = [];\n      this.firstLevel = -1;\n      this.autoLevelCapping = Number.POSITIVE_INFINITY;\n      if (this.timer) {\n        self.clearInterval(this.timer);\n        this.timer = undefined;\n      }\n    };\n    _proto.getDimensions = function getDimensions() {\n      if (this.clientRect) {\n        return this.clientRect;\n      }\n      var media = this.media;\n      var boundsRect = {\n        width: 0,\n        height: 0\n      };\n      if (media) {\n        var clientRect = media.getBoundingClientRect();\n        boundsRect.width = clientRect.width;\n        boundsRect.height = clientRect.height;\n        if (!boundsRect.width && !boundsRect.height) {\n          // When the media element has no width or height (equivalent to not being in the DOM),\n          // then use its width and height attributes (media.width, media.height)\n          boundsRect.width = clientRect.right - clientRect.left || media.width || 0;\n          boundsRect.height = clientRect.bottom - clientRect.top || media.height || 0;\n        }\n      }\n      this.clientRect = boundsRect;\n      return boundsRect;\n    };\n    _proto.isLevelAllowed = function isLevelAllowed(level) {\n      var restrictedLevels = this.restrictedLevels;\n      return !restrictedLevels.some(function (restrictedLevel) {\n        return level.bitrate === restrictedLevel.bitrate && level.width === restrictedLevel.width && level.height === restrictedLevel.height;\n      });\n    };\n    CapLevelController.getMaxLevelByMediaSize = function getMaxLevelByMediaSize(levels, width, height) {\n      if (!(levels != null && levels.length)) {\n        return -1;\n      }\n\n      // Levels can have the same dimensions but differing bandwidths - since levels are ordered, we can look to the next\n      // to determine whether we've chosen the greatest bandwidth for the media's dimensions\n      var atGreatestBandwidth = function atGreatestBandwidth(curLevel, nextLevel) {\n        if (!nextLevel) {\n          return true;\n        }\n        return curLevel.width !== nextLevel.width || curLevel.height !== nextLevel.height;\n      };\n\n      // If we run through the loop without breaking, the media's dimensions are greater than every level, so default to\n      // the max level\n      var maxLevelIndex = levels.length - 1;\n      // Prevent changes in aspect-ratio from causing capping to toggle back and forth\n      var squareSize = Math.max(width, height);\n      for (var i = 0; i < levels.length; i += 1) {\n        var level = levels[i];\n        if ((level.width >= squareSize || level.height >= squareSize) && atGreatestBandwidth(level, levels[i + 1])) {\n          maxLevelIndex = i;\n          break;\n        }\n      }\n      return maxLevelIndex;\n    };\n    _createClass(CapLevelController, [{\n      key: \"mediaWidth\",\n      get: function get() {\n        return this.getDimensions().width * this.contentScaleFactor;\n      }\n    }, {\n      key: \"mediaHeight\",\n      get: function get() {\n        return this.getDimensions().height * this.contentScaleFactor;\n      }\n    }, {\n      key: \"contentScaleFactor\",\n      get: function get() {\n        var pixelRatio = 1;\n        if (!this.hls.config.ignoreDevicePixelRatio) {\n          try {\n            pixelRatio = self.devicePixelRatio;\n          } catch (e) {\n            /* no-op */\n          }\n        }\n        return pixelRatio;\n      }\n    }]);\n    return CapLevelController;\n  }();\n\n  var FPSController = /*#__PURE__*/function () {\n    function FPSController(hls) {\n      this.hls = void 0;\n      this.isVideoPlaybackQualityAvailable = false;\n      this.timer = void 0;\n      this.media = null;\n      this.lastTime = void 0;\n      this.lastDroppedFrames = 0;\n      this.lastDecodedFrames = 0;\n      // stream controller must be provided as a dependency!\n      this.streamController = void 0;\n      this.hls = hls;\n      this.registerListeners();\n    }\n    var _proto = FPSController.prototype;\n    _proto.setStreamController = function setStreamController(streamController) {\n      this.streamController = streamController;\n    };\n    _proto.registerListeners = function registerListeners() {\n      this.hls.on(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    };\n    _proto.unregisterListeners = function unregisterListeners() {\n      this.hls.off(Events.MEDIA_ATTACHING, this.onMediaAttaching, this);\n    };\n    _proto.destroy = function destroy() {\n      if (this.timer) {\n        clearInterval(this.timer);\n      }\n      this.unregisterListeners();\n      this.isVideoPlaybackQualityAvailable = false;\n      this.media = null;\n    };\n    _proto.onMediaAttaching = function onMediaAttaching(event, data) {\n      var config = this.hls.config;\n      if (config.capLevelOnFPSDrop) {\n        var media = data.media instanceof self.HTMLVideoElement ? data.media : null;\n        this.media = media;\n        if (media && typeof media.getVideoPlaybackQuality === 'function') {\n          this.isVideoPlaybackQualityAvailable = true;\n        }\n        self.clearInterval(this.timer);\n        this.timer = self.setInterval(this.checkFPSInterval.bind(this), config.fpsDroppedMonitoringPeriod);\n      }\n    };\n    _proto.checkFPS = function checkFPS(video, decodedFrames, droppedFrames) {\n      var currentTime = performance.now();\n      if (decodedFrames) {\n        if (this.lastTime) {\n          var currentPeriod = currentTime - this.lastTime;\n          var currentDropped = droppedFrames - this.lastDroppedFrames;\n          var currentDecoded = decodedFrames - this.lastDecodedFrames;\n          var droppedFPS = 1000 * currentDropped / currentPeriod;\n          var hls = this.hls;\n          hls.trigger(Events.FPS_DROP, {\n            currentDropped: currentDropped,\n            currentDecoded: currentDecoded,\n            totalDroppedFrames: droppedFrames\n          });\n          if (droppedFPS > 0) {\n            // logger.log('checkFPS : droppedFPS/decodedFPS:' + droppedFPS/(1000 * currentDecoded / currentPeriod));\n            if (currentDropped > hls.config.fpsDroppedMonitoringThreshold * currentDecoded) {\n              var currentLevel = hls.currentLevel;\n              logger.warn('drop FPS ratio greater than max allowed value for currentLevel: ' + currentLevel);\n              if (currentLevel > 0 && (hls.autoLevelCapping === -1 || hls.autoLevelCapping >= currentLevel)) {\n                currentLevel = currentLevel - 1;\n                hls.trigger(Events.FPS_DROP_LEVEL_CAPPING, {\n                  level: currentLevel,\n                  droppedLevel: hls.currentLevel\n                });\n                hls.autoLevelCapping = currentLevel;\n                this.streamController.nextLevelSwitch();\n              }\n            }\n          }\n        }\n        this.lastTime = currentTime;\n        this.lastDroppedFrames = droppedFrames;\n        this.lastDecodedFrames = decodedFrames;\n      }\n    };\n    _proto.checkFPSInterval = function checkFPSInterval() {\n      var video = this.media;\n      if (video) {\n        if (this.isVideoPlaybackQualityAvailable) {\n          var videoPlaybackQuality = video.getVideoPlaybackQuality();\n          this.checkFPS(video, videoPlaybackQuality.totalVideoFrames, videoPlaybackQuality.droppedVideoFrames);\n        } else {\n          // HTMLVideoElement doesn't include the webkit types\n          this.checkFPS(video, video.webkitDecodedFrameCount, video.webkitDroppedFrameCount);\n        }\n      }\n    };\n    return FPSController;\n  }();\n\n  var LOGGER_PREFIX = '[eme]';\n  /**\n   * Controller to deal with encrypted media extensions (EME)\n   * @see https://developer.mozilla.org/en-US/docs/Web/API/Encrypted_Media_Extensions_API\n   *\n   * @class\n   * @constructor\n   */\n  var EMEController = /*#__PURE__*/function () {\n    function EMEController(hls) {\n      this.hls = void 0;\n      this.config = void 0;\n      this.media = null;\n      this.keyFormatPromise = null;\n      this.keySystemAccessPromises = {};\n      this._requestLicenseFailureCount = 0;\n      this.mediaKeySessions = [];\n      this.keyIdToKeySessionPromise = {};\n      this.setMediaKeysQueue = EMEController.CDMCleanupPromise ? [EMEController.CDMCleanupPromise] : [];\n      this.onMediaEncrypted = this._onMediaEncrypted.bind(this);\n      this.onWaitingForKey = this._onWaitingForKey.bind(this);\n      this.debug = logger.debug.bind(logger, LOGGER_PREFIX);\n      this.log = logger.log.bind(logger, LOGGER_PREFIX);\n      this.warn = logger.warn.bind(logger, LOGGER_PREFIX);\n      this.error = logger.error.bind(logger, LOGGER_PREFIX);\n      this.hls = hls;\n      this.config = hls.config;\n      this.registerListeners();\n    }\n    var _proto = EMEController.prototype;\n    _proto.destroy = function destroy() {\n      this.unregisterListeners();\n      this.onMediaDetached();\n      // Remove any references that could be held in config options or callbacks\n      var config = this.config;\n      config.requestMediaKeySystemAccessFunc = null;\n      config.licenseXhrSetup = config.licenseResponseCallback = undefined;\n      config.drmSystems = config.drmSystemOptions = {};\n      // @ts-ignore\n      this.hls = this.onMediaEncrypted = this.onWaitingForKey = this.keyIdToKeySessionPromise = null;\n      // @ts-ignore\n      this.config = null;\n    };\n    _proto.registerListeners = function registerListeners() {\n      this.hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      this.hls.on(Events.MEDIA_DETACHED, this.onMediaDetached, this);\n      this.hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      this.hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    };\n    _proto.unregisterListeners = function unregisterListeners() {\n      this.hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      this.hls.off(Events.MEDIA_DETACHED, this.onMediaDetached, this);\n      this.hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      this.hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n    };\n    _proto.getLicenseServerUrl = function getLicenseServerUrl(keySystem) {\n      var _this$config = this.config,\n        drmSystems = _this$config.drmSystems,\n        widevineLicenseUrl = _this$config.widevineLicenseUrl;\n      var keySystemConfiguration = drmSystems[keySystem];\n      if (keySystemConfiguration) {\n        return keySystemConfiguration.licenseUrl;\n      }\n\n      // For backward compatibility\n      if (keySystem === KeySystems.WIDEVINE && widevineLicenseUrl) {\n        return widevineLicenseUrl;\n      }\n      throw new Error(\"no license server URL configured for key-system \\\"\" + keySystem + \"\\\"\");\n    };\n    _proto.getServerCertificateUrl = function getServerCertificateUrl(keySystem) {\n      var drmSystems = this.config.drmSystems;\n      var keySystemConfiguration = drmSystems[keySystem];\n      if (keySystemConfiguration) {\n        return keySystemConfiguration.serverCertificateUrl;\n      } else {\n        this.log(\"No Server Certificate in config.drmSystems[\\\"\" + keySystem + \"\\\"]\");\n      }\n    };\n    _proto.attemptKeySystemAccess = function attemptKeySystemAccess(keySystemsToAttempt) {\n      var _this = this;\n      var levels = this.hls.levels;\n      var uniqueCodec = function uniqueCodec(value, i, a) {\n        return !!value && a.indexOf(value) === i;\n      };\n      var audioCodecs = levels.map(function (level) {\n        return level.audioCodec;\n      }).filter(uniqueCodec);\n      var videoCodecs = levels.map(function (level) {\n        return level.videoCodec;\n      }).filter(uniqueCodec);\n      if (audioCodecs.length + videoCodecs.length === 0) {\n        videoCodecs.push('avc1.42e01e');\n      }\n      return new Promise(function (resolve, reject) {\n        var attempt = function attempt(keySystems) {\n          var keySystem = keySystems.shift();\n          _this.getMediaKeysPromise(keySystem, audioCodecs, videoCodecs).then(function (mediaKeys) {\n            return resolve({\n              keySystem: keySystem,\n              mediaKeys: mediaKeys\n            });\n          }).catch(function (error) {\n            if (keySystems.length) {\n              attempt(keySystems);\n            } else if (error instanceof EMEKeyError) {\n              reject(error);\n            } else {\n              reject(new EMEKeyError({\n                type: ErrorTypes.KEY_SYSTEM_ERROR,\n                details: ErrorDetails.KEY_SYSTEM_NO_ACCESS,\n                error: error,\n                fatal: true\n              }, error.message));\n            }\n          });\n        };\n        attempt(keySystemsToAttempt);\n      });\n    };\n    _proto.requestMediaKeySystemAccess = function requestMediaKeySystemAccess$1(keySystem, supportedConfigurations) {\n      var requestMediaKeySystemAccessFunc = this.config.requestMediaKeySystemAccessFunc;\n      if (!(typeof requestMediaKeySystemAccessFunc === 'function')) {\n        var errMessage = \"Configured requestMediaKeySystemAccess is not a function \" + requestMediaKeySystemAccessFunc;\n        if (requestMediaKeySystemAccess === null && self.location.protocol === 'http:') {\n          errMessage = \"navigator.requestMediaKeySystemAccess is not available over insecure protocol \" + location.protocol;\n        }\n        return Promise.reject(new Error(errMessage));\n      }\n      return requestMediaKeySystemAccessFunc(keySystem, supportedConfigurations);\n    };\n    _proto.getMediaKeysPromise = function getMediaKeysPromise(keySystem, audioCodecs, videoCodecs) {\n      var _this2 = this;\n      // This can throw, but is caught in event handler callpath\n      var mediaKeySystemConfigs = getSupportedMediaKeySystemConfigurations(keySystem, audioCodecs, videoCodecs, this.config.drmSystemOptions);\n      var keySystemAccessPromises = this.keySystemAccessPromises[keySystem];\n      var keySystemAccess = keySystemAccessPromises == null ? void 0 : keySystemAccessPromises.keySystemAccess;\n      if (!keySystemAccess) {\n        this.log(\"Requesting encrypted media \\\"\" + keySystem + \"\\\" key-system access with config: \" + JSON.stringify(mediaKeySystemConfigs));\n        keySystemAccess = this.requestMediaKeySystemAccess(keySystem, mediaKeySystemConfigs);\n        var _keySystemAccessPromises = this.keySystemAccessPromises[keySystem] = {\n          keySystemAccess: keySystemAccess\n        };\n        keySystemAccess.catch(function (error) {\n          _this2.log(\"Failed to obtain access to key-system \\\"\" + keySystem + \"\\\": \" + error);\n        });\n        return keySystemAccess.then(function (mediaKeySystemAccess) {\n          _this2.log(\"Access for key-system \\\"\" + mediaKeySystemAccess.keySystem + \"\\\" obtained\");\n          var certificateRequest = _this2.fetchServerCertificate(keySystem);\n          _this2.log(\"Create media-keys for \\\"\" + keySystem + \"\\\"\");\n          _keySystemAccessPromises.mediaKeys = mediaKeySystemAccess.createMediaKeys().then(function (mediaKeys) {\n            _this2.log(\"Media-keys created for \\\"\" + keySystem + \"\\\"\");\n            return certificateRequest.then(function (certificate) {\n              if (certificate) {\n                return _this2.setMediaKeysServerCertificate(mediaKeys, keySystem, certificate);\n              }\n              return mediaKeys;\n            });\n          });\n          _keySystemAccessPromises.mediaKeys.catch(function (error) {\n            _this2.error(\"Failed to create media-keys for \\\"\" + keySystem + \"\\\"}: \" + error);\n          });\n          return _keySystemAccessPromises.mediaKeys;\n        });\n      }\n      return keySystemAccess.then(function () {\n        return keySystemAccessPromises.mediaKeys;\n      });\n    };\n    _proto.createMediaKeySessionContext = function createMediaKeySessionContext(_ref) {\n      var decryptdata = _ref.decryptdata,\n        keySystem = _ref.keySystem,\n        mediaKeys = _ref.mediaKeys;\n      this.log(\"Creating key-system session \\\"\" + keySystem + \"\\\" keyId: \" + Hex.hexDump(decryptdata.keyId || []));\n      var mediaKeysSession = mediaKeys.createSession();\n      var mediaKeySessionContext = {\n        decryptdata: decryptdata,\n        keySystem: keySystem,\n        mediaKeys: mediaKeys,\n        mediaKeysSession: mediaKeysSession,\n        keyStatus: 'status-pending'\n      };\n      this.mediaKeySessions.push(mediaKeySessionContext);\n      return mediaKeySessionContext;\n    };\n    _proto.renewKeySession = function renewKeySession(mediaKeySessionContext) {\n      var decryptdata = mediaKeySessionContext.decryptdata;\n      if (decryptdata.pssh) {\n        var keySessionContext = this.createMediaKeySessionContext(mediaKeySessionContext);\n        var _keyId = this.getKeyIdString(decryptdata);\n        var scheme = 'cenc';\n        this.keyIdToKeySessionPromise[_keyId] = this.generateRequestWithPreferredKeySession(keySessionContext, scheme, decryptdata.pssh, 'expired');\n      } else {\n        this.warn(\"Could not renew expired session. Missing pssh initData.\");\n      }\n      this.removeSession(mediaKeySessionContext);\n    };\n    _proto.getKeyIdString = function getKeyIdString(decryptdata) {\n      if (!decryptdata) {\n        throw new Error('Could not read keyId of undefined decryptdata');\n      }\n      if (decryptdata.keyId === null) {\n        throw new Error('keyId is null');\n      }\n      return Hex.hexDump(decryptdata.keyId);\n    };\n    _proto.updateKeySession = function updateKeySession(mediaKeySessionContext, data) {\n      var _mediaKeySessionConte;\n      var keySession = mediaKeySessionContext.mediaKeysSession;\n      this.log(\"Updating key-session \\\"\" + keySession.sessionId + \"\\\" for keyID \" + Hex.hexDump(((_mediaKeySessionConte = mediaKeySessionContext.decryptdata) == null ? void 0 : _mediaKeySessionConte.keyId) || []) + \"\\n      } (data length: \" + (data ? data.byteLength : data) + \")\");\n      return keySession.update(data);\n    };\n    _proto.selectKeySystemFormat = function selectKeySystemFormat(frag) {\n      var keyFormats = Object.keys(frag.levelkeys || {});\n      if (!this.keyFormatPromise) {\n        this.log(\"Selecting key-system from fragment (sn: \" + frag.sn + \" \" + frag.type + \": \" + frag.level + \") key formats \" + keyFormats.join(', '));\n        this.keyFormatPromise = this.getKeyFormatPromise(keyFormats);\n      }\n      return this.keyFormatPromise;\n    };\n    _proto.getKeyFormatPromise = function getKeyFormatPromise(keyFormats) {\n      var _this3 = this;\n      return new Promise(function (resolve, reject) {\n        var keySystemsInConfig = getKeySystemsForConfig(_this3.config);\n        var keySystemsToAttempt = keyFormats.map(keySystemFormatToKeySystemDomain).filter(function (value) {\n          return !!value && keySystemsInConfig.indexOf(value) !== -1;\n        });\n        return _this3.getKeySystemSelectionPromise(keySystemsToAttempt).then(function (_ref2) {\n          var keySystem = _ref2.keySystem;\n          var keySystemFormat = keySystemDomainToKeySystemFormat(keySystem);\n          if (keySystemFormat) {\n            resolve(keySystemFormat);\n          } else {\n            reject(new Error(\"Unable to find format for key-system \\\"\" + keySystem + \"\\\"\"));\n          }\n        }).catch(reject);\n      });\n    };\n    _proto.loadKey = function loadKey(data) {\n      var _this4 = this;\n      var decryptdata = data.keyInfo.decryptdata;\n      var keyId = this.getKeyIdString(decryptdata);\n      var keyDetails = \"(keyId: \" + keyId + \" format: \\\"\" + decryptdata.keyFormat + \"\\\" method: \" + decryptdata.method + \" uri: \" + decryptdata.uri + \")\";\n      this.log(\"Starting session for key \" + keyDetails);\n      var keySessionContextPromise = this.keyIdToKeySessionPromise[keyId];\n      if (!keySessionContextPromise) {\n        keySessionContextPromise = this.keyIdToKeySessionPromise[keyId] = this.getKeySystemForKeyPromise(decryptdata).then(function (_ref3) {\n          var keySystem = _ref3.keySystem,\n            mediaKeys = _ref3.mediaKeys;\n          _this4.throwIfDestroyed();\n          _this4.log(\"Handle encrypted media sn: \" + data.frag.sn + \" \" + data.frag.type + \": \" + data.frag.level + \" using key \" + keyDetails);\n          return _this4.attemptSetMediaKeys(keySystem, mediaKeys).then(function () {\n            _this4.throwIfDestroyed();\n            var keySessionContext = _this4.createMediaKeySessionContext({\n              keySystem: keySystem,\n              mediaKeys: mediaKeys,\n              decryptdata: decryptdata\n            });\n            var scheme = 'cenc';\n            return _this4.generateRequestWithPreferredKeySession(keySessionContext, scheme, decryptdata.pssh, 'playlist-key');\n          });\n        });\n        keySessionContextPromise.catch(function (error) {\n          return _this4.handleError(error);\n        });\n      }\n      return keySessionContextPromise;\n    };\n    _proto.throwIfDestroyed = function throwIfDestroyed(message) {\n      if (!this.hls) {\n        throw new Error('invalid state');\n      }\n    };\n    _proto.handleError = function handleError(error) {\n      if (!this.hls) {\n        return;\n      }\n      this.error(error.message);\n      if (error instanceof EMEKeyError) {\n        this.hls.trigger(Events.ERROR, error.data);\n      } else {\n        this.hls.trigger(Events.ERROR, {\n          type: ErrorTypes.KEY_SYSTEM_ERROR,\n          details: ErrorDetails.KEY_SYSTEM_NO_KEYS,\n          error: error,\n          fatal: true\n        });\n      }\n    };\n    _proto.getKeySystemForKeyPromise = function getKeySystemForKeyPromise(decryptdata) {\n      var keyId = this.getKeyIdString(decryptdata);\n      var mediaKeySessionContext = this.keyIdToKeySessionPromise[keyId];\n      if (!mediaKeySessionContext) {\n        var keySystem = keySystemFormatToKeySystemDomain(decryptdata.keyFormat);\n        var keySystemsToAttempt = keySystem ? [keySystem] : getKeySystemsForConfig(this.config);\n        return this.attemptKeySystemAccess(keySystemsToAttempt);\n      }\n      return mediaKeySessionContext;\n    };\n    _proto.getKeySystemSelectionPromise = function getKeySystemSelectionPromise(keySystemsToAttempt) {\n      if (!keySystemsToAttempt.length) {\n        keySystemsToAttempt = getKeySystemsForConfig(this.config);\n      }\n      if (keySystemsToAttempt.length === 0) {\n        throw new EMEKeyError({\n          type: ErrorTypes.KEY_SYSTEM_ERROR,\n          details: ErrorDetails.KEY_SYSTEM_NO_CONFIGURED_LICENSE,\n          fatal: true\n        }, \"Missing key-system license configuration options \" + JSON.stringify({\n          drmSystems: this.config.drmSystems\n        }));\n      }\n      return this.attemptKeySystemAccess(keySystemsToAttempt);\n    };\n    _proto._onMediaEncrypted = function _onMediaEncrypted(event) {\n      var _this5 = this;\n      var initDataType = event.initDataType,\n        initData = event.initData;\n      var logMessage = \"\\\"\" + event.type + \"\\\" event: init data type: \\\"\" + initDataType + \"\\\"\";\n      this.debug(logMessage);\n\n      // Ignore event when initData is null\n      if (initData === null) {\n        return;\n      }\n      var keyId;\n      var keySystemDomain;\n      if (initDataType === 'sinf' && this.config.drmSystems[KeySystems.FAIRPLAY]) {\n        // Match sinf keyId to playlist skd://keyId=\n        var json = bin2str(new Uint8Array(initData));\n        try {\n          var sinf = base64Decode(JSON.parse(json).sinf);\n          var tenc = parseSinf(new Uint8Array(sinf));\n          if (!tenc) {\n            throw new Error(\"'schm' box missing or not cbcs/cenc with schi > tenc\");\n          }\n          keyId = tenc.subarray(8, 24);\n          keySystemDomain = KeySystems.FAIRPLAY;\n        } catch (error) {\n          this.warn(logMessage + \" Failed to parse sinf: \" + error);\n          return;\n        }\n      } else {\n        // Support Widevine clear-lead key-session creation (otherwise depend on playlist keys)\n        var psshResults = parseMultiPssh(initData);\n        var psshInfo = psshResults.filter(function (pssh) {\n          return pssh.systemId === KeySystemIds.WIDEVINE;\n        })[0];\n        if (!psshInfo) {\n          if (psshResults.length === 0 || psshResults.some(function (pssh) {\n            return !pssh.systemId;\n          })) {\n            this.warn(logMessage + \" contains incomplete or invalid pssh data\");\n          } else {\n            this.log(\"ignoring \" + logMessage + \" for \" + psshResults.map(function (pssh) {\n              return keySystemIdToKeySystemDomain(pssh.systemId);\n            }).join(',') + \" pssh data in favor of playlist keys\");\n          }\n          return;\n        }\n        keySystemDomain = keySystemIdToKeySystemDomain(psshInfo.systemId);\n        if (psshInfo.version === 0 && psshInfo.data) {\n          var offset = psshInfo.data.length - 22;\n          keyId = psshInfo.data.subarray(offset, offset + 16);\n        }\n      }\n      if (!keySystemDomain || !keyId) {\n        return;\n      }\n      var keyIdHex = Hex.hexDump(keyId);\n      var keyIdToKeySessionPromise = this.keyIdToKeySessionPromise,\n        mediaKeySessions = this.mediaKeySessions;\n      var keySessionContextPromise = keyIdToKeySessionPromise[keyIdHex];\n      var _loop = function _loop() {\n          // Match playlist key\n          var keyContext = mediaKeySessions[i];\n          var decryptdata = keyContext.decryptdata;\n          if (!decryptdata.keyId) {\n            return 0; // continue\n          }\n          var oldKeyIdHex = Hex.hexDump(decryptdata.keyId);\n          if (keyIdHex === oldKeyIdHex || decryptdata.uri.replace(/-/g, '').indexOf(keyIdHex) !== -1) {\n            keySessionContextPromise = keyIdToKeySessionPromise[oldKeyIdHex];\n            if (decryptdata.pssh) {\n              return 1; // break\n            }\n            delete keyIdToKeySessionPromise[oldKeyIdHex];\n            decryptdata.pssh = new Uint8Array(initData);\n            decryptdata.keyId = keyId;\n            keySessionContextPromise = keyIdToKeySessionPromise[keyIdHex] = keySessionContextPromise.then(function () {\n              return _this5.generateRequestWithPreferredKeySession(keyContext, initDataType, initData, 'encrypted-event-key-match');\n            });\n            return 1; // break\n          }\n        },\n        _ret;\n      for (var i = 0; i < mediaKeySessions.length; i++) {\n        _ret = _loop();\n        if (_ret === 0) continue;\n        if (_ret === 1) break;\n      }\n      if (!keySessionContextPromise) {\n        // Clear-lead key (not encountered in playlist)\n        keySessionContextPromise = keyIdToKeySessionPromise[keyIdHex] = this.getKeySystemSelectionPromise([keySystemDomain]).then(function (_ref4) {\n          var _keySystemToKeySystem;\n          var keySystem = _ref4.keySystem,\n            mediaKeys = _ref4.mediaKeys;\n          _this5.throwIfDestroyed();\n          var decryptdata = new LevelKey('ISO-23001-7', keyIdHex, (_keySystemToKeySystem = keySystemDomainToKeySystemFormat(keySystem)) != null ? _keySystemToKeySystem : '');\n          decryptdata.pssh = new Uint8Array(initData);\n          decryptdata.keyId = keyId;\n          return _this5.attemptSetMediaKeys(keySystem, mediaKeys).then(function () {\n            _this5.throwIfDestroyed();\n            var keySessionContext = _this5.createMediaKeySessionContext({\n              decryptdata: decryptdata,\n              keySystem: keySystem,\n              mediaKeys: mediaKeys\n            });\n            return _this5.generateRequestWithPreferredKeySession(keySessionContext, initDataType, initData, 'encrypted-event-no-match');\n          });\n        });\n      }\n      keySessionContextPromise.catch(function (error) {\n        return _this5.handleError(error);\n      });\n    };\n    _proto._onWaitingForKey = function _onWaitingForKey(event) {\n      this.log(\"\\\"\" + event.type + \"\\\" event\");\n    };\n    _proto.attemptSetMediaKeys = function attemptSetMediaKeys(keySystem, mediaKeys) {\n      var _this6 = this;\n      var queue = this.setMediaKeysQueue.slice();\n      this.log(\"Setting media-keys for \\\"\" + keySystem + \"\\\"\");\n      // Only one setMediaKeys() can run at one time, and multiple setMediaKeys() operations\n      // can be queued for execution for multiple key sessions.\n      var setMediaKeysPromise = Promise.all(queue).then(function () {\n        if (!_this6.media) {\n          throw new Error('Attempted to set mediaKeys without media element attached');\n        }\n        return _this6.media.setMediaKeys(mediaKeys);\n      });\n      this.setMediaKeysQueue.push(setMediaKeysPromise);\n      return setMediaKeysPromise.then(function () {\n        _this6.log(\"Media-keys set for \\\"\" + keySystem + \"\\\"\");\n        queue.push(setMediaKeysPromise);\n        _this6.setMediaKeysQueue = _this6.setMediaKeysQueue.filter(function (p) {\n          return queue.indexOf(p) === -1;\n        });\n      });\n    };\n    _proto.generateRequestWithPreferredKeySession = function generateRequestWithPreferredKeySession(context, initDataType, initData, reason) {\n      var _this$config$drmSyste,\n        _this$config$drmSyste2,\n        _this7 = this;\n      var generateRequestFilter = (_this$config$drmSyste = this.config.drmSystems) == null ? void 0 : (_this$config$drmSyste2 = _this$config$drmSyste[context.keySystem]) == null ? void 0 : _this$config$drmSyste2.generateRequest;\n      if (generateRequestFilter) {\n        try {\n          var mappedInitData = generateRequestFilter.call(this.hls, initDataType, initData, context);\n          if (!mappedInitData) {\n            throw new Error('Invalid response from configured generateRequest filter');\n          }\n          initDataType = mappedInitData.initDataType;\n          initData = context.decryptdata.pssh = mappedInitData.initData ? new Uint8Array(mappedInitData.initData) : null;\n        } catch (error) {\n          var _this$hls;\n          this.warn(error.message);\n          if ((_this$hls = this.hls) != null && _this$hls.config.debug) {\n            throw error;\n          }\n        }\n      }\n      if (initData === null) {\n        this.log(\"Skipping key-session request for \\\"\" + reason + \"\\\" (no initData)\");\n        return Promise.resolve(context);\n      }\n      var keyId = this.getKeyIdString(context.decryptdata);\n      this.log(\"Generating key-session request for \\\"\" + reason + \"\\\": \" + keyId + \" (init data type: \" + initDataType + \" length: \" + (initData ? initData.byteLength : null) + \")\");\n      var licenseStatus = new EventEmitter();\n      var onmessage = context._onmessage = function (event) {\n        var keySession = context.mediaKeysSession;\n        if (!keySession) {\n          licenseStatus.emit('error', new Error('invalid state'));\n          return;\n        }\n        var messageType = event.messageType,\n          message = event.message;\n        _this7.log(\"\\\"\" + messageType + \"\\\" message event for session \\\"\" + keySession.sessionId + \"\\\" message size: \" + message.byteLength);\n        if (messageType === 'license-request' || messageType === 'license-renewal') {\n          _this7.renewLicense(context, message).catch(function (error) {\n            _this7.handleError(error);\n            licenseStatus.emit('error', error);\n          });\n        } else if (messageType === 'license-release') {\n          if (context.keySystem === KeySystems.FAIRPLAY) {\n            _this7.updateKeySession(context, strToUtf8array('acknowledged'));\n            _this7.removeSession(context);\n          }\n        } else {\n          _this7.warn(\"unhandled media key message type \\\"\" + messageType + \"\\\"\");\n        }\n      };\n      var onkeystatuseschange = context._onkeystatuseschange = function (event) {\n        var keySession = context.mediaKeysSession;\n        if (!keySession) {\n          licenseStatus.emit('error', new Error('invalid state'));\n          return;\n        }\n        _this7.onKeyStatusChange(context);\n        var keyStatus = context.keyStatus;\n        licenseStatus.emit('keyStatus', keyStatus);\n        if (keyStatus === 'expired') {\n          _this7.warn(context.keySystem + \" expired for key \" + keyId);\n          _this7.renewKeySession(context);\n        }\n      };\n      context.mediaKeysSession.addEventListener('message', onmessage);\n      context.mediaKeysSession.addEventListener('keystatuseschange', onkeystatuseschange);\n      var keyUsablePromise = new Promise(function (resolve, reject) {\n        licenseStatus.on('error', reject);\n        licenseStatus.on('keyStatus', function (keyStatus) {\n          if (keyStatus.startsWith('usable')) {\n            resolve();\n          } else if (keyStatus === 'output-restricted') {\n            reject(new EMEKeyError({\n              type: ErrorTypes.KEY_SYSTEM_ERROR,\n              details: ErrorDetails.KEY_SYSTEM_STATUS_OUTPUT_RESTRICTED,\n              fatal: false\n            }, 'HDCP level output restricted'));\n          } else if (keyStatus === 'internal-error') {\n            reject(new EMEKeyError({\n              type: ErrorTypes.KEY_SYSTEM_ERROR,\n              details: ErrorDetails.KEY_SYSTEM_STATUS_INTERNAL_ERROR,\n              fatal: true\n            }, \"key status changed to \\\"\" + keyStatus + \"\\\"\"));\n          } else if (keyStatus === 'expired') {\n            reject(new Error('key expired while generating request'));\n          } else {\n            _this7.warn(\"unhandled key status change \\\"\" + keyStatus + \"\\\"\");\n          }\n        });\n      });\n      return context.mediaKeysSession.generateRequest(initDataType, initData).then(function () {\n        var _context$mediaKeysSes;\n        _this7.log(\"Request generated for key-session \\\"\" + ((_context$mediaKeysSes = context.mediaKeysSession) == null ? void 0 : _context$mediaKeysSes.sessionId) + \"\\\" keyId: \" + keyId);\n      }).catch(function (error) {\n        throw new EMEKeyError({\n          type: ErrorTypes.KEY_SYSTEM_ERROR,\n          details: ErrorDetails.KEY_SYSTEM_NO_SESSION,\n          error: error,\n          fatal: false\n        }, \"Error generating key-session request: \" + error);\n      }).then(function () {\n        return keyUsablePromise;\n      }).catch(function (error) {\n        licenseStatus.removeAllListeners();\n        _this7.removeSession(context);\n        throw error;\n      }).then(function () {\n        licenseStatus.removeAllListeners();\n        return context;\n      });\n    };\n    _proto.onKeyStatusChange = function onKeyStatusChange(mediaKeySessionContext) {\n      var _this8 = this;\n      mediaKeySessionContext.mediaKeysSession.keyStatuses.forEach(function (status, keyId) {\n        _this8.log(\"key status change \\\"\" + status + \"\\\" for keyStatuses keyId: \" + Hex.hexDump('buffer' in keyId ? new Uint8Array(keyId.buffer, keyId.byteOffset, keyId.byteLength) : new Uint8Array(keyId)) + \" session keyId: \" + Hex.hexDump(new Uint8Array(mediaKeySessionContext.decryptdata.keyId || [])) + \" uri: \" + mediaKeySessionContext.decryptdata.uri);\n        mediaKeySessionContext.keyStatus = status;\n      });\n    };\n    _proto.fetchServerCertificate = function fetchServerCertificate(keySystem) {\n      var config = this.config;\n      var Loader = config.loader;\n      var certLoader = new Loader(config);\n      var url = this.getServerCertificateUrl(keySystem);\n      if (!url) {\n        return Promise.resolve();\n      }\n      this.log(\"Fetching server certificate for \\\"\" + keySystem + \"\\\"\");\n      return new Promise(function (resolve, reject) {\n        var loaderContext = {\n          responseType: 'arraybuffer',\n          url: url\n        };\n        var loadPolicy = config.certLoadPolicy.default;\n        var loaderConfig = {\n          loadPolicy: loadPolicy,\n          timeout: loadPolicy.maxLoadTimeMs,\n          maxRetry: 0,\n          retryDelay: 0,\n          maxRetryDelay: 0\n        };\n        var loaderCallbacks = {\n          onSuccess: function onSuccess(response, stats, context, networkDetails) {\n            resolve(response.data);\n          },\n          onError: function onError(response, contex, networkDetails, stats) {\n            reject(new EMEKeyError({\n              type: ErrorTypes.KEY_SYSTEM_ERROR,\n              details: ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED,\n              fatal: true,\n              networkDetails: networkDetails,\n              response: _objectSpread2({\n                url: loaderContext.url,\n                data: undefined\n              }, response)\n            }, \"\\\"\" + keySystem + \"\\\" certificate request failed (\" + url + \"). Status: \" + response.code + \" (\" + response.text + \")\"));\n          },\n          onTimeout: function onTimeout(stats, context, networkDetails) {\n            reject(new EMEKeyError({\n              type: ErrorTypes.KEY_SYSTEM_ERROR,\n              details: ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_REQUEST_FAILED,\n              fatal: true,\n              networkDetails: networkDetails,\n              response: {\n                url: loaderContext.url,\n                data: undefined\n              }\n            }, \"\\\"\" + keySystem + \"\\\" certificate request timed out (\" + url + \")\"));\n          },\n          onAbort: function onAbort(stats, context, networkDetails) {\n            reject(new Error('aborted'));\n          }\n        };\n        certLoader.load(loaderContext, loaderConfig, loaderCallbacks);\n      });\n    };\n    _proto.setMediaKeysServerCertificate = function setMediaKeysServerCertificate(mediaKeys, keySystem, cert) {\n      var _this9 = this;\n      return new Promise(function (resolve, reject) {\n        mediaKeys.setServerCertificate(cert).then(function (success) {\n          _this9.log(\"setServerCertificate \" + (success ? 'success' : 'not supported by CDM') + \" (\" + (cert == null ? void 0 : cert.byteLength) + \") on \\\"\" + keySystem + \"\\\"\");\n          resolve(mediaKeys);\n        }).catch(function (error) {\n          reject(new EMEKeyError({\n            type: ErrorTypes.KEY_SYSTEM_ERROR,\n            details: ErrorDetails.KEY_SYSTEM_SERVER_CERTIFICATE_UPDATE_FAILED,\n            error: error,\n            fatal: true\n          }, error.message));\n        });\n      });\n    };\n    _proto.renewLicense = function renewLicense(context, keyMessage) {\n      var _this10 = this;\n      return this.requestLicense(context, new Uint8Array(keyMessage)).then(function (data) {\n        return _this10.updateKeySession(context, new Uint8Array(data)).catch(function (error) {\n          throw new EMEKeyError({\n            type: ErrorTypes.KEY_SYSTEM_ERROR,\n            details: ErrorDetails.KEY_SYSTEM_SESSION_UPDATE_FAILED,\n            error: error,\n            fatal: true\n          }, error.message);\n        });\n      });\n    };\n    _proto.unpackPlayReadyKeyMessage = function unpackPlayReadyKeyMessage(xhr, licenseChallenge) {\n      // On Edge, the raw license message is UTF-16-encoded XML.  We need\n      // to unpack the Challenge element (base64-encoded string containing the\n      // actual license request) and any HttpHeader elements (sent as request\n      // headers).\n      // For PlayReady CDMs, we need to dig the Challenge out of the XML.\n      var xmlString = String.fromCharCode.apply(null, new Uint16Array(licenseChallenge.buffer));\n      if (!xmlString.includes('PlayReadyKeyMessage')) {\n        // This does not appear to be a wrapped message as on Edge.  Some\n        // clients do not need this unwrapping, so we will assume this is one of\n        // them.  Note that \"xml\" at this point probably looks like random\n        // garbage, since we interpreted UTF-8 as UTF-16.\n        xhr.setRequestHeader('Content-Type', 'text/xml; charset=utf-8');\n        return licenseChallenge;\n      }\n      var keyMessageXml = new DOMParser().parseFromString(xmlString, 'application/xml');\n      // Set request headers.\n      var headers = keyMessageXml.querySelectorAll('HttpHeader');\n      if (headers.length > 0) {\n        var header;\n        for (var i = 0, len = headers.length; i < len; i++) {\n          var _header$querySelector, _header$querySelector2;\n          header = headers[i];\n          var name = (_header$querySelector = header.querySelector('name')) == null ? void 0 : _header$querySelector.textContent;\n          var _value = (_header$querySelector2 = header.querySelector('value')) == null ? void 0 : _header$querySelector2.textContent;\n          if (name && _value) {\n            xhr.setRequestHeader(name, _value);\n          }\n        }\n      }\n      var challengeElement = keyMessageXml.querySelector('Challenge');\n      var challengeText = challengeElement == null ? void 0 : challengeElement.textContent;\n      if (!challengeText) {\n        throw new Error(\"Cannot find <Challenge> in key message\");\n      }\n      return strToUtf8array(atob(challengeText));\n    };\n    _proto.setupLicenseXHR = function setupLicenseXHR(xhr, url, keysListItem, licenseChallenge) {\n      var _this11 = this;\n      var licenseXhrSetup = this.config.licenseXhrSetup;\n      if (!licenseXhrSetup) {\n        xhr.open('POST', url, true);\n        return Promise.resolve({\n          xhr: xhr,\n          licenseChallenge: licenseChallenge\n        });\n      }\n      return Promise.resolve().then(function () {\n        if (!keysListItem.decryptdata) {\n          throw new Error('Key removed');\n        }\n        return licenseXhrSetup.call(_this11.hls, xhr, url, keysListItem, licenseChallenge);\n      }).catch(function (error) {\n        if (!keysListItem.decryptdata) {\n          // Key session removed. Cancel license request.\n          throw error;\n        }\n        // let's try to open before running setup\n        xhr.open('POST', url, true);\n        return licenseXhrSetup.call(_this11.hls, xhr, url, keysListItem, licenseChallenge);\n      }).then(function (licenseXhrSetupResult) {\n        // if licenseXhrSetup did not yet call open, let's do it now\n        if (!xhr.readyState) {\n          xhr.open('POST', url, true);\n        }\n        var finalLicenseChallenge = licenseXhrSetupResult ? licenseXhrSetupResult : licenseChallenge;\n        return {\n          xhr: xhr,\n          licenseChallenge: finalLicenseChallenge\n        };\n      });\n    };\n    _proto.requestLicense = function requestLicense(keySessionContext, licenseChallenge) {\n      var _this12 = this;\n      var keyLoadPolicy = this.config.keyLoadPolicy.default;\n      return new Promise(function (resolve, reject) {\n        var url = _this12.getLicenseServerUrl(keySessionContext.keySystem);\n        _this12.log(\"Sending license request to URL: \" + url);\n        var xhr = new XMLHttpRequest();\n        xhr.responseType = 'arraybuffer';\n        xhr.onreadystatechange = function () {\n          if (!_this12.hls || !keySessionContext.mediaKeysSession) {\n            return reject(new Error('invalid state'));\n          }\n          if (xhr.readyState === 4) {\n            if (xhr.status === 200) {\n              _this12._requestLicenseFailureCount = 0;\n              var data = xhr.response;\n              _this12.log(\"License received \" + (data instanceof ArrayBuffer ? data.byteLength : data));\n              var licenseResponseCallback = _this12.config.licenseResponseCallback;\n              if (licenseResponseCallback) {\n                try {\n                  data = licenseResponseCallback.call(_this12.hls, xhr, url, keySessionContext);\n                } catch (error) {\n                  _this12.error(error);\n                }\n              }\n              resolve(data);\n            } else {\n              var retryConfig = keyLoadPolicy.errorRetry;\n              var maxNumRetry = retryConfig ? retryConfig.maxNumRetry : 0;\n              _this12._requestLicenseFailureCount++;\n              if (_this12._requestLicenseFailureCount > maxNumRetry || xhr.status >= 400 && xhr.status < 500) {\n                reject(new EMEKeyError({\n                  type: ErrorTypes.KEY_SYSTEM_ERROR,\n                  details: ErrorDetails.KEY_SYSTEM_LICENSE_REQUEST_FAILED,\n                  fatal: true,\n                  networkDetails: xhr,\n                  response: {\n                    url: url,\n                    data: undefined,\n                    code: xhr.status,\n                    text: xhr.statusText\n                  }\n                }, \"License Request XHR failed (\" + url + \"). Status: \" + xhr.status + \" (\" + xhr.statusText + \")\"));\n              } else {\n                var attemptsLeft = maxNumRetry - _this12._requestLicenseFailureCount + 1;\n                _this12.warn(\"Retrying license request, \" + attemptsLeft + \" attempts left\");\n                _this12.requestLicense(keySessionContext, licenseChallenge).then(resolve, reject);\n              }\n            }\n          }\n        };\n        if (keySessionContext.licenseXhr && keySessionContext.licenseXhr.readyState !== XMLHttpRequest.DONE) {\n          keySessionContext.licenseXhr.abort();\n        }\n        keySessionContext.licenseXhr = xhr;\n        _this12.setupLicenseXHR(xhr, url, keySessionContext, licenseChallenge).then(function (_ref5) {\n          var xhr = _ref5.xhr,\n            licenseChallenge = _ref5.licenseChallenge;\n          if (keySessionContext.keySystem == KeySystems.PLAYREADY) {\n            licenseChallenge = _this12.unpackPlayReadyKeyMessage(xhr, licenseChallenge);\n          }\n          xhr.send(licenseChallenge);\n        });\n      });\n    };\n    _proto.onMediaAttached = function onMediaAttached(event, data) {\n      if (!this.config.emeEnabled) {\n        return;\n      }\n      var media = data.media;\n\n      // keep reference of media\n      this.media = media;\n      media.addEventListener('encrypted', this.onMediaEncrypted);\n      media.addEventListener('waitingforkey', this.onWaitingForKey);\n    };\n    _proto.onMediaDetached = function onMediaDetached() {\n      var _this13 = this;\n      var media = this.media;\n      var mediaKeysList = this.mediaKeySessions;\n      if (media) {\n        media.removeEventListener('encrypted', this.onMediaEncrypted);\n        media.removeEventListener('waitingforkey', this.onWaitingForKey);\n        this.media = null;\n      }\n      this._requestLicenseFailureCount = 0;\n      this.setMediaKeysQueue = [];\n      this.mediaKeySessions = [];\n      this.keyIdToKeySessionPromise = {};\n      LevelKey.clearKeyUriToKeyIdMap();\n\n      // Close all sessions and remove media keys from the video element.\n      var keySessionCount = mediaKeysList.length;\n      EMEController.CDMCleanupPromise = Promise.all(mediaKeysList.map(function (mediaKeySessionContext) {\n        return _this13.removeSession(mediaKeySessionContext);\n      }).concat(media == null ? void 0 : media.setMediaKeys(null).catch(function (error) {\n        _this13.log(\"Could not clear media keys: \" + error);\n      }))).then(function () {\n        if (keySessionCount) {\n          _this13.log('finished closing key sessions and clearing media keys');\n          mediaKeysList.length = 0;\n        }\n      }).catch(function (error) {\n        _this13.log(\"Could not close sessions and clear media keys: \" + error);\n      });\n    };\n    _proto.onManifestLoading = function onManifestLoading() {\n      this.keyFormatPromise = null;\n    };\n    _proto.onManifestLoaded = function onManifestLoaded(event, _ref6) {\n      var sessionKeys = _ref6.sessionKeys;\n      if (!sessionKeys || !this.config.emeEnabled) {\n        return;\n      }\n      if (!this.keyFormatPromise) {\n        var keyFormats = sessionKeys.reduce(function (formats, sessionKey) {\n          if (formats.indexOf(sessionKey.keyFormat) === -1) {\n            formats.push(sessionKey.keyFormat);\n          }\n          return formats;\n        }, []);\n        this.log(\"Selecting key-system from session-keys \" + keyFormats.join(', '));\n        this.keyFormatPromise = this.getKeyFormatPromise(keyFormats);\n      }\n    };\n    _proto.removeSession = function removeSession(mediaKeySessionContext) {\n      var _this14 = this;\n      var mediaKeysSession = mediaKeySessionContext.mediaKeysSession,\n        licenseXhr = mediaKeySessionContext.licenseXhr;\n      if (mediaKeysSession) {\n        this.log(\"Remove licenses and keys and close session \" + mediaKeysSession.sessionId);\n        if (mediaKeySessionContext._onmessage) {\n          mediaKeysSession.removeEventListener('message', mediaKeySessionContext._onmessage);\n          mediaKeySessionContext._onmessage = undefined;\n        }\n        if (mediaKeySessionContext._onkeystatuseschange) {\n          mediaKeysSession.removeEventListener('keystatuseschange', mediaKeySessionContext._onkeystatuseschange);\n          mediaKeySessionContext._onkeystatuseschange = undefined;\n        }\n        if (licenseXhr && licenseXhr.readyState !== XMLHttpRequest.DONE) {\n          licenseXhr.abort();\n        }\n        mediaKeySessionContext.mediaKeysSession = mediaKeySessionContext.decryptdata = mediaKeySessionContext.licenseXhr = undefined;\n        var index = this.mediaKeySessions.indexOf(mediaKeySessionContext);\n        if (index > -1) {\n          this.mediaKeySessions.splice(index, 1);\n        }\n        return mediaKeysSession.remove().catch(function (error) {\n          _this14.log(\"Could not remove session: \" + error);\n        }).then(function () {\n          return mediaKeysSession.close();\n        }).catch(function (error) {\n          _this14.log(\"Could not close session: \" + error);\n        });\n      }\n    };\n    return EMEController;\n  }();\n  EMEController.CDMCleanupPromise = void 0;\n  var EMEKeyError = /*#__PURE__*/function (_Error) {\n    _inheritsLoose(EMEKeyError, _Error);\n    function EMEKeyError(data, message) {\n      var _this15;\n      _this15 = _Error.call(this, message) || this;\n      _this15.data = void 0;\n      data.error || (data.error = new Error(message));\n      _this15.data = data;\n      data.err = data.error;\n      return _this15;\n    }\n    return EMEKeyError;\n  }( /*#__PURE__*/_wrapNativeSuper(Error));\n\n  /**\n   * Common Media Object Type\n   *\n   * @group CMCD\n   * @group CMSD\n   *\n   * @beta\n   */\n  var CmObjectType;\n  (function (CmObjectType) {\n    /**\n     * text file, such as a manifest or playlist\n     */\n    CmObjectType[\"MANIFEST\"] = \"m\";\n    /**\n     * audio only\n     */\n    CmObjectType[\"AUDIO\"] = \"a\";\n    /**\n     * video only\n     */\n    CmObjectType[\"VIDEO\"] = \"v\";\n    /**\n     * muxed audio and video\n     */\n    CmObjectType[\"MUXED\"] = \"av\";\n    /**\n     * init segment\n     */\n    CmObjectType[\"INIT\"] = \"i\";\n    /**\n     * caption or subtitle\n     */\n    CmObjectType[\"CAPTION\"] = \"c\";\n    /**\n     * ISOBMFF timed text track\n     */\n    CmObjectType[\"TIMED_TEXT\"] = \"tt\";\n    /**\n     * cryptographic key, license or certificate.\n     */\n    CmObjectType[\"KEY\"] = \"k\";\n    /**\n     * other\n     */\n    CmObjectType[\"OTHER\"] = \"o\";\n  })(CmObjectType || (CmObjectType = {}));\n\n  /**\n   * Common Media Streaming Format\n   *\n   * @group CMCD\n   * @group CMSD\n   *\n   * @beta\n   */\n  var CmStreamingFormat;\n  (function (CmStreamingFormat) {\n    /**\n     * MPEG DASH\n     */\n    CmStreamingFormat[\"DASH\"] = \"d\";\n    /**\n     * HTTP Live Streaming (HLS)\n     */\n    CmStreamingFormat[\"HLS\"] = \"h\";\n    /**\n     * Smooth Streaming\n     */\n    CmStreamingFormat[\"SMOOTH\"] = \"s\";\n    /**\n     * Other\n     */\n    CmStreamingFormat[\"OTHER\"] = \"o\";\n  })(CmStreamingFormat || (CmStreamingFormat = {}));\n\n  /**\n   * CMCD header fields.\n   *\n   * @group CMCD\n   *\n   * @beta\n   */\n  var CmcdHeaderField;\n  (function (CmcdHeaderField) {\n    /**\n     * keys whose values vary with the object being requested.\n     */\n    CmcdHeaderField[\"OBJECT\"] = \"CMCD-Object\";\n    /**\n     * keys whose values vary with each request.\n     */\n    CmcdHeaderField[\"REQUEST\"] = \"CMCD-Request\";\n    /**\n     * keys whose values are expected to be invariant over the life of the session.\n     */\n    CmcdHeaderField[\"SESSION\"] = \"CMCD-Session\";\n    /**\n     * keys whose values do not vary with every request or object.\n     */\n    CmcdHeaderField[\"STATUS\"] = \"CMCD-Status\";\n  })(CmcdHeaderField || (CmcdHeaderField = {}));\n\n  var _CmcdHeaderMap;\n  /**\n   * The map of CMCD header fields to official CMCD keys.\n   *\n   * @internal\n   *\n   * @group CMCD\n   */\n  var CmcdHeaderMap = (_CmcdHeaderMap = {}, _CmcdHeaderMap[CmcdHeaderField.OBJECT] = ['br', 'd', 'ot', 'tb'], _CmcdHeaderMap[CmcdHeaderField.REQUEST] = ['bl', 'dl', 'mtp', 'nor', 'nrr', 'su'], _CmcdHeaderMap[CmcdHeaderField.SESSION] = ['cid', 'pr', 'sf', 'sid', 'st', 'v'], _CmcdHeaderMap[CmcdHeaderField.STATUS] = ['bs', 'rtp'], _CmcdHeaderMap);\n\n  /**\n   * Structured Field Item\n   *\n   * @group Structured Field\n   *\n   * @beta\n   */\n  var SfItem = function SfItem(value, params) {\n    this.value = void 0;\n    this.params = void 0;\n    if (Array.isArray(value)) {\n      value = value.map(function (v) {\n        return v instanceof SfItem ? v : new SfItem(v);\n      });\n    }\n    this.value = value;\n    this.params = params;\n  };\n\n  /**\n   * A class to represent structured field tokens when `Symbol` is not available.\n   *\n   * @group Structured Field\n   *\n   * @beta\n   */\n  var SfToken = function SfToken(description) {\n    this.description = void 0;\n    this.description = description;\n  };\n\n  var DICT = 'Dict';\n\n  function format(value) {\n    if (Array.isArray(value)) {\n      return JSON.stringify(value);\n    }\n    if (value instanceof Map) {\n      return 'Map{}';\n    }\n    if (value instanceof Set) {\n      return 'Set{}';\n    }\n    if (typeof value === 'object') {\n      return JSON.stringify(value);\n    }\n    return String(value);\n  }\n  function throwError(action, src, type, cause) {\n    return new Error(\"failed to \" + action + \" \\\"\" + format(src) + \"\\\" as \" + type, {\n      cause: cause\n    });\n  }\n\n  var BARE_ITEM = 'Bare Item';\n\n  var BOOLEAN = 'Boolean';\n\n  var BYTES = 'Byte Sequence';\n\n  var DECIMAL = 'Decimal';\n\n  var INTEGER = 'Integer';\n\n  function isInvalidInt(value) {\n    return value < -999999999999999 || 999999999999999 < value;\n  }\n\n  var STRING_REGEX = /[\\x00-\\x1f\\x7f]+/; // eslint-disable-line no-control-regex\n\n  var TOKEN = 'Token';\n\n  var KEY = 'Key';\n\n  function serializeError(src, type, cause) {\n    return throwError('serialize', src, type, cause);\n  }\n\n  // 4.1.9.  Serializing a Boolean\n  //\n  // Given a Boolean as input_boolean, return an ASCII string suitable for\n  // use in a HTTP field value.\n  //\n  // 1.  If input_boolean is not a boolean, fail serialization.\n  //\n  // 2.  Let output be an empty string.\n  //\n  // 3.  Append \"?\" to output.\n  //\n  // 4.  If input_boolean is true, append \"1\" to output.\n  //\n  // 5.  If input_boolean is false, append \"0\" to output.\n  //\n  // 6.  Return output.\n  function serializeBoolean(value) {\n    if (typeof value !== 'boolean') {\n      throw serializeError(value, BOOLEAN);\n    }\n    return value ? '?1' : '?0';\n  }\n\n  /**\n   * Encodes binary data to base64\n   *\n   * @param binary - The binary data to encode\n   * @returns The base64 encoded string\n   *\n   * @group Utils\n   *\n   * @beta\n   */\n  function base64encode(binary) {\n    return btoa(String.fromCharCode.apply(String, binary));\n  }\n\n  // 4.1.8.  Serializing a Byte Sequence\n  //\n  // Given a Byte Sequence as input_bytes, return an ASCII string suitable\n  // for use in a HTTP field value.\n  //\n  // 1.  If input_bytes is not a sequence of bytes, fail serialization.\n  //\n  // 2.  Let output be an empty string.\n  //\n  // 3.  Append \":\" to output.\n  //\n  // 4.  Append the result of base64-encoding input_bytes as per\n  //     [RFC4648], Section 4, taking account of the requirements below.\n  //\n  // 5.  Append \":\" to output.\n  //\n  // 6.  Return output.\n  //\n  // The encoded data is required to be padded with \"=\", as per [RFC4648],\n  // Section 3.2.\n  //\n  // Likewise, encoded data SHOULD have pad bits set to zero, as per\n  // [RFC4648], Section 3.5, unless it is not possible to do so due to\n  // implementation constraints.\n  function serializeByteSequence(value) {\n    if (ArrayBuffer.isView(value) === false) {\n      throw serializeError(value, BYTES);\n    }\n    return \":\" + base64encode(value) + \":\";\n  }\n\n  // 4.1.4.  Serializing an Integer\n  //\n  // Given an Integer as input_integer, return an ASCII string suitable\n  // for use in a HTTP field value.\n  //\n  // 1.  If input_integer is not an integer in the range of\n  //     -999,999,999,999,999 to 999,999,999,999,999 inclusive, fail\n  //     serialization.\n  //\n  // 2.  Let output be an empty string.\n  //\n  // 3.  If input_integer is less than (but not equal to) 0, append \"-\" to\n  //     output.\n  //\n  // 4.  Append input_integer's numeric value represented in base 10 using\n  //     only decimal digits to output.\n  //\n  // 5.  Return output.\n  function serializeInteger(value) {\n    if (isInvalidInt(value)) {\n      throw serializeError(value, INTEGER);\n    }\n    return value.toString();\n  }\n\n  // 4.1.10.  Serializing a Date\n  //\n  // Given a Date as input_integer, return an ASCII string suitable for\n  // use in an HTTP field value.\n  // 1.  Let output be \"@\".\n  // 2.  Append to output the result of running Serializing an Integer\n  //     with input_date (Section 4.1.4).\n  // 3.  Return output.\n  function serializeDate(value) {\n    return \"@\" + serializeInteger(value.getTime() / 1000);\n  }\n\n  /**\n   * This implements the rounding procedure described in step 2 of the \"Serializing a Decimal\" specification.\n   * This rounding style is known as \"even rounding\", \"banker's rounding\", or \"commercial rounding\".\n   *\n   * @param value - The value to round\n   * @param precision - The number of decimal places to round to\n   * @returns The rounded value\n   *\n   * @group Utils\n   *\n   * @beta\n   */\n  function roundToEven(value, precision) {\n    if (value < 0) {\n      return -roundToEven(-value, precision);\n    }\n    var decimalShift = Math.pow(10, precision);\n    var isEquidistant = Math.abs(value * decimalShift % 1 - 0.5) < Number.EPSILON;\n    if (isEquidistant) {\n      // If the tail of the decimal place is 'equidistant' we round to the nearest even value\n      var flooredValue = Math.floor(value * decimalShift);\n      return (flooredValue % 2 === 0 ? flooredValue : flooredValue + 1) / decimalShift;\n    } else {\n      // Otherwise, proceed as normal\n      return Math.round(value * decimalShift) / decimalShift;\n    }\n  }\n\n  // 4.1.5.  Serializing a Decimal\n  //\n  // Given a decimal number as input_decimal, return an ASCII string\n  // suitable for use in a HTTP field value.\n  //\n  // 1.   If input_decimal is not a decimal number, fail serialization.\n  //\n  // 2.   If input_decimal has more than three significant digits to the\n  //      right of the decimal point, round it to three decimal places,\n  //      rounding the final digit to the nearest value, or to the even\n  //      value if it is equidistant.\n  //\n  // 3.   If input_decimal has more than 12 significant digits to the left\n  //      of the decimal point after rounding, fail serialization.\n  //\n  // 4.   Let output be an empty string.\n  //\n  // 5.   If input_decimal is less than (but not equal to) 0, append \"-\"\n  //      to output.\n  //\n  // 6.   Append input_decimal's integer component represented in base 10\n  //      (using only decimal digits) to output; if it is zero, append\n  //      \"0\".\n  //\n  // 7.   Append \".\" to output.\n  //\n  // 8.   If input_decimal's fractional component is zero, append \"0\" to\n  //      output.\n  //\n  // 9.   Otherwise, append the significant digits of input_decimal's\n  //      fractional component represented in base 10 (using only decimal\n  //      digits) to output.\n  //\n  // 10.  Return output.\n  function serializeDecimal(value) {\n    var roundedValue = roundToEven(value, 3); // round to 3 decimal places\n    if (Math.floor(Math.abs(roundedValue)).toString().length > 12) {\n      throw serializeError(value, DECIMAL);\n    }\n    var stringValue = roundedValue.toString();\n    return stringValue.includes('.') ? stringValue : stringValue + \".0\";\n  }\n\n  var STRING = 'String';\n\n  // 4.1.6.  Serializing a String\n  //\n  // Given a String as input_string, return an ASCII string suitable for\n  // use in a HTTP field value.\n  //\n  // 1.  Convert input_string into a sequence of ASCII characters; if\n  //     conversion fails, fail serialization.\n  //\n  // 2.  If input_string contains characters in the range %x00-1f or %x7f\n  //     (i.e., not in VCHAR or SP), fail serialization.\n  //\n  // 3.  Let output be the string DQUOTE.\n  //\n  // 4.  For each character char in input_string:\n  //\n  //     1.  If char is \"\\\" or DQUOTE:\n  //\n  //         1.  Append \"\\\" to output.\n  //\n  //     2.  Append char to output.\n  //\n  // 5.  Append DQUOTE to output.\n  //\n  // 6.  Return output.\n  function serializeString(value) {\n    if (STRING_REGEX.test(value)) {\n      throw serializeError(value, STRING);\n    }\n    return \"\\\"\" + value.replace(/\\\\/g, \"\\\\\\\\\").replace(/\"/g, \"\\\\\\\"\") + \"\\\"\";\n  }\n\n  function symbolToStr(symbol) {\n    return symbol.description || symbol.toString().slice(7, -1);\n  }\n\n  function serializeToken(token) {\n    var value = symbolToStr(token);\n    if (/^([a-zA-Z*])([!#$%&'*+\\-.^_`|~\\w:/]*)$/.test(value) === false) {\n      throw serializeError(value, TOKEN);\n    }\n    return value;\n  }\n\n  // 4.1.3.1.  Serializing a Bare Item\n  //\n  // Given an Item as input_item, return an ASCII string suitable for use\n  // in a HTTP field value.\n  //\n  // 1.  If input_item is an Integer, return the result of running\n  //     Serializing an Integer (Section 4.1.4) with input_item.\n  //\n  // 2.  If input_item is a Decimal, return the result of running\n  //     Serializing a Decimal (Section 4.1.5) with input_item.\n  //\n  // 3.  If input_item is a String, return the result of running\n  //     Serializing a String (Section 4.1.6) with input_item.\n  //\n  // 4.  If input_item is a Token, return the result of running\n  //     Serializing a Token (Section 4.1.7) with input_item.\n  //\n  // 5.  If input_item is a Boolean, return the result of running\n  //     Serializing a Boolean (Section 4.1.9) with input_item.\n  //\n  // 6.  If input_item is a Byte Sequence, return the result of running\n  //     Serializing a Byte Sequence (Section 4.1.8) with input_item.\n  //\n  // 7.  If input_item is a Date, return the result of running Serializing\n  //     a Date (Section 4.1.10) with input_item.\n  //\n  // 8.  Otherwise, fail serialization.\n  function serializeBareItem(value) {\n    switch (typeof value) {\n      case 'number':\n        if (!isFiniteNumber(value)) {\n          throw serializeError(value, BARE_ITEM);\n        }\n        if (Number.isInteger(value)) {\n          return serializeInteger(value);\n        }\n        return serializeDecimal(value);\n      case 'string':\n        return serializeString(value);\n      case 'symbol':\n        return serializeToken(value);\n      case 'boolean':\n        return serializeBoolean(value);\n      case 'object':\n        if (value instanceof Date) {\n          return serializeDate(value);\n        }\n        if (value instanceof Uint8Array) {\n          return serializeByteSequence(value);\n        }\n        if (value instanceof SfToken) {\n          return serializeToken(value);\n        }\n      default:\n        // fail\n        throw serializeError(value, BARE_ITEM);\n    }\n  }\n\n  // 4.1.1.3.  Serializing a Key\n  //\n  // Given a key as input_key, return an ASCII string suitable for use in\n  // a HTTP field value.\n  //\n  // 1.  Convert input_key into a sequence of ASCII characters; if\n  //     conversion fails, fail serialization.\n  //\n  // 2.  If input_key contains characters not in lcalpha, DIGIT, \"_\", \"-\",\n  //     \".\", or \"*\" fail serialization.\n  //\n  // 3.  If the first character of input_key is not lcalpha or \"*\", fail\n  //     serialization.\n  //\n  // 4.  Let output be an empty string.\n  //\n  // 5.  Append input_key to output.\n  //\n  // 6.  Return output.\n  function serializeKey(value) {\n    if (/^[a-z*][a-z0-9\\-_.*]*$/.test(value) === false) {\n      throw serializeError(value, KEY);\n    }\n    return value;\n  }\n\n  // 4.1.1.2.  Serializing Parameters\n  //\n  // Given an ordered Dictionary as input_parameters (each member having a\n  // param_name and a param_value), return an ASCII string suitable for\n  // use in a HTTP field value.\n  //\n  // 1.  Let output be an empty string.\n  //\n  // 2.  For each param_name with a value of param_value in\n  //     input_parameters:\n  //\n  //     1.  Append \";\" to output.\n  //\n  //     2.  Append the result of running Serializing a Key\n  //         (Section 4.1.1.3) with param_name to output.\n  //\n  //     3.  If param_value is not Boolean true:\n  //\n  //         1.  Append \"=\" to output.\n  //\n  //         2.  Append the result of running Serializing a bare Item\n  //             (Section 4.1.3.1) with param_value to output.\n  //\n  // 3.  Return output.\n  function serializeParams(params) {\n    if (params == null) {\n      return '';\n    }\n    return Object.entries(params).map(function (_ref) {\n      var key = _ref[0],\n        value = _ref[1];\n      if (value === true) {\n        return \";\" + serializeKey(key); // omit true\n      }\n      return \";\" + serializeKey(key) + \"=\" + serializeBareItem(value);\n    }).join('');\n  }\n\n  // 4.1.3.  Serializing an Item\n  //\n  // Given an Item as bare_item and Parameters as item_parameters, return\n  // an ASCII string suitable for use in a HTTP field value.\n  //\n  // 1.  Let output be an empty string.\n  //\n  // 2.  Append the result of running Serializing a Bare Item\n  //     Section 4.1.3.1 with bare_item to output.\n  //\n  // 3.  Append the result of running Serializing Parameters\n  //     Section 4.1.1.2 with item_parameters to output.\n  //\n  // 4.  Return output.\n  function serializeItem(value) {\n    if (value instanceof SfItem) {\n      return \"\" + serializeBareItem(value.value) + serializeParams(value.params);\n    } else {\n      return serializeBareItem(value);\n    }\n  }\n\n  // 4.1.1.1.  Serializing an Inner List\n  //\n  // Given an array of (member_value, parameters) tuples as inner_list,\n  // and parameters as list_parameters, return an ASCII string suitable\n  // for use in a HTTP field value.\n  //\n  // 1.  Let output be the string \"(\".\n  //\n  // 2.  For each (member_value, parameters) of inner_list:\n  //\n  //     1.  Append the result of running Serializing an Item\n  //         (Section 4.1.3) with (member_value, parameters) to output.\n  //\n  //     2.  If more values remain in inner_list, append a single SP to\n  //         output.\n  //\n  // 3.  Append \")\" to output.\n  //\n  // 4.  Append the result of running Serializing Parameters\n  //     (Section 4.1.1.2) with list_parameters to output.\n  //\n  // 5.  Return output.\n  function serializeInnerList(value) {\n    return \"(\" + value.value.map(serializeItem).join(' ') + \")\" + serializeParams(value.params);\n  }\n\n  // 4.1.2.  Serializing a Dictionary\n  //\n  // Given an ordered Dictionary as input_dictionary (each member having a\n  // member_name and a tuple value of (member_value, parameters)), return\n  // an ASCII string suitable for use in a HTTP field value.\n  //\n  // 1.  Let output be an empty string.\n  //\n  // 2.  For each member_name with a value of (member_value, parameters)\n  //     in input_dictionary:\n  //\n  //     1.  Append the result of running Serializing a Key\n  //         (Section 4.1.1.3) with member's member_name to output.\n  //\n  //     2.  If member_value is Boolean true:\n  //\n  //         1.  Append the result of running Serializing Parameters\n  //             (Section 4.1.1.2) with parameters to output.\n  //\n  //     3.  Otherwise:\n  //\n  //         1.  Append \"=\" to output.\n  //\n  //         2.  If member_value is an array, append the result of running\n  //             Serializing an Inner List (Section 4.1.1.1) with\n  //             (member_value, parameters) to output.\n  //\n  //         3.  Otherwise, append the result of running Serializing an\n  //             Item (Section 4.1.3) with (member_value, parameters) to\n  //             output.\n  //\n  //     4.  If more members remain in input_dictionary:\n  //\n  //         1.  Append \",\" to output.\n  //\n  //         2.  Append a single SP to output.\n  //\n  // 3.  Return output.\n  function serializeDict(dict, options) {\n    var _options;\n    if (options === void 0) {\n      options = {\n        whitespace: true\n      };\n    }\n    if (typeof dict !== 'object') {\n      throw serializeError(dict, DICT);\n    }\n    var entries = dict instanceof Map ? dict.entries() : Object.entries(dict);\n    var optionalWhiteSpace = (_options = options) != null && _options.whitespace ? ' ' : '';\n    return Array.from(entries).map(function (_ref) {\n      var key = _ref[0],\n        item = _ref[1];\n      if (item instanceof SfItem === false) {\n        item = new SfItem(item);\n      }\n      var output = serializeKey(key);\n      if (item.value === true) {\n        output += serializeParams(item.params);\n      } else {\n        output += '=';\n        if (Array.isArray(item.value)) {\n          output += serializeInnerList(item);\n        } else {\n          output += serializeItem(item);\n        }\n      }\n      return output;\n    }).join(\",\" + optionalWhiteSpace);\n  }\n\n  /**\n   * Encode an object into a structured field dictionary\n   *\n   * @param input - The structured field dictionary to encode\n   * @returns The structured field string\n   *\n   * @group Structured Field\n   *\n   * @beta\n   */\n  function encodeSfDict(value, options) {\n    return serializeDict(value, options);\n  }\n\n  /**\n   * Checks if the given key is a token field.\n   *\n   * @param key - The key to check.\n   *\n   * @returns `true` if the key is a token field.\n   *\n   * @internal\n   *\n   * @group CMCD\n   */\n  var isTokenField = function isTokenField(key) {\n    return key === 'ot' || key === 'sf' || key === 'st';\n  };\n\n  var isValid = function isValid(value) {\n    if (typeof value === 'number') {\n      return isFiniteNumber(value);\n    }\n    return value != null && value !== '' && value !== false;\n  };\n\n  /**\n   * Constructs a relative path from a URL.\n   *\n   * @param url - The destination URL\n   * @param base - The base URL\n   * @returns The relative path\n   *\n   * @group Utils\n   *\n   * @beta\n   */\n  function urlToRelativePath(url, base) {\n    var to = new URL(url);\n    var from = new URL(base);\n    if (to.origin !== from.origin) {\n      return url;\n    }\n    var toPath = to.pathname.split('/').slice(1);\n    var fromPath = from.pathname.split('/').slice(1, -1);\n    // remove common parents\n    while (toPath[0] === fromPath[0]) {\n      toPath.shift();\n      fromPath.shift();\n    }\n    // add back paths\n    while (fromPath.length) {\n      fromPath.shift();\n      toPath.unshift('..');\n    }\n    return toPath.join('/');\n  }\n\n  /**\n   * Generate a random v4 UUID\n   *\n   * @returns A random v4 UUID\n   *\n   * @group Utils\n   *\n   * @beta\n   */\n  function uuid() {\n    try {\n      return crypto.randomUUID();\n    } catch (error) {\n      try {\n        var url = URL.createObjectURL(new Blob());\n        var _uuid = url.toString();\n        URL.revokeObjectURL(url);\n        return _uuid.slice(_uuid.lastIndexOf('/') + 1);\n      } catch (error) {\n        var dt = new Date().getTime();\n        var _uuid2 = 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {\n          var r = (dt + Math.random() * 16) % 16 | 0;\n          dt = Math.floor(dt / 16);\n          return (c == 'x' ? r : r & 0x3 | 0x8).toString(16);\n        });\n        return _uuid2;\n      }\n    }\n  }\n\n  var toRounded = function toRounded(value) {\n    return Math.round(value);\n  };\n  var toUrlSafe = function toUrlSafe(value, options) {\n    if (options != null && options.baseUrl) {\n      value = urlToRelativePath(value, options.baseUrl);\n    }\n    return encodeURIComponent(value);\n  };\n  var toHundred = function toHundred(value) {\n    return toRounded(value / 100) * 100;\n  };\n  /**\n   * The default formatters for CMCD values.\n   *\n   * @group CMCD\n   *\n   * @beta\n   */\n  var CmcdFormatters = {\n    /**\n     * Bitrate (kbps) rounded integer\n     */\n    br: toRounded,\n    /**\n     * Duration (milliseconds) rounded integer\n     */\n    d: toRounded,\n    /**\n     * Buffer Length (milliseconds) rounded nearest 100ms\n     */\n    bl: toHundred,\n    /**\n     * Deadline (milliseconds) rounded nearest 100ms\n     */\n    dl: toHundred,\n    /**\n     * Measured Throughput (kbps) rounded nearest 100kbps\n     */\n    mtp: toHundred,\n    /**\n     * Next Object Request URL encoded\n     */\n    nor: toUrlSafe,\n    /**\n     * Requested maximum throughput (kbps) rounded nearest 100kbps\n     */\n    rtp: toHundred,\n    /**\n     * Top Bitrate (kbps) rounded integer\n     */\n    tb: toRounded\n  };\n\n  /**\n   * Internal CMCD processing function.\n   *\n   * @param obj - The CMCD object to process.\n   * @param map - The mapping function to use.\n   * @param options - Options for encoding.\n   *\n   * @internal\n   *\n   * @group CMCD\n   */\n  function processCmcd(obj, options) {\n    var results = {};\n    if (obj == null || typeof obj !== 'object') {\n      return results;\n    }\n    var keys = Object.keys(obj).sort();\n    var formatters = _extends({}, CmcdFormatters, options == null ? void 0 : options.formatters);\n    var filter = options == null ? void 0 : options.filter;\n    keys.forEach(function (key) {\n      if (filter != null && filter(key)) {\n        return;\n      }\n      var value = obj[key];\n      var formatter = formatters[key];\n      if (formatter) {\n        value = formatter(value, options);\n      }\n      // Version should only be reported if not equal to 1.\n      if (key === 'v' && value === 1) {\n        return;\n      }\n      // Playback rate should only be sent if not equal to 1.\n      if (key == 'pr' && value === 1) {\n        return;\n      }\n      // ignore invalid values\n      if (!isValid(value)) {\n        return;\n      }\n      if (isTokenField(key) && typeof value === 'string') {\n        value = new SfToken(value);\n      }\n      results[key] = value;\n    });\n    return results;\n  }\n\n  /**\n   * Encode a CMCD object to a string.\n   *\n   * @param cmcd - The CMCD object to encode.\n   * @param options - Options for encoding.\n   *\n   * @returns The encoded CMCD string.\n   *\n   * @group CMCD\n   *\n   * @beta\n   */\n  function encodeCmcd(cmcd, options) {\n    if (options === void 0) {\n      options = {};\n    }\n    if (!cmcd) {\n      return '';\n    }\n    return encodeSfDict(processCmcd(cmcd, options), _extends({\n      whitespace: false\n    }, options));\n  }\n\n  /**\n   * Convert a CMCD data object to request headers\n   *\n   * @param cmcd - The CMCD data object to convert.\n   * @param options - Options for encoding the CMCD object.\n   *\n   * @returns The CMCD header shards.\n   *\n   * @group CMCD\n   *\n   * @beta\n   */\n  function toCmcdHeaders(cmcd, options) {\n    var _options;\n    if (options === void 0) {\n      options = {};\n    }\n    if (!cmcd) {\n      return {};\n    }\n    var entries = Object.entries(cmcd);\n    var headerMap = Object.entries(CmcdHeaderMap).concat(Object.entries(((_options = options) == null ? void 0 : _options.customHeaderMap) || {}));\n    var shards = entries.reduce(function (acc, entry) {\n      var _headerMap$find, _acc$field;\n      var key = entry[0],\n        value = entry[1];\n      var field = ((_headerMap$find = headerMap.find(function (entry) {\n        return entry[1].includes(key);\n      })) == null ? void 0 : _headerMap$find[0]) || CmcdHeaderField.REQUEST;\n      (_acc$field = acc[field]) != null ? _acc$field : acc[field] = {};\n      acc[field][key] = value;\n      return acc;\n    }, {});\n    return Object.entries(shards).reduce(function (acc, _ref) {\n      var field = _ref[0],\n        value = _ref[1];\n      acc[field] = encodeCmcd(value, options);\n      return acc;\n    }, {});\n  }\n\n  /**\n   * Append CMCD query args to a header object.\n   *\n   * @param headers - The headers to append to.\n   * @param cmcd - The CMCD object to append.\n   * @param customHeaderMap - A map of custom CMCD keys to header fields.\n   *\n   * @returns The headers with the CMCD header shards appended.\n   *\n   * @group CMCD\n   *\n   * @beta\n   */\n  function appendCmcdHeaders(headers, cmcd, options) {\n    return _extends(headers, toCmcdHeaders(cmcd, options));\n  }\n\n  /**\n   * CMCD parameter name.\n   *\n   * @group CMCD\n   *\n   * @beta\n   */\n  var CMCD_PARAM = 'CMCD';\n\n  /**\n   * Convert a CMCD data object to a query arg.\n   *\n   * @param cmcd - The CMCD object to convert.\n   * @param options - Options for encoding the CMCD object.\n   *\n   * @returns The CMCD query arg.\n   *\n   * @group CMCD\n   *\n   * @beta\n   */\n  function toCmcdQuery(cmcd, options) {\n    if (options === void 0) {\n      options = {};\n    }\n    if (!cmcd) {\n      return '';\n    }\n    var params = encodeCmcd(cmcd, options);\n    return CMCD_PARAM + \"=\" + encodeURIComponent(params);\n  }\n\n  var REGEX = /CMCD=[^&#]+/;\n  /**\n   * Append CMCD query args to a URL.\n   *\n   * @param url - The URL to append to.\n   * @param cmcd - The CMCD object to append.\n   * @param options - Options for encoding the CMCD object.\n   *\n   * @returns The URL with the CMCD query args appended.\n   *\n   * @group CMCD\n   *\n   * @beta\n   */\n  function appendCmcdQuery(url, cmcd, options) {\n    // TODO: Replace with URLSearchParams once we drop Safari < 10.1 & Chrome < 49 support.\n    // https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams\n    var query = toCmcdQuery(cmcd, options);\n    if (!query) {\n      return url;\n    }\n    if (REGEX.test(url)) {\n      return url.replace(REGEX, query);\n    }\n    var separator = url.includes('?') ? '&' : '?';\n    return \"\" + url + separator + query;\n  }\n\n  /**\n   * Controller to deal with Common Media Client Data (CMCD)\n   * @see https://cdn.cta.tech/cta/media/media/resources/standards/pdfs/cta-5004-final.pdf\n   */\n  var CMCDController = /*#__PURE__*/function () {\n    // eslint-disable-line no-restricted-globals\n\n    function CMCDController(hls) {\n      var _this = this;\n      this.hls = void 0;\n      this.config = void 0;\n      this.media = void 0;\n      this.sid = void 0;\n      this.cid = void 0;\n      this.useHeaders = false;\n      this.includeKeys = void 0;\n      this.initialized = false;\n      this.starved = false;\n      this.buffering = true;\n      this.audioBuffer = void 0;\n      // eslint-disable-line no-restricted-globals\n      this.videoBuffer = void 0;\n      this.onWaiting = function () {\n        if (_this.initialized) {\n          _this.starved = true;\n        }\n        _this.buffering = true;\n      };\n      this.onPlaying = function () {\n        if (!_this.initialized) {\n          _this.initialized = true;\n        }\n        _this.buffering = false;\n      };\n      /**\n       * Apply CMCD data to a manifest request.\n       */\n      this.applyPlaylistData = function (context) {\n        try {\n          _this.apply(context, {\n            ot: CmObjectType.MANIFEST,\n            su: !_this.initialized\n          });\n        } catch (error) {\n          logger.warn('Could not generate manifest CMCD data.', error);\n        }\n      };\n      /**\n       * Apply CMCD data to a segment request\n       */\n      this.applyFragmentData = function (context) {\n        try {\n          var fragment = context.frag;\n          var level = _this.hls.levels[fragment.level];\n          var ot = _this.getObjectType(fragment);\n          var data = {\n            d: fragment.duration * 1000,\n            ot: ot\n          };\n          if (ot === CmObjectType.VIDEO || ot === CmObjectType.AUDIO || ot == CmObjectType.MUXED) {\n            data.br = level.bitrate / 1000;\n            data.tb = _this.getTopBandwidth(ot) / 1000;\n            data.bl = _this.getBufferLength(ot);\n          }\n          _this.apply(context, data);\n        } catch (error) {\n          logger.warn('Could not generate segment CMCD data.', error);\n        }\n      };\n      this.hls = hls;\n      var config = this.config = hls.config;\n      var cmcd = config.cmcd;\n      if (cmcd != null) {\n        config.pLoader = this.createPlaylistLoader();\n        config.fLoader = this.createFragmentLoader();\n        this.sid = cmcd.sessionId || uuid();\n        this.cid = cmcd.contentId;\n        this.useHeaders = cmcd.useHeaders === true;\n        this.includeKeys = cmcd.includeKeys;\n        this.registerListeners();\n      }\n    }\n    var _proto = CMCDController.prototype;\n    _proto.registerListeners = function registerListeners() {\n      var hls = this.hls;\n      hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.on(Events.MEDIA_DETACHED, this.onMediaDetached, this);\n      hls.on(Events.BUFFER_CREATED, this.onBufferCreated, this);\n    };\n    _proto.unregisterListeners = function unregisterListeners() {\n      var hls = this.hls;\n      hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.off(Events.MEDIA_DETACHED, this.onMediaDetached, this);\n      hls.off(Events.BUFFER_CREATED, this.onBufferCreated, this);\n    };\n    _proto.destroy = function destroy() {\n      this.unregisterListeners();\n      this.onMediaDetached();\n\n      // @ts-ignore\n      this.hls = this.config = this.audioBuffer = this.videoBuffer = null;\n      // @ts-ignore\n      this.onWaiting = this.onPlaying = null;\n    };\n    _proto.onMediaAttached = function onMediaAttached(event, data) {\n      this.media = data.media;\n      this.media.addEventListener('waiting', this.onWaiting);\n      this.media.addEventListener('playing', this.onPlaying);\n    };\n    _proto.onMediaDetached = function onMediaDetached() {\n      if (!this.media) {\n        return;\n      }\n      this.media.removeEventListener('waiting', this.onWaiting);\n      this.media.removeEventListener('playing', this.onPlaying);\n\n      // @ts-ignore\n      this.media = null;\n    };\n    _proto.onBufferCreated = function onBufferCreated(event, data) {\n      var _data$tracks$audio, _data$tracks$video;\n      this.audioBuffer = (_data$tracks$audio = data.tracks.audio) == null ? void 0 : _data$tracks$audio.buffer;\n      this.videoBuffer = (_data$tracks$video = data.tracks.video) == null ? void 0 : _data$tracks$video.buffer;\n    };\n    /**\n     * Create baseline CMCD data\n     */\n    _proto.createData = function createData() {\n      var _this$media;\n      return {\n        v: 1,\n        sf: CmStreamingFormat.HLS,\n        sid: this.sid,\n        cid: this.cid,\n        pr: (_this$media = this.media) == null ? void 0 : _this$media.playbackRate,\n        mtp: this.hls.bandwidthEstimate / 1000\n      };\n    }\n\n    /**\n     * Apply CMCD data to a request.\n     */;\n    _proto.apply = function apply(context, data) {\n      if (data === void 0) {\n        data = {};\n      }\n      // apply baseline data\n      _extends(data, this.createData());\n      var isVideo = data.ot === CmObjectType.INIT || data.ot === CmObjectType.VIDEO || data.ot === CmObjectType.MUXED;\n      if (this.starved && isVideo) {\n        data.bs = true;\n        data.su = true;\n        this.starved = false;\n      }\n      if (data.su == null) {\n        data.su = this.buffering;\n      }\n\n      // TODO: Implement rtp, nrr, nor, dl\n\n      var includeKeys = this.includeKeys;\n      if (includeKeys) {\n        data = Object.keys(data).reduce(function (acc, key) {\n          includeKeys.includes(key) && (acc[key] = data[key]);\n          return acc;\n        }, {});\n      }\n      if (this.useHeaders) {\n        if (!context.headers) {\n          context.headers = {};\n        }\n        appendCmcdHeaders(context.headers, data);\n      } else {\n        context.url = appendCmcdQuery(context.url, data);\n      }\n    };\n    /**\n     * The CMCD object type.\n     */\n    _proto.getObjectType = function getObjectType(fragment) {\n      var type = fragment.type;\n      if (type === 'subtitle') {\n        return CmObjectType.TIMED_TEXT;\n      }\n      if (fragment.sn === 'initSegment') {\n        return CmObjectType.INIT;\n      }\n      if (type === 'audio') {\n        return CmObjectType.AUDIO;\n      }\n      if (type === 'main') {\n        if (!this.hls.audioTracks.length) {\n          return CmObjectType.MUXED;\n        }\n        return CmObjectType.VIDEO;\n      }\n      return undefined;\n    }\n\n    /**\n     * Get the highest bitrate.\n     */;\n    _proto.getTopBandwidth = function getTopBandwidth(type) {\n      var bitrate = 0;\n      var levels;\n      var hls = this.hls;\n      if (type === CmObjectType.AUDIO) {\n        levels = hls.audioTracks;\n      } else {\n        var max = hls.maxAutoLevel;\n        var len = max > -1 ? max + 1 : hls.levels.length;\n        levels = hls.levels.slice(0, len);\n      }\n      for (var _iterator = _createForOfIteratorHelperLoose(levels), _step; !(_step = _iterator()).done;) {\n        var level = _step.value;\n        if (level.bitrate > bitrate) {\n          bitrate = level.bitrate;\n        }\n      }\n      return bitrate > 0 ? bitrate : NaN;\n    }\n\n    /**\n     * Get the buffer length for a media type in milliseconds\n     */;\n    _proto.getBufferLength = function getBufferLength(type) {\n      var media = this.hls.media;\n      var buffer = type === CmObjectType.AUDIO ? this.audioBuffer : this.videoBuffer;\n      if (!buffer || !media) {\n        return NaN;\n      }\n      var info = BufferHelper.bufferInfo(buffer, media.currentTime, this.config.maxBufferHole);\n      return info.len * 1000;\n    }\n\n    /**\n     * Create a playlist loader\n     */;\n    _proto.createPlaylistLoader = function createPlaylistLoader() {\n      var pLoader = this.config.pLoader;\n      var apply = this.applyPlaylistData;\n      var Ctor = pLoader || this.config.loader;\n      return /*#__PURE__*/function () {\n        function CmcdPlaylistLoader(config) {\n          this.loader = void 0;\n          this.loader = new Ctor(config);\n        }\n        var _proto2 = CmcdPlaylistLoader.prototype;\n        _proto2.destroy = function destroy() {\n          this.loader.destroy();\n        };\n        _proto2.abort = function abort() {\n          this.loader.abort();\n        };\n        _proto2.load = function load(context, config, callbacks) {\n          apply(context);\n          this.loader.load(context, config, callbacks);\n        };\n        _createClass(CmcdPlaylistLoader, [{\n          key: \"stats\",\n          get: function get() {\n            return this.loader.stats;\n          }\n        }, {\n          key: \"context\",\n          get: function get() {\n            return this.loader.context;\n          }\n        }]);\n        return CmcdPlaylistLoader;\n      }();\n    }\n\n    /**\n     * Create a playlist loader\n     */;\n    _proto.createFragmentLoader = function createFragmentLoader() {\n      var fLoader = this.config.fLoader;\n      var apply = this.applyFragmentData;\n      var Ctor = fLoader || this.config.loader;\n      return /*#__PURE__*/function () {\n        function CmcdFragmentLoader(config) {\n          this.loader = void 0;\n          this.loader = new Ctor(config);\n        }\n        var _proto3 = CmcdFragmentLoader.prototype;\n        _proto3.destroy = function destroy() {\n          this.loader.destroy();\n        };\n        _proto3.abort = function abort() {\n          this.loader.abort();\n        };\n        _proto3.load = function load(context, config, callbacks) {\n          apply(context);\n          this.loader.load(context, config, callbacks);\n        };\n        _createClass(CmcdFragmentLoader, [{\n          key: \"stats\",\n          get: function get() {\n            return this.loader.stats;\n          }\n        }, {\n          key: \"context\",\n          get: function get() {\n            return this.loader.context;\n          }\n        }]);\n        return CmcdFragmentLoader;\n      }();\n    };\n    return CMCDController;\n  }();\n\n  var PATHWAY_PENALTY_DURATION_MS = 300000;\n  var ContentSteeringController = /*#__PURE__*/function () {\n    function ContentSteeringController(hls) {\n      this.hls = void 0;\n      this.log = void 0;\n      this.loader = null;\n      this.uri = null;\n      this.pathwayId = '.';\n      this.pathwayPriority = null;\n      this.timeToLoad = 300;\n      this.reloadTimer = -1;\n      this.updated = 0;\n      this.started = false;\n      this.enabled = true;\n      this.levels = null;\n      this.audioTracks = null;\n      this.subtitleTracks = null;\n      this.penalizedPathways = {};\n      this.hls = hls;\n      this.log = logger.log.bind(logger, \"[content-steering]:\");\n      this.registerListeners();\n    }\n    var _proto = ContentSteeringController.prototype;\n    _proto.registerListeners = function registerListeners() {\n      var hls = this.hls;\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n      hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n      hls.on(Events.ERROR, this.onError, this);\n    };\n    _proto.unregisterListeners = function unregisterListeners() {\n      var hls = this.hls;\n      if (!hls) {\n        return;\n      }\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n      hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n      hls.off(Events.ERROR, this.onError, this);\n    };\n    _proto.startLoad = function startLoad() {\n      this.started = true;\n      this.clearTimeout();\n      if (this.enabled && this.uri) {\n        if (this.updated) {\n          var ttl = this.timeToLoad * 1000 - (performance.now() - this.updated);\n          if (ttl > 0) {\n            this.scheduleRefresh(this.uri, ttl);\n            return;\n          }\n        }\n        this.loadSteeringManifest(this.uri);\n      }\n    };\n    _proto.stopLoad = function stopLoad() {\n      this.started = false;\n      if (this.loader) {\n        this.loader.destroy();\n        this.loader = null;\n      }\n      this.clearTimeout();\n    };\n    _proto.clearTimeout = function clearTimeout() {\n      if (this.reloadTimer !== -1) {\n        self.clearTimeout(this.reloadTimer);\n        this.reloadTimer = -1;\n      }\n    };\n    _proto.destroy = function destroy() {\n      this.unregisterListeners();\n      this.stopLoad();\n      // @ts-ignore\n      this.hls = null;\n      this.levels = this.audioTracks = this.subtitleTracks = null;\n    };\n    _proto.removeLevel = function removeLevel(levelToRemove) {\n      var levels = this.levels;\n      if (levels) {\n        this.levels = levels.filter(function (level) {\n          return level !== levelToRemove;\n        });\n      }\n    };\n    _proto.onManifestLoading = function onManifestLoading() {\n      this.stopLoad();\n      this.enabled = true;\n      this.timeToLoad = 300;\n      this.updated = 0;\n      this.uri = null;\n      this.pathwayId = '.';\n      this.levels = this.audioTracks = this.subtitleTracks = null;\n    };\n    _proto.onManifestLoaded = function onManifestLoaded(event, data) {\n      var contentSteering = data.contentSteering;\n      if (contentSteering === null) {\n        return;\n      }\n      this.pathwayId = contentSteering.pathwayId;\n      this.uri = contentSteering.uri;\n      if (this.started) {\n        this.startLoad();\n      }\n    };\n    _proto.onManifestParsed = function onManifestParsed(event, data) {\n      this.audioTracks = data.audioTracks;\n      this.subtitleTracks = data.subtitleTracks;\n    };\n    _proto.onError = function onError(event, data) {\n      var errorAction = data.errorAction;\n      if ((errorAction == null ? void 0 : errorAction.action) === NetworkErrorAction.SendAlternateToPenaltyBox && errorAction.flags === ErrorActionFlags.MoveAllAlternatesMatchingHost) {\n        var levels = this.levels;\n        var pathwayPriority = this.pathwayPriority;\n        var errorPathway = this.pathwayId;\n        if (data.context) {\n          var _data$context = data.context,\n            groupId = _data$context.groupId,\n            _pathwayId = _data$context.pathwayId,\n            type = _data$context.type;\n          if (groupId && levels) {\n            errorPathway = this.getPathwayForGroupId(groupId, type, errorPathway);\n          } else if (_pathwayId) {\n            errorPathway = _pathwayId;\n          }\n        }\n        if (!(errorPathway in this.penalizedPathways)) {\n          this.penalizedPathways[errorPathway] = performance.now();\n        }\n        if (!pathwayPriority && levels) {\n          // If PATHWAY-PRIORITY was not provided, list pathways for error handling\n          pathwayPriority = levels.reduce(function (pathways, level) {\n            if (pathways.indexOf(level.pathwayId) === -1) {\n              pathways.push(level.pathwayId);\n            }\n            return pathways;\n          }, []);\n        }\n        if (pathwayPriority && pathwayPriority.length > 1) {\n          this.updatePathwayPriority(pathwayPriority);\n          errorAction.resolved = this.pathwayId !== errorPathway;\n        }\n        if (!errorAction.resolved) {\n          logger.warn(\"Could not resolve \" + data.details + \" (\\\"\" + data.error.message + \"\\\") with content-steering for Pathway: \" + errorPathway + \" levels: \" + (levels ? levels.length : levels) + \" priorities: \" + JSON.stringify(pathwayPriority) + \" penalized: \" + JSON.stringify(this.penalizedPathways));\n        }\n      }\n    };\n    _proto.filterParsedLevels = function filterParsedLevels(levels) {\n      // Filter levels to only include those that are in the initial pathway\n      this.levels = levels;\n      var pathwayLevels = this.getLevelsForPathway(this.pathwayId);\n      if (pathwayLevels.length === 0) {\n        var _pathwayId2 = levels[0].pathwayId;\n        this.log(\"No levels found in Pathway \" + this.pathwayId + \". Setting initial Pathway to \\\"\" + _pathwayId2 + \"\\\"\");\n        pathwayLevels = this.getLevelsForPathway(_pathwayId2);\n        this.pathwayId = _pathwayId2;\n      }\n      if (pathwayLevels.length !== levels.length) {\n        this.log(\"Found \" + pathwayLevels.length + \"/\" + levels.length + \" levels in Pathway \\\"\" + this.pathwayId + \"\\\"\");\n      }\n      return pathwayLevels;\n    };\n    _proto.getLevelsForPathway = function getLevelsForPathway(pathwayId) {\n      if (this.levels === null) {\n        return [];\n      }\n      return this.levels.filter(function (level) {\n        return pathwayId === level.pathwayId;\n      });\n    };\n    _proto.updatePathwayPriority = function updatePathwayPriority(pathwayPriority) {\n      this.pathwayPriority = pathwayPriority;\n      var levels;\n\n      // Evaluate if we should remove the pathway from the penalized list\n      var penalizedPathways = this.penalizedPathways;\n      var now = performance.now();\n      Object.keys(penalizedPathways).forEach(function (pathwayId) {\n        if (now - penalizedPathways[pathwayId] > PATHWAY_PENALTY_DURATION_MS) {\n          delete penalizedPathways[pathwayId];\n        }\n      });\n      for (var i = 0; i < pathwayPriority.length; i++) {\n        var _pathwayId3 = pathwayPriority[i];\n        if (_pathwayId3 in penalizedPathways) {\n          continue;\n        }\n        if (_pathwayId3 === this.pathwayId) {\n          return;\n        }\n        var selectedIndex = this.hls.nextLoadLevel;\n        var selectedLevel = this.hls.levels[selectedIndex];\n        levels = this.getLevelsForPathway(_pathwayId3);\n        if (levels.length > 0) {\n          this.log(\"Setting Pathway to \\\"\" + _pathwayId3 + \"\\\"\");\n          this.pathwayId = _pathwayId3;\n          reassignFragmentLevelIndexes(levels);\n          this.hls.trigger(Events.LEVELS_UPDATED, {\n            levels: levels\n          });\n          // Set LevelController's level to trigger LEVEL_SWITCHING which loads playlist if needed\n          var levelAfterChange = this.hls.levels[selectedIndex];\n          if (selectedLevel && levelAfterChange && this.levels) {\n            if (levelAfterChange.attrs['STABLE-VARIANT-ID'] !== selectedLevel.attrs['STABLE-VARIANT-ID'] && levelAfterChange.bitrate !== selectedLevel.bitrate) {\n              this.log(\"Unstable Pathways change from bitrate \" + selectedLevel.bitrate + \" to \" + levelAfterChange.bitrate);\n            }\n            this.hls.nextLoadLevel = selectedIndex;\n          }\n          break;\n        }\n      }\n    };\n    _proto.getPathwayForGroupId = function getPathwayForGroupId(groupId, type, defaultPathway) {\n      var levels = this.getLevelsForPathway(defaultPathway).concat(this.levels || []);\n      for (var i = 0; i < levels.length; i++) {\n        if (type === PlaylistContextType.AUDIO_TRACK && levels[i].hasAudioGroup(groupId) || type === PlaylistContextType.SUBTITLE_TRACK && levels[i].hasSubtitleGroup(groupId)) {\n          return levels[i].pathwayId;\n        }\n      }\n      return defaultPathway;\n    };\n    _proto.clonePathways = function clonePathways(pathwayClones) {\n      var _this = this;\n      var levels = this.levels;\n      if (!levels) {\n        return;\n      }\n      var audioGroupCloneMap = {};\n      var subtitleGroupCloneMap = {};\n      pathwayClones.forEach(function (pathwayClone) {\n        var cloneId = pathwayClone.ID,\n          baseId = pathwayClone['BASE-ID'],\n          uriReplacement = pathwayClone['URI-REPLACEMENT'];\n        if (levels.some(function (level) {\n          return level.pathwayId === cloneId;\n        })) {\n          return;\n        }\n        var clonedVariants = _this.getLevelsForPathway(baseId).map(function (baseLevel) {\n          var attributes = new AttrList(baseLevel.attrs);\n          attributes['PATHWAY-ID'] = cloneId;\n          var clonedAudioGroupId = attributes.AUDIO && attributes.AUDIO + \"_clone_\" + cloneId;\n          var clonedSubtitleGroupId = attributes.SUBTITLES && attributes.SUBTITLES + \"_clone_\" + cloneId;\n          if (clonedAudioGroupId) {\n            audioGroupCloneMap[attributes.AUDIO] = clonedAudioGroupId;\n            attributes.AUDIO = clonedAudioGroupId;\n          }\n          if (clonedSubtitleGroupId) {\n            subtitleGroupCloneMap[attributes.SUBTITLES] = clonedSubtitleGroupId;\n            attributes.SUBTITLES = clonedSubtitleGroupId;\n          }\n          var url = performUriReplacement(baseLevel.uri, attributes['STABLE-VARIANT-ID'], 'PER-VARIANT-URIS', uriReplacement);\n          var clonedLevel = new Level({\n            attrs: attributes,\n            audioCodec: baseLevel.audioCodec,\n            bitrate: baseLevel.bitrate,\n            height: baseLevel.height,\n            name: baseLevel.name,\n            url: url,\n            videoCodec: baseLevel.videoCodec,\n            width: baseLevel.width\n          });\n          if (baseLevel.audioGroups) {\n            for (var i = 1; i < baseLevel.audioGroups.length; i++) {\n              clonedLevel.addGroupId('audio', baseLevel.audioGroups[i] + \"_clone_\" + cloneId);\n            }\n          }\n          if (baseLevel.subtitleGroups) {\n            for (var _i = 1; _i < baseLevel.subtitleGroups.length; _i++) {\n              clonedLevel.addGroupId('text', baseLevel.subtitleGroups[_i] + \"_clone_\" + cloneId);\n            }\n          }\n          return clonedLevel;\n        });\n        levels.push.apply(levels, clonedVariants);\n        cloneRenditionGroups(_this.audioTracks, audioGroupCloneMap, uriReplacement, cloneId);\n        cloneRenditionGroups(_this.subtitleTracks, subtitleGroupCloneMap, uriReplacement, cloneId);\n      });\n    };\n    _proto.loadSteeringManifest = function loadSteeringManifest(uri) {\n      var _this2 = this;\n      var config = this.hls.config;\n      var Loader = config.loader;\n      if (this.loader) {\n        this.loader.destroy();\n      }\n      this.loader = new Loader(config);\n      var url;\n      try {\n        url = new self.URL(uri);\n      } catch (error) {\n        this.enabled = false;\n        this.log(\"Failed to parse Steering Manifest URI: \" + uri);\n        return;\n      }\n      if (url.protocol !== 'data:') {\n        var throughput = (this.hls.bandwidthEstimate || config.abrEwmaDefaultEstimate) | 0;\n        url.searchParams.set('_HLS_pathway', this.pathwayId);\n        url.searchParams.set('_HLS_throughput', '' + throughput);\n      }\n      var context = {\n        responseType: 'json',\n        url: url.href\n      };\n      var loadPolicy = config.steeringManifestLoadPolicy.default;\n      var legacyRetryCompatibility = loadPolicy.errorRetry || loadPolicy.timeoutRetry || {};\n      var loaderConfig = {\n        loadPolicy: loadPolicy,\n        timeout: loadPolicy.maxLoadTimeMs,\n        maxRetry: legacyRetryCompatibility.maxNumRetry || 0,\n        retryDelay: legacyRetryCompatibility.retryDelayMs || 0,\n        maxRetryDelay: legacyRetryCompatibility.maxRetryDelayMs || 0\n      };\n      var callbacks = {\n        onSuccess: function onSuccess(response, stats, context, networkDetails) {\n          _this2.log(\"Loaded steering manifest: \\\"\" + url + \"\\\"\");\n          var steeringData = response.data;\n          if (steeringData.VERSION !== 1) {\n            _this2.log(\"Steering VERSION \" + steeringData.VERSION + \" not supported!\");\n            return;\n          }\n          _this2.updated = performance.now();\n          _this2.timeToLoad = steeringData.TTL;\n          var reloadUri = steeringData['RELOAD-URI'],\n            pathwayClones = steeringData['PATHWAY-CLONES'],\n            pathwayPriority = steeringData['PATHWAY-PRIORITY'];\n          if (reloadUri) {\n            try {\n              _this2.uri = new self.URL(reloadUri, url).href;\n            } catch (error) {\n              _this2.enabled = false;\n              _this2.log(\"Failed to parse Steering Manifest RELOAD-URI: \" + reloadUri);\n              return;\n            }\n          }\n          _this2.scheduleRefresh(_this2.uri || context.url);\n          if (pathwayClones) {\n            _this2.clonePathways(pathwayClones);\n          }\n          var loadedSteeringData = {\n            steeringManifest: steeringData,\n            url: url.toString()\n          };\n          _this2.hls.trigger(Events.STEERING_MANIFEST_LOADED, loadedSteeringData);\n          if (pathwayPriority) {\n            _this2.updatePathwayPriority(pathwayPriority);\n          }\n        },\n        onError: function onError(error, context, networkDetails, stats) {\n          _this2.log(\"Error loading steering manifest: \" + error.code + \" \" + error.text + \" (\" + context.url + \")\");\n          _this2.stopLoad();\n          if (error.code === 410) {\n            _this2.enabled = false;\n            _this2.log(\"Steering manifest \" + context.url + \" no longer available\");\n            return;\n          }\n          var ttl = _this2.timeToLoad * 1000;\n          if (error.code === 429) {\n            var loader = _this2.loader;\n            if (typeof (loader == null ? void 0 : loader.getResponseHeader) === 'function') {\n              var retryAfter = loader.getResponseHeader('Retry-After');\n              if (retryAfter) {\n                ttl = parseFloat(retryAfter) * 1000;\n              }\n            }\n            _this2.log(\"Steering manifest \" + context.url + \" rate limited\");\n            return;\n          }\n          _this2.scheduleRefresh(_this2.uri || context.url, ttl);\n        },\n        onTimeout: function onTimeout(stats, context, networkDetails) {\n          _this2.log(\"Timeout loading steering manifest (\" + context.url + \")\");\n          _this2.scheduleRefresh(_this2.uri || context.url);\n        }\n      };\n      this.log(\"Requesting steering manifest: \" + url);\n      this.loader.load(context, loaderConfig, callbacks);\n    };\n    _proto.scheduleRefresh = function scheduleRefresh(uri, ttlMs) {\n      var _this3 = this;\n      if (ttlMs === void 0) {\n        ttlMs = this.timeToLoad * 1000;\n      }\n      this.clearTimeout();\n      this.reloadTimer = self.setTimeout(function () {\n        var _this3$hls;\n        var media = (_this3$hls = _this3.hls) == null ? void 0 : _this3$hls.media;\n        if (media && !media.ended) {\n          _this3.loadSteeringManifest(uri);\n          return;\n        }\n        _this3.scheduleRefresh(uri, _this3.timeToLoad * 1000);\n      }, ttlMs);\n    };\n    return ContentSteeringController;\n  }();\n  function cloneRenditionGroups(tracks, groupCloneMap, uriReplacement, cloneId) {\n    if (!tracks) {\n      return;\n    }\n    Object.keys(groupCloneMap).forEach(function (audioGroupId) {\n      var clonedTracks = tracks.filter(function (track) {\n        return track.groupId === audioGroupId;\n      }).map(function (track) {\n        var clonedTrack = _extends({}, track);\n        clonedTrack.details = undefined;\n        clonedTrack.attrs = new AttrList(clonedTrack.attrs);\n        clonedTrack.url = clonedTrack.attrs.URI = performUriReplacement(track.url, track.attrs['STABLE-RENDITION-ID'], 'PER-RENDITION-URIS', uriReplacement);\n        clonedTrack.groupId = clonedTrack.attrs['GROUP-ID'] = groupCloneMap[audioGroupId];\n        clonedTrack.attrs['PATHWAY-ID'] = cloneId;\n        return clonedTrack;\n      });\n      tracks.push.apply(tracks, clonedTracks);\n    });\n  }\n  function performUriReplacement(uri, stableId, perOptionKey, uriReplacement) {\n    var host = uriReplacement.HOST,\n      params = uriReplacement.PARAMS,\n      perOptionUris = uriReplacement[perOptionKey];\n    var perVariantUri;\n    if (stableId) {\n      perVariantUri = perOptionUris == null ? void 0 : perOptionUris[stableId];\n      if (perVariantUri) {\n        uri = perVariantUri;\n      }\n    }\n    var url = new self.URL(uri);\n    if (host && !perVariantUri) {\n      url.host = host;\n    }\n    if (params) {\n      Object.keys(params).sort().forEach(function (key) {\n        if (key) {\n          url.searchParams.set(key, params[key]);\n        }\n      });\n    }\n    return url.href;\n  }\n\n  var AGE_HEADER_LINE_REGEX = /^age:\\s*[\\d.]+\\s*$/im;\n  var XhrLoader = /*#__PURE__*/function () {\n    function XhrLoader(config) {\n      this.xhrSetup = void 0;\n      this.requestTimeout = void 0;\n      this.retryTimeout = void 0;\n      this.retryDelay = void 0;\n      this.config = null;\n      this.callbacks = null;\n      this.context = null;\n      this.loader = null;\n      this.stats = void 0;\n      this.xhrSetup = config ? config.xhrSetup || null : null;\n      this.stats = new LoadStats();\n      this.retryDelay = 0;\n    }\n    var _proto = XhrLoader.prototype;\n    _proto.destroy = function destroy() {\n      this.callbacks = null;\n      this.abortInternal();\n      this.loader = null;\n      this.config = null;\n      this.context = null;\n      this.xhrSetup = null;\n    };\n    _proto.abortInternal = function abortInternal() {\n      var loader = this.loader;\n      self.clearTimeout(this.requestTimeout);\n      self.clearTimeout(this.retryTimeout);\n      if (loader) {\n        loader.onreadystatechange = null;\n        loader.onprogress = null;\n        if (loader.readyState !== 4) {\n          this.stats.aborted = true;\n          loader.abort();\n        }\n      }\n    };\n    _proto.abort = function abort() {\n      var _this$callbacks;\n      this.abortInternal();\n      if ((_this$callbacks = this.callbacks) != null && _this$callbacks.onAbort) {\n        this.callbacks.onAbort(this.stats, this.context, this.loader);\n      }\n    };\n    _proto.load = function load(context, config, callbacks) {\n      if (this.stats.loading.start) {\n        throw new Error('Loader can only be used once.');\n      }\n      this.stats.loading.start = self.performance.now();\n      this.context = context;\n      this.config = config;\n      this.callbacks = callbacks;\n      this.loadInternal();\n    };\n    _proto.loadInternal = function loadInternal() {\n      var _this = this;\n      var config = this.config,\n        context = this.context;\n      if (!config || !context) {\n        return;\n      }\n      var xhr = this.loader = new self.XMLHttpRequest();\n      var stats = this.stats;\n      stats.loading.first = 0;\n      stats.loaded = 0;\n      stats.aborted = false;\n      var xhrSetup = this.xhrSetup;\n      if (xhrSetup) {\n        Promise.resolve().then(function () {\n          if (_this.loader !== xhr || _this.stats.aborted) return;\n          return xhrSetup(xhr, context.url);\n        }).catch(function (error) {\n          if (_this.loader !== xhr || _this.stats.aborted) return;\n          xhr.open('GET', context.url, true);\n          return xhrSetup(xhr, context.url);\n        }).then(function () {\n          if (_this.loader !== xhr || _this.stats.aborted) return;\n          _this.openAndSendXhr(xhr, context, config);\n        }).catch(function (error) {\n          // IE11 throws an exception on xhr.open if attempting to access an HTTP resource over HTTPS\n          _this.callbacks.onError({\n            code: xhr.status,\n            text: error.message\n          }, context, xhr, stats);\n          return;\n        });\n      } else {\n        this.openAndSendXhr(xhr, context, config);\n      }\n    };\n    _proto.openAndSendXhr = function openAndSendXhr(xhr, context, config) {\n      if (!xhr.readyState) {\n        xhr.open('GET', context.url, true);\n      }\n      var headers = context.headers;\n      var _config$loadPolicy = config.loadPolicy,\n        maxTimeToFirstByteMs = _config$loadPolicy.maxTimeToFirstByteMs,\n        maxLoadTimeMs = _config$loadPolicy.maxLoadTimeMs;\n      if (headers) {\n        for (var header in headers) {\n          xhr.setRequestHeader(header, headers[header]);\n        }\n      }\n      if (context.rangeEnd) {\n        xhr.setRequestHeader('Range', 'bytes=' + context.rangeStart + '-' + (context.rangeEnd - 1));\n      }\n      xhr.onreadystatechange = this.readystatechange.bind(this);\n      xhr.onprogress = this.loadprogress.bind(this);\n      xhr.responseType = context.responseType;\n      // setup timeout before we perform request\n      self.clearTimeout(this.requestTimeout);\n      config.timeout = maxTimeToFirstByteMs && isFiniteNumber(maxTimeToFirstByteMs) ? maxTimeToFirstByteMs : maxLoadTimeMs;\n      this.requestTimeout = self.setTimeout(this.loadtimeout.bind(this), config.timeout);\n      xhr.send();\n    };\n    _proto.readystatechange = function readystatechange() {\n      var context = this.context,\n        xhr = this.loader,\n        stats = this.stats;\n      if (!context || !xhr) {\n        return;\n      }\n      var readyState = xhr.readyState;\n      var config = this.config;\n\n      // don't proceed if xhr has been aborted\n      if (stats.aborted) {\n        return;\n      }\n\n      // >= HEADERS_RECEIVED\n      if (readyState >= 2) {\n        if (stats.loading.first === 0) {\n          stats.loading.first = Math.max(self.performance.now(), stats.loading.start);\n          // readyState >= 2 AND readyState !==4 (readyState = HEADERS_RECEIVED || LOADING) rearm timeout as xhr not finished yet\n          if (config.timeout !== config.loadPolicy.maxLoadTimeMs) {\n            self.clearTimeout(this.requestTimeout);\n            config.timeout = config.loadPolicy.maxLoadTimeMs;\n            this.requestTimeout = self.setTimeout(this.loadtimeout.bind(this), config.loadPolicy.maxLoadTimeMs - (stats.loading.first - stats.loading.start));\n          }\n        }\n        if (readyState === 4) {\n          self.clearTimeout(this.requestTimeout);\n          xhr.onreadystatechange = null;\n          xhr.onprogress = null;\n          var _status = xhr.status;\n          // http status between 200 to 299 are all successful\n          var useResponse = xhr.responseType !== 'text';\n          if (_status >= 200 && _status < 300 && (useResponse && xhr.response || xhr.responseText !== null)) {\n            stats.loading.end = Math.max(self.performance.now(), stats.loading.first);\n            var data = useResponse ? xhr.response : xhr.responseText;\n            var len = xhr.responseType === 'arraybuffer' ? data.byteLength : data.length;\n            stats.loaded = stats.total = len;\n            stats.bwEstimate = stats.total * 8000 / (stats.loading.end - stats.loading.first);\n            if (!this.callbacks) {\n              return;\n            }\n            var onProgress = this.callbacks.onProgress;\n            if (onProgress) {\n              onProgress(stats, context, data, xhr);\n            }\n            if (!this.callbacks) {\n              return;\n            }\n            var response = {\n              url: xhr.responseURL,\n              data: data,\n              code: _status\n            };\n            this.callbacks.onSuccess(response, stats, context, xhr);\n          } else {\n            var retryConfig = config.loadPolicy.errorRetry;\n            var retryCount = stats.retry;\n            // if max nb of retries reached or if http status between 400 and 499 (such error cannot be recovered, retrying is useless), return error\n            var _response = {\n              url: context.url,\n              data: undefined,\n              code: _status\n            };\n            if (shouldRetry(retryConfig, retryCount, false, _response)) {\n              this.retry(retryConfig);\n            } else {\n              logger.error(_status + \" while loading \" + context.url);\n              this.callbacks.onError({\n                code: _status,\n                text: xhr.statusText\n              }, context, xhr, stats);\n            }\n          }\n        }\n      }\n    };\n    _proto.loadtimeout = function loadtimeout() {\n      if (!this.config) return;\n      var retryConfig = this.config.loadPolicy.timeoutRetry;\n      var retryCount = this.stats.retry;\n      if (shouldRetry(retryConfig, retryCount, true)) {\n        this.retry(retryConfig);\n      } else {\n        var _this$context;\n        logger.warn(\"timeout while loading \" + ((_this$context = this.context) == null ? void 0 : _this$context.url));\n        var callbacks = this.callbacks;\n        if (callbacks) {\n          this.abortInternal();\n          callbacks.onTimeout(this.stats, this.context, this.loader);\n        }\n      }\n    };\n    _proto.retry = function retry(retryConfig) {\n      var context = this.context,\n        stats = this.stats;\n      this.retryDelay = getRetryDelay(retryConfig, stats.retry);\n      stats.retry++;\n      logger.warn((status ? 'HTTP Status ' + status : 'Timeout') + \" while loading \" + (context == null ? void 0 : context.url) + \", retrying \" + stats.retry + \"/\" + retryConfig.maxNumRetry + \" in \" + this.retryDelay + \"ms\");\n      // abort and reset internal state\n      this.abortInternal();\n      this.loader = null;\n      // schedule retry\n      self.clearTimeout(this.retryTimeout);\n      this.retryTimeout = self.setTimeout(this.loadInternal.bind(this), this.retryDelay);\n    };\n    _proto.loadprogress = function loadprogress(event) {\n      var stats = this.stats;\n      stats.loaded = event.loaded;\n      if (event.lengthComputable) {\n        stats.total = event.total;\n      }\n    };\n    _proto.getCacheAge = function getCacheAge() {\n      var result = null;\n      if (this.loader && AGE_HEADER_LINE_REGEX.test(this.loader.getAllResponseHeaders())) {\n        var ageHeader = this.loader.getResponseHeader('age');\n        result = ageHeader ? parseFloat(ageHeader) : null;\n      }\n      return result;\n    };\n    _proto.getResponseHeader = function getResponseHeader(name) {\n      if (this.loader && new RegExp(\"^\" + name + \":\\\\s*[\\\\d.]+\\\\s*$\", 'im').test(this.loader.getAllResponseHeaders())) {\n        return this.loader.getResponseHeader(name);\n      }\n      return null;\n    };\n    return XhrLoader;\n  }();\n\n  function fetchSupported() {\n    if (\n    // @ts-ignore\n    self.fetch && self.AbortController && self.ReadableStream && self.Request) {\n      try {\n        new self.ReadableStream({}); // eslint-disable-line no-new\n        return true;\n      } catch (e) {\n        /* noop */\n      }\n    }\n    return false;\n  }\n  var BYTERANGE = /(\\d+)-(\\d+)\\/(\\d+)/;\n  var FetchLoader = /*#__PURE__*/function () {\n    function FetchLoader(config /* HlsConfig */) {\n      this.fetchSetup = void 0;\n      this.requestTimeout = void 0;\n      this.request = null;\n      this.response = null;\n      this.controller = void 0;\n      this.context = null;\n      this.config = null;\n      this.callbacks = null;\n      this.stats = void 0;\n      this.loader = null;\n      this.fetchSetup = config.fetchSetup || getRequest;\n      this.controller = new self.AbortController();\n      this.stats = new LoadStats();\n    }\n    var _proto = FetchLoader.prototype;\n    _proto.destroy = function destroy() {\n      this.loader = this.callbacks = this.context = this.config = this.request = null;\n      this.abortInternal();\n      this.response = null;\n      // @ts-ignore\n      this.fetchSetup = this.controller = this.stats = null;\n    };\n    _proto.abortInternal = function abortInternal() {\n      if (this.controller && !this.stats.loading.end) {\n        this.stats.aborted = true;\n        this.controller.abort();\n      }\n    };\n    _proto.abort = function abort() {\n      var _this$callbacks;\n      this.abortInternal();\n      if ((_this$callbacks = this.callbacks) != null && _this$callbacks.onAbort) {\n        this.callbacks.onAbort(this.stats, this.context, this.response);\n      }\n    };\n    _proto.load = function load(context, config, callbacks) {\n      var _this = this;\n      var stats = this.stats;\n      if (stats.loading.start) {\n        throw new Error('Loader can only be used once.');\n      }\n      stats.loading.start = self.performance.now();\n      var initParams = getRequestParameters(context, this.controller.signal);\n      var onProgress = callbacks.onProgress;\n      var isArrayBuffer = context.responseType === 'arraybuffer';\n      var LENGTH = isArrayBuffer ? 'byteLength' : 'length';\n      var _config$loadPolicy = config.loadPolicy,\n        maxTimeToFirstByteMs = _config$loadPolicy.maxTimeToFirstByteMs,\n        maxLoadTimeMs = _config$loadPolicy.maxLoadTimeMs;\n      this.context = context;\n      this.config = config;\n      this.callbacks = callbacks;\n      this.request = this.fetchSetup(context, initParams);\n      self.clearTimeout(this.requestTimeout);\n      config.timeout = maxTimeToFirstByteMs && isFiniteNumber(maxTimeToFirstByteMs) ? maxTimeToFirstByteMs : maxLoadTimeMs;\n      this.requestTimeout = self.setTimeout(function () {\n        _this.abortInternal();\n        callbacks.onTimeout(stats, context, _this.response);\n      }, config.timeout);\n      self.fetch(this.request).then(function (response) {\n        _this.response = _this.loader = response;\n        var first = Math.max(self.performance.now(), stats.loading.start);\n        self.clearTimeout(_this.requestTimeout);\n        config.timeout = maxLoadTimeMs;\n        _this.requestTimeout = self.setTimeout(function () {\n          _this.abortInternal();\n          callbacks.onTimeout(stats, context, _this.response);\n        }, maxLoadTimeMs - (first - stats.loading.start));\n        if (!response.ok) {\n          var status = response.status,\n            statusText = response.statusText;\n          throw new FetchError(statusText || 'fetch, bad network response', status, response);\n        }\n        stats.loading.first = first;\n        stats.total = getContentLength(response.headers) || stats.total;\n        if (onProgress && isFiniteNumber(config.highWaterMark)) {\n          return _this.loadProgressively(response, stats, context, config.highWaterMark, onProgress);\n        }\n        if (isArrayBuffer) {\n          return response.arrayBuffer();\n        }\n        if (context.responseType === 'json') {\n          return response.json();\n        }\n        return response.text();\n      }).then(function (responseData) {\n        var response = _this.response;\n        if (!response) {\n          throw new Error('loader destroyed');\n        }\n        self.clearTimeout(_this.requestTimeout);\n        stats.loading.end = Math.max(self.performance.now(), stats.loading.first);\n        var total = responseData[LENGTH];\n        if (total) {\n          stats.loaded = stats.total = total;\n        }\n        var loaderResponse = {\n          url: response.url,\n          data: responseData,\n          code: response.status\n        };\n        if (onProgress && !isFiniteNumber(config.highWaterMark)) {\n          onProgress(stats, context, responseData, response);\n        }\n        callbacks.onSuccess(loaderResponse, stats, context, response);\n      }).catch(function (error) {\n        self.clearTimeout(_this.requestTimeout);\n        if (stats.aborted) {\n          return;\n        }\n        // CORS errors result in an undefined code. Set it to 0 here to align with XHR's behavior\n        // when destroying, 'error' itself can be undefined\n        var code = !error ? 0 : error.code || 0;\n        var text = !error ? null : error.message;\n        callbacks.onError({\n          code: code,\n          text: text\n        }, context, error ? error.details : null, stats);\n      });\n    };\n    _proto.getCacheAge = function getCacheAge() {\n      var result = null;\n      if (this.response) {\n        var ageHeader = this.response.headers.get('age');\n        result = ageHeader ? parseFloat(ageHeader) : null;\n      }\n      return result;\n    };\n    _proto.getResponseHeader = function getResponseHeader(name) {\n      return this.response ? this.response.headers.get(name) : null;\n    };\n    _proto.loadProgressively = function loadProgressively(response, stats, context, highWaterMark, onProgress) {\n      if (highWaterMark === void 0) {\n        highWaterMark = 0;\n      }\n      var chunkCache = new ChunkCache();\n      var reader = response.body.getReader();\n      var pump = function pump() {\n        return reader.read().then(function (data) {\n          if (data.done) {\n            if (chunkCache.dataLength) {\n              onProgress(stats, context, chunkCache.flush(), response);\n            }\n            return Promise.resolve(new ArrayBuffer(0));\n          }\n          var chunk = data.value;\n          var len = chunk.length;\n          stats.loaded += len;\n          if (len < highWaterMark || chunkCache.dataLength) {\n            // The current chunk is too small to to be emitted or the cache already has data\n            // Push it to the cache\n            chunkCache.push(chunk);\n            if (chunkCache.dataLength >= highWaterMark) {\n              // flush in order to join the typed arrays\n              onProgress(stats, context, chunkCache.flush(), response);\n            }\n          } else {\n            // If there's nothing cached already, and the chache is large enough\n            // just emit the progress event\n            onProgress(stats, context, chunk, response);\n          }\n          return pump();\n        }).catch(function () {\n          /* aborted */\n          return Promise.reject();\n        });\n      };\n      return pump();\n    };\n    return FetchLoader;\n  }();\n  function getRequestParameters(context, signal) {\n    var initParams = {\n      method: 'GET',\n      mode: 'cors',\n      credentials: 'same-origin',\n      signal: signal,\n      headers: new self.Headers(_extends({}, context.headers))\n    };\n    if (context.rangeEnd) {\n      initParams.headers.set('Range', 'bytes=' + context.rangeStart + '-' + String(context.rangeEnd - 1));\n    }\n    return initParams;\n  }\n  function getByteRangeLength(byteRangeHeader) {\n    var result = BYTERANGE.exec(byteRangeHeader);\n    if (result) {\n      return parseInt(result[2]) - parseInt(result[1]) + 1;\n    }\n  }\n  function getContentLength(headers) {\n    var contentRange = headers.get('Content-Range');\n    if (contentRange) {\n      var byteRangeLength = getByteRangeLength(contentRange);\n      if (isFiniteNumber(byteRangeLength)) {\n        return byteRangeLength;\n      }\n    }\n    var contentLength = headers.get('Content-Length');\n    if (contentLength) {\n      return parseInt(contentLength);\n    }\n  }\n  function getRequest(context, initParams) {\n    return new self.Request(context.url, initParams);\n  }\n  var FetchError = /*#__PURE__*/function (_Error) {\n    _inheritsLoose(FetchError, _Error);\n    function FetchError(message, code, details) {\n      var _this2;\n      _this2 = _Error.call(this, message) || this;\n      _this2.code = void 0;\n      _this2.details = void 0;\n      _this2.code = code;\n      _this2.details = details;\n      return _this2;\n    }\n    return FetchError;\n  }( /*#__PURE__*/_wrapNativeSuper(Error));\n\n  var WHITESPACE_CHAR = /\\s/;\n  var Cues = {\n    newCue: function newCue(track, startTime, endTime, captionScreen) {\n      var result = [];\n      var row;\n      // the type data states this is VTTCue, but it can potentially be a TextTrackCue on old browsers\n      var cue;\n      var indenting;\n      var indent;\n      var text;\n      var Cue = self.VTTCue || self.TextTrackCue;\n      for (var r = 0; r < captionScreen.rows.length; r++) {\n        row = captionScreen.rows[r];\n        indenting = true;\n        indent = 0;\n        text = '';\n        if (!row.isEmpty()) {\n          var _track$cues;\n          for (var c = 0; c < row.chars.length; c++) {\n            if (WHITESPACE_CHAR.test(row.chars[c].uchar) && indenting) {\n              indent++;\n            } else {\n              text += row.chars[c].uchar;\n              indenting = false;\n            }\n          }\n          // To be used for cleaning-up orphaned roll-up captions\n          row.cueStartTime = startTime;\n\n          // Give a slight bump to the endTime if it's equal to startTime to avoid a SyntaxError in IE\n          if (startTime === endTime) {\n            endTime += 0.0001;\n          }\n          if (indent >= 16) {\n            indent--;\n          } else {\n            indent++;\n          }\n          var cueText = fixLineBreaks(text.trim());\n          var id = generateCueId(startTime, endTime, cueText);\n\n          // If this cue already exists in the track do not push it\n          if (!(track != null && (_track$cues = track.cues) != null && _track$cues.getCueById(id))) {\n            cue = new Cue(startTime, endTime, cueText);\n            cue.id = id;\n            cue.line = r + 1;\n            cue.align = 'left';\n            // Clamp the position between 10 and 80 percent (CEA-608 PAC indent code)\n            // https://dvcs.w3.org/hg/text-tracks/raw-file/default/608toVTT/608toVTT.html#positioning-in-cea-608\n            // Firefox throws an exception and captions break with out of bounds 0-100 values\n            cue.position = 10 + Math.min(80, Math.floor(indent * 8 / 32) * 10);\n            result.push(cue);\n          }\n        }\n      }\n      if (track && result.length) {\n        // Sort bottom cues in reverse order so that they render in line order when overlapping in Chrome\n        result.sort(function (cueA, cueB) {\n          if (cueA.line === 'auto' || cueB.line === 'auto') {\n            return 0;\n          }\n          if (cueA.line > 8 && cueB.line > 8) {\n            return cueB.line - cueA.line;\n          }\n          return cueA.line - cueB.line;\n        });\n        result.forEach(function (cue) {\n          return addCueToTrack(track, cue);\n        });\n      }\n      return result;\n    }\n  };\n\n  /**\n   * @deprecated use fragLoadPolicy.default\n   */\n\n  /**\n   * @deprecated use manifestLoadPolicy.default and playlistLoadPolicy.default\n   */\n\n  var defaultLoadPolicy = {\n    maxTimeToFirstByteMs: 8000,\n    maxLoadTimeMs: 20000,\n    timeoutRetry: null,\n    errorRetry: null\n  };\n\n  /**\n   * @ignore\n   * If possible, keep hlsDefaultConfig shallow\n   * It is cloned whenever a new Hls instance is created, by keeping the config\n   * shallow the properties are cloned, and we don't end up manipulating the default\n   */\n  var hlsDefaultConfig = _objectSpread2(_objectSpread2({\n    autoStartLoad: true,\n    // used by stream-controller\n    startPosition: -1,\n    // used by stream-controller\n    defaultAudioCodec: undefined,\n    // used by stream-controller\n    debug: false,\n    // used by logger\n    capLevelOnFPSDrop: false,\n    // used by fps-controller\n    capLevelToPlayerSize: false,\n    // used by cap-level-controller\n    ignoreDevicePixelRatio: false,\n    // used by cap-level-controller\n    preferManagedMediaSource: true,\n    initialLiveManifestSize: 1,\n    // used by stream-controller\n    maxBufferLength: 30,\n    // used by stream-controller\n    backBufferLength: Infinity,\n    // used by buffer-controller\n    frontBufferFlushThreshold: Infinity,\n    maxBufferSize: 60 * 1000 * 1000,\n    // used by stream-controller\n    maxBufferHole: 0.1,\n    // used by stream-controller\n    highBufferWatchdogPeriod: 2,\n    // used by stream-controller\n    nudgeOffset: 0.1,\n    // used by stream-controller\n    nudgeMaxRetry: 3,\n    // used by stream-controller\n    maxFragLookUpTolerance: 0.25,\n    // used by stream-controller\n    liveSyncDurationCount: 3,\n    // used by latency-controller\n    liveMaxLatencyDurationCount: Infinity,\n    // used by latency-controller\n    liveSyncDuration: undefined,\n    // used by latency-controller\n    liveMaxLatencyDuration: undefined,\n    // used by latency-controller\n    maxLiveSyncPlaybackRate: 1,\n    // used by latency-controller\n    liveDurationInfinity: false,\n    // used by buffer-controller\n    /**\n     * @deprecated use backBufferLength\n     */\n    liveBackBufferLength: null,\n    // used by buffer-controller\n    maxMaxBufferLength: 600,\n    // used by stream-controller\n    enableWorker: true,\n    // used by transmuxer\n    workerPath: null,\n    // used by transmuxer\n    enableSoftwareAES: true,\n    // used by decrypter\n    startLevel: undefined,\n    // used by level-controller\n    startFragPrefetch: false,\n    // used by stream-controller\n    fpsDroppedMonitoringPeriod: 5000,\n    // used by fps-controller\n    fpsDroppedMonitoringThreshold: 0.2,\n    // used by fps-controller\n    appendErrorMaxRetry: 3,\n    // used by buffer-controller\n    loader: XhrLoader,\n    // loader: FetchLoader,\n    fLoader: undefined,\n    // used by fragment-loader\n    pLoader: undefined,\n    // used by playlist-loader\n    xhrSetup: undefined,\n    // used by xhr-loader\n    licenseXhrSetup: undefined,\n    // used by eme-controller\n    licenseResponseCallback: undefined,\n    // used by eme-controller\n    abrController: AbrController,\n    bufferController: BufferController,\n    capLevelController: CapLevelController,\n    errorController: ErrorController,\n    fpsController: FPSController,\n    stretchShortVideoTrack: false,\n    // used by mp4-remuxer\n    maxAudioFramesDrift: 1,\n    // used by mp4-remuxer\n    forceKeyFrameOnDiscontinuity: true,\n    // used by ts-demuxer\n    abrEwmaFastLive: 3,\n    // used by abr-controller\n    abrEwmaSlowLive: 9,\n    // used by abr-controller\n    abrEwmaFastVoD: 3,\n    // used by abr-controller\n    abrEwmaSlowVoD: 9,\n    // used by abr-controller\n    abrEwmaDefaultEstimate: 5e5,\n    // 500 kbps  // used by abr-controller\n    abrEwmaDefaultEstimateMax: 5e6,\n    // 5 mbps\n    abrBandWidthFactor: 0.95,\n    // used by abr-controller\n    abrBandWidthUpFactor: 0.7,\n    // used by abr-controller\n    abrMaxWithRealBitrate: false,\n    // used by abr-controller\n    maxStarvationDelay: 4,\n    // used by abr-controller\n    maxLoadingDelay: 4,\n    // used by abr-controller\n    minAutoBitrate: 0,\n    // used by hls\n    emeEnabled: false,\n    // used by eme-controller\n    widevineLicenseUrl: undefined,\n    // used by eme-controller\n    drmSystems: {},\n    // used by eme-controller\n    drmSystemOptions: {},\n    // used by eme-controller\n    requestMediaKeySystemAccessFunc: requestMediaKeySystemAccess ,\n    // used by eme-controller\n    testBandwidth: true,\n    progressive: false,\n    lowLatencyMode: true,\n    cmcd: undefined,\n    enableDateRangeMetadataCues: true,\n    enableEmsgMetadataCues: true,\n    enableID3MetadataCues: true,\n    useMediaCapabilities: true,\n    certLoadPolicy: {\n      default: defaultLoadPolicy\n    },\n    keyLoadPolicy: {\n      default: {\n        maxTimeToFirstByteMs: 8000,\n        maxLoadTimeMs: 20000,\n        timeoutRetry: {\n          maxNumRetry: 1,\n          retryDelayMs: 1000,\n          maxRetryDelayMs: 20000,\n          backoff: 'linear'\n        },\n        errorRetry: {\n          maxNumRetry: 8,\n          retryDelayMs: 1000,\n          maxRetryDelayMs: 20000,\n          backoff: 'linear'\n        }\n      }\n    },\n    manifestLoadPolicy: {\n      default: {\n        maxTimeToFirstByteMs: Infinity,\n        maxLoadTimeMs: 20000,\n        timeoutRetry: {\n          maxNumRetry: 2,\n          retryDelayMs: 0,\n          maxRetryDelayMs: 0\n        },\n        errorRetry: {\n          maxNumRetry: 1,\n          retryDelayMs: 1000,\n          maxRetryDelayMs: 8000\n        }\n      }\n    },\n    playlistLoadPolicy: {\n      default: {\n        maxTimeToFirstByteMs: 10000,\n        maxLoadTimeMs: 20000,\n        timeoutRetry: {\n          maxNumRetry: 2,\n          retryDelayMs: 0,\n          maxRetryDelayMs: 0\n        },\n        errorRetry: {\n          maxNumRetry: 2,\n          retryDelayMs: 1000,\n          maxRetryDelayMs: 8000\n        }\n      }\n    },\n    fragLoadPolicy: {\n      default: {\n        maxTimeToFirstByteMs: 10000,\n        maxLoadTimeMs: 120000,\n        timeoutRetry: {\n          maxNumRetry: 4,\n          retryDelayMs: 0,\n          maxRetryDelayMs: 0\n        },\n        errorRetry: {\n          maxNumRetry: 6,\n          retryDelayMs: 1000,\n          maxRetryDelayMs: 8000\n        }\n      }\n    },\n    steeringManifestLoadPolicy: {\n      default: {\n        maxTimeToFirstByteMs: 10000,\n        maxLoadTimeMs: 20000,\n        timeoutRetry: {\n          maxNumRetry: 2,\n          retryDelayMs: 0,\n          maxRetryDelayMs: 0\n        },\n        errorRetry: {\n          maxNumRetry: 1,\n          retryDelayMs: 1000,\n          maxRetryDelayMs: 8000\n        }\n      } \n    },\n    // These default settings are deprecated in favor of the above policies\n    // and are maintained for backwards compatibility\n    manifestLoadingTimeOut: 10000,\n    manifestLoadingMaxRetry: 1,\n    manifestLoadingRetryDelay: 1000,\n    manifestLoadingMaxRetryTimeout: 64000,\n    levelLoadingTimeOut: 10000,\n    levelLoadingMaxRetry: 4,\n    levelLoadingRetryDelay: 1000,\n    levelLoadingMaxRetryTimeout: 64000,\n    fragLoadingTimeOut: 20000,\n    fragLoadingMaxRetry: 6,\n    fragLoadingRetryDelay: 1000,\n    fragLoadingMaxRetryTimeout: 64000\n  }, timelineConfig()), {}, {\n    subtitleStreamController: SubtitleStreamController ,\n    subtitleTrackController: SubtitleTrackController ,\n    timelineController: TimelineController ,\n    audioStreamController: AudioStreamController ,\n    audioTrackController: AudioTrackController ,\n    emeController: EMEController ,\n    cmcdController: CMCDController ,\n    contentSteeringController: ContentSteeringController \n  });\n  function timelineConfig() {\n    return {\n      cueHandler: Cues,\n      // used by timeline-controller\n      enableWebVTT: true,\n      // used by timeline-controller\n      enableIMSC1: true,\n      // used by timeline-controller\n      enableCEA708Captions: true,\n      // used by timeline-controller\n      captionsTextTrack1Label: 'English',\n      // used by timeline-controller\n      captionsTextTrack1LanguageCode: 'en',\n      // used by timeline-controller\n      captionsTextTrack2Label: 'Spanish',\n      // used by timeline-controller\n      captionsTextTrack2LanguageCode: 'es',\n      // used by timeline-controller\n      captionsTextTrack3Label: 'Unknown CC',\n      // used by timeline-controller\n      captionsTextTrack3LanguageCode: '',\n      // used by timeline-controller\n      captionsTextTrack4Label: 'Unknown CC',\n      // used by timeline-controller\n      captionsTextTrack4LanguageCode: '',\n      // used by timeline-controller\n      renderTextTracksNatively: true\n    };\n  }\n\n  /**\n   * @ignore\n   */\n  function mergeConfig(defaultConfig, userConfig) {\n    if ((userConfig.liveSyncDurationCount || userConfig.liveMaxLatencyDurationCount) && (userConfig.liveSyncDuration || userConfig.liveMaxLatencyDuration)) {\n      throw new Error(\"Illegal hls.js config: don't mix up liveSyncDurationCount/liveMaxLatencyDurationCount and liveSyncDuration/liveMaxLatencyDuration\");\n    }\n    if (userConfig.liveMaxLatencyDurationCount !== undefined && (userConfig.liveSyncDurationCount === undefined || userConfig.liveMaxLatencyDurationCount <= userConfig.liveSyncDurationCount)) {\n      throw new Error('Illegal hls.js config: \"liveMaxLatencyDurationCount\" must be greater than \"liveSyncDurationCount\"');\n    }\n    if (userConfig.liveMaxLatencyDuration !== undefined && (userConfig.liveSyncDuration === undefined || userConfig.liveMaxLatencyDuration <= userConfig.liveSyncDuration)) {\n      throw new Error('Illegal hls.js config: \"liveMaxLatencyDuration\" must be greater than \"liveSyncDuration\"');\n    }\n    var defaultsCopy = deepCpy(defaultConfig);\n\n    // Backwards compatibility with deprecated config values\n    var deprecatedSettingTypes = ['manifest', 'level', 'frag'];\n    var deprecatedSettings = ['TimeOut', 'MaxRetry', 'RetryDelay', 'MaxRetryTimeout'];\n    deprecatedSettingTypes.forEach(function (type) {\n      var policyName = (type === 'level' ? 'playlist' : type) + \"LoadPolicy\";\n      var policyNotSet = userConfig[policyName] === undefined;\n      var report = [];\n      deprecatedSettings.forEach(function (setting) {\n        var deprecatedSetting = type + \"Loading\" + setting;\n        var value = userConfig[deprecatedSetting];\n        if (value !== undefined && policyNotSet) {\n          report.push(deprecatedSetting);\n          var settings = defaultsCopy[policyName].default;\n          userConfig[policyName] = {\n            default: settings\n          };\n          switch (setting) {\n            case 'TimeOut':\n              settings.maxLoadTimeMs = value;\n              settings.maxTimeToFirstByteMs = value;\n              break;\n            case 'MaxRetry':\n              settings.errorRetry.maxNumRetry = value;\n              settings.timeoutRetry.maxNumRetry = value;\n              break;\n            case 'RetryDelay':\n              settings.errorRetry.retryDelayMs = value;\n              settings.timeoutRetry.retryDelayMs = value;\n              break;\n            case 'MaxRetryTimeout':\n              settings.errorRetry.maxRetryDelayMs = value;\n              settings.timeoutRetry.maxRetryDelayMs = value;\n              break;\n          }\n        }\n      });\n      if (report.length) {\n        logger.warn(\"hls.js config: \\\"\" + report.join('\", \"') + \"\\\" setting(s) are deprecated, use \\\"\" + policyName + \"\\\": \" + JSON.stringify(userConfig[policyName]));\n      }\n    });\n    return _objectSpread2(_objectSpread2({}, defaultsCopy), userConfig);\n  }\n  function deepCpy(obj) {\n    if (obj && typeof obj === 'object') {\n      if (Array.isArray(obj)) {\n        return obj.map(deepCpy);\n      }\n      return Object.keys(obj).reduce(function (result, key) {\n        result[key] = deepCpy(obj[key]);\n        return result;\n      }, {});\n    }\n    return obj;\n  }\n\n  /**\n   * @ignore\n   */\n  function enableStreamingMode(config) {\n    var currentLoader = config.loader;\n    if (currentLoader !== FetchLoader && currentLoader !== XhrLoader) {\n      // If a developer has configured their own loader, respect that choice\n      logger.log('[config]: Custom loader detected, cannot enable progressive streaming');\n      config.progressive = false;\n    } else {\n      var canStreamProgressively = fetchSupported();\n      if (canStreamProgressively) {\n        config.loader = FetchLoader;\n        config.progressive = true;\n        config.enableSoftwareAES = true;\n        logger.log('[config]: Progressive streaming enabled, using FetchLoader');\n      }\n    }\n  }\n\n  var chromeOrFirefox;\n  var LevelController = /*#__PURE__*/function (_BasePlaylistControll) {\n    _inheritsLoose(LevelController, _BasePlaylistControll);\n    function LevelController(hls, contentSteeringController) {\n      var _this;\n      _this = _BasePlaylistControll.call(this, hls, '[level-controller]') || this;\n      _this._levels = [];\n      _this._firstLevel = -1;\n      _this._maxAutoLevel = -1;\n      _this._startLevel = void 0;\n      _this.currentLevel = null;\n      _this.currentLevelIndex = -1;\n      _this.manualLevelIndex = -1;\n      _this.steering = void 0;\n      _this.onParsedComplete = void 0;\n      _this.steering = contentSteeringController;\n      _this._registerListeners();\n      return _this;\n    }\n    var _proto = LevelController.prototype;\n    _proto._registerListeners = function _registerListeners() {\n      var hls = this.hls;\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n      hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n      hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n      hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n      hls.on(Events.ERROR, this.onError, this);\n    };\n    _proto._unregisterListeners = function _unregisterListeners() {\n      var hls = this.hls;\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.MANIFEST_LOADED, this.onManifestLoaded, this);\n      hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n      hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n      hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n      hls.off(Events.ERROR, this.onError, this);\n    };\n    _proto.destroy = function destroy() {\n      this._unregisterListeners();\n      this.steering = null;\n      this.resetLevels();\n      _BasePlaylistControll.prototype.destroy.call(this);\n    };\n    _proto.stopLoad = function stopLoad() {\n      var levels = this._levels;\n\n      // clean up live level details to force reload them, and reset load errors\n      levels.forEach(function (level) {\n        level.loadError = 0;\n        level.fragmentError = 0;\n      });\n      _BasePlaylistControll.prototype.stopLoad.call(this);\n    };\n    _proto.resetLevels = function resetLevels() {\n      this._startLevel = undefined;\n      this.manualLevelIndex = -1;\n      this.currentLevelIndex = -1;\n      this.currentLevel = null;\n      this._levels = [];\n      this._maxAutoLevel = -1;\n    };\n    _proto.onManifestLoading = function onManifestLoading(event, data) {\n      this.resetLevels();\n    };\n    _proto.onManifestLoaded = function onManifestLoaded(event, data) {\n      var preferManagedMediaSource = this.hls.config.preferManagedMediaSource;\n      var levels = [];\n      var redundantSet = {};\n      var generatePathwaySet = {};\n      var resolutionFound = false;\n      var videoCodecFound = false;\n      var audioCodecFound = false;\n      data.levels.forEach(function (levelParsed) {\n        var _audioCodec, _videoCodec;\n        var attributes = levelParsed.attrs;\n\n        // erase audio codec info if browser does not support mp4a.40.34.\n        // demuxer will autodetect codec and fallback to mpeg/audio\n        var audioCodec = levelParsed.audioCodec,\n          videoCodec = levelParsed.videoCodec;\n        if (((_audioCodec = audioCodec) == null ? void 0 : _audioCodec.indexOf('mp4a.40.34')) !== -1) {\n          chromeOrFirefox || (chromeOrFirefox = /chrome|firefox/i.test(navigator.userAgent));\n          if (chromeOrFirefox) {\n            levelParsed.audioCodec = audioCodec = undefined;\n          }\n        }\n        if (audioCodec) {\n          levelParsed.audioCodec = audioCodec = getCodecCompatibleName(audioCodec, preferManagedMediaSource);\n        }\n        if (((_videoCodec = videoCodec) == null ? void 0 : _videoCodec.indexOf('avc1')) === 0) {\n          videoCodec = levelParsed.videoCodec = convertAVC1ToAVCOTI(videoCodec);\n        }\n\n        // only keep levels with supported audio/video codecs\n        var width = levelParsed.width,\n          height = levelParsed.height,\n          unknownCodecs = levelParsed.unknownCodecs;\n        resolutionFound || (resolutionFound = !!(width && height));\n        videoCodecFound || (videoCodecFound = !!videoCodec);\n        audioCodecFound || (audioCodecFound = !!audioCodec);\n        if (unknownCodecs != null && unknownCodecs.length || audioCodec && !areCodecsMediaSourceSupported(audioCodec, 'audio', preferManagedMediaSource) || videoCodec && !areCodecsMediaSourceSupported(videoCodec, 'video', preferManagedMediaSource)) {\n          return;\n        }\n        var CODECS = attributes.CODECS,\n          FRAMERATE = attributes['FRAME-RATE'],\n          HDCP = attributes['HDCP-LEVEL'],\n          PATHWAY = attributes['PATHWAY-ID'],\n          RESOLUTION = attributes.RESOLUTION,\n          VIDEO_RANGE = attributes['VIDEO-RANGE'];\n        var contentSteeringPrefix = (PATHWAY || '.') + \"-\";\n        var levelKey = \"\" + contentSteeringPrefix + levelParsed.bitrate + \"-\" + RESOLUTION + \"-\" + FRAMERATE + \"-\" + CODECS + \"-\" + VIDEO_RANGE + \"-\" + HDCP;\n        if (!redundantSet[levelKey]) {\n          var level = new Level(levelParsed);\n          redundantSet[levelKey] = level;\n          generatePathwaySet[levelKey] = 1;\n          levels.push(level);\n        } else if (redundantSet[levelKey].uri !== levelParsed.url && !levelParsed.attrs['PATHWAY-ID']) {\n          // Assign Pathway IDs to Redundant Streams (default Pathways is \".\". Redundant Streams \"..\", \"...\", and so on.)\n          // Content Steering controller to handles Pathway fallback on error\n          var pathwayCount = generatePathwaySet[levelKey] += 1;\n          levelParsed.attrs['PATHWAY-ID'] = new Array(pathwayCount + 1).join('.');\n          var _level = new Level(levelParsed);\n          redundantSet[levelKey] = _level;\n          levels.push(_level);\n        } else {\n          redundantSet[levelKey].addGroupId('audio', attributes.AUDIO);\n          redundantSet[levelKey].addGroupId('text', attributes.SUBTITLES);\n        }\n      });\n      this.filterAndSortMediaOptions(levels, data, resolutionFound, videoCodecFound, audioCodecFound);\n    };\n    _proto.filterAndSortMediaOptions = function filterAndSortMediaOptions(filteredLevels, data, resolutionFound, videoCodecFound, audioCodecFound) {\n      var _this2 = this;\n      var audioTracks = [];\n      var subtitleTracks = [];\n      var levels = filteredLevels;\n\n      // remove audio-only and invalid video-range levels if we also have levels with video codecs or RESOLUTION signalled\n      if ((resolutionFound || videoCodecFound) && audioCodecFound) {\n        levels = levels.filter(function (_ref) {\n          var videoCodec = _ref.videoCodec,\n            videoRange = _ref.videoRange,\n            width = _ref.width,\n            height = _ref.height;\n          return (!!videoCodec || !!(width && height)) && isVideoRange(videoRange);\n        });\n      }\n      if (levels.length === 0) {\n        // Dispatch error after MANIFEST_LOADED is done propagating\n        Promise.resolve().then(function () {\n          if (_this2.hls) {\n            if (data.levels.length) {\n              _this2.warn(\"One or more CODECS in variant not supported: \" + JSON.stringify(data.levels[0].attrs));\n            }\n            var error = new Error('no level with compatible codecs found in manifest');\n            _this2.hls.trigger(Events.ERROR, {\n              type: ErrorTypes.MEDIA_ERROR,\n              details: ErrorDetails.MANIFEST_INCOMPATIBLE_CODECS_ERROR,\n              fatal: true,\n              url: data.url,\n              error: error,\n              reason: error.message\n            });\n          }\n        });\n        return;\n      }\n      if (data.audioTracks) {\n        var preferManagedMediaSource = this.hls.config.preferManagedMediaSource;\n        audioTracks = data.audioTracks.filter(function (track) {\n          return !track.audioCodec || areCodecsMediaSourceSupported(track.audioCodec, 'audio', preferManagedMediaSource);\n        });\n        // Assign ids after filtering as array indices by group-id\n        assignTrackIdsByGroup(audioTracks);\n      }\n      if (data.subtitles) {\n        subtitleTracks = data.subtitles;\n        assignTrackIdsByGroup(subtitleTracks);\n      }\n      // start bitrate is the first bitrate of the manifest\n      var unsortedLevels = levels.slice(0);\n      // sort levels from lowest to highest\n      levels.sort(function (a, b) {\n        if (a.attrs['HDCP-LEVEL'] !== b.attrs['HDCP-LEVEL']) {\n          return (a.attrs['HDCP-LEVEL'] || '') > (b.attrs['HDCP-LEVEL'] || '') ? 1 : -1;\n        }\n        // sort on height before bitrate for cap-level-controller\n        if (resolutionFound && a.height !== b.height) {\n          return a.height - b.height;\n        }\n        if (a.frameRate !== b.frameRate) {\n          return a.frameRate - b.frameRate;\n        }\n        if (a.videoRange !== b.videoRange) {\n          return VideoRangeValues.indexOf(a.videoRange) - VideoRangeValues.indexOf(b.videoRange);\n        }\n        if (a.videoCodec !== b.videoCodec) {\n          var valueA = videoCodecPreferenceValue(a.videoCodec);\n          var valueB = videoCodecPreferenceValue(b.videoCodec);\n          if (valueA !== valueB) {\n            return valueB - valueA;\n          }\n        }\n        if (a.uri === b.uri && a.codecSet !== b.codecSet) {\n          var _valueA = codecsSetSelectionPreferenceValue(a.codecSet);\n          var _valueB = codecsSetSelectionPreferenceValue(b.codecSet);\n          if (_valueA !== _valueB) {\n            return _valueB - _valueA;\n          }\n        }\n        if (a.averageBitrate !== b.averageBitrate) {\n          return a.averageBitrate - b.averageBitrate;\n        }\n        return 0;\n      });\n      var firstLevelInPlaylist = unsortedLevels[0];\n      if (this.steering) {\n        levels = this.steering.filterParsedLevels(levels);\n        if (levels.length !== unsortedLevels.length) {\n          for (var i = 0; i < unsortedLevels.length; i++) {\n            if (unsortedLevels[i].pathwayId === levels[0].pathwayId) {\n              firstLevelInPlaylist = unsortedLevels[i];\n              break;\n            }\n          }\n        }\n      }\n      this._levels = levels;\n\n      // find index of first level in sorted levels\n      for (var _i = 0; _i < levels.length; _i++) {\n        if (levels[_i] === firstLevelInPlaylist) {\n          var _this$hls$userConfig;\n          this._firstLevel = _i;\n          var firstLevelBitrate = firstLevelInPlaylist.bitrate;\n          var bandwidthEstimate = this.hls.bandwidthEstimate;\n          this.log(\"manifest loaded, \" + levels.length + \" level(s) found, first bitrate: \" + firstLevelBitrate);\n          // Update default bwe to first variant bitrate as long it has not been configured or set\n          if (((_this$hls$userConfig = this.hls.userConfig) == null ? void 0 : _this$hls$userConfig.abrEwmaDefaultEstimate) === undefined) {\n            var startingBwEstimate = Math.min(firstLevelBitrate, this.hls.config.abrEwmaDefaultEstimateMax);\n            if (startingBwEstimate > bandwidthEstimate && bandwidthEstimate === hlsDefaultConfig.abrEwmaDefaultEstimate) {\n              this.hls.bandwidthEstimate = startingBwEstimate;\n            }\n          }\n          break;\n        }\n      }\n\n      // Audio is only alternate if manifest include a URI along with the audio group tag,\n      // and this is not an audio-only stream where levels contain audio-only\n      var audioOnly = audioCodecFound && !videoCodecFound;\n      var edata = {\n        levels: levels,\n        audioTracks: audioTracks,\n        subtitleTracks: subtitleTracks,\n        sessionData: data.sessionData,\n        sessionKeys: data.sessionKeys,\n        firstLevel: this._firstLevel,\n        stats: data.stats,\n        audio: audioCodecFound,\n        video: videoCodecFound,\n        altAudio: !audioOnly && audioTracks.some(function (t) {\n          return !!t.url;\n        })\n      };\n      this.hls.trigger(Events.MANIFEST_PARSED, edata);\n\n      // Initiate loading after all controllers have received MANIFEST_PARSED\n      if (this.hls.config.autoStartLoad || this.hls.forceStartLoad) {\n        this.hls.startLoad(this.hls.config.startPosition);\n      }\n    };\n    _proto.onError = function onError(event, data) {\n      if (data.fatal || !data.context) {\n        return;\n      }\n      if (data.context.type === PlaylistContextType.LEVEL && data.context.level === this.level) {\n        this.checkRetry(data);\n      }\n    }\n\n    // reset errors on the successful load of a fragment\n    ;\n    _proto.onFragBuffered = function onFragBuffered(event, _ref2) {\n      var frag = _ref2.frag;\n      if (frag !== undefined && frag.type === PlaylistLevelType.MAIN) {\n        var el = frag.elementaryStreams;\n        if (!Object.keys(el).some(function (type) {\n          return !!el[type];\n        })) {\n          return;\n        }\n        var level = this._levels[frag.level];\n        if (level != null && level.loadError) {\n          this.log(\"Resetting level error count of \" + level.loadError + \" on frag buffered\");\n          level.loadError = 0;\n        }\n      }\n    };\n    _proto.onLevelLoaded = function onLevelLoaded(event, data) {\n      var _data$deliveryDirecti2;\n      var level = data.level,\n        details = data.details;\n      var curLevel = this._levels[level];\n      if (!curLevel) {\n        var _data$deliveryDirecti;\n        this.warn(\"Invalid level index \" + level);\n        if ((_data$deliveryDirecti = data.deliveryDirectives) != null && _data$deliveryDirecti.skip) {\n          details.deltaUpdateFailed = true;\n        }\n        return;\n      }\n\n      // only process level loaded events matching with expected level\n      if (level === this.currentLevelIndex) {\n        // reset level load error counter on successful level loaded only if there is no issues with fragments\n        if (curLevel.fragmentError === 0) {\n          curLevel.loadError = 0;\n        }\n        this.playlistLoaded(level, data, curLevel.details);\n      } else if ((_data$deliveryDirecti2 = data.deliveryDirectives) != null && _data$deliveryDirecti2.skip) {\n        // received a delta playlist update that cannot be merged\n        details.deltaUpdateFailed = true;\n      }\n    };\n    _proto.loadPlaylist = function loadPlaylist(hlsUrlParameters) {\n      _BasePlaylistControll.prototype.loadPlaylist.call(this);\n      var currentLevelIndex = this.currentLevelIndex;\n      var currentLevel = this.currentLevel;\n      if (currentLevel && this.shouldLoadPlaylist(currentLevel)) {\n        var url = currentLevel.uri;\n        if (hlsUrlParameters) {\n          try {\n            url = hlsUrlParameters.addDirectives(url);\n          } catch (error) {\n            this.warn(\"Could not construct new URL with HLS Delivery Directives: \" + error);\n          }\n        }\n        var pathwayId = currentLevel.attrs['PATHWAY-ID'];\n        this.log(\"Loading level index \" + currentLevelIndex + ((hlsUrlParameters == null ? void 0 : hlsUrlParameters.msn) !== undefined ? ' at sn ' + hlsUrlParameters.msn + ' part ' + hlsUrlParameters.part : '') + \" with\" + (pathwayId ? ' Pathway ' + pathwayId : '') + \" \" + url);\n\n        // console.log('Current audio track group ID:', this.hls.audioTracks[this.hls.audioTrack].groupId);\n        // console.log('New video quality level audio group id:', levelObject.attrs.AUDIO, level);\n        this.clearTimer();\n        this.hls.trigger(Events.LEVEL_LOADING, {\n          url: url,\n          level: currentLevelIndex,\n          pathwayId: currentLevel.attrs['PATHWAY-ID'],\n          id: 0,\n          // Deprecated Level urlId\n          deliveryDirectives: hlsUrlParameters || null\n        });\n      }\n    };\n    _proto.removeLevel = function removeLevel(levelIndex) {\n      var _this3 = this,\n        _this$currentLevel;\n      var levels = this._levels.filter(function (level, index) {\n        if (index !== levelIndex) {\n          return true;\n        }\n        if (_this3.steering) {\n          _this3.steering.removeLevel(level);\n        }\n        if (level === _this3.currentLevel) {\n          _this3.currentLevel = null;\n          _this3.currentLevelIndex = -1;\n          if (level.details) {\n            level.details.fragments.forEach(function (f) {\n              return f.level = -1;\n            });\n          }\n        }\n        return false;\n      });\n      reassignFragmentLevelIndexes(levels);\n      this._levels = levels;\n      if (this.currentLevelIndex > -1 && (_this$currentLevel = this.currentLevel) != null && _this$currentLevel.details) {\n        this.currentLevelIndex = this.currentLevel.details.fragments[0].level;\n      }\n      this.hls.trigger(Events.LEVELS_UPDATED, {\n        levels: levels\n      });\n    };\n    _proto.onLevelsUpdated = function onLevelsUpdated(event, _ref3) {\n      var levels = _ref3.levels;\n      this._levels = levels;\n    };\n    _proto.checkMaxAutoUpdated = function checkMaxAutoUpdated() {\n      var _this$hls = this.hls,\n        autoLevelCapping = _this$hls.autoLevelCapping,\n        maxAutoLevel = _this$hls.maxAutoLevel,\n        maxHdcpLevel = _this$hls.maxHdcpLevel;\n      if (this._maxAutoLevel !== maxAutoLevel) {\n        this._maxAutoLevel = maxAutoLevel;\n        this.hls.trigger(Events.MAX_AUTO_LEVEL_UPDATED, {\n          autoLevelCapping: autoLevelCapping,\n          levels: this.levels,\n          maxAutoLevel: maxAutoLevel,\n          minAutoLevel: this.hls.minAutoLevel,\n          maxHdcpLevel: maxHdcpLevel\n        });\n      }\n    };\n    _createClass(LevelController, [{\n      key: \"levels\",\n      get: function get() {\n        if (this._levels.length === 0) {\n          return null;\n        }\n        return this._levels;\n      }\n    }, {\n      key: \"level\",\n      get: function get() {\n        return this.currentLevelIndex;\n      },\n      set: function set(newLevel) {\n        var levels = this._levels;\n        if (levels.length === 0) {\n          return;\n        }\n        // check if level idx is valid\n        if (newLevel < 0 || newLevel >= levels.length) {\n          // invalid level id given, trigger error\n          var error = new Error('invalid level idx');\n          var fatal = newLevel < 0;\n          this.hls.trigger(Events.ERROR, {\n            type: ErrorTypes.OTHER_ERROR,\n            details: ErrorDetails.LEVEL_SWITCH_ERROR,\n            level: newLevel,\n            fatal: fatal,\n            error: error,\n            reason: error.message\n          });\n          if (fatal) {\n            return;\n          }\n          newLevel = Math.min(newLevel, levels.length - 1);\n        }\n        var lastLevelIndex = this.currentLevelIndex;\n        var lastLevel = this.currentLevel;\n        var lastPathwayId = lastLevel ? lastLevel.attrs['PATHWAY-ID'] : undefined;\n        var level = levels[newLevel];\n        var pathwayId = level.attrs['PATHWAY-ID'];\n        this.currentLevelIndex = newLevel;\n        this.currentLevel = level;\n        if (lastLevelIndex === newLevel && level.details && lastLevel && lastPathwayId === pathwayId) {\n          return;\n        }\n        this.log(\"Switching to level \" + newLevel + \" (\" + (level.height ? level.height + 'p ' : '') + (level.videoRange ? level.videoRange + ' ' : '') + (level.codecSet ? level.codecSet + ' ' : '') + \"@\" + level.bitrate + \")\" + (pathwayId ? ' with Pathway ' + pathwayId : '') + \" from level \" + lastLevelIndex + (lastPathwayId ? ' with Pathway ' + lastPathwayId : ''));\n        var levelSwitchingData = {\n          level: newLevel,\n          attrs: level.attrs,\n          details: level.details,\n          bitrate: level.bitrate,\n          averageBitrate: level.averageBitrate,\n          maxBitrate: level.maxBitrate,\n          realBitrate: level.realBitrate,\n          width: level.width,\n          height: level.height,\n          codecSet: level.codecSet,\n          audioCodec: level.audioCodec,\n          videoCodec: level.videoCodec,\n          audioGroups: level.audioGroups,\n          subtitleGroups: level.subtitleGroups,\n          loaded: level.loaded,\n          loadError: level.loadError,\n          fragmentError: level.fragmentError,\n          name: level.name,\n          id: level.id,\n          uri: level.uri,\n          url: level.url,\n          urlId: 0,\n          audioGroupIds: level.audioGroupIds,\n          textGroupIds: level.textGroupIds\n        };\n        this.hls.trigger(Events.LEVEL_SWITCHING, levelSwitchingData);\n        // check if we need to load playlist for this level\n        var levelDetails = level.details;\n        if (!levelDetails || levelDetails.live) {\n          // level not retrieved yet, or live playlist we need to (re)load it\n          var hlsUrlParameters = this.switchParams(level.uri, lastLevel == null ? void 0 : lastLevel.details, levelDetails);\n          this.loadPlaylist(hlsUrlParameters);\n        }\n      }\n    }, {\n      key: \"manualLevel\",\n      get: function get() {\n        return this.manualLevelIndex;\n      },\n      set: function set(newLevel) {\n        this.manualLevelIndex = newLevel;\n        if (this._startLevel === undefined) {\n          this._startLevel = newLevel;\n        }\n        if (newLevel !== -1) {\n          this.level = newLevel;\n        }\n      }\n    }, {\n      key: \"firstLevel\",\n      get: function get() {\n        return this._firstLevel;\n      },\n      set: function set(newLevel) {\n        this._firstLevel = newLevel;\n      }\n    }, {\n      key: \"startLevel\",\n      get: function get() {\n        // Setting hls.startLevel (this._startLevel) overrides config.startLevel\n        if (this._startLevel === undefined) {\n          var configStartLevel = this.hls.config.startLevel;\n          if (configStartLevel !== undefined) {\n            return configStartLevel;\n          }\n          return this.hls.firstAutoLevel;\n        }\n        return this._startLevel;\n      },\n      set: function set(newLevel) {\n        this._startLevel = newLevel;\n      }\n    }, {\n      key: \"nextLoadLevel\",\n      get: function get() {\n        if (this.manualLevelIndex !== -1) {\n          return this.manualLevelIndex;\n        } else {\n          return this.hls.nextAutoLevel;\n        }\n      },\n      set: function set(nextLevel) {\n        this.level = nextLevel;\n        if (this.manualLevelIndex === -1) {\n          this.hls.nextAutoLevel = nextLevel;\n        }\n      }\n    }]);\n    return LevelController;\n  }(BasePlaylistController);\n  function assignTrackIdsByGroup(tracks) {\n    var groups = {};\n    tracks.forEach(function (track) {\n      var groupId = track.groupId || '';\n      track.id = groups[groupId] = groups[groupId] || 0;\n      groups[groupId]++;\n    });\n  }\n\n  var KeyLoader = /*#__PURE__*/function () {\n    function KeyLoader(config) {\n      this.config = void 0;\n      this.keyUriToKeyInfo = {};\n      this.emeController = null;\n      this.config = config;\n    }\n    var _proto = KeyLoader.prototype;\n    _proto.abort = function abort(type) {\n      for (var uri in this.keyUriToKeyInfo) {\n        var loader = this.keyUriToKeyInfo[uri].loader;\n        if (loader) {\n          var _loader$context;\n          if (type && type !== ((_loader$context = loader.context) == null ? void 0 : _loader$context.frag.type)) {\n            return;\n          }\n          loader.abort();\n        }\n      }\n    };\n    _proto.detach = function detach() {\n      for (var uri in this.keyUriToKeyInfo) {\n        var keyInfo = this.keyUriToKeyInfo[uri];\n        // Remove cached EME keys on detach\n        if (keyInfo.mediaKeySessionContext || keyInfo.decryptdata.isCommonEncryption) {\n          delete this.keyUriToKeyInfo[uri];\n        }\n      }\n    };\n    _proto.destroy = function destroy() {\n      this.detach();\n      for (var uri in this.keyUriToKeyInfo) {\n        var loader = this.keyUriToKeyInfo[uri].loader;\n        if (loader) {\n          loader.destroy();\n        }\n      }\n      this.keyUriToKeyInfo = {};\n    };\n    _proto.createKeyLoadError = function createKeyLoadError(frag, details, error, networkDetails, response) {\n      if (details === void 0) {\n        details = ErrorDetails.KEY_LOAD_ERROR;\n      }\n      return new LoadError({\n        type: ErrorTypes.NETWORK_ERROR,\n        details: details,\n        fatal: false,\n        frag: frag,\n        response: response,\n        error: error,\n        networkDetails: networkDetails\n      });\n    };\n    _proto.loadClear = function loadClear(loadingFrag, encryptedFragments) {\n      var _this = this;\n      if (this.emeController && this.config.emeEnabled) {\n        // access key-system with nearest key on start (loaidng frag is unencrypted)\n        var sn = loadingFrag.sn,\n          cc = loadingFrag.cc;\n        var _loop = function _loop() {\n          var frag = encryptedFragments[i];\n          if (cc <= frag.cc && (sn === 'initSegment' || frag.sn === 'initSegment' || sn < frag.sn)) {\n            _this.emeController.selectKeySystemFormat(frag).then(function (keySystemFormat) {\n              frag.setKeyFormat(keySystemFormat);\n            });\n            return 1; // break\n          }\n        };\n        for (var i = 0; i < encryptedFragments.length; i++) {\n          if (_loop()) break;\n        }\n      }\n    };\n    _proto.load = function load(frag) {\n      var _this2 = this;\n      if (!frag.decryptdata && frag.encrypted && this.emeController) {\n        // Multiple keys, but none selected, resolve in eme-controller\n        return this.emeController.selectKeySystemFormat(frag).then(function (keySystemFormat) {\n          return _this2.loadInternal(frag, keySystemFormat);\n        });\n      }\n      return this.loadInternal(frag);\n    };\n    _proto.loadInternal = function loadInternal(frag, keySystemFormat) {\n      var _keyInfo, _keyInfo2;\n      if (keySystemFormat) {\n        frag.setKeyFormat(keySystemFormat);\n      }\n      var decryptdata = frag.decryptdata;\n      if (!decryptdata) {\n        var error = new Error(keySystemFormat ? \"Expected frag.decryptdata to be defined after setting format \" + keySystemFormat : 'Missing decryption data on fragment in onKeyLoading');\n        return Promise.reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, error));\n      }\n      var uri = decryptdata.uri;\n      if (!uri) {\n        return Promise.reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, new Error(\"Invalid key URI: \\\"\" + uri + \"\\\"\")));\n      }\n      var keyInfo = this.keyUriToKeyInfo[uri];\n      if ((_keyInfo = keyInfo) != null && _keyInfo.decryptdata.key) {\n        decryptdata.key = keyInfo.decryptdata.key;\n        return Promise.resolve({\n          frag: frag,\n          keyInfo: keyInfo\n        });\n      }\n      // Return key load promise as long as it does not have a mediakey session with an unusable key status\n      if ((_keyInfo2 = keyInfo) != null && _keyInfo2.keyLoadPromise) {\n        var _keyInfo$mediaKeySess;\n        switch ((_keyInfo$mediaKeySess = keyInfo.mediaKeySessionContext) == null ? void 0 : _keyInfo$mediaKeySess.keyStatus) {\n          case undefined:\n          case 'status-pending':\n          case 'usable':\n          case 'usable-in-future':\n            return keyInfo.keyLoadPromise.then(function (keyLoadedData) {\n              // Return the correct fragment with updated decryptdata key and loaded keyInfo\n              decryptdata.key = keyLoadedData.keyInfo.decryptdata.key;\n              return {\n                frag: frag,\n                keyInfo: keyInfo\n              };\n            });\n        }\n        // If we have a key session and status and it is not pending or usable, continue\n        // This will go back to the eme-controller for expired keys to get a new keyLoadPromise\n      }\n\n      // Load the key or return the loading promise\n      keyInfo = this.keyUriToKeyInfo[uri] = {\n        decryptdata: decryptdata,\n        keyLoadPromise: null,\n        loader: null,\n        mediaKeySessionContext: null\n      };\n      switch (decryptdata.method) {\n        case 'ISO-23001-7':\n        case 'SAMPLE-AES':\n        case 'SAMPLE-AES-CENC':\n        case 'SAMPLE-AES-CTR':\n          if (decryptdata.keyFormat === 'identity') {\n            // loadKeyHTTP handles http(s) and data URLs\n            return this.loadKeyHTTP(keyInfo, frag);\n          }\n          return this.loadKeyEME(keyInfo, frag);\n        case 'AES-128':\n          return this.loadKeyHTTP(keyInfo, frag);\n        default:\n          return Promise.reject(this.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, new Error(\"Key supplied with unsupported METHOD: \\\"\" + decryptdata.method + \"\\\"\")));\n      }\n    };\n    _proto.loadKeyEME = function loadKeyEME(keyInfo, frag) {\n      var keyLoadedData = {\n        frag: frag,\n        keyInfo: keyInfo\n      };\n      if (this.emeController && this.config.emeEnabled) {\n        var keySessionContextPromise = this.emeController.loadKey(keyLoadedData);\n        if (keySessionContextPromise) {\n          return (keyInfo.keyLoadPromise = keySessionContextPromise.then(function (keySessionContext) {\n            keyInfo.mediaKeySessionContext = keySessionContext;\n            return keyLoadedData;\n          })).catch(function (error) {\n            // Remove promise for license renewal or retry\n            keyInfo.keyLoadPromise = null;\n            throw error;\n          });\n        }\n      }\n      return Promise.resolve(keyLoadedData);\n    };\n    _proto.loadKeyHTTP = function loadKeyHTTP(keyInfo, frag) {\n      var _this3 = this;\n      var config = this.config;\n      var Loader = config.loader;\n      var keyLoader = new Loader(config);\n      frag.keyLoader = keyInfo.loader = keyLoader;\n      return keyInfo.keyLoadPromise = new Promise(function (resolve, reject) {\n        var loaderContext = {\n          keyInfo: keyInfo,\n          frag: frag,\n          responseType: 'arraybuffer',\n          url: keyInfo.decryptdata.uri\n        };\n\n        // maxRetry is 0 so that instead of retrying the same key on the same variant multiple times,\n        // key-loader will trigger an error and rely on stream-controller to handle retry logic.\n        // this will also align retry logic with fragment-loader\n        var loadPolicy = config.keyLoadPolicy.default;\n        var loaderConfig = {\n          loadPolicy: loadPolicy,\n          timeout: loadPolicy.maxLoadTimeMs,\n          maxRetry: 0,\n          retryDelay: 0,\n          maxRetryDelay: 0\n        };\n        var loaderCallbacks = {\n          onSuccess: function onSuccess(response, stats, context, networkDetails) {\n            var frag = context.frag,\n              keyInfo = context.keyInfo,\n              uri = context.url;\n            if (!frag.decryptdata || keyInfo !== _this3.keyUriToKeyInfo[uri]) {\n              return reject(_this3.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, new Error('after key load, decryptdata unset or changed'), networkDetails));\n            }\n            keyInfo.decryptdata.key = frag.decryptdata.key = new Uint8Array(response.data);\n\n            // detach fragment key loader on load success\n            frag.keyLoader = null;\n            keyInfo.loader = null;\n            resolve({\n              frag: frag,\n              keyInfo: keyInfo\n            });\n          },\n          onError: function onError(response, context, networkDetails, stats) {\n            _this3.resetLoader(context);\n            reject(_this3.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_ERROR, new Error(\"HTTP Error \" + response.code + \" loading key \" + response.text), networkDetails, _objectSpread2({\n              url: loaderContext.url,\n              data: undefined\n            }, response)));\n          },\n          onTimeout: function onTimeout(stats, context, networkDetails) {\n            _this3.resetLoader(context);\n            reject(_this3.createKeyLoadError(frag, ErrorDetails.KEY_LOAD_TIMEOUT, new Error('key loading timed out'), networkDetails));\n          },\n          onAbort: function onAbort(stats, context, networkDetails) {\n            _this3.resetLoader(context);\n            reject(_this3.createKeyLoadError(frag, ErrorDetails.INTERNAL_ABORTED, new Error('key loading aborted'), networkDetails));\n          }\n        };\n        keyLoader.load(loaderContext, loaderConfig, loaderCallbacks);\n      });\n    };\n    _proto.resetLoader = function resetLoader(context) {\n      var frag = context.frag,\n        keyInfo = context.keyInfo,\n        uri = context.url;\n      var loader = keyInfo.loader;\n      if (frag.keyLoader === loader) {\n        frag.keyLoader = null;\n        keyInfo.loader = null;\n      }\n      delete this.keyUriToKeyInfo[uri];\n      if (loader) {\n        loader.destroy();\n      }\n    };\n    return KeyLoader;\n  }();\n\n  function getSourceBuffer() {\n    return self.SourceBuffer || self.WebKitSourceBuffer;\n  }\n  function isMSESupported() {\n    var mediaSource = getMediaSource();\n    if (!mediaSource) {\n      return false;\n    }\n\n    // if SourceBuffer is exposed ensure its API is valid\n    // Older browsers do not expose SourceBuffer globally so checking SourceBuffer.prototype is impossible\n    var sourceBuffer = getSourceBuffer();\n    return !sourceBuffer || sourceBuffer.prototype && typeof sourceBuffer.prototype.appendBuffer === 'function' && typeof sourceBuffer.prototype.remove === 'function';\n  }\n  function isSupported() {\n    if (!isMSESupported()) {\n      return false;\n    }\n    var mediaSource = getMediaSource();\n    return typeof (mediaSource == null ? void 0 : mediaSource.isTypeSupported) === 'function' && (['avc1.42E01E,mp4a.40.2', 'av01.0.01M.08', 'vp09.00.50.08'].some(function (codecsForVideoContainer) {\n      return mediaSource.isTypeSupported(mimeTypeForCodec(codecsForVideoContainer, 'video'));\n    }) || ['mp4a.40.2', 'fLaC'].some(function (codecForAudioContainer) {\n      return mediaSource.isTypeSupported(mimeTypeForCodec(codecForAudioContainer, 'audio'));\n    }));\n  }\n  function changeTypeSupported() {\n    var _sourceBuffer$prototy;\n    var sourceBuffer = getSourceBuffer();\n    return typeof (sourceBuffer == null ? void 0 : (_sourceBuffer$prototy = sourceBuffer.prototype) == null ? void 0 : _sourceBuffer$prototy.changeType) === 'function';\n  }\n\n  var STALL_MINIMUM_DURATION_MS = 250;\n  var MAX_START_GAP_JUMP = 2.0;\n  var SKIP_BUFFER_HOLE_STEP_SECONDS = 0.1;\n  var SKIP_BUFFER_RANGE_START = 0.05;\n  var GapController = /*#__PURE__*/function () {\n    function GapController(config, media, fragmentTracker, hls) {\n      this.config = void 0;\n      this.media = null;\n      this.fragmentTracker = void 0;\n      this.hls = void 0;\n      this.nudgeRetry = 0;\n      this.stallReported = false;\n      this.stalled = null;\n      this.moved = false;\n      this.seeking = false;\n      this.config = config;\n      this.media = media;\n      this.fragmentTracker = fragmentTracker;\n      this.hls = hls;\n    }\n    var _proto = GapController.prototype;\n    _proto.destroy = function destroy() {\n      this.media = null;\n      // @ts-ignore\n      this.hls = this.fragmentTracker = null;\n    }\n\n    /**\n     * Checks if the playhead is stuck within a gap, and if so, attempts to free it.\n     * A gap is an unbuffered range between two buffered ranges (or the start and the first buffered range).\n     *\n     * @param lastCurrentTime - Previously read playhead position\n     */;\n    _proto.poll = function poll(lastCurrentTime, activeFrag) {\n      var config = this.config,\n        media = this.media,\n        stalled = this.stalled;\n      if (media === null) {\n        return;\n      }\n      var currentTime = media.currentTime,\n        seeking = media.seeking;\n      var seeked = this.seeking && !seeking;\n      var beginSeek = !this.seeking && seeking;\n      this.seeking = seeking;\n\n      // The playhead is moving, no-op\n      if (currentTime !== lastCurrentTime) {\n        this.moved = true;\n        if (!seeking) {\n          this.nudgeRetry = 0;\n        }\n        if (stalled !== null) {\n          // The playhead is now moving, but was previously stalled\n          if (this.stallReported) {\n            var _stalledDuration = self.performance.now() - stalled;\n            logger.warn(\"playback not stuck anymore @\" + currentTime + \", after \" + Math.round(_stalledDuration) + \"ms\");\n            this.stallReported = false;\n          }\n          this.stalled = null;\n        }\n        return;\n      }\n\n      // Clear stalled state when beginning or finishing seeking so that we don't report stalls coming out of a seek\n      if (beginSeek || seeked) {\n        this.stalled = null;\n        return;\n      }\n\n      // The playhead should not be moving\n      if (media.paused && !seeking || media.ended || media.playbackRate === 0 || !BufferHelper.getBuffered(media).length) {\n        this.nudgeRetry = 0;\n        return;\n      }\n      var bufferInfo = BufferHelper.bufferInfo(media, currentTime, 0);\n      var nextStart = bufferInfo.nextStart || 0;\n      if (seeking) {\n        // Waiting for seeking in a buffered range to complete\n        var hasEnoughBuffer = bufferInfo.len > MAX_START_GAP_JUMP;\n        // Next buffered range is too far ahead to jump to while still seeking\n        var noBufferGap = !nextStart || activeFrag && activeFrag.start <= currentTime || nextStart - currentTime > MAX_START_GAP_JUMP && !this.fragmentTracker.getPartialFragment(currentTime);\n        if (hasEnoughBuffer || noBufferGap) {\n          return;\n        }\n        // Reset moved state when seeking to a point in or before a gap\n        this.moved = false;\n      }\n\n      // Skip start gaps if we haven't played, but the last poll detected the start of a stall\n      // The addition poll gives the browser a chance to jump the gap for us\n      if (!this.moved && this.stalled !== null) {\n        var _level$details;\n        // There is no playable buffer (seeked, waiting for buffer)\n        var isBuffered = bufferInfo.len > 0;\n        if (!isBuffered && !nextStart) {\n          return;\n        }\n        // Jump start gaps within jump threshold\n        var startJump = Math.max(nextStart, bufferInfo.start || 0) - currentTime;\n\n        // When joining a live stream with audio tracks, account for live playlist window sliding by allowing\n        // a larger jump over start gaps caused by the audio-stream-controller buffering a start fragment\n        // that begins over 1 target duration after the video start position.\n        var level = this.hls.levels ? this.hls.levels[this.hls.currentLevel] : null;\n        var isLive = level == null ? void 0 : (_level$details = level.details) == null ? void 0 : _level$details.live;\n        var maxStartGapJump = isLive ? level.details.targetduration * 2 : MAX_START_GAP_JUMP;\n        var partialOrGap = this.fragmentTracker.getPartialFragment(currentTime);\n        if (startJump > 0 && (startJump <= maxStartGapJump || partialOrGap)) {\n          if (!media.paused) {\n            this._trySkipBufferHole(partialOrGap);\n          }\n          return;\n        }\n      }\n\n      // Start tracking stall time\n      var tnow = self.performance.now();\n      if (stalled === null) {\n        this.stalled = tnow;\n        return;\n      }\n      var stalledDuration = tnow - stalled;\n      if (!seeking && stalledDuration >= STALL_MINIMUM_DURATION_MS) {\n        // Report stalling after trying to fix\n        this._reportStall(bufferInfo);\n        if (!this.media) {\n          return;\n        }\n      }\n      var bufferedWithHoles = BufferHelper.bufferInfo(media, currentTime, config.maxBufferHole);\n      this._tryFixBufferStall(bufferedWithHoles, stalledDuration);\n    }\n\n    /**\n     * Detects and attempts to fix known buffer stalling issues.\n     * @param bufferInfo - The properties of the current buffer.\n     * @param stalledDurationMs - The amount of time Hls.js has been stalling for.\n     * @private\n     */;\n    _proto._tryFixBufferStall = function _tryFixBufferStall(bufferInfo, stalledDurationMs) {\n      var config = this.config,\n        fragmentTracker = this.fragmentTracker,\n        media = this.media;\n      if (media === null) {\n        return;\n      }\n      var currentTime = media.currentTime;\n      var partial = fragmentTracker.getPartialFragment(currentTime);\n      if (partial) {\n        // Try to skip over the buffer hole caused by a partial fragment\n        // This method isn't limited by the size of the gap between buffered ranges\n        var targetTime = this._trySkipBufferHole(partial);\n        // we return here in this case, meaning\n        // the branch below only executes when we haven't seeked to a new position\n        if (targetTime || !this.media) {\n          return;\n        }\n      }\n\n      // if we haven't had to skip over a buffer hole of a partial fragment\n      // we may just have to \"nudge\" the playlist as the browser decoding/rendering engine\n      // needs to cross some sort of threshold covering all source-buffers content\n      // to start playing properly.\n      if ((bufferInfo.len > config.maxBufferHole || bufferInfo.nextStart && bufferInfo.nextStart - currentTime < config.maxBufferHole) && stalledDurationMs > config.highBufferWatchdogPeriod * 1000) {\n        logger.warn('Trying to nudge playhead over buffer-hole');\n        // Try to nudge currentTime over a buffer hole if we've been stalling for the configured amount of seconds\n        // We only try to jump the hole if it's under the configured size\n        // Reset stalled so to rearm watchdog timer\n        this.stalled = null;\n        this._tryNudgeBuffer();\n      }\n    }\n\n    /**\n     * Triggers a BUFFER_STALLED_ERROR event, but only once per stall period.\n     * @param bufferLen - The playhead distance from the end of the current buffer segment.\n     * @private\n     */;\n    _proto._reportStall = function _reportStall(bufferInfo) {\n      var hls = this.hls,\n        media = this.media,\n        stallReported = this.stallReported;\n      if (!stallReported && media) {\n        // Report stalled error once\n        this.stallReported = true;\n        var error = new Error(\"Playback stalling at @\" + media.currentTime + \" due to low buffer (\" + JSON.stringify(bufferInfo) + \")\");\n        logger.warn(error.message);\n        hls.trigger(Events.ERROR, {\n          type: ErrorTypes.MEDIA_ERROR,\n          details: ErrorDetails.BUFFER_STALLED_ERROR,\n          fatal: false,\n          error: error,\n          buffer: bufferInfo.len\n        });\n      }\n    }\n\n    /**\n     * Attempts to fix buffer stalls by jumping over known gaps caused by partial fragments\n     * @param partial - The partial fragment found at the current time (where playback is stalling).\n     * @private\n     */;\n    _proto._trySkipBufferHole = function _trySkipBufferHole(partial) {\n      var config = this.config,\n        hls = this.hls,\n        media = this.media;\n      if (media === null) {\n        return 0;\n      }\n\n      // Check if currentTime is between unbuffered regions of partial fragments\n      var currentTime = media.currentTime;\n      var bufferInfo = BufferHelper.bufferInfo(media, currentTime, 0);\n      var startTime = currentTime < bufferInfo.start ? bufferInfo.start : bufferInfo.nextStart;\n      if (startTime) {\n        var bufferStarved = bufferInfo.len <= config.maxBufferHole;\n        var waiting = bufferInfo.len > 0 && bufferInfo.len < 1 && media.readyState < 3;\n        var gapLength = startTime - currentTime;\n        if (gapLength > 0 && (bufferStarved || waiting)) {\n          // Only allow large gaps to be skipped if it is a start gap, or all fragments in skip range are partial\n          if (gapLength > config.maxBufferHole) {\n            var fragmentTracker = this.fragmentTracker;\n            var startGap = false;\n            if (currentTime === 0) {\n              var startFrag = fragmentTracker.getAppendedFrag(0, PlaylistLevelType.MAIN);\n              if (startFrag && startTime < startFrag.end) {\n                startGap = true;\n              }\n            }\n            if (!startGap) {\n              var startProvisioned = partial || fragmentTracker.getAppendedFrag(currentTime, PlaylistLevelType.MAIN);\n              if (startProvisioned) {\n                var moreToLoad = false;\n                var pos = startProvisioned.end;\n                while (pos < startTime) {\n                  var provisioned = fragmentTracker.getPartialFragment(pos);\n                  if (provisioned) {\n                    pos += provisioned.duration;\n                  } else {\n                    moreToLoad = true;\n                    break;\n                  }\n                }\n                if (moreToLoad) {\n                  return 0;\n                }\n              }\n            }\n          }\n          var targetTime = Math.max(startTime + SKIP_BUFFER_RANGE_START, currentTime + SKIP_BUFFER_HOLE_STEP_SECONDS);\n          logger.warn(\"skipping hole, adjusting currentTime from \" + currentTime + \" to \" + targetTime);\n          this.moved = true;\n          this.stalled = null;\n          media.currentTime = targetTime;\n          if (partial && !partial.gap) {\n            var error = new Error(\"fragment loaded with buffer holes, seeking from \" + currentTime + \" to \" + targetTime);\n            hls.trigger(Events.ERROR, {\n              type: ErrorTypes.MEDIA_ERROR,\n              details: ErrorDetails.BUFFER_SEEK_OVER_HOLE,\n              fatal: false,\n              error: error,\n              reason: error.message,\n              frag: partial\n            });\n          }\n          return targetTime;\n        }\n      }\n      return 0;\n    }\n\n    /**\n     * Attempts to fix buffer stalls by advancing the mediaElement's current time by a small amount.\n     * @private\n     */;\n    _proto._tryNudgeBuffer = function _tryNudgeBuffer() {\n      var config = this.config,\n        hls = this.hls,\n        media = this.media,\n        nudgeRetry = this.nudgeRetry;\n      if (media === null) {\n        return;\n      }\n      var currentTime = media.currentTime;\n      this.nudgeRetry++;\n      if (nudgeRetry < config.nudgeMaxRetry) {\n        var targetTime = currentTime + (nudgeRetry + 1) * config.nudgeOffset;\n        // playback stalled in buffered area ... let's nudge currentTime to try to overcome this\n        var error = new Error(\"Nudging 'currentTime' from \" + currentTime + \" to \" + targetTime);\n        logger.warn(error.message);\n        media.currentTime = targetTime;\n        hls.trigger(Events.ERROR, {\n          type: ErrorTypes.MEDIA_ERROR,\n          details: ErrorDetails.BUFFER_NUDGE_ON_STALL,\n          error: error,\n          fatal: false\n        });\n      } else {\n        var _error = new Error(\"Playhead still not moving while enough data buffered @\" + currentTime + \" after \" + config.nudgeMaxRetry + \" nudges\");\n        logger.error(_error.message);\n        hls.trigger(Events.ERROR, {\n          type: ErrorTypes.MEDIA_ERROR,\n          details: ErrorDetails.BUFFER_STALLED_ERROR,\n          error: _error,\n          fatal: true\n        });\n      }\n    };\n    return GapController;\n  }();\n\n  var TICK_INTERVAL = 100; // how often to tick in ms\n  var StreamController = /*#__PURE__*/function (_BaseStreamController) {\n    _inheritsLoose(StreamController, _BaseStreamController);\n    function StreamController(hls, fragmentTracker, keyLoader) {\n      var _this;\n      _this = _BaseStreamController.call(this, hls, fragmentTracker, keyLoader, '[stream-controller]', PlaylistLevelType.MAIN) || this;\n      _this.audioCodecSwap = false;\n      _this.gapController = null;\n      _this.level = -1;\n      _this._forceStartLoad = false;\n      _this.altAudio = false;\n      _this.audioOnly = false;\n      _this.fragPlaying = null;\n      _this.onvplaying = null;\n      _this.onvseeked = null;\n      _this.fragLastKbps = 0;\n      _this.couldBacktrack = false;\n      _this.backtrackFragment = null;\n      _this.audioCodecSwitch = false;\n      _this.videoBuffer = null;\n      _this._registerListeners();\n      return _this;\n    }\n    var _proto = StreamController.prototype;\n    _proto._registerListeners = function _registerListeners() {\n      var hls = this.hls;\n      hls.on(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.on(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.on(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.on(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n      hls.on(Events.LEVEL_LOADING, this.onLevelLoading, this);\n      hls.on(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n      hls.on(Events.FRAG_LOAD_EMERGENCY_ABORTED, this.onFragLoadEmergencyAborted, this);\n      hls.on(Events.ERROR, this.onError, this);\n      hls.on(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);\n      hls.on(Events.AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);\n      hls.on(Events.BUFFER_CREATED, this.onBufferCreated, this);\n      hls.on(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);\n      hls.on(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n      hls.on(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    };\n    _proto._unregisterListeners = function _unregisterListeners() {\n      var hls = this.hls;\n      hls.off(Events.MEDIA_ATTACHED, this.onMediaAttached, this);\n      hls.off(Events.MEDIA_DETACHING, this.onMediaDetaching, this);\n      hls.off(Events.MANIFEST_LOADING, this.onManifestLoading, this);\n      hls.off(Events.MANIFEST_PARSED, this.onManifestParsed, this);\n      hls.off(Events.LEVEL_LOADED, this.onLevelLoaded, this);\n      hls.off(Events.FRAG_LOAD_EMERGENCY_ABORTED, this.onFragLoadEmergencyAborted, this);\n      hls.off(Events.ERROR, this.onError, this);\n      hls.off(Events.AUDIO_TRACK_SWITCHING, this.onAudioTrackSwitching, this);\n      hls.off(Events.AUDIO_TRACK_SWITCHED, this.onAudioTrackSwitched, this);\n      hls.off(Events.BUFFER_CREATED, this.onBufferCreated, this);\n      hls.off(Events.BUFFER_FLUSHED, this.onBufferFlushed, this);\n      hls.off(Events.LEVELS_UPDATED, this.onLevelsUpdated, this);\n      hls.off(Events.FRAG_BUFFERED, this.onFragBuffered, this);\n    };\n    _proto.onHandlerDestroying = function onHandlerDestroying() {\n      this._unregisterListeners();\n      _BaseStreamController.prototype.onHandlerDestroying.call(this);\n    };\n    _proto.startLoad = function startLoad(startPosition) {\n      if (this.levels) {\n        var lastCurrentTime = this.lastCurrentTime,\n          hls = this.hls;\n        this.stopLoad();\n        this.setInterval(TICK_INTERVAL);\n        this.level = -1;\n        if (!this.startFragRequested) {\n          // determine load level\n          var startLevel = hls.startLevel;\n          if (startLevel === -1) {\n            if (hls.config.testBandwidth && this.levels.length > 1) {\n              // -1 : guess start Level by doing a bitrate test by loading first fragment of lowest quality level\n              startLevel = 0;\n              this.bitrateTest = true;\n            } else {\n              startLevel = hls.firstAutoLevel;\n            }\n          }\n          // set new level to playlist loader : this will trigger start level load\n          // hls.nextLoadLevel remains until it is set to a new value or until a new frag is successfully loaded\n          hls.nextLoadLevel = startLevel;\n          this.level = hls.loadLevel;\n          this.loadedmetadata = false;\n        }\n        // if startPosition undefined but lastCurrentTime set, set startPosition to last currentTime\n        if (lastCurrentTime > 0 && startPosition === -1) {\n          this.log(\"Override startPosition with lastCurrentTime @\" + lastCurrentTime.toFixed(3));\n          startPosition = lastCurrentTime;\n        }\n        this.state = State.IDLE;\n        this.nextLoadPosition = this.startPosition = this.lastCurrentTime = startPosition;\n        this.tick();\n      } else {\n        this._forceStartLoad = true;\n        this.state = State.STOPPED;\n      }\n    };\n    _proto.stopLoad = function stopLoad() {\n      this._forceStartLoad = false;\n      _BaseStreamController.prototype.stopLoad.call(this);\n    };\n    _proto.doTick = function doTick() {\n      switch (this.state) {\n        case State.WAITING_LEVEL:\n          {\n            var levels = this.levels,\n              level = this.level;\n            var currentLevel = levels == null ? void 0 : levels[level];\n            var details = currentLevel == null ? void 0 : currentLevel.details;\n            if (details && (!details.live || this.levelLastLoaded === currentLevel)) {\n              if (this.waitForCdnTuneIn(details)) {\n                break;\n              }\n              this.state = State.IDLE;\n              break;\n            } else if (this.hls.nextLoadLevel !== this.level) {\n              this.state = State.IDLE;\n              break;\n            }\n            break;\n          }\n        case State.FRAG_LOADING_WAITING_RETRY:\n          {\n            var _this$media;\n            var now = self.performance.now();\n            var retryDate = this.retryDate;\n            // if current time is gt than retryDate, or if media seeking let's switch to IDLE state to retry loading\n            if (!retryDate || now >= retryDate || (_this$media = this.media) != null && _this$media.seeking) {\n              var _levels = this.levels,\n                _level = this.level;\n              var _currentLevel = _levels == null ? void 0 : _levels[_level];\n              this.resetStartWhenNotLoaded(_currentLevel || null);\n              this.state = State.IDLE;\n            }\n          }\n          break;\n      }\n      if (this.state === State.IDLE) {\n        this.doTickIdle();\n      }\n      this.onTickEnd();\n    };\n    _proto.onTickEnd = function onTickEnd() {\n      _BaseStreamController.prototype.onTickEnd.call(this);\n      this.checkBuffer();\n      this.checkFragmentChanged();\n    };\n    _proto.doTickIdle = function doTickIdle() {\n      var hls = this.hls,\n        levelLastLoaded = this.levelLastLoaded,\n        levels = this.levels,\n        media = this.media;\n\n      // if start level not parsed yet OR\n      // if video not attached AND start fragment already requested OR start frag prefetch not enabled\n      // exit loop, as we either need more info (level not parsed) or we need media to be attached to load new fragment\n      if (levelLastLoaded === null || !media && (this.startFragRequested || !hls.config.startFragPrefetch)) {\n        return;\n      }\n\n      // If the \"main\" level is audio-only but we are loading an alternate track in the same group, do not load anything\n      if (this.altAudio && this.audioOnly) {\n        return;\n      }\n      var level = hls.nextLoadLevel;\n      if (!(levels != null && levels[level])) {\n        return;\n      }\n      var levelInfo = levels[level];\n\n      // if buffer length is less than maxBufLen try to load a new fragment\n\n      var bufferInfo = this.getMainFwdBufferInfo();\n      if (bufferInfo === null) {\n        return;\n      }\n      var lastDetails = this.getLevelDetails();\n      if (lastDetails && this._streamEnded(bufferInfo, lastDetails)) {\n        var data = {};\n        if (this.altAudio) {\n          data.type = 'video';\n        }\n        this.hls.trigger(Events.BUFFER_EOS, data);\n        this.state = State.ENDED;\n        return;\n      }\n\n      // set next load level : this will trigger a playlist load if needed\n      if (hls.loadLevel !== level && hls.manualLevel === -1) {\n        this.log(\"Adapting to level \" + level + \" from level \" + this.level);\n      }\n      this.level = hls.nextLoadLevel = level;\n      var levelDetails = levelInfo.details;\n      // if level info not retrieved yet, switch state and wait for level retrieval\n      // if live playlist, ensure that new playlist has been refreshed to avoid loading/try to load\n      // a useless and outdated fragment (that might even introduce load error if it is already out of the live playlist)\n      if (!levelDetails || this.state === State.WAITING_LEVEL || levelDetails.live && this.levelLastLoaded !== levelInfo) {\n        this.level = level;\n        this.state = State.WAITING_LEVEL;\n        return;\n      }\n      var bufferLen = bufferInfo.len;\n\n      // compute max Buffer Length that we could get from this load level, based on level bitrate. don't buffer more than 60 MB and more than 30s\n      var maxBufLen = this.getMaxBufferLength(levelInfo.maxBitrate);\n\n      // Stay idle if we are still with buffer margins\n      if (bufferLen >= maxBufLen) {\n        return;\n      }\n      if (this.backtrackFragment && this.backtrackFragment.start > bufferInfo.end) {\n        this.backtrackFragment = null;\n      }\n      var targetBufferTime = this.backtrackFragment ? this.backtrackFragment.start : bufferInfo.end;\n      var frag = this.getNextFragment(targetBufferTime, levelDetails);\n      // Avoid backtracking by loading an earlier segment in streams with segments that do not start with a key frame (flagged by `couldBacktrack`)\n      if (this.couldBacktrack && !this.fragPrevious && frag && frag.sn !== 'initSegment' && this.fragmentTracker.getState(frag) !== FragmentState.OK) {\n        var _this$backtrackFragme;\n        var backtrackSn = ((_this$backtrackFragme = this.backtrackFragment) != null ? _this$backtrackFragme : frag).sn;\n        var fragIdx = backtrackSn - levelDetails.startSN;\n        var backtrackFrag = levelDetails.fragments[fragIdx - 1];\n        if (backtrackFrag && frag.cc === backtrackFrag.cc) {\n          frag = backtrackFrag;\n          this.fragmentTracker.removeFragment(backtrackFrag);\n        }\n      } else if (this.backtrackFragment && bufferInfo.len) {\n        this.backtrackFragment = null;\n      }\n      // Avoid loop loading by using nextLoadPosition set for backtracking and skipping consecutive GAP tags\n      if (frag && this.isLoopLoading(frag, targetBufferTime)) {\n        var gapStart = frag.gap;\n        if (!gapStart) {\n          // Cleanup the fragment tracker before trying to find the next unbuffered fragment\n          var type = this.audioOnly && !this.altAudio ? ElementaryStreamTypes.AUDIO : ElementaryStreamTypes.VIDEO;\n          var mediaBuffer = (type === ElementaryStreamTypes.VIDEO ? this.videoBuffer : this.mediaBuffer) || this.media;\n          if (mediaBuffer) {\n            this.afterBufferFlushed(mediaBuffer, type, PlaylistLevelType.MAIN);\n          }\n        }\n        frag = this.getNextFragmentLoopLoading(frag, levelDetails, bufferInfo, PlaylistLevelType.MAIN, maxBufLen);\n      }\n      if (!frag) {\n        return;\n      }\n      if (frag.initSegment && !frag.initSegment.data && !this.bitrateTest) {\n        frag = frag.initSegment;\n      }\n      this.loadFragment(frag, levelInfo, targetBufferTime);\n    };\n    _proto.loadFragment = function loadFragment(frag, level, targetBufferTime) {\n      // Check if fragment is not loaded\n      var fragState = this.fragmentTracker.getState(frag);\n      this.fragCurrent = frag;\n      if (fragState === FragmentState.NOT_LOADED || fragState === FragmentState.PARTIAL) {\n        if (frag.sn === 'initSegment') {\n          this._loadInitSegment(frag, level);\n        } else if (this.bitrateTest) {\n          this.log(\"Fragment \" + frag.sn + \" of level \" + frag.level + \" is being downloaded to test bitrate and will not be buffered\");\n          this._loadBitrateTestFrag(frag, level);\n        } else {\n          this.startFragRequested = true;\n          _BaseStreamController.prototype.loadFragment.call(this, frag, level, targetBufferTime);\n        }\n      } else {\n        this.clearTrackerIfNeeded(frag);\n      }\n    };\n    _proto.getBufferedFrag = function getBufferedFrag(position) {\n      return this.fragmentTracker.getBufferedFrag(position, PlaylistLevelType.MAIN);\n    };\n    _proto.followingBufferedFrag = function followingBufferedFrag(frag) {\n      if (frag) {\n        // try to get range of next fragment (500ms after this range)\n        return this.getBufferedFrag(frag.end + 0.5);\n      }\n      return null;\n    }\n\n    /*\n      on immediate level switch :\n       - pause playback if playing\n       - cancel any pending load request\n       - and trigger a buffer flush\n    */;\n    _proto.immediateLevelSwitch = function immediateLevelSwitch() {\n      this.abortCurrentFrag();\n      this.flushMainBuffer(0, Number.POSITIVE_INFINITY);\n    }\n\n    /**\n     * try to switch ASAP without breaking video playback:\n     * in order to ensure smooth but quick level switching,\n     * we need to find the next flushable buffer range\n     * we should take into account new segment fetch time\n     */;\n    _proto.nextLevelSwitch = function nextLevelSwitch() {\n      var levels = this.levels,\n        media = this.media;\n      // ensure that media is defined and that metadata are available (to retrieve currentTime)\n      if (media != null && media.readyState) {\n        var fetchdelay;\n        var fragPlayingCurrent = this.getAppendedFrag(media.currentTime);\n        if (fragPlayingCurrent && fragPlayingCurrent.start > 1) {\n          // flush buffer preceding current fragment (flush until current fragment start offset)\n          // minus 1s to avoid video freezing, that could happen if we flush keyframe of current video ...\n          this.flushMainBuffer(0, fragPlayingCurrent.start - 1);\n        }\n        var levelDetails = this.getLevelDetails();\n        if (levelDetails != null && levelDetails.live) {\n          var bufferInfo = this.getMainFwdBufferInfo();\n          // Do not flush in live stream with low buffer\n          if (!bufferInfo || bufferInfo.len < levelDetails.targetduration * 2) {\n            return;\n          }\n        }\n        if (!media.paused && levels) {\n          // add a safety delay of 1s\n          var nextLevelId = this.hls.nextLoadLevel;\n          var nextLevel = levels[nextLevelId];\n          var fragLastKbps = this.fragLastKbps;\n          if (fragLastKbps && this.fragCurrent) {\n            fetchdelay = this.fragCurrent.duration * nextLevel.maxBitrate / (1000 * fragLastKbps) + 1;\n          } else {\n            fetchdelay = 0;\n          }\n        } else {\n          fetchdelay = 0;\n        }\n        // this.log('fetchdelay:'+fetchdelay);\n        // find buffer range that will be reached once new fragment will be fetched\n        var bufferedFrag = this.getBufferedFrag(media.currentTime + fetchdelay);\n        if (bufferedFrag) {\n          // we can flush buffer range following this one without stalling playback\n          var nextBufferedFrag = this.followingBufferedFrag(bufferedFrag);\n          if (nextBufferedFrag) {\n            // if we are here, we can also cancel any loading/demuxing in progress, as they are useless\n            this.abortCurrentFrag();\n            // start flush position is in next buffered frag. Leave some padding for non-independent segments and smoother playback.\n            var maxStart = nextBufferedFrag.maxStartPTS ? nextBufferedFrag.maxStartPTS : nextBufferedFrag.start;\n            var fragDuration = nextBufferedFrag.duration;\n            var startPts = Math.max(bufferedFrag.end, maxStart + Math.min(Math.max(fragDuration - this.config.maxFragLookUpTolerance, fragDuration * (this.couldBacktrack ? 0.5 : 0.125)), fragDuration * (this.couldBacktrack ? 0.75 : 0.25)));\n            this.flushMainBuffer(startPts, Number.POSITIVE_INFINITY);\n          }\n        }\n      }\n    };\n    _proto.abortCurrentFrag = function abortCurrentFrag() {\n      var fragCurrent = this.fragCurrent;\n      this.fragCurrent = null;\n      this.backtrackFragment = null;\n      if (fragCurrent) {\n        fragCurrent.abortRequests();\n        this.fragmentTracker.removeFragment(fragCurrent);\n      }\n      switch (this.state) {\n        case State.KEY_LOADING:\n        case State.FRAG_LOADING:\n        case State.FRAG_LOADING_WAITING_RETRY:\n        case State.PARSING:\n        case State.PARSED:\n          this.state = State.IDLE;\n          break;\n      }\n      this.nextLoadPosition = this.getLoadPosition();\n    };\n    _proto.flushMainBuffer = function flushMainBuffer(startOffset, endOffset) {\n      _BaseStreamController.prototype.flushMainBuffer.call(this, startOffset, endOffset, this.altAudio ? 'video' : null);\n    };\n    _proto.onMediaAttached = function onMediaAttached(event, data) {\n      _BaseStreamController.prototype.onMediaAttached.call(this, event, data);\n      var media = data.media;\n      this.onvplaying = this.onMediaPlaying.bind(this);\n      this.onvseeked = this.onMediaSeeked.bind(this);\n      media.addEventListener('playing', this.onvplaying);\n      media.addEventListener('seeked', this.onvseeked);\n      this.gapController = new GapController(this.config, media, this.fragmentTracker, this.hls);\n    };\n    _proto.onMediaDetaching = function onMediaDetaching() {\n      var media = this.media;\n      if (media && this.onvplaying && this.onvseeked) {\n        media.removeEventListener('playing', this.onvplaying);\n        media.removeEventListener('seeked', this.onvseeked);\n        this.onvplaying = this.onvseeked = null;\n        this.videoBuffer = null;\n      }\n      this.fragPlaying = null;\n      if (this.gapController) {\n        this.gapController.destroy();\n        this.gapController = null;\n      }\n      _BaseStreamController.prototype.onMediaDetaching.call(this);\n    };\n    _proto.onMediaPlaying = function onMediaPlaying() {\n      // tick to speed up FRAG_CHANGED triggering\n      this.tick();\n    };\n    _proto.onMediaSeeked = function onMediaSeeked() {\n      var media = this.media;\n      var currentTime = media ? media.currentTime : null;\n      if (isFiniteNumber(currentTime)) {\n        this.log(\"Media seeked to \" + currentTime.toFixed(3));\n      }\n\n      // If seeked was issued before buffer was appended do not tick immediately\n      var bufferInfo = this.getMainFwdBufferInfo();\n      if (bufferInfo === null || bufferInfo.len === 0) {\n        this.warn(\"Main forward buffer length on \\\"seeked\\\" event \" + (bufferInfo ? bufferInfo.len : 'empty') + \")\");\n        return;\n      }\n\n      // tick to speed up FRAG_CHANGED triggering\n      this.tick();\n    };\n    _proto.onManifestLoading = function onManifestLoading() {\n      // reset buffer on manifest loading\n      this.log('Trigger BUFFER_RESET');\n      this.hls.trigger(Events.BUFFER_RESET, undefined);\n      this.fragmentTracker.removeAllFragments();\n      this.couldBacktrack = false;\n      this.startPosition = this.lastCurrentTime = this.fragLastKbps = 0;\n      this.levels = this.fragPlaying = this.backtrackFragment = this.levelLastLoaded = null;\n      this.altAudio = this.audioOnly = this.startFragRequested = false;\n    };\n    _proto.onManifestParsed = function onManifestParsed(event, data) {\n      // detect if we have different kind of audio codecs used amongst playlists\n      var aac = false;\n      var heaac = false;\n      data.levels.forEach(function (level) {\n        var codec = level.audioCodec;\n        if (codec) {\n          aac = aac || codec.indexOf('mp4a.40.2') !== -1;\n          heaac = heaac || codec.indexOf('mp4a.40.5') !== -1;\n        }\n      });\n      this.audioCodecSwitch = aac && heaac && !changeTypeSupported();\n      if (this.audioCodecSwitch) {\n        this.log('Both AAC/HE-AAC audio found in levels; declaring level codec as HE-AAC');\n      }\n      this.levels = data.levels;\n      this.startFragRequested = false;\n    };\n    _proto.onLevelLoading = function onLevelLoading(event, data) {\n      var levels = this.levels;\n      if (!levels || this.state !== State.IDLE) {\n        return;\n      }\n      var level = levels[data.level];\n      if (!level.details || level.details.live && this.levelLastLoaded !== level || this.waitForCdnTuneIn(level.details)) {\n        this.state = State.WAITING_LEVEL;\n      }\n    };\n    _proto.onLevelLoaded = function onLevelLoaded(event, data) {\n      var _curLevel$details;\n      var levels = this.levels;\n      var newLevelId = data.level;\n      var newDetails = data.details;\n      var duration = newDetails.totalduration;\n      if (!levels) {\n        this.warn(\"Levels were reset while loading level \" + newLevelId);\n        return;\n      }\n      this.log(\"Level \" + newLevelId + \" loaded [\" + newDetails.startSN + \",\" + newDetails.endSN + \"]\" + (newDetails.lastPartSn ? \"[part-\" + newDetails.lastPartSn + \"-\" + newDetails.lastPartIndex + \"]\" : '') + \", cc [\" + newDetails.startCC + \", \" + newDetails.endCC + \"] duration:\" + duration);\n      var curLevel = levels[newLevelId];\n      var fragCurrent = this.fragCurrent;\n      if (fragCurrent && (this.state === State.FRAG_LOADING || this.state === State.FRAG_LOADING_WAITING_RETRY)) {\n        if (fragCurrent.level !== data.level && fragCurrent.loader) {\n          this.abortCurrentFrag();\n        }\n      }\n      var sliding = 0;\n      if (newDetails.live || (_curLevel$details = curLevel.details) != null && _curLevel$details.live) {\n        var _this$levelLastLoaded;\n        this.checkLiveUpdate(newDetails);\n        if (newDetails.deltaUpdateFailed) {\n          return;\n        }\n        sliding = this.alignPlaylists(newDetails, curLevel.details, (_this$levelLastLoaded = this.levelLastLoaded) == null ? void 0 : _this$levelLastLoaded.details);\n      }\n      // override level info\n      curLevel.details = newDetails;\n      this.levelLastLoaded = curLevel;\n      this.hls.trigger(Events.LEVEL_UPDATED, {\n        details: newDetails,\n        level: newLevelId\n      });\n\n      // only switch back to IDLE state if we were waiting for level to start downloading a new fragment\n      if (this.state === State.WAITING_LEVEL) {\n        if (this.waitForCdnTuneIn(newDetails)) {\n          // Wait for Low-Latency CDN Tune-in\n          return;\n        }\n        this.state = State.IDLE;\n      }\n      if (!this.startFragRequested) {\n        this.setStartPosition(newDetails, sliding);\n      } else if (newDetails.live) {\n        this.synchronizeToLiveEdge(newDetails);\n      }\n\n      // trigger handler right now\n      this.tick();\n    };\n    _proto._handleFragmentLoadProgress = function _handleFragmentLoadProgress(data) {\n      var _frag$initSegment;\n      var frag = data.frag,\n        part = data.part,\n        payload = data.payload;\n      var levels = this.levels;\n      if (!levels) {\n        this.warn(\"Levels were reset while fragment load was in progress. Fragment \" + frag.sn + \" of level \" + frag.level + \" will not be buffered\");\n        return;\n      }\n      var currentLevel = levels[frag.level];\n      var details = currentLevel.details;\n      if (!details) {\n        this.warn(\"Dropping fragment \" + frag.sn + \" of level \" + frag.level + \" after level details were reset\");\n        this.fragmentTracker.removeFragment(frag);\n        return;\n      }\n      var videoCodec = currentLevel.videoCodec;\n\n      // time Offset is accurate if level PTS is known, or if playlist is not sliding (not live)\n      var accurateTimeOffset = details.PTSKnown || !details.live;\n      var initSegmentData = (_frag$initSegment = frag.initSegment) == null ? void 0 : _frag$initSegment.data;\n      var audioCodec = this._getAudioCodec(currentLevel);\n\n      // transmux the MPEG-TS data to ISO-BMFF segments\n      // this.log(`Transmuxing ${frag.sn} of [${details.startSN} ,${details.endSN}],level ${frag.level}, cc ${frag.cc}`);\n      var transmuxer = this.transmuxer = this.transmuxer || new TransmuxerInterface(this.hls, PlaylistLevelType.MAIN, this._handleTransmuxComplete.bind(this), this._handleTransmuxerFlush.bind(this));\n      var partIndex = part ? part.index : -1;\n      var partial = partIndex !== -1;\n      var chunkMeta = new ChunkMetadata(frag.level, frag.sn, frag.stats.chunkCount, payload.byteLength, partIndex, partial);\n      var initPTS = this.initPTS[frag.cc];\n      transmuxer.push(payload, initSegmentData, audioCodec, videoCodec, frag, part, details.totalduration, accurateTimeOffset, chunkMeta, initPTS);\n    };\n    _proto.onAudioTrackSwitching = function onAudioTrackSwitching(event, data) {\n      // if any URL found on new audio track, it is an alternate audio track\n      var fromAltAudio = this.altAudio;\n      var altAudio = !!data.url;\n      // if we switch on main audio, ensure that main fragment scheduling is synced with media.buffered\n      // don't do anything if we switch to alt audio: audio stream controller is handling it.\n      // we will just have to change buffer scheduling on audioTrackSwitched\n      if (!altAudio) {\n        if (this.mediaBuffer !== this.media) {\n          this.log('Switching on main audio, use media.buffered to schedule main fragment loading');\n          this.mediaBuffer = this.media;\n          var fragCurrent = this.fragCurrent;\n          // we need to refill audio buffer from main: cancel any frag loading to speed up audio switch\n          if (fragCurrent) {\n            this.log('Switching to main audio track, cancel main fragment load');\n            fragCurrent.abortRequests();\n            this.fragmentTracker.removeFragment(fragCurrent);\n          }\n          // destroy transmuxer to force init segment generation (following audio switch)\n          this.resetTransmuxer();\n          // switch to IDLE state to load new fragment\n          this.resetLoadingState();\n        } else if (this.audioOnly) {\n          // Reset audio transmuxer so when switching back to main audio we're not still appending where we left off\n          this.resetTransmuxer();\n        }\n        var hls = this.hls;\n        // If switching from alt to main audio, flush all audio and trigger track switched\n        if (fromAltAudio) {\n          hls.trigger(Events.BUFFER_FLUSHING, {\n            startOffset: 0,\n            endOffset: Number.POSITIVE_INFINITY,\n            type: null\n          });\n          this.fragmentTracker.removeAllFragments();\n        }\n        hls.trigger(Events.AUDIO_TRACK_SWITCHED, data);\n      }\n    };\n    _proto.onAudioTrackSwitched = function onAudioTrackSwitched(event, data) {\n      var trackId = data.id;\n      var altAudio = !!this.hls.audioTracks[trackId].url;\n      if (altAudio) {\n        var videoBuffer = this.videoBuffer;\n        // if we switched on alternate audio, ensure that main fragment scheduling is synced with video sourcebuffer buffered\n        if (videoBuffer && this.mediaBuffer !== videoBuffer) {\n          this.log('Switching on alternate audio, use video.buffered to schedule main fragment loading');\n          this.mediaBuffer = videoBuffer;\n        }\n      }\n      this.altAudio = altAudio;\n      this.tick();\n    };\n    _proto.onBufferCreated = function onBufferCreated(event, data) {\n      var tracks = data.tracks;\n      var mediaTrack;\n      var name;\n      var alternate = false;\n      for (var type in tracks) {\n        var track = tracks[type];\n        if (track.id === 'main') {\n          name = type;\n          mediaTrack = track;\n          // keep video source buffer reference\n          if (type === 'video') {\n            var videoTrack = tracks[type];\n            if (videoTrack) {\n              this.videoBuffer = videoTrack.buffer;\n            }\n          }\n        } else {\n          alternate = true;\n        }\n      }\n      if (alternate && mediaTrack) {\n        this.log(\"Alternate track found, use \" + name + \".buffered to schedule main fragment loading\");\n        this.mediaBuffer = mediaTrack.buffer;\n      } else {\n        this.mediaBuffer = this.media;\n      }\n    };\n    _proto.onFragBuffered = function onFragBuffered(event, data) {\n      var frag = data.frag,\n        part = data.part;\n      if (frag && frag.type !== PlaylistLevelType.MAIN) {\n        return;\n      }\n      if (this.fragContextChanged(frag)) {\n        // If a level switch was requested while a fragment was buffering, it will emit the FRAG_BUFFERED event upon completion\n        // Avoid setting state back to IDLE, since that will interfere with a level switch\n        this.warn(\"Fragment \" + frag.sn + (part ? ' p: ' + part.index : '') + \" of level \" + frag.level + \" finished buffering, but was aborted. state: \" + this.state);\n        if (this.state === State.PARSED) {\n          this.state = State.IDLE;\n        }\n        return;\n      }\n      var stats = part ? part.stats : frag.stats;\n      this.fragLastKbps = Math.round(8 * stats.total / (stats.buffering.end - stats.loading.first));\n      if (frag.sn !== 'initSegment') {\n        this.fragPrevious = frag;\n      }\n      this.fragBufferedComplete(frag, part);\n    };\n    _proto.onError = function onError(event, data) {\n      var _data$context;\n      if (data.fatal) {\n        this.state = State.ERROR;\n        return;\n      }\n      switch (data.details) {\n        case ErrorDetails.FRAG_GAP:\n        case ErrorDetails.FRAG_PARSING_ERROR:\n        case ErrorDetails.FRAG_DECRYPT_ERROR:\n        case ErrorDetails.FRAG_LOAD_ERROR:\n        case ErrorDetails.FRAG_LOAD_TIMEOUT:\n        case ErrorDetails.KEY_LOAD_ERROR:\n        case ErrorDetails.KEY_LOAD_TIMEOUT:\n          this.onFragmentOrKeyLoadError(PlaylistLevelType.MAIN, data);\n          break;\n        case ErrorDetails.LEVEL_LOAD_ERROR:\n        case ErrorDetails.LEVEL_LOAD_TIMEOUT:\n        case ErrorDetails.LEVEL_PARSING_ERROR:\n          // in case of non fatal error while loading level, if level controller is not retrying to load level, switch back to IDLE\n          if (!data.levelRetry && this.state === State.WAITING_LEVEL && ((_data$context = data.context) == null ? void 0 : _data$context.type) === PlaylistContextType.LEVEL) {\n            this.state = State.IDLE;\n          }\n          break;\n        case ErrorDetails.BUFFER_APPEND_ERROR:\n        case ErrorDetails.BUFFER_FULL_ERROR:\n          if (!data.parent || data.parent !== 'main') {\n            return;\n          }\n          if (data.details === ErrorDetails.BUFFER_APPEND_ERROR) {\n            this.resetLoadingState();\n            return;\n          }\n          if (this.reduceLengthAndFlushBuffer(data)) {\n            this.flushMainBuffer(0, Number.POSITIVE_INFINITY);\n          }\n          break;\n        case ErrorDetails.INTERNAL_EXCEPTION:\n          this.recoverWorkerError(data);\n          break;\n      }\n    }\n\n    // Checks the health of the buffer and attempts to resolve playback stalls.\n    ;\n    _proto.checkBuffer = function checkBuffer() {\n      var media = this.media,\n        gapController = this.gapController;\n      if (!media || !gapController || !media.readyState) {\n        // Exit early if we don't have media or if the media hasn't buffered anything yet (readyState 0)\n        return;\n      }\n      if (this.loadedmetadata || !BufferHelper.getBuffered(media).length) {\n        // Resolve gaps using the main buffer, whose ranges are the intersections of the A/V sourcebuffers\n        var activeFrag = this.state !== State.IDLE ? this.fragCurrent : null;\n        gapController.poll(this.lastCurrentTime, activeFrag);\n      }\n      this.lastCurrentTime = media.currentTime;\n    };\n    _proto.onFragLoadEmergencyAborted = function onFragLoadEmergencyAborted() {\n      this.state = State.IDLE;\n      // if loadedmetadata is not set, it means that we are emergency switch down on first frag\n      // in that case, reset startFragRequested flag\n      if (!this.loadedmetadata) {\n        this.startFragRequested = false;\n        this.nextLoadPosition = this.startPosition;\n      }\n      this.tickImmediate();\n    };\n    _proto.onBufferFlushed = function onBufferFlushed(event, _ref) {\n      var type = _ref.type;\n      if (type !== ElementaryStreamTypes.AUDIO || this.audioOnly && !this.altAudio) {\n        var mediaBuffer = (type === ElementaryStreamTypes.VIDEO ? this.videoBuffer : this.mediaBuffer) || this.media;\n        this.afterBufferFlushed(mediaBuffer, type, PlaylistLevelType.MAIN);\n        this.tick();\n      }\n    };\n    _proto.onLevelsUpdated = function onLevelsUpdated(event, data) {\n      if (this.level > -1 && this.fragCurrent) {\n        this.level = this.fragCurrent.level;\n      }\n      this.levels = data.levels;\n    };\n    _proto.swapAudioCodec = function swapAudioCodec() {\n      this.audioCodecSwap = !this.audioCodecSwap;\n    }\n\n    /**\n     * Seeks to the set startPosition if not equal to the mediaElement's current time.\n     */;\n    _proto.seekToStartPos = function seekToStartPos() {\n      var media = this.media;\n      if (!media) {\n        return;\n      }\n      var currentTime = media.currentTime;\n      var startPosition = this.startPosition;\n      // only adjust currentTime if different from startPosition or if startPosition not buffered\n      // at that stage, there should be only one buffered range, as we reach that code after first fragment has been buffered\n      if (startPosition >= 0 && currentTime < startPosition) {\n        if (media.seeking) {\n          this.log(\"could not seek to \" + startPosition + \", already seeking at \" + currentTime);\n          return;\n        }\n        var buffered = BufferHelper.getBuffered(media);\n        var bufferStart = buffered.length ? buffered.start(0) : 0;\n        var delta = bufferStart - startPosition;\n        if (delta > 0 && (delta < this.config.maxBufferHole || delta < this.config.maxFragLookUpTolerance)) {\n          this.log(\"adjusting start position by \" + delta + \" to match buffer start\");\n          startPosition += delta;\n          this.startPosition = startPosition;\n        }\n        this.log(\"seek to target start position \" + startPosition + \" from current time \" + currentTime);\n        media.currentTime = startPosition;\n      }\n    };\n    _proto._getAudioCodec = function _getAudioCodec(currentLevel) {\n      var audioCodec = this.config.defaultAudioCodec || currentLevel.audioCodec;\n      if (this.audioCodecSwap && audioCodec) {\n        this.log('Swapping audio codec');\n        if (audioCodec.indexOf('mp4a.40.5') !== -1) {\n          audioCodec = 'mp4a.40.2';\n        } else {\n          audioCodec = 'mp4a.40.5';\n        }\n      }\n      return audioCodec;\n    };\n    _proto._loadBitrateTestFrag = function _loadBitrateTestFrag(frag, level) {\n      var _this2 = this;\n      frag.bitrateTest = true;\n      this._doFragLoad(frag, level).then(function (data) {\n        var hls = _this2.hls;\n        if (!data || _this2.fragContextChanged(frag)) {\n          return;\n        }\n        level.fragmentError = 0;\n        _this2.state = State.IDLE;\n        _this2.startFragRequested = false;\n        _this2.bitrateTest = false;\n        var stats = frag.stats;\n        // Bitrate tests fragments are neither parsed nor buffered\n        stats.parsing.start = stats.parsing.end = stats.buffering.start = stats.buffering.end = self.performance.now();\n        hls.trigger(Events.FRAG_LOADED, data);\n        frag.bitrateTest = false;\n      });\n    };\n    _proto._handleTransmuxComplete = function _handleTransmuxComplete(transmuxResult) {\n      var _id3$samples;\n      var id = 'main';\n      var hls = this.hls;\n      var remuxResult = transmuxResult.remuxResult,\n        chunkMeta = transmuxResult.chunkMeta;\n      var context = this.getCurrentContext(chunkMeta);\n      if (!context) {\n        this.resetWhenMissingContext(chunkMeta);\n        return;\n      }\n      var frag = context.frag,\n        part = context.part,\n        level = context.level;\n      var video = remuxResult.video,\n        text = remuxResult.text,\n        id3 = remuxResult.id3,\n        initSegment = remuxResult.initSegment;\n      var details = level.details;\n      // The audio-stream-controller handles audio buffering if Hls.js is playing an alternate audio track\n      var audio = this.altAudio ? undefined : remuxResult.audio;\n\n      // Check if the current fragment has been aborted. We check this by first seeing if we're still playing the current level.\n      // If we are, subsequently check if the currently loading fragment (fragCurrent) has changed.\n      if (this.fragContextChanged(frag)) {\n        this.fragmentTracker.removeFragment(frag);\n        return;\n      }\n      this.state = State.PARSING;\n      if (initSegment) {\n        if (initSegment != null && initSegment.tracks) {\n          var mapFragment = frag.initSegment || frag;\n          this._bufferInitSegment(level, initSegment.tracks, mapFragment, chunkMeta);\n          hls.trigger(Events.FRAG_PARSING_INIT_SEGMENT, {\n            frag: mapFragment,\n            id: id,\n            tracks: initSegment.tracks\n          });\n        }\n\n        // This would be nice if Number.isFinite acted as a typeguard, but it doesn't. See: https://github.com/Microsoft/TypeScript/issues/10038\n        var initPTS = initSegment.initPTS;\n        var timescale = initSegment.timescale;\n        if (isFiniteNumber(initPTS)) {\n          this.initPTS[frag.cc] = {\n            baseTime: initPTS,\n            timescale: timescale\n          };\n          hls.trigger(Events.INIT_PTS_FOUND, {\n            frag: frag,\n            id: id,\n            initPTS: initPTS,\n            timescale: timescale\n          });\n        }\n      }\n\n      // Avoid buffering if backtracking this fragment\n      if (video && details && frag.sn !== 'initSegment') {\n        var prevFrag = details.fragments[frag.sn - 1 - details.startSN];\n        var isFirstFragment = frag.sn === details.startSN;\n        var isFirstInDiscontinuity = !prevFrag || frag.cc > prevFrag.cc;\n        if (remuxResult.independent !== false) {\n          var startPTS = video.startPTS,\n            endPTS = video.endPTS,\n            startDTS = video.startDTS,\n            endDTS = video.endDTS;\n          if (part) {\n            part.elementaryStreams[video.type] = {\n              startPTS: startPTS,\n              endPTS: endPTS,\n              startDTS: startDTS,\n              endDTS: endDTS\n            };\n          } else {\n            if (video.firstKeyFrame && video.independent && chunkMeta.id === 1 && !isFirstInDiscontinuity) {\n              this.couldBacktrack = true;\n            }\n            if (video.dropped && video.independent) {\n              // Backtrack if dropped frames create a gap after currentTime\n\n              var bufferInfo = this.getMainFwdBufferInfo();\n              var targetBufferTime = (bufferInfo ? bufferInfo.end : this.getLoadPosition()) + this.config.maxBufferHole;\n              var startTime = video.firstKeyFramePTS ? video.firstKeyFramePTS : startPTS;\n              if (!isFirstFragment && targetBufferTime < startTime - this.config.maxBufferHole && !isFirstInDiscontinuity) {\n                this.backtrack(frag);\n                return;\n              } else if (isFirstInDiscontinuity) {\n                // Mark segment with a gap to avoid loop loading\n                frag.gap = true;\n              }\n              // Set video stream start to fragment start so that truncated samples do not distort the timeline, and mark it partial\n              frag.setElementaryStreamInfo(video.type, frag.start, endPTS, frag.start, endDTS, true);\n            } else if (isFirstFragment && startPTS > MAX_START_GAP_JUMP) {\n              // Mark segment with a gap to skip large start gap\n              frag.gap = true;\n            }\n          }\n          frag.setElementaryStreamInfo(video.type, startPTS, endPTS, startDTS, endDTS);\n          if (this.backtrackFragment) {\n            this.backtrackFragment = frag;\n          }\n          this.bufferFragmentData(video, frag, part, chunkMeta, isFirstFragment || isFirstInDiscontinuity);\n        } else if (isFirstFragment || isFirstInDiscontinuity) {\n          // Mark segment with a gap to avoid loop loading\n          frag.gap = true;\n        } else {\n          this.backtrack(frag);\n          return;\n        }\n      }\n      if (audio) {\n        var _startPTS = audio.startPTS,\n          _endPTS = audio.endPTS,\n          _startDTS = audio.startDTS,\n          _endDTS = audio.endDTS;\n        if (part) {\n          part.elementaryStreams[ElementaryStreamTypes.AUDIO] = {\n            startPTS: _startPTS,\n            endPTS: _endPTS,\n            startDTS: _startDTS,\n            endDTS: _endDTS\n          };\n        }\n        frag.setElementaryStreamInfo(ElementaryStreamTypes.AUDIO, _startPTS, _endPTS, _startDTS, _endDTS);\n        this.bufferFragmentData(audio, frag, part, chunkMeta);\n      }\n      if (details && id3 != null && (_id3$samples = id3.samples) != null && _id3$samples.length) {\n        var emittedID3 = {\n          id: id,\n          frag: frag,\n          details: details,\n          samples: id3.samples\n        };\n        hls.trigger(Events.FRAG_PARSING_METADATA, emittedID3);\n      }\n      if (details && text) {\n        var emittedText = {\n          id: id,\n          frag: frag,\n          details: details,\n          samples: text.samples\n        };\n        hls.trigger(Events.FRAG_PARSING_USERDATA, emittedText);\n      }\n    };\n    _proto._bufferInitSegment = function _bufferInitSegment(currentLevel, tracks, frag, chunkMeta) {\n      var _this3 = this;\n      if (this.state !== State.PARSING) {\n        return;\n      }\n      this.audioOnly = !!tracks.audio && !tracks.video;\n\n      // if audio track is expected to come from audio stream controller, discard any coming from main\n      if (this.altAudio && !this.audioOnly) {\n        delete tracks.audio;\n      }\n      // include levelCodec in audio and video tracks\n      var audio = tracks.audio,\n        video = tracks.video,\n        audiovideo = tracks.audiovideo;\n      if (audio) {\n        var audioCodec = currentLevel.audioCodec;\n        var ua = navigator.userAgent.toLowerCase();\n        if (this.audioCodecSwitch) {\n          if (audioCodec) {\n            if (audioCodec.indexOf('mp4a.40.5') !== -1) {\n              audioCodec = 'mp4a.40.2';\n            } else {\n              audioCodec = 'mp4a.40.5';\n            }\n          }\n          // In the case that AAC and HE-AAC audio codecs are signalled in manifest,\n          // force HE-AAC, as it seems that most browsers prefers it.\n          // don't force HE-AAC if mono stream, or in Firefox\n          var audioMetadata = audio.metadata;\n          if (audioMetadata && 'channelCount' in audioMetadata && (audioMetadata.channelCount || 1) !== 1 && ua.indexOf('firefox') === -1) {\n            audioCodec = 'mp4a.40.5';\n          }\n        }\n        // HE-AAC is broken on Android, always signal audio codec as AAC even if variant manifest states otherwise\n        if (audioCodec && audioCodec.indexOf('mp4a.40.5') !== -1 && ua.indexOf('android') !== -1 && audio.container !== 'audio/mpeg') {\n          // Exclude mpeg audio\n          audioCodec = 'mp4a.40.2';\n          this.log(\"Android: force audio codec to \" + audioCodec);\n        }\n        if (currentLevel.audioCodec && currentLevel.audioCodec !== audioCodec) {\n          this.log(\"Swapping manifest audio codec \\\"\" + currentLevel.audioCodec + \"\\\" for \\\"\" + audioCodec + \"\\\"\");\n        }\n        audio.levelCodec = audioCodec;\n        audio.id = 'main';\n        this.log(\"Init audio buffer, container:\" + audio.container + \", codecs[selected/level/parsed]=[\" + (audioCodec || '') + \"/\" + (currentLevel.audioCodec || '') + \"/\" + audio.codec + \"]\");\n      }\n      if (video) {\n        video.levelCodec = currentLevel.videoCodec;\n        video.id = 'main';\n        this.log(\"Init video buffer, container:\" + video.container + \", codecs[level/parsed]=[\" + (currentLevel.videoCodec || '') + \"/\" + video.codec + \"]\");\n      }\n      if (audiovideo) {\n        this.log(\"Init audiovideo buffer, container:\" + audiovideo.container + \", codecs[level/parsed]=[\" + currentLevel.codecs + \"/\" + audiovideo.codec + \"]\");\n      }\n      this.hls.trigger(Events.BUFFER_CODECS, tracks);\n      // loop through tracks that are going to be provided to bufferController\n      Object.keys(tracks).forEach(function (trackName) {\n        var track = tracks[trackName];\n        var initSegment = track.initSegment;\n        if (initSegment != null && initSegment.byteLength) {\n          _this3.hls.trigger(Events.BUFFER_APPENDING, {\n            type: trackName,\n            data: initSegment,\n            frag: frag,\n            part: null,\n            chunkMeta: chunkMeta,\n            parent: frag.type\n          });\n        }\n      });\n      // trigger handler right now\n      this.tickImmediate();\n    };\n    _proto.getMainFwdBufferInfo = function getMainFwdBufferInfo() {\n      return this.getFwdBufferInfo(this.mediaBuffer ? this.mediaBuffer : this.media, PlaylistLevelType.MAIN);\n    };\n    _proto.backtrack = function backtrack(frag) {\n      this.couldBacktrack = true;\n      // Causes findFragments to backtrack through fragments to find the keyframe\n      this.backtrackFragment = frag;\n      this.resetTransmuxer();\n      this.flushBufferGap(frag);\n      this.fragmentTracker.removeFragment(frag);\n      this.fragPrevious = null;\n      this.nextLoadPosition = frag.start;\n      this.state = State.IDLE;\n    };\n    _proto.checkFragmentChanged = function checkFragmentChanged() {\n      var video = this.media;\n      var fragPlayingCurrent = null;\n      if (video && video.readyState > 1 && video.seeking === false) {\n        var currentTime = video.currentTime;\n        /* if video element is in seeked state, currentTime can only increase.\n          (assuming that playback rate is positive ...)\n          As sometimes currentTime jumps back to zero after a\n          media decode error, check this, to avoid seeking back to\n          wrong position after a media decode error\n        */\n\n        if (BufferHelper.isBuffered(video, currentTime)) {\n          fragPlayingCurrent = this.getAppendedFrag(currentTime);\n        } else if (BufferHelper.isBuffered(video, currentTime + 0.1)) {\n          /* ensure that FRAG_CHANGED event is triggered at startup,\n            when first video frame is displayed and playback is paused.\n            add a tolerance of 100ms, in case current position is not buffered,\n            check if current pos+100ms is buffered and use that buffer range\n            for FRAG_CHANGED event reporting */\n          fragPlayingCurrent = this.getAppendedFrag(currentTime + 0.1);\n        }\n        if (fragPlayingCurrent) {\n          this.backtrackFragment = null;\n          var fragPlaying = this.fragPlaying;\n          var fragCurrentLevel = fragPlayingCurrent.level;\n          if (!fragPlaying || fragPlayingCurrent.sn !== fragPlaying.sn || fragPlaying.level !== fragCurrentLevel) {\n            this.fragPlaying = fragPlayingCurrent;\n            this.hls.trigger(Events.FRAG_CHANGED, {\n              frag: fragPlayingCurrent\n            });\n            if (!fragPlaying || fragPlaying.level !== fragCurrentLevel) {\n              this.hls.trigger(Events.LEVEL_SWITCHED, {\n                level: fragCurrentLevel\n              });\n            }\n          }\n        }\n      }\n    };\n    _createClass(StreamController, [{\n      key: \"nextLevel\",\n      get: function get() {\n        var frag = this.nextBufferedFrag;\n        if (frag) {\n          return frag.level;\n        }\n        return -1;\n      }\n    }, {\n      key: \"currentFrag\",\n      get: function get() {\n        var media = this.media;\n        if (media) {\n          return this.fragPlaying || this.getAppendedFrag(media.currentTime);\n        }\n        return null;\n      }\n    }, {\n      key: \"currentProgramDateTime\",\n      get: function get() {\n        var media = this.media;\n        if (media) {\n          var currentTime = media.currentTime;\n          var frag = this.currentFrag;\n          if (frag && isFiniteNumber(currentTime) && isFiniteNumber(frag.programDateTime)) {\n            var epocMs = frag.programDateTime + (currentTime - frag.start) * 1000;\n            return new Date(epocMs);\n          }\n        }\n        return null;\n      }\n    }, {\n      key: \"currentLevel\",\n      get: function get() {\n        var frag = this.currentFrag;\n        if (frag) {\n          return frag.level;\n        }\n        return -1;\n      }\n    }, {\n      key: \"nextBufferedFrag\",\n      get: function get() {\n        var frag = this.currentFrag;\n        if (frag) {\n          return this.followingBufferedFrag(frag);\n        }\n        return null;\n      }\n    }, {\n      key: \"forceStartLoad\",\n      get: function get() {\n        return this._forceStartLoad;\n      }\n    }]);\n    return StreamController;\n  }(BaseStreamController);\n\n  /**\n   * The `Hls` class is the core of the HLS.js library used to instantiate player instances.\n   * @public\n   */\n  var Hls = /*#__PURE__*/function () {\n    /**\n     * Check if the required MediaSource Extensions are available.\n     */\n    Hls.isMSESupported = function isMSESupported$1() {\n      return isMSESupported();\n    }\n\n    /**\n     * Check if MediaSource Extensions are available and isTypeSupported checks pass for any baseline codecs.\n     */;\n    Hls.isSupported = function isSupported$1() {\n      return isSupported();\n    }\n\n    /**\n     * Get the MediaSource global used for MSE playback (ManagedMediaSource, MediaSource, or WebKitMediaSource).\n     */;\n    Hls.getMediaSource = function getMediaSource$1() {\n      return getMediaSource();\n    };\n    /**\n     * Creates an instance of an HLS client that can attach to exactly one `HTMLMediaElement`.\n     * @param userConfig - Configuration options applied over `Hls.DefaultConfig`\n     */\n    function Hls(userConfig) {\n      if (userConfig === void 0) {\n        userConfig = {};\n      }\n      /**\n       * The runtime configuration used by the player. At instantiation this is combination of `hls.userConfig` merged over `Hls.DefaultConfig`.\n       */\n      this.config = void 0;\n      /**\n       * The configuration object provided on player instantiation.\n       */\n      this.userConfig = void 0;\n      this.coreComponents = void 0;\n      this.networkControllers = void 0;\n      this.started = false;\n      this._emitter = new EventEmitter();\n      this._autoLevelCapping = -1;\n      this._maxHdcpLevel = null;\n      this.abrController = void 0;\n      this.bufferController = void 0;\n      this.capLevelController = void 0;\n      this.latencyController = void 0;\n      this.levelController = void 0;\n      this.streamController = void 0;\n      this.audioTrackController = void 0;\n      this.subtitleTrackController = void 0;\n      this.emeController = void 0;\n      this.cmcdController = void 0;\n      this._media = null;\n      this.url = null;\n      this.triggeringException = void 0;\n      enableLogs(userConfig.debug || false, 'Hls instance');\n      var config = this.config = mergeConfig(Hls.DefaultConfig, userConfig);\n      this.userConfig = userConfig;\n      if (config.progressive) {\n        enableStreamingMode(config);\n      }\n\n      // core controllers and network loaders\n      var ConfigAbrController = config.abrController,\n        ConfigBufferController = config.bufferController,\n        ConfigCapLevelController = config.capLevelController,\n        ConfigErrorController = config.errorController,\n        ConfigFpsController = config.fpsController;\n      var errorController = new ConfigErrorController(this);\n      var abrController = this.abrController = new ConfigAbrController(this);\n      var bufferController = this.bufferController = new ConfigBufferController(this);\n      var capLevelController = this.capLevelController = new ConfigCapLevelController(this);\n      var fpsController = new ConfigFpsController(this);\n      var playListLoader = new PlaylistLoader(this);\n      var id3TrackController = new ID3TrackController(this);\n      var ConfigContentSteeringController = config.contentSteeringController;\n      // ConentSteeringController is defined before LevelController to receive Multivariant Playlist events first\n      var contentSteering = ConfigContentSteeringController ? new ConfigContentSteeringController(this) : null;\n      var levelController = this.levelController = new LevelController(this, contentSteering);\n      // FragmentTracker must be defined before StreamController because the order of event handling is important\n      var fragmentTracker = new FragmentTracker(this);\n      var keyLoader = new KeyLoader(this.config);\n      var streamController = this.streamController = new StreamController(this, fragmentTracker, keyLoader);\n\n      // Cap level controller uses streamController to flush the buffer\n      capLevelController.setStreamController(streamController);\n      // fpsController uses streamController to switch when frames are being dropped\n      fpsController.setStreamController(streamController);\n      var networkControllers = [playListLoader, levelController, streamController];\n      if (contentSteering) {\n        networkControllers.splice(1, 0, contentSteering);\n      }\n      this.networkControllers = networkControllers;\n      var coreComponents = [abrController, bufferController, capLevelController, fpsController, id3TrackController, fragmentTracker];\n      this.audioTrackController = this.createController(config.audioTrackController, networkControllers);\n      var AudioStreamControllerClass = config.audioStreamController;\n      if (AudioStreamControllerClass) {\n        networkControllers.push(new AudioStreamControllerClass(this, fragmentTracker, keyLoader));\n      }\n      // subtitleTrackController must be defined before subtitleStreamController because the order of event handling is important\n      this.subtitleTrackController = this.createController(config.subtitleTrackController, networkControllers);\n      var SubtitleStreamControllerClass = config.subtitleStreamController;\n      if (SubtitleStreamControllerClass) {\n        networkControllers.push(new SubtitleStreamControllerClass(this, fragmentTracker, keyLoader));\n      }\n      this.createController(config.timelineController, coreComponents);\n      keyLoader.emeController = this.emeController = this.createController(config.emeController, coreComponents);\n      this.cmcdController = this.createController(config.cmcdController, coreComponents);\n      this.latencyController = this.createController(LatencyController, coreComponents);\n      this.coreComponents = coreComponents;\n\n      // Error controller handles errors before and after all other controllers\n      // This listener will be invoked after all other controllers error listeners\n      networkControllers.push(errorController);\n      var onErrorOut = errorController.onErrorOut;\n      if (typeof onErrorOut === 'function') {\n        this.on(Events.ERROR, onErrorOut, errorController);\n      }\n    }\n    var _proto = Hls.prototype;\n    _proto.createController = function createController(ControllerClass, components) {\n      if (ControllerClass) {\n        var controllerInstance = new ControllerClass(this);\n        if (components) {\n          components.push(controllerInstance);\n        }\n        return controllerInstance;\n      }\n      return null;\n    }\n\n    // Delegate the EventEmitter through the public API of Hls.js\n    ;\n    _proto.on = function on(event, listener, context) {\n      if (context === void 0) {\n        context = this;\n      }\n      this._emitter.on(event, listener, context);\n    };\n    _proto.once = function once(event, listener, context) {\n      if (context === void 0) {\n        context = this;\n      }\n      this._emitter.once(event, listener, context);\n    };\n    _proto.removeAllListeners = function removeAllListeners(event) {\n      this._emitter.removeAllListeners(event);\n    };\n    _proto.off = function off(event, listener, context, once) {\n      if (context === void 0) {\n        context = this;\n      }\n      this._emitter.off(event, listener, context, once);\n    };\n    _proto.listeners = function listeners(event) {\n      return this._emitter.listeners(event);\n    };\n    _proto.emit = function emit(event, name, eventObject) {\n      return this._emitter.emit(event, name, eventObject);\n    };\n    _proto.trigger = function trigger(event, eventObject) {\n      if (this.config.debug) {\n        return this.emit(event, event, eventObject);\n      } else {\n        try {\n          return this.emit(event, event, eventObject);\n        } catch (error) {\n          logger.error('An internal error happened while handling event ' + event + '. Error message: \"' + error.message + '\". Here is a stacktrace:', error);\n          // Prevent recursion in error event handlers that throw #5497\n          if (!this.triggeringException) {\n            this.triggeringException = true;\n            var fatal = event === Events.ERROR;\n            this.trigger(Events.ERROR, {\n              type: ErrorTypes.OTHER_ERROR,\n              details: ErrorDetails.INTERNAL_EXCEPTION,\n              fatal: fatal,\n              event: event,\n              error: error\n            });\n            this.triggeringException = false;\n          }\n        }\n      }\n      return false;\n    };\n    _proto.listenerCount = function listenerCount(event) {\n      return this._emitter.listenerCount(event);\n    }\n\n    /**\n     * Dispose of the instance\n     */;\n    _proto.destroy = function destroy() {\n      logger.log('destroy');\n      this.trigger(Events.DESTROYING, undefined);\n      this.detachMedia();\n      this.removeAllListeners();\n      this._autoLevelCapping = -1;\n      this.url = null;\n      this.networkControllers.forEach(function (component) {\n        return component.destroy();\n      });\n      this.networkControllers.length = 0;\n      this.coreComponents.forEach(function (component) {\n        return component.destroy();\n      });\n      this.coreComponents.length = 0;\n      // Remove any references that could be held in config options or callbacks\n      var config = this.config;\n      config.xhrSetup = config.fetchSetup = undefined;\n      // @ts-ignore\n      this.userConfig = null;\n    }\n\n    /**\n     * Attaches Hls.js to a media element\n     */;\n    _proto.attachMedia = function attachMedia(media) {\n      logger.log('attachMedia');\n      this._media = media;\n      this.trigger(Events.MEDIA_ATTACHING, {\n        media: media\n      });\n    }\n\n    /**\n     * Detach Hls.js from the media\n     */;\n    _proto.detachMedia = function detachMedia() {\n      logger.log('detachMedia');\n      this.trigger(Events.MEDIA_DETACHING, undefined);\n      this._media = null;\n    }\n\n    /**\n     * Set the source URL. Can be relative or absolute.\n     */;\n    _proto.loadSource = function loadSource(url) {\n      this.stopLoad();\n      var media = this.media;\n      var loadedSource = this.url;\n      var loadingSource = this.url = urlToolkitExports.buildAbsoluteURL(self.location.href, url, {\n        alwaysNormalize: true\n      });\n      this._autoLevelCapping = -1;\n      this._maxHdcpLevel = null;\n      logger.log(\"loadSource:\" + loadingSource);\n      if (media && loadedSource && (loadedSource !== loadingSource || this.bufferController.hasSourceTypes())) {\n        this.detachMedia();\n        this.attachMedia(media);\n      }\n      // when attaching to a source URL, trigger a playlist load\n      this.trigger(Events.MANIFEST_LOADING, {\n        url: url\n      });\n    }\n\n    /**\n     * Start loading data from the stream source.\n     * Depending on default config, client starts loading automatically when a source is set.\n     *\n     * @param startPosition - Set the start position to stream from.\n     * Defaults to -1 (None: starts from earliest point)\n     */;\n    _proto.startLoad = function startLoad(startPosition) {\n      if (startPosition === void 0) {\n        startPosition = -1;\n      }\n      logger.log(\"startLoad(\" + startPosition + \")\");\n      this.started = true;\n      this.networkControllers.forEach(function (controller) {\n        controller.startLoad(startPosition);\n      });\n    }\n\n    /**\n     * Stop loading of any stream data.\n     */;\n    _proto.stopLoad = function stopLoad() {\n      logger.log('stopLoad');\n      this.started = false;\n      this.networkControllers.forEach(function (controller) {\n        controller.stopLoad();\n      });\n    }\n\n    /**\n     * Resumes stream controller segment loading if previously started.\n     */;\n    _proto.resumeBuffering = function resumeBuffering() {\n      if (this.started) {\n        this.networkControllers.forEach(function (controller) {\n          if ('fragmentLoader' in controller) {\n            controller.startLoad(-1);\n          }\n        });\n      }\n    }\n\n    /**\n     * Stops stream controller segment loading without changing 'started' state like stopLoad().\n     * This allows for media buffering to be paused without interupting playlist loading.\n     */;\n    _proto.pauseBuffering = function pauseBuffering() {\n      this.networkControllers.forEach(function (controller) {\n        if ('fragmentLoader' in controller) {\n          controller.stopLoad();\n        }\n      });\n    }\n\n    /**\n     * Swap through possible audio codecs in the stream (for example to switch from stereo to 5.1)\n     */;\n    _proto.swapAudioCodec = function swapAudioCodec() {\n      logger.log('swapAudioCodec');\n      this.streamController.swapAudioCodec();\n    }\n\n    /**\n     * When the media-element fails, this allows to detach and then re-attach it\n     * as one call (convenience method).\n     *\n     * Automatic recovery of media-errors by this process is configurable.\n     */;\n    _proto.recoverMediaError = function recoverMediaError() {\n      logger.log('recoverMediaError');\n      var media = this._media;\n      this.detachMedia();\n      if (media) {\n        this.attachMedia(media);\n      }\n    };\n    _proto.removeLevel = function removeLevel(levelIndex) {\n      this.levelController.removeLevel(levelIndex);\n    }\n\n    /**\n     * @returns an array of levels (variants) sorted by HDCP-LEVEL, RESOLUTION (height), FRAME-RATE, CODECS, VIDEO-RANGE, and BANDWIDTH\n     */;\n    /**\n     * Find and select the best matching audio track, making a level switch when a Group change is necessary.\n     * Updates `hls.config.audioPreference`. Returns the selected track, or null when no matching track is found.\n     */\n    _proto.setAudioOption = function setAudioOption(audioOption) {\n      var _this$audioTrackContr;\n      return (_this$audioTrackContr = this.audioTrackController) == null ? void 0 : _this$audioTrackContr.setAudioOption(audioOption);\n    }\n    /**\n     * Find and select the best matching subtitle track, making a level switch when a Group change is necessary.\n     * Updates `hls.config.subtitlePreference`. Returns the selected track, or null when no matching track is found.\n     */;\n    _proto.setSubtitleOption = function setSubtitleOption(subtitleOption) {\n      var _this$subtitleTrackCo;\n      (_this$subtitleTrackCo = this.subtitleTrackController) == null ? void 0 : _this$subtitleTrackCo.setSubtitleOption(subtitleOption);\n      return null;\n    }\n\n    /**\n     * Get the complete list of audio tracks across all media groups\n     */;\n    _createClass(Hls, [{\n      key: \"levels\",\n      get: function get() {\n        var levels = this.levelController.levels;\n        return levels ? levels : [];\n      }\n\n      /**\n       * Index of quality level (variant) currently played\n       */\n    }, {\n      key: \"currentLevel\",\n      get: function get() {\n        return this.streamController.currentLevel;\n      }\n\n      /**\n       * Set quality level index immediately. This will flush the current buffer to replace the quality asap. That means playback will interrupt at least shortly to re-buffer and re-sync eventually. Set to -1 for automatic level selection.\n       */,\n      set: function set(newLevel) {\n        logger.log(\"set currentLevel:\" + newLevel);\n        this.levelController.manualLevel = newLevel;\n        this.streamController.immediateLevelSwitch();\n      }\n\n      /**\n       * Index of next quality level loaded as scheduled by stream controller.\n       */\n    }, {\n      key: \"nextLevel\",\n      get: function get() {\n        return this.streamController.nextLevel;\n      }\n\n      /**\n       * Set quality level index for next loaded data.\n       * This will switch the video quality asap, without interrupting playback.\n       * May abort current loading of data, and flush parts of buffer (outside currently played fragment region).\n       * @param newLevel - Pass -1 for automatic level selection\n       */,\n      set: function set(newLevel) {\n        logger.log(\"set nextLevel:\" + newLevel);\n        this.levelController.manualLevel = newLevel;\n        this.streamController.nextLevelSwitch();\n      }\n\n      /**\n       * Return the quality level of the currently or last (of none is loaded currently) segment\n       */\n    }, {\n      key: \"loadLevel\",\n      get: function get() {\n        return this.levelController.level;\n      }\n\n      /**\n       * Set quality level index for next loaded data in a conservative way.\n       * This will switch the quality without flushing, but interrupt current loading.\n       * Thus the moment when the quality switch will appear in effect will only be after the already existing buffer.\n       * @param newLevel - Pass -1 for automatic level selection\n       */,\n      set: function set(newLevel) {\n        logger.log(\"set loadLevel:\" + newLevel);\n        this.levelController.manualLevel = newLevel;\n      }\n\n      /**\n       * get next quality level loaded\n       */\n    }, {\n      key: \"nextLoadLevel\",\n      get: function get() {\n        return this.levelController.nextLoadLevel;\n      }\n\n      /**\n       * Set quality level of next loaded segment in a fully \"non-destructive\" way.\n       * Same as `loadLevel` but will wait for next switch (until current loading is done).\n       */,\n      set: function set(level) {\n        this.levelController.nextLoadLevel = level;\n      }\n\n      /**\n       * Return \"first level\": like a default level, if not set,\n       * falls back to index of first level referenced in manifest\n       */\n    }, {\n      key: \"firstLevel\",\n      get: function get() {\n        return Math.max(this.levelController.firstLevel, this.minAutoLevel);\n      }\n\n      /**\n       * Sets \"first-level\", see getter.\n       */,\n      set: function set(newLevel) {\n        logger.log(\"set firstLevel:\" + newLevel);\n        this.levelController.firstLevel = newLevel;\n      }\n\n      /**\n       * Return the desired start level for the first fragment that will be loaded.\n       * The default value of -1 indicates automatic start level selection.\n       * Setting hls.nextAutoLevel without setting a startLevel will result in\n       * the nextAutoLevel value being used for one fragment load.\n       */\n    }, {\n      key: \"startLevel\",\n      get: function get() {\n        var startLevel = this.levelController.startLevel;\n        if (startLevel === -1 && this.abrController.forcedAutoLevel > -1) {\n          return this.abrController.forcedAutoLevel;\n        }\n        return startLevel;\n      }\n\n      /**\n       * set  start level (level of first fragment that will be played back)\n       * if not overrided by user, first level appearing in manifest will be used as start level\n       * if -1 : automatic start level selection, playback will start from level matching download bandwidth\n       * (determined from download of first segment)\n       */,\n      set: function set(newLevel) {\n        logger.log(\"set startLevel:\" + newLevel);\n        // if not in automatic start level detection, ensure startLevel is greater than minAutoLevel\n        if (newLevel !== -1) {\n          newLevel = Math.max(newLevel, this.minAutoLevel);\n        }\n        this.levelController.startLevel = newLevel;\n      }\n\n      /**\n       * Whether level capping is enabled.\n       * Default value is set via `config.capLevelToPlayerSize`.\n       */\n    }, {\n      key: \"capLevelToPlayerSize\",\n      get: function get() {\n        return this.config.capLevelToPlayerSize;\n      }\n\n      /**\n       * Enables or disables level capping. If disabled after previously enabled, `nextLevelSwitch` will be immediately called.\n       */,\n      set: function set(shouldStartCapping) {\n        var newCapLevelToPlayerSize = !!shouldStartCapping;\n        if (newCapLevelToPlayerSize !== this.config.capLevelToPlayerSize) {\n          if (newCapLevelToPlayerSize) {\n            this.capLevelController.startCapping(); // If capping occurs, nextLevelSwitch will happen based on size.\n          } else {\n            this.capLevelController.stopCapping();\n            this.autoLevelCapping = -1;\n            this.streamController.nextLevelSwitch(); // Now we're uncapped, get the next level asap.\n          }\n          this.config.capLevelToPlayerSize = newCapLevelToPlayerSize;\n        }\n      }\n\n      /**\n       * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)\n       */\n    }, {\n      key: \"autoLevelCapping\",\n      get: function get() {\n        return this._autoLevelCapping;\n      }\n\n      /**\n       * Returns the current bandwidth estimate in bits per second, when available. Otherwise, `NaN` is returned.\n       */,\n      set:\n      /**\n       * Capping/max level value that should be used by automatic level selection algorithm (`ABRController`)\n       */\n      function set(newLevel) {\n        if (this._autoLevelCapping !== newLevel) {\n          logger.log(\"set autoLevelCapping:\" + newLevel);\n          this._autoLevelCapping = newLevel;\n          this.levelController.checkMaxAutoUpdated();\n        }\n      }\n    }, {\n      key: \"bandwidthEstimate\",\n      get: function get() {\n        var bwEstimator = this.abrController.bwEstimator;\n        if (!bwEstimator) {\n          return NaN;\n        }\n        return bwEstimator.getEstimate();\n      },\n      set: function set(abrEwmaDefaultEstimate) {\n        this.abrController.resetEstimator(abrEwmaDefaultEstimate);\n      }\n\n      /**\n       * get time to first byte estimate\n       * @type {number}\n       */\n    }, {\n      key: \"ttfbEstimate\",\n      get: function get() {\n        var bwEstimator = this.abrController.bwEstimator;\n        if (!bwEstimator) {\n          return NaN;\n        }\n        return bwEstimator.getEstimateTTFB();\n      }\n    }, {\n      key: \"maxHdcpLevel\",\n      get: function get() {\n        return this._maxHdcpLevel;\n      },\n      set: function set(value) {\n        if (isHdcpLevel(value) && this._maxHdcpLevel !== value) {\n          this._maxHdcpLevel = value;\n          this.levelController.checkMaxAutoUpdated();\n        }\n      }\n\n      /**\n       * True when automatic level selection enabled\n       */\n    }, {\n      key: \"autoLevelEnabled\",\n      get: function get() {\n        return this.levelController.manualLevel === -1;\n      }\n\n      /**\n       * Level set manually (if any)\n       */\n    }, {\n      key: \"manualLevel\",\n      get: function get() {\n        return this.levelController.manualLevel;\n      }\n\n      /**\n       * min level selectable in auto mode according to config.minAutoBitrate\n       */\n    }, {\n      key: \"minAutoLevel\",\n      get: function get() {\n        var levels = this.levels,\n          minAutoBitrate = this.config.minAutoBitrate;\n        if (!levels) return 0;\n        var len = levels.length;\n        for (var i = 0; i < len; i++) {\n          if (levels[i].maxBitrate >= minAutoBitrate) {\n            return i;\n          }\n        }\n        return 0;\n      }\n\n      /**\n       * max level selectable in auto mode according to autoLevelCapping\n       */\n    }, {\n      key: \"maxAutoLevel\",\n      get: function get() {\n        var levels = this.levels,\n          autoLevelCapping = this.autoLevelCapping,\n          maxHdcpLevel = this.maxHdcpLevel;\n        var maxAutoLevel;\n        if (autoLevelCapping === -1 && levels != null && levels.length) {\n          maxAutoLevel = levels.length - 1;\n        } else {\n          maxAutoLevel = autoLevelCapping;\n        }\n        if (maxHdcpLevel) {\n          for (var i = maxAutoLevel; i--;) {\n            var hdcpLevel = levels[i].attrs['HDCP-LEVEL'];\n            if (hdcpLevel && hdcpLevel <= maxHdcpLevel) {\n              return i;\n            }\n          }\n        }\n        return maxAutoLevel;\n      }\n    }, {\n      key: \"firstAutoLevel\",\n      get: function get() {\n        return this.abrController.firstAutoLevel;\n      }\n\n      /**\n       * next automatically selected quality level\n       */\n    }, {\n      key: \"nextAutoLevel\",\n      get: function get() {\n        return this.abrController.nextAutoLevel;\n      }\n\n      /**\n       * this setter is used to force next auto level.\n       * this is useful to force a switch down in auto mode:\n       * in case of load error on level N, hls.js can set nextAutoLevel to N-1 for example)\n       * forced value is valid for one fragment. upon successful frag loading at forced level,\n       * this value will be resetted to -1 by ABR controller.\n       */,\n      set: function set(nextLevel) {\n        this.abrController.nextAutoLevel = nextLevel;\n      }\n\n      /**\n       * get the datetime value relative to media.currentTime for the active level Program Date Time if present\n       */\n    }, {\n      key: \"playingDate\",\n      get: function get() {\n        return this.streamController.currentProgramDateTime;\n      }\n    }, {\n      key: \"mainForwardBufferInfo\",\n      get: function get() {\n        return this.streamController.getMainFwdBufferInfo();\n      }\n    }, {\n      key: \"allAudioTracks\",\n      get: function get() {\n        var audioTrackController = this.audioTrackController;\n        return audioTrackController ? audioTrackController.allAudioTracks : [];\n      }\n\n      /**\n       * Get the list of selectable audio tracks\n       */\n    }, {\n      key: \"audioTracks\",\n      get: function get() {\n        var audioTrackController = this.audioTrackController;\n        return audioTrackController ? audioTrackController.audioTracks : [];\n      }\n\n      /**\n       * index of the selected audio track (index in audio track lists)\n       */\n    }, {\n      key: \"audioTrack\",\n      get: function get() {\n        var audioTrackController = this.audioTrackController;\n        return audioTrackController ? audioTrackController.audioTrack : -1;\n      }\n\n      /**\n       * selects an audio track, based on its index in audio track lists\n       */,\n      set: function set(audioTrackId) {\n        var audioTrackController = this.audioTrackController;\n        if (audioTrackController) {\n          audioTrackController.audioTrack = audioTrackId;\n        }\n      }\n\n      /**\n       * get the complete list of subtitle tracks across all media groups\n       */\n    }, {\n      key: \"allSubtitleTracks\",\n      get: function get() {\n        var subtitleTrackController = this.subtitleTrackController;\n        return subtitleTrackController ? subtitleTrackController.allSubtitleTracks : [];\n      }\n\n      /**\n       * get alternate subtitle tracks list from playlist\n       */\n    }, {\n      key: \"subtitleTracks\",\n      get: function get() {\n        var subtitleTrackController = this.subtitleTrackController;\n        return subtitleTrackController ? subtitleTrackController.subtitleTracks : [];\n      }\n\n      /**\n       * index of the selected subtitle track (index in subtitle track lists)\n       */\n    }, {\n      key: \"subtitleTrack\",\n      get: function get() {\n        var subtitleTrackController = this.subtitleTrackController;\n        return subtitleTrackController ? subtitleTrackController.subtitleTrack : -1;\n      },\n      set:\n      /**\n       * select an subtitle track, based on its index in subtitle track lists\n       */\n      function set(subtitleTrackId) {\n        var subtitleTrackController = this.subtitleTrackController;\n        if (subtitleTrackController) {\n          subtitleTrackController.subtitleTrack = subtitleTrackId;\n        }\n      }\n\n      /**\n       * Whether subtitle display is enabled or not\n       */\n    }, {\n      key: \"media\",\n      get: function get() {\n        return this._media;\n      }\n    }, {\n      key: \"subtitleDisplay\",\n      get: function get() {\n        var subtitleTrackController = this.subtitleTrackController;\n        return subtitleTrackController ? subtitleTrackController.subtitleDisplay : false;\n      }\n\n      /**\n       * Enable/disable subtitle display rendering\n       */,\n      set: function set(value) {\n        var subtitleTrackController = this.subtitleTrackController;\n        if (subtitleTrackController) {\n          subtitleTrackController.subtitleDisplay = value;\n        }\n      }\n\n      /**\n       * get mode for Low-Latency HLS loading\n       */\n    }, {\n      key: \"lowLatencyMode\",\n      get: function get() {\n        return this.config.lowLatencyMode;\n      }\n\n      /**\n       * Enable/disable Low-Latency HLS part playlist and segment loading, and start live streams at playlist PART-HOLD-BACK rather than HOLD-BACK.\n       */,\n      set: function set(mode) {\n        this.config.lowLatencyMode = mode;\n      }\n\n      /**\n       * Position (in seconds) of live sync point (ie edge of live position minus safety delay defined by ```hls.config.liveSyncDuration```)\n       * @returns null prior to loading live Playlist\n       */\n    }, {\n      key: \"liveSyncPosition\",\n      get: function get() {\n        return this.latencyController.liveSyncPosition;\n      }\n\n      /**\n       * Estimated position (in seconds) of live edge (ie edge of live playlist plus time sync playlist advanced)\n       * @returns 0 before first playlist is loaded\n       */\n    }, {\n      key: \"latency\",\n      get: function get() {\n        return this.latencyController.latency;\n      }\n\n      /**\n       * maximum distance from the edge before the player seeks forward to ```hls.liveSyncPosition```\n       * configured using ```liveMaxLatencyDurationCount``` (multiple of target duration) or ```liveMaxLatencyDuration```\n       * @returns 0 before first playlist is loaded\n       */\n    }, {\n      key: \"maxLatency\",\n      get: function get() {\n        return this.latencyController.maxLatency;\n      }\n\n      /**\n       * target distance from the edge as calculated by the latency controller\n       */\n    }, {\n      key: \"targetLatency\",\n      get: function get() {\n        return this.latencyController.targetLatency;\n      }\n\n      /**\n       * the rate at which the edge of the current live playlist is advancing or 1 if there is none\n       */\n    }, {\n      key: \"drift\",\n      get: function get() {\n        return this.latencyController.drift;\n      }\n\n      /**\n       * set to true when startLoad is called before MANIFEST_PARSED event\n       */\n    }, {\n      key: \"forceStartLoad\",\n      get: function get() {\n        return this.streamController.forceStartLoad;\n      }\n    }], [{\n      key: \"version\",\n      get:\n      /**\n       * Get the video-dev/hls.js package version.\n       */\n      function get() {\n        return \"1.5.17\";\n      }\n    }, {\n      key: \"Events\",\n      get: function get() {\n        return Events;\n      }\n    }, {\n      key: \"ErrorTypes\",\n      get: function get() {\n        return ErrorTypes;\n      }\n    }, {\n      key: \"ErrorDetails\",\n      get: function get() {\n        return ErrorDetails;\n      }\n\n      /**\n       * Get the default configuration applied to new instances.\n       */\n    }, {\n      key: \"DefaultConfig\",\n      get: function get() {\n        if (!Hls.defaultConfig) {\n          return hlsDefaultConfig;\n        }\n        return Hls.defaultConfig;\n      }\n\n      /**\n       * Replace the default configuration applied to new instances.\n       */,\n      set: function set(defaultConfig) {\n        Hls.defaultConfig = defaultConfig;\n      }\n    }]);\n    return Hls;\n  }();\n  Hls.defaultConfig = void 0;\n\n  return Hls;\n\n}));\n})(false);\n//# sourceMappingURL=hls.js.map\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/hls.js@1.5.17/node_modules/hls.js/dist/hls.js?")},"./node_modules/.pnpm/media-typer@1.1.0/node_modules/media-typer/index.js":
/*!********************************************************************************!*\
  !*** ./node_modules/.pnpm/media-typer@1.1.0/node_modules/media-typer/index.js ***!
  \********************************************************************************/function(__unused_webpack_module,exports){"use strict";eval("/*!\n * media-typer\n * Copyright(c) 2014-2017 Douglas Christopher Wilson\n * MIT Licensed\n */\n\n\n\n/**\n * RegExp to match type in RFC 6838\n *\n * type-name = restricted-name\n * subtype-name = restricted-name\n * restricted-name = restricted-name-first *126restricted-name-chars\n * restricted-name-first  = ALPHA / DIGIT\n * restricted-name-chars  = ALPHA / DIGIT / \"!\" / \"#\" /\n *                          \"$\" / \"&\" / \"-\" / \"^\" / \"_\"\n * restricted-name-chars =/ \".\" ; Characters before first dot always\n *                              ; specify a facet name\n * restricted-name-chars =/ \"+\" ; Characters after last plus always\n *                              ; specify a structured syntax suffix\n * ALPHA =  %x41-5A / %x61-7A   ; A-Z / a-z\n * DIGIT =  %x30-39             ; 0-9\n */\nvar SUBTYPE_NAME_REGEXP = /^[A-Za-z0-9][A-Za-z0-9!#$&^_.-]{0,126}$/\nvar TYPE_NAME_REGEXP = /^[A-Za-z0-9][A-Za-z0-9!#$&^_-]{0,126}$/\nvar TYPE_REGEXP = /^ *([A-Za-z0-9][A-Za-z0-9!#$&^_-]{0,126})\\/([A-Za-z0-9][A-Za-z0-9!#$&^_.+-]{0,126}) *$/\n\n/**\n * Module exports.\n */\n\nexports.format = format\nexports.parse = parse\nexports.test = test\n\n/**\n * Format object to media type.\n *\n * @param {object} obj\n * @return {string}\n * @public\n */\n\nfunction format (obj) {\n  if (!obj || typeof obj !== 'object') {\n    throw new TypeError('argument obj is required')\n  }\n\n  var subtype = obj.subtype\n  var suffix = obj.suffix\n  var type = obj.type\n\n  if (!type || !TYPE_NAME_REGEXP.test(type)) {\n    throw new TypeError('invalid type')\n  }\n\n  if (!subtype || !SUBTYPE_NAME_REGEXP.test(subtype)) {\n    throw new TypeError('invalid subtype')\n  }\n\n  // format as type/subtype\n  var string = type + '/' + subtype\n\n  // append +suffix\n  if (suffix) {\n    if (!TYPE_NAME_REGEXP.test(suffix)) {\n      throw new TypeError('invalid suffix')\n    }\n\n    string += '+' + suffix\n  }\n\n  return string\n}\n\n/**\n * Test media type.\n *\n * @param {string} string\n * @return {object}\n * @public\n */\n\nfunction test (string) {\n  if (!string) {\n    throw new TypeError('argument string is required')\n  }\n\n  if (typeof string !== 'string') {\n    throw new TypeError('argument string is required to be a string')\n  }\n\n  return TYPE_REGEXP.test(string.toLowerCase())\n}\n\n/**\n * Parse media type to object.\n *\n * @param {string} string\n * @return {object}\n * @public\n */\n\nfunction parse (string) {\n  if (!string) {\n    throw new TypeError('argument string is required')\n  }\n\n  if (typeof string !== 'string') {\n    throw new TypeError('argument string is required to be a string')\n  }\n\n  var match = TYPE_REGEXP.exec(string.toLowerCase())\n\n  if (!match) {\n    throw new TypeError('invalid media type')\n  }\n\n  var type = match[1]\n  var subtype = match[2]\n  var suffix\n\n  // suffix after last +\n  var index = subtype.lastIndexOf('+')\n  if (index !== -1) {\n    suffix = subtype.substr(index + 1)\n    subtype = subtype.substr(0, index)\n  }\n\n  return new MediaType(type, subtype, suffix)\n}\n\n/**\n * Class for MediaType object.\n * @public\n */\n\nfunction MediaType (type, subtype, suffix) {\n  this.type = type\n  this.subtype = subtype\n  this.suffix = suffix\n}\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/media-typer@1.1.0/node_modules/media-typer/index.js?")},"./node_modules/.pnpm/ms@2.1.3/node_modules/ms/index.js":
/*!**************************************************************!*\
  !*** ./node_modules/.pnpm/ms@2.1.3/node_modules/ms/index.js ***!
  \**************************************************************/function(module){eval("/**\n * Helpers.\n */\n\nvar s = 1000;\nvar m = s * 60;\nvar h = m * 60;\nvar d = h * 24;\nvar w = d * 7;\nvar y = d * 365.25;\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} [options]\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function (val, options) {\n  options = options || {};\n  var type = typeof val;\n  if (type === 'string' && val.length > 0) {\n    return parse(val);\n  } else if (type === 'number' && isFinite(val)) {\n    return options.long ? fmtLong(val) : fmtShort(val);\n  }\n  throw new Error(\n    'val is not a non-empty string or a valid number. val=' +\n      JSON.stringify(val)\n  );\n};\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str);\n  if (str.length > 100) {\n    return;\n  }\n  var match = /^(-?(?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(\n    str\n  );\n  if (!match) {\n    return;\n  }\n  var n = parseFloat(match[1]);\n  var type = (match[2] || 'ms').toLowerCase();\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y;\n    case 'weeks':\n    case 'week':\n    case 'w':\n      return n * w;\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d;\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h;\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m;\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s;\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n;\n    default:\n      return undefined;\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return Math.round(ms / d) + 'd';\n  }\n  if (msAbs >= h) {\n    return Math.round(ms / h) + 'h';\n  }\n  if (msAbs >= m) {\n    return Math.round(ms / m) + 'm';\n  }\n  if (msAbs >= s) {\n    return Math.round(ms / s) + 's';\n  }\n  return ms + 'ms';\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return plural(ms, msAbs, d, 'day');\n  }\n  if (msAbs >= h) {\n    return plural(ms, msAbs, h, 'hour');\n  }\n  if (msAbs >= m) {\n    return plural(ms, msAbs, m, 'minute');\n  }\n  if (msAbs >= s) {\n    return plural(ms, msAbs, s, 'second');\n  }\n  return ms + ' ms';\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, msAbs, n, name) {\n  var isPlural = msAbs >= n * 1.5;\n  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');\n}\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/ms@2.1.3/node_modules/ms/index.js?")},"./node_modules/.pnpm/music-metadata-browser@2.5.11/node_modules/music-metadata-browser/lib/index.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata-browser@2.5.11/node_modules/music-metadata-browser/lib/index.js ***!
  \***********************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\r\nObject.defineProperty(exports, "__esModule", ({ value: true }));\r\nexports.fetchFromUrl = exports.parseBlob = exports.parseReadableStream = exports.parseNodeStream = exports.selectCover = exports.ratingToStars = exports.orderTags = exports.parseFromTokenizer = exports.parseBuffer = void 0;\r\nconst initDebug = __webpack_require__(/*! debug */ "./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js");\r\nconst mm = __webpack_require__(/*! music-metadata/lib/core */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/core.js");\r\nconst readable_web_to_node_stream_1 = __webpack_require__(/*! readable-web-to-node-stream */ "./node_modules/.pnpm/readable-web-to-node-stream@3.0.2/node_modules/readable-web-to-node-stream/lib/index.js");\r\nconst debug = initDebug(\'music-metadata-browser:main\');\r\nvar core_1 = __webpack_require__(/*! music-metadata/lib/core */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/core.js");\r\nObject.defineProperty(exports, "parseBuffer", ({ enumerable: true, get: function () { return core_1.parseBuffer; } }));\r\nObject.defineProperty(exports, "parseFromTokenizer", ({ enumerable: true, get: function () { return core_1.parseFromTokenizer; } }));\r\nObject.defineProperty(exports, "orderTags", ({ enumerable: true, get: function () { return core_1.orderTags; } }));\r\nObject.defineProperty(exports, "ratingToStars", ({ enumerable: true, get: function () { return core_1.ratingToStars; } }));\r\nObject.defineProperty(exports, "selectCover", ({ enumerable: true, get: function () { return core_1.selectCover; } }));\r\n/**\r\n * Parse audio Stream\r\n * @param stream - ReadableStream\r\n * @param contentType - MIME-Type\r\n * @param options - Parsing options\r\n * @returns Metadata\r\n */\r\nexports.parseNodeStream = mm.parseStream;\r\n/**\r\n * Parse Web API ReadableStream: https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream\r\n * @param stream - ReadableStream (web stream according WTWG Streams Standard)\r\n * @param fileInfo FileInfo object or MIME-Type\r\n * @param options - Parsing options\r\n * @returns Metadata\r\n */\r\nasync function parseReadableStream(stream, fileInfo, options) {\r\n    const ns = new readable_web_to_node_stream_1.ReadableWebToNodeStream(stream);\r\n    const res = await (0, exports.parseNodeStream)(ns, typeof fileInfo === \'string\' ? { mimeType: fileInfo } : fileInfo, options);\r\n    await ns.close();\r\n    return res;\r\n}\r\nexports.parseReadableStream = parseReadableStream;\r\n/**\r\n * Parse Web API File\r\n * @param blob - Blob to parse\r\n * @param options - Parsing options\r\n * @returns Metadata\r\n */\r\nasync function parseBlob(blob, options) {\r\n    const fileInfo = { mimeType: blob.type, size: blob.size };\r\n    if (blob instanceof File) {\r\n        fileInfo.path = blob.name;\r\n    }\r\n    const stream = (blob.stream ? blob.stream() : convertBlobToReadableStream(blob));\r\n    return parseReadableStream(stream, { mimeType: blob.type, size: blob.size }, options);\r\n}\r\nexports.parseBlob = parseBlob;\r\n/**\r\n * Convert Blob to ReadableStream\r\n * Fallback for Safari versions < 14.1\r\n * @param blob\r\n */\r\nfunction convertBlobToReadableStream(blob) {\r\n    const fileReader = new FileReader();\r\n    return new ReadableStream({\r\n        start(controller) {\r\n            // The following function handles each data chunk\r\n            fileReader.onloadend = event => {\r\n                let data = event.target.result;\r\n                if (data instanceof ArrayBuffer) {\r\n                    data = new Uint8Array(data);\r\n                }\r\n                controller.enqueue(data);\r\n                controller.close();\r\n            };\r\n            fileReader.onerror = error => {\r\n                controller.close();\r\n            };\r\n            fileReader.onabort = error => {\r\n                controller.close();\r\n            };\r\n            fileReader.readAsArrayBuffer(blob);\r\n        }\r\n    });\r\n}\r\n/**\r\n * Parse fetched file, using the Web Fetch API\r\n * @param audioTrackUrl - URL to download the audio track from\r\n * @param options - Parsing options\r\n * @returns Metadata\r\n */\r\nasync function fetchFromUrl(audioTrackUrl, options) {\r\n    const response = await fetch(audioTrackUrl);\r\n    const fileInfo = {\r\n        size: parseInt(response.headers.get(\'Content-Length\'), 10),\r\n        mimeType: response.headers.get(\'Content-Type\')\r\n    };\r\n    if (response.ok) {\r\n        if (response.body) {\r\n            const res = await parseReadableStream(response.body, fileInfo, options);\r\n            debug(\'Closing HTTP-readable-stream...\');\r\n            if (!response.body.locked) { // Prevent error in Firefox\r\n                await response.body.cancel();\r\n            }\r\n            debug(\'HTTP-readable-stream closed.\');\r\n            return res;\r\n        }\r\n        else {\r\n            // Fall back on Blob\r\n            return parseBlob(await response.blob(), options);\r\n        }\r\n    }\r\n    else {\r\n        throw new Error(`HTTP error status=${response.status}: ${response.statusText}`);\r\n    }\r\n}\r\nexports.fetchFromUrl = fetchFromUrl;\r\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata-browser@2.5.11/node_modules/music-metadata-browser/lib/index.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ParserFactory.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ParserFactory.js ***!
  \***************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ \"./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js\")[\"Buffer\"];\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ParserFactory = exports.parseHttpContentType = void 0;\nconst FileType = __webpack_require__(/*! file-type/core */ \"./node_modules/.pnpm/file-type@16.5.4/node_modules/file-type/core.js\");\nconst ContentType = __webpack_require__(/*! content-type */ \"./node_modules/.pnpm/content-type@1.0.5/node_modules/content-type/index.js\");\nconst MimeType = __webpack_require__(/*! media-typer */ \"./node_modules/.pnpm/media-typer@1.1.0/node_modules/media-typer/index.js\");\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst MetadataCollector_1 = __webpack_require__(/*! ./common/MetadataCollector */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/MetadataCollector.js\");\nconst AiffParser_1 = __webpack_require__(/*! ./aiff/AiffParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/aiff/AiffParser.js\");\nconst APEv2Parser_1 = __webpack_require__(/*! ./apev2/APEv2Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2Parser.js\");\nconst AsfParser_1 = __webpack_require__(/*! ./asf/AsfParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfParser.js\");\nconst FlacParser_1 = __webpack_require__(/*! ./flac/FlacParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/flac/FlacParser.js\");\nconst MP4Parser_1 = __webpack_require__(/*! ./mp4/MP4Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/MP4Parser.js\");\nconst MpegParser_1 = __webpack_require__(/*! ./mpeg/MpegParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/MpegParser.js\");\nconst musepack_1 = __webpack_require__(/*! ./musepack */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/index.js\");\nconst OggParser_1 = __webpack_require__(/*! ./ogg/OggParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/OggParser.js\");\nconst WaveParser_1 = __webpack_require__(/*! ./wav/WaveParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wav/WaveParser.js\");\nconst WavPackParser_1 = __webpack_require__(/*! ./wavpack/WavPackParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wavpack/WavPackParser.js\");\nconst DsfParser_1 = __webpack_require__(/*! ./dsf/DsfParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsf/DsfParser.js\");\nconst DsdiffParser_1 = __webpack_require__(/*! ./dsdiff/DsdiffParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsdiff/DsdiffParser.js\");\nconst MatroskaParser_1 = __webpack_require__(/*! ./matroska/MatroskaParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/MatroskaParser.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:factory');\nfunction parseHttpContentType(contentType) {\n    const type = ContentType.parse(contentType);\n    const mime = MimeType.parse(type.type);\n    return {\n        type: mime.type,\n        subtype: mime.subtype,\n        suffix: mime.suffix,\n        parameters: type.parameters\n    };\n}\nexports.parseHttpContentType = parseHttpContentType;\nasync function parse(tokenizer, parserId, opts = {}) {\n    // Parser found, execute parser\n    const parser = await ParserFactory.loadParser(parserId);\n    const metadata = new MetadataCollector_1.MetadataCollector(opts);\n    await parser.init(metadata, tokenizer, opts).parse();\n    return metadata.toCommonMetadata();\n}\nclass ParserFactory {\n    /**\n     * Parse metadata from tokenizer\n     * @param tokenizer - Tokenizer\n     * @param opts - Options\n     * @returns Native metadata\n     */\n    static async parseOnContentType(tokenizer, opts) {\n        const { mimeType, path, url } = await tokenizer.fileInfo;\n        // Resolve parser based on MIME-type or file extension\n        const parserId = ParserFactory.getParserIdForMimeType(mimeType) || ParserFactory.getParserIdForExtension(path) || ParserFactory.getParserIdForExtension(url);\n        if (!parserId) {\n            debug('No parser found for MIME-type / extension: ' + mimeType);\n        }\n        return this.parse(tokenizer, parserId, opts);\n    }\n    static async parse(tokenizer, parserId, opts) {\n        if (!parserId) {\n            // Parser could not be determined on MIME-type or extension\n            debug('Guess parser on content...');\n            const buf = Buffer.alloc(4100);\n            await tokenizer.peekBuffer(buf, { mayBeLess: true });\n            if (tokenizer.fileInfo.path) {\n                parserId = this.getParserIdForExtension(tokenizer.fileInfo.path);\n            }\n            if (!parserId) {\n                const guessedType = await FileType.fromBuffer(buf);\n                if (!guessedType) {\n                    throw new Error('Failed to determine audio format');\n                }\n                debug(`Guessed file type is mime=${guessedType.mime}, extension=${guessedType.ext}`);\n                parserId = ParserFactory.getParserIdForMimeType(guessedType.mime);\n                if (!parserId) {\n                    throw new Error('Guessed MIME-type not supported: ' + guessedType.mime);\n                }\n            }\n        }\n        // Parser found, execute parser\n        return parse(tokenizer, parserId, opts);\n    }\n    /**\n     * @param filePath - Path, filename or extension to audio file\n     * @return Parser sub-module name\n     */\n    static getParserIdForExtension(filePath) {\n        if (!filePath)\n            return;\n        const extension = this.getExtension(filePath).toLocaleLowerCase() || filePath;\n        switch (extension) {\n            case '.mp2':\n            case '.mp3':\n            case '.m2a':\n            case '.aac': // Assume it is ADTS-container\n                return 'mpeg';\n            case '.ape':\n                return 'apev2';\n            case '.mp4':\n            case '.m4a':\n            case '.m4b':\n            case '.m4pa':\n            case '.m4v':\n            case '.m4r':\n            case '.3gp':\n                return 'mp4';\n            case '.wma':\n            case '.wmv':\n            case '.asf':\n                return 'asf';\n            case '.flac':\n                return 'flac';\n            case '.ogg':\n            case '.ogv':\n            case '.oga':\n            case '.ogm':\n            case '.ogx':\n            case '.opus': // recommended filename extension for Ogg Opus\n            case '.spx': // recommended filename extension for Ogg Speex\n                return 'ogg';\n            case '.aif':\n            case '.aiff':\n            case '.aifc':\n                return 'aiff';\n            case '.wav':\n            case '.bwf': // Broadcast Wave Format\n                return 'riff';\n            case '.wv':\n            case '.wvp':\n                return 'wavpack';\n            case '.mpc':\n                return 'musepack';\n            case '.dsf':\n                return 'dsf';\n            case '.dff':\n                return 'dsdiff';\n            case '.mka':\n            case '.mkv':\n            case '.mk3d':\n            case '.mks':\n            case '.webm':\n                return 'matroska';\n        }\n    }\n    static async loadParser(moduleName) {\n        switch (moduleName) {\n            case 'aiff': return new AiffParser_1.AIFFParser();\n            case 'adts':\n            case 'mpeg':\n                return new MpegParser_1.MpegParser();\n            case 'apev2': return new APEv2Parser_1.APEv2Parser();\n            case 'asf': return new AsfParser_1.AsfParser();\n            case 'dsf': return new DsfParser_1.DsfParser();\n            case 'dsdiff': return new DsdiffParser_1.DsdiffParser();\n            case 'flac': return new FlacParser_1.FlacParser();\n            case 'mp4': return new MP4Parser_1.MP4Parser();\n            case 'musepack': return new musepack_1.default();\n            case 'ogg': return new OggParser_1.OggParser();\n            case 'riff': return new WaveParser_1.WaveParser();\n            case 'wavpack': return new WavPackParser_1.WavPackParser();\n            case 'matroska': return new MatroskaParser_1.MatroskaParser();\n            default:\n                throw new Error(`Unknown parser type: ${moduleName}`);\n        }\n    }\n    static getExtension(fname) {\n        const i = fname.lastIndexOf('.');\n        return i === -1 ? '' : fname.slice(i);\n    }\n    /**\n     * @param httpContentType - HTTP Content-Type, extension, path or filename\n     * @returns Parser sub-module name\n     */\n    static getParserIdForMimeType(httpContentType) {\n        let mime;\n        try {\n            mime = parseHttpContentType(httpContentType);\n        }\n        catch (err) {\n            debug(`Invalid HTTP Content-Type header value: ${httpContentType}`);\n            return;\n        }\n        const subType = mime.subtype.indexOf('x-') === 0 ? mime.subtype.substring(2) : mime.subtype;\n        switch (mime.type) {\n            case 'audio':\n                switch (subType) {\n                    case 'mp3': // Incorrect MIME-type, Chrome, in Web API File object\n                    case 'mpeg':\n                        return 'mpeg';\n                    case 'aac':\n                    case 'aacp':\n                        return 'adts';\n                    case 'flac':\n                        return 'flac';\n                    case 'ape':\n                    case 'monkeys-audio':\n                        return 'apev2';\n                    case 'mp4':\n                    case 'm4a':\n                        return 'mp4';\n                    case 'ogg': // RFC 7845\n                    case 'opus': // RFC 6716\n                    case 'speex': // RFC 5574\n                        return 'ogg';\n                    case 'ms-wma':\n                    case 'ms-wmv':\n                    case 'ms-asf':\n                        return 'asf';\n                    case 'aiff':\n                    case 'aif':\n                    case 'aifc':\n                        return 'aiff';\n                    case 'vnd.wave':\n                    case 'wav':\n                    case 'wave':\n                        return 'riff';\n                    case 'wavpack':\n                        return 'wavpack';\n                    case 'musepack':\n                        return 'musepack';\n                    case 'matroska':\n                    case 'webm':\n                        return 'matroska';\n                    case 'dsf':\n                        return 'dsf';\n                }\n                break;\n            case 'video':\n                switch (subType) {\n                    case 'ms-asf':\n                    case 'ms-wmv':\n                        return 'asf';\n                    case 'm4v':\n                    case 'mp4':\n                        return 'mp4';\n                    case 'ogg':\n                        return 'ogg';\n                    case 'matroska':\n                    case 'webm':\n                        return 'matroska';\n                }\n                break;\n            case 'application':\n                switch (subType) {\n                    case 'vnd.ms-asf':\n                        return 'asf';\n                    case 'ogg':\n                        return 'ogg';\n                }\n                break;\n        }\n    }\n}\nexports.ParserFactory = ParserFactory;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ParserFactory.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/aiff/AiffParser.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/aiff/AiffParser.js ***!
  \*****************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AIFFParser = void 0;\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst strtok3 = __webpack_require__(/*! strtok3/lib/core */ \"./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/core.js\");\nconst ID3v2Parser_1 = __webpack_require__(/*! ../id3v2/ID3v2Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Parser.js\");\nconst FourCC_1 = __webpack_require__(/*! ../common/FourCC */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js\");\nconst BasicParser_1 = __webpack_require__(/*! ../common/BasicParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js\");\nconst AiffToken = __webpack_require__(/*! ./AiffToken */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/aiff/AiffToken.js\");\nconst iff = __webpack_require__(/*! ../iff */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/iff/index.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:aiff');\nconst compressionTypes = {\n    NONE: 'not compressed\tPCM\tApple Computer',\n    sowt: 'PCM (byte swapped)',\n    fl32: '32-bit floating point IEEE 32-bit float',\n    fl64: '64-bit floating point IEEE 64-bit float\tApple Computer',\n    alaw: 'ALaw 2:1\t8-bit ITU-T G.711 A-law',\n    ulaw: 'Law 2:1\t8-bit ITU-T G.711 -law\tApple Computer',\n    ULAW: 'CCITT G.711 u-law 8-bit ITU-T G.711 -law',\n    ALAW: 'CCITT G.711 A-law 8-bit ITU-T G.711 A-law',\n    FL32: 'Float 32\tIEEE 32-bit float '\n};\n/**\n * AIFF - Audio Interchange File Format\n *\n * Ref:\n * - http://www-mmsp.ece.mcgill.ca/Documents/AudioFormats/AIFF/AIFF.html\n * - http://www-mmsp.ece.mcgill.ca/Documents/AudioFormats/AIFF/Docs/AIFF-1.3.pdf\n */\nclass AIFFParser extends BasicParser_1.BasicParser {\n    async parse() {\n        const header = await this.tokenizer.readToken(iff.Header);\n        if (header.chunkID !== 'FORM')\n            throw new Error('Invalid Chunk-ID, expected \\'FORM\\''); // Not AIFF format\n        const type = await this.tokenizer.readToken(FourCC_1.FourCcToken);\n        switch (type) {\n            case 'AIFF':\n                this.metadata.setFormat('container', type);\n                this.isCompressed = false;\n                break;\n            case 'AIFC':\n                this.metadata.setFormat('container', 'AIFF-C');\n                this.isCompressed = true;\n                break;\n            default:\n                throw Error('Unsupported AIFF type: ' + type);\n        }\n        this.metadata.setFormat('lossless', !this.isCompressed);\n        try {\n            while (!this.tokenizer.fileInfo.size || this.tokenizer.fileInfo.size - this.tokenizer.position >= iff.Header.len) {\n                debug('Reading AIFF chunk at offset=' + this.tokenizer.position);\n                const chunkHeader = await this.tokenizer.readToken(iff.Header);\n                const nextChunk = 2 * Math.round(chunkHeader.chunkSize / 2);\n                const bytesRead = await this.readData(chunkHeader);\n                await this.tokenizer.ignore(nextChunk - bytesRead);\n            }\n        }\n        catch (err) {\n            if (err instanceof strtok3.EndOfStreamError) {\n                debug(`End-of-stream`);\n            }\n            else {\n                throw err;\n            }\n        }\n    }\n    async readData(header) {\n        var _a;\n        switch (header.chunkID) {\n            case 'COMM': // The Common Chunk\n                const common = await this.tokenizer.readToken(new AiffToken.Common(header, this.isCompressed));\n                this.metadata.setFormat('bitsPerSample', common.sampleSize);\n                this.metadata.setFormat('sampleRate', common.sampleRate);\n                this.metadata.setFormat('numberOfChannels', common.numChannels);\n                this.metadata.setFormat('numberOfSamples', common.numSampleFrames);\n                this.metadata.setFormat('duration', common.numSampleFrames / common.sampleRate);\n                this.metadata.setFormat('codec', (_a = common.compressionName) !== null && _a !== void 0 ? _a : compressionTypes[common.compressionType]);\n                return header.chunkSize;\n            case 'ID3 ': // ID3-meta-data\n                const id3_data = await this.tokenizer.readToken(new Token.Uint8ArrayType(header.chunkSize));\n                const rst = strtok3.fromBuffer(id3_data);\n                await new ID3v2Parser_1.ID3v2Parser().parse(this.metadata, rst, this.options);\n                return header.chunkSize;\n            case 'SSND': // Sound Data Chunk\n                if (this.metadata.format.duration) {\n                    this.metadata.setFormat('bitrate', 8 * header.chunkSize / this.metadata.format.duration);\n                }\n                return 0;\n            case 'NAME': // Sample name chunk\n            case 'AUTH': // Author chunk\n            case '(c) ': // Copyright chunk\n            case 'ANNO': // Annotation chunk\n                return this.readTextChunk(header);\n            default:\n                debug(`Ignore chunk id=${header.chunkID}, size=${header.chunkSize}`);\n                return 0;\n        }\n    }\n    async readTextChunk(header) {\n        const value = await this.tokenizer.readToken(new Token.StringType(header.chunkSize, 'ascii'));\n        value.split('\\0').map(v => v.trim()).filter(v => v && v.length > 0).forEach(v => {\n            this.metadata.addTag('AIFF', header.chunkID, v.trim());\n        });\n        return header.chunkSize;\n    }\n}\nexports.AIFFParser = AIFFParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/aiff/AiffParser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/aiff/AiffTagMap.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/aiff/AiffTagMap.js ***!
  \*****************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AiffTagMapper = void 0;\nconst GenericTagMapper_1 = __webpack_require__(/*! ../common/GenericTagMapper */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/GenericTagMapper.js\");\n/**\n * ID3v1 tag mappings\n */\nconst tagMap = {\n    NAME: 'title',\n    AUTH: 'artist',\n    '(c) ': 'copyright',\n    ANNO: 'comment'\n};\nclass AiffTagMapper extends GenericTagMapper_1.CommonTagMapper {\n    constructor() {\n        super(['AIFF'], tagMap);\n    }\n}\nexports.AiffTagMapper = AiffTagMapper;\n//# sourceMappingURL=AiffTagMap.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/aiff/AiffTagMap.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/aiff/AiffToken.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/aiff/AiffToken.js ***!
  \****************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Common = void 0;\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst FourCC_1 = __webpack_require__(/*! ../common/FourCC */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js\");\nclass Common {\n    constructor(header, isAifc) {\n        this.isAifc = isAifc;\n        const minimumChunkSize = isAifc ? 22 : 18;\n        if (header.chunkSize < minimumChunkSize)\n            throw new Error(`COMMON CHUNK size should always be at least ${minimumChunkSize}`);\n        this.len = header.chunkSize;\n    }\n    get(buf, off) {\n        // see: https://cycling74.com/forums/aiffs-80-bit-sample-rate-value\n        const shift = buf.readUInt16BE(off + 8) - 16398;\n        const baseSampleRate = buf.readUInt16BE(off + 8 + 2);\n        const res = {\n            numChannels: buf.readUInt16BE(off),\n            numSampleFrames: buf.readUInt32BE(off + 2),\n            sampleSize: buf.readUInt16BE(off + 6),\n            sampleRate: shift < 0 ? baseSampleRate >> Math.abs(shift) : baseSampleRate << shift\n        };\n        if (this.isAifc) {\n            res.compressionType = FourCC_1.FourCcToken.get(buf, off + 18);\n            if (this.len > 22) {\n                const strLen = buf.readInt8(off + 22);\n                if (strLen > 0) {\n                    const padding = (strLen + 1) % 2;\n                    if (23 + strLen + padding === this.len) {\n                        res.compressionName = new Token.StringType(strLen, 'binary').get(buf, off + 23);\n                    }\n                    else {\n                        throw new Error('Illegal pstring length');\n                    }\n                }\n                else {\n                    res.compressionName = undefined;\n                }\n            }\n        }\n        else {\n            res.compressionName = 'PCM';\n        }\n        return res;\n    }\n}\nexports.Common = Common;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/aiff/AiffToken.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2Parser.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2Parser.js ***!
  \*******************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ \"./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js\")[\"Buffer\"];\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.APEv2Parser = void 0;\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst strtok3 = __webpack_require__(/*! strtok3/lib/core */ \"./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/core.js\");\nconst token_types_1 = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst util = __webpack_require__(/*! ../common/Util */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js\");\nconst BasicParser_1 = __webpack_require__(/*! ../common/BasicParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js\");\nconst APEv2Token_1 = __webpack_require__(/*! ./APEv2Token */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2Token.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:APEv2');\nconst tagFormat = 'APEv2';\nconst preamble = 'APETAGEX';\nclass APEv2Parser extends BasicParser_1.BasicParser {\n    constructor() {\n        super(...arguments);\n        this.ape = {};\n    }\n    static tryParseApeHeader(metadata, tokenizer, options) {\n        const apeParser = new APEv2Parser();\n        apeParser.init(metadata, tokenizer, options);\n        return apeParser.tryParseApeHeader();\n    }\n    /**\n     * Calculate the media file duration\n     * @param ah ApeHeader\n     * @return {number} duration in seconds\n     */\n    static calculateDuration(ah) {\n        let duration = ah.totalFrames > 1 ? ah.blocksPerFrame * (ah.totalFrames - 1) : 0;\n        duration += ah.finalFrameBlocks;\n        return duration / ah.sampleRate;\n    }\n    /**\n     * Calculates the APEv1 / APEv2 first field offset\n     * @param reader\n     * @param offset\n     */\n    static async findApeFooterOffset(reader, offset) {\n        // Search for APE footer header at the end of the file\n        const apeBuf = Buffer.alloc(APEv2Token_1.TagFooter.len);\n        await reader.randomRead(apeBuf, 0, APEv2Token_1.TagFooter.len, offset - APEv2Token_1.TagFooter.len);\n        const tagFooter = APEv2Token_1.TagFooter.get(apeBuf, 0);\n        if (tagFooter.ID === 'APETAGEX') {\n            debug(`APE footer header at offset=${offset}`);\n            return { footer: tagFooter, offset: offset - tagFooter.size };\n        }\n    }\n    static parseTagFooter(metadata, buffer, options) {\n        const footer = APEv2Token_1.TagFooter.get(buffer, buffer.length - APEv2Token_1.TagFooter.len);\n        if (footer.ID !== preamble)\n            throw new Error('Unexpected APEv2 Footer ID preamble value.');\n        strtok3.fromBuffer(buffer);\n        const apeParser = new APEv2Parser();\n        apeParser.init(metadata, strtok3.fromBuffer(buffer), options);\n        return apeParser.parseTags(footer);\n    }\n    /**\n     * Parse APEv1 / APEv2 header if header signature found\n     */\n    async tryParseApeHeader() {\n        if (this.tokenizer.fileInfo.size && this.tokenizer.fileInfo.size - this.tokenizer.position < APEv2Token_1.TagFooter.len) {\n            debug(`No APEv2 header found, end-of-file reached`);\n            return;\n        }\n        const footer = await this.tokenizer.peekToken(APEv2Token_1.TagFooter);\n        if (footer.ID === preamble) {\n            await this.tokenizer.ignore(APEv2Token_1.TagFooter.len);\n            return this.parseTags(footer);\n        }\n        else {\n            debug(`APEv2 header not found at offset=${this.tokenizer.position}`);\n            if (this.tokenizer.fileInfo.size) {\n                // Try to read the APEv2 header using just the footer-header\n                const remaining = this.tokenizer.fileInfo.size - this.tokenizer.position; // ToDo: take ID3v1 into account\n                const buffer = Buffer.alloc(remaining);\n                await this.tokenizer.readBuffer(buffer);\n                return APEv2Parser.parseTagFooter(this.metadata, buffer, this.options);\n            }\n        }\n    }\n    async parse() {\n        const descriptor = await this.tokenizer.readToken(APEv2Token_1.DescriptorParser);\n        if (descriptor.ID !== 'MAC ')\n            throw new Error('Unexpected descriptor ID');\n        this.ape.descriptor = descriptor;\n        const lenExp = descriptor.descriptorBytes - APEv2Token_1.DescriptorParser.len;\n        const header = await (lenExp > 0 ? this.parseDescriptorExpansion(lenExp) : this.parseHeader());\n        await this.tokenizer.ignore(header.forwardBytes);\n        return this.tryParseApeHeader();\n    }\n    async parseTags(footer) {\n        const keyBuffer = Buffer.alloc(256); // maximum tag key length\n        let bytesRemaining = footer.size - APEv2Token_1.TagFooter.len;\n        debug(`Parse APE tags at offset=${this.tokenizer.position}, size=${bytesRemaining}`);\n        for (let i = 0; i < footer.fields; i++) {\n            if (bytesRemaining < APEv2Token_1.TagItemHeader.len) {\n                this.metadata.addWarning(`APEv2 Tag-header: ${footer.fields - i} items remaining, but no more tag data to read.`);\n                break;\n            }\n            // Only APEv2 tag has tag item headers\n            const tagItemHeader = await this.tokenizer.readToken(APEv2Token_1.TagItemHeader);\n            bytesRemaining -= APEv2Token_1.TagItemHeader.len + tagItemHeader.size;\n            await this.tokenizer.peekBuffer(keyBuffer, { length: Math.min(keyBuffer.length, bytesRemaining) });\n            let zero = util.findZero(keyBuffer, 0, keyBuffer.length);\n            const key = await this.tokenizer.readToken(new token_types_1.StringType(zero, 'ascii'));\n            await this.tokenizer.ignore(1);\n            bytesRemaining -= key.length + 1;\n            switch (tagItemHeader.flags.dataType) {\n                case APEv2Token_1.DataType.text_utf8: { // utf-8 text-string\n                    const value = await this.tokenizer.readToken(new token_types_1.StringType(tagItemHeader.size, 'utf8'));\n                    const values = value.split(/\\x00/g);\n                    for (const val of values) {\n                        this.metadata.addTag(tagFormat, key, val);\n                    }\n                    break;\n                }\n                case APEv2Token_1.DataType.binary: // binary (probably artwork)\n                    if (this.options.skipCovers) {\n                        await this.tokenizer.ignore(tagItemHeader.size);\n                    }\n                    else {\n                        const picData = Buffer.alloc(tagItemHeader.size);\n                        await this.tokenizer.readBuffer(picData);\n                        zero = util.findZero(picData, 0, picData.length);\n                        const description = picData.toString('utf8', 0, zero);\n                        const data = Buffer.from(picData.slice(zero + 1));\n                        this.metadata.addTag(tagFormat, key, {\n                            description,\n                            data\n                        });\n                    }\n                    break;\n                case APEv2Token_1.DataType.external_info:\n                    debug(`Ignore external info ${key}`);\n                    await this.tokenizer.ignore(tagItemHeader.size);\n                    break;\n                case APEv2Token_1.DataType.reserved:\n                    debug(`Ignore external info ${key}`);\n                    this.metadata.addWarning(`APEv2 header declares a reserved datatype for \"${key}\"`);\n                    await this.tokenizer.ignore(tagItemHeader.size);\n                    break;\n            }\n        }\n    }\n    async parseDescriptorExpansion(lenExp) {\n        await this.tokenizer.ignore(lenExp);\n        return this.parseHeader();\n    }\n    async parseHeader() {\n        const header = await this.tokenizer.readToken(APEv2Token_1.Header);\n        // ToDo before\n        this.metadata.setFormat('lossless', true);\n        this.metadata.setFormat('container', 'Monkey\\'s Audio');\n        this.metadata.setFormat('bitsPerSample', header.bitsPerSample);\n        this.metadata.setFormat('sampleRate', header.sampleRate);\n        this.metadata.setFormat('numberOfChannels', header.channel);\n        this.metadata.setFormat('duration', APEv2Parser.calculateDuration(header));\n        return {\n            forwardBytes: this.ape.descriptor.seekTableBytes + this.ape.descriptor.headerDataBytes +\n                this.ape.descriptor.apeFrameDataBytes + this.ape.descriptor.terminatingDataBytes\n        };\n    }\n}\nexports.APEv2Parser = APEv2Parser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2Parser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2TagMapper.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2TagMapper.js ***!
  \**********************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.APEv2TagMapper = void 0;\nconst CaseInsensitiveTagMap_1 = __webpack_require__(/*! ../common/CaseInsensitiveTagMap */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/CaseInsensitiveTagMap.js\");\n/**\n * ID3v2.2 tag mappings\n */\nconst apev2TagMap = {\n    Title: 'title',\n    Artist: 'artist',\n    Artists: 'artists',\n    'Album Artist': 'albumartist',\n    Album: 'album',\n    Year: 'date',\n    Originalyear: 'originalyear',\n    Originaldate: 'originaldate',\n    Comment: 'comment',\n    Track: 'track',\n    Disc: 'disk',\n    DISCNUMBER: 'disk',\n    Genre: 'genre',\n    'Cover Art (Front)': 'picture',\n    'Cover Art (Back)': 'picture',\n    Composer: 'composer',\n    Lyrics: 'lyrics',\n    ALBUMSORT: 'albumsort',\n    TITLESORT: 'titlesort',\n    WORK: 'work',\n    ARTISTSORT: 'artistsort',\n    ALBUMARTISTSORT: 'albumartistsort',\n    COMPOSERSORT: 'composersort',\n    Lyricist: 'lyricist',\n    Writer: 'writer',\n    Conductor: 'conductor',\n    // 'Performer=artist(instrument)': 'performer:instrument',\n    MixArtist: 'remixer',\n    Arranger: 'arranger',\n    Engineer: 'engineer',\n    Producer: 'producer',\n    DJMixer: 'djmixer',\n    Mixer: 'mixer',\n    Label: 'label',\n    Grouping: 'grouping',\n    Subtitle: 'subtitle',\n    DiscSubtitle: 'discsubtitle',\n    Compilation: 'compilation',\n    BPM: 'bpm',\n    Mood: 'mood',\n    Media: 'media',\n    CatalogNumber: 'catalognumber',\n    MUSICBRAINZ_ALBUMSTATUS: 'releasestatus',\n    MUSICBRAINZ_ALBUMTYPE: 'releasetype',\n    RELEASECOUNTRY: 'releasecountry',\n    Script: 'script',\n    Language: 'language',\n    Copyright: 'copyright',\n    LICENSE: 'license',\n    EncodedBy: 'encodedby',\n    EncoderSettings: 'encodersettings',\n    Barcode: 'barcode',\n    ISRC: 'isrc',\n    ASIN: 'asin',\n    musicbrainz_trackid: 'musicbrainz_recordingid',\n    musicbrainz_releasetrackid: 'musicbrainz_trackid',\n    MUSICBRAINZ_ALBUMID: 'musicbrainz_albumid',\n    MUSICBRAINZ_ARTISTID: 'musicbrainz_artistid',\n    MUSICBRAINZ_ALBUMARTISTID: 'musicbrainz_albumartistid',\n    MUSICBRAINZ_RELEASEGROUPID: 'musicbrainz_releasegroupid',\n    MUSICBRAINZ_WORKID: 'musicbrainz_workid',\n    MUSICBRAINZ_TRMID: 'musicbrainz_trmid',\n    MUSICBRAINZ_DISCID: 'musicbrainz_discid',\n    Acoustid_Id: 'acoustid_id',\n    ACOUSTID_FINGERPRINT: 'acoustid_fingerprint',\n    MUSICIP_PUID: 'musicip_puid',\n    Weblink: 'website',\n    REPLAYGAIN_TRACK_GAIN: 'replaygain_track_gain',\n    REPLAYGAIN_TRACK_PEAK: 'replaygain_track_peak',\n    MP3GAIN_MINMAX: 'replaygain_track_minmax',\n    MP3GAIN_UNDO: 'replaygain_undo'\n};\nclass APEv2TagMapper extends CaseInsensitiveTagMap_1.CaseInsensitiveTagMap {\n    constructor() {\n        super(['APEv2'], apev2TagMap);\n    }\n}\nexports.APEv2TagMapper = APEv2TagMapper;\n//# sourceMappingURL=APEv2TagMapper.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2TagMapper.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2Token.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2Token.js ***!
  \******************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.isBitSet = exports.parseTagFlags = exports.TagField = exports.TagItemHeader = exports.TagFooter = exports.Header = exports.DescriptorParser = exports.DataType = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nconst FourCC_1 = __webpack_require__(/*! ../common/FourCC */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js");\nvar DataType;\n(function (DataType) {\n    DataType[DataType["text_utf8"] = 0] = "text_utf8";\n    DataType[DataType["binary"] = 1] = "binary";\n    DataType[DataType["external_info"] = 2] = "external_info";\n    DataType[DataType["reserved"] = 3] = "reserved";\n})(DataType = exports.DataType || (exports.DataType = {}));\n/**\n * APE_DESCRIPTOR: defines the sizes (and offsets) of all the pieces, as well as the MD5 checksum\n */\nexports.DescriptorParser = {\n    len: 52,\n    get: (buf, off) => {\n        return {\n            // should equal \'MAC \'\n            ID: FourCC_1.FourCcToken.get(buf, off),\n            // versionIndex number * 1000 (3.81 = 3810) (remember that 4-byte alignment causes this to take 4-bytes)\n            version: Token.UINT32_LE.get(buf, off + 4) / 1000,\n            // the number of descriptor bytes (allows later expansion of this header)\n            descriptorBytes: Token.UINT32_LE.get(buf, off + 8),\n            // the number of header APE_HEADER bytes\n            headerBytes: Token.UINT32_LE.get(buf, off + 12),\n            // the number of header APE_HEADER bytes\n            seekTableBytes: Token.UINT32_LE.get(buf, off + 16),\n            // the number of header data bytes (from original file)\n            headerDataBytes: Token.UINT32_LE.get(buf, off + 20),\n            // the number of bytes of APE frame data\n            apeFrameDataBytes: Token.UINT32_LE.get(buf, off + 24),\n            // the high order number of APE frame data bytes\n            apeFrameDataBytesHigh: Token.UINT32_LE.get(buf, off + 28),\n            // the terminating data of the file (not including tag data)\n            terminatingDataBytes: Token.UINT32_LE.get(buf, off + 32),\n            // the MD5 hash of the file (see notes for usage... it\'s a little tricky)\n            fileMD5: new Token.Uint8ArrayType(16).get(buf, off + 36)\n        };\n    }\n};\n/**\n * APE_HEADER: describes all of the necessary information about the APE file\n */\nexports.Header = {\n    len: 24,\n    get: (buf, off) => {\n        return {\n            // the compression level (see defines I.E. COMPRESSION_LEVEL_FAST)\n            compressionLevel: Token.UINT16_LE.get(buf, off),\n            // any format flags (for future use)\n            formatFlags: Token.UINT16_LE.get(buf, off + 2),\n            // the number of audio blocks in one frame\n            blocksPerFrame: Token.UINT32_LE.get(buf, off + 4),\n            // the number of audio blocks in the final frame\n            finalFrameBlocks: Token.UINT32_LE.get(buf, off + 8),\n            // the total number of frames\n            totalFrames: Token.UINT32_LE.get(buf, off + 12),\n            // the bits per sample (typically 16)\n            bitsPerSample: Token.UINT16_LE.get(buf, off + 16),\n            // the number of channels (1 or 2)\n            channel: Token.UINT16_LE.get(buf, off + 18),\n            // the sample rate (typically 44100)\n            sampleRate: Token.UINT32_LE.get(buf, off + 20)\n        };\n    }\n};\n/**\n * APE Tag Header/Footer Version 2.0\n * TAG: describes all the properties of the file [optional]\n */\nexports.TagFooter = {\n    len: 32,\n    get: (buf, off) => {\n        return {\n            // should equal \'APETAGEX\'\n            ID: new Token.StringType(8, \'ascii\').get(buf, off),\n            // equals CURRENT_APE_TAG_VERSION\n            version: Token.UINT32_LE.get(buf, off + 8),\n            // the complete size of the tag, including this footer (excludes header)\n            size: Token.UINT32_LE.get(buf, off + 12),\n            // the number of fields in the tag\n            fields: Token.UINT32_LE.get(buf, off + 16),\n            // reserved for later use (must be zero),\n            flags: parseTagFlags(Token.UINT32_LE.get(buf, off + 20))\n        };\n    }\n};\n/**\n * APE Tag v2.0 Item Header\n */\nexports.TagItemHeader = {\n    len: 8,\n    get: (buf, off) => {\n        return {\n            // Length of assigned value in bytes\n            size: Token.UINT32_LE.get(buf, off),\n            // reserved for later use (must be zero),\n            flags: parseTagFlags(Token.UINT32_LE.get(buf, off + 4))\n        };\n    }\n};\nconst TagField = footer => {\n    return new Token.Uint8ArrayType(footer.size - exports.TagFooter.len);\n};\nexports.TagField = TagField;\nfunction parseTagFlags(flags) {\n    return {\n        containsHeader: isBitSet(flags, 31),\n        containsFooter: isBitSet(flags, 30),\n        isHeader: isBitSet(flags, 31),\n        readOnly: isBitSet(flags, 0),\n        dataType: (flags & 6) >> 1\n    };\n}\nexports.parseTagFlags = parseTagFlags;\n/**\n * @param num {number}\n * @param bit 0 is least significant bit (LSB)\n * @return {boolean} true if bit is 1; otherwise false\n */\nfunction isBitSet(num, bit) {\n    return (num & 1 << bit) !== 0;\n}\nexports.isBitSet = isBitSet;\n//# sourceMappingURL=APEv2Token.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2Token.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfObject.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfObject.js ***!
  \***************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ "./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js")["Buffer"];\n\n// ASF Objects\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.WmPictureToken = exports.MetadataLibraryObjectState = exports.MetadataObjectState = exports.ExtendedStreamPropertiesObjectState = exports.ExtendedContentDescriptionObjectState = exports.ContentDescriptionObjectState = exports.readCodecEntries = exports.HeaderExtensionObject = exports.StreamPropertiesObject = exports.FilePropertiesObject = exports.IgnoreObjectState = exports.State = exports.HeaderObjectToken = exports.TopLevelHeaderObjectToken = exports.DataType = void 0;\nconst util = __webpack_require__(/*! ../common/Util */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js");\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nconst GUID_1 = __webpack_require__(/*! ./GUID */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/GUID.js");\nconst AsfUtil_1 = __webpack_require__(/*! ./AsfUtil */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfUtil.js");\nconst ID3v2Token_1 = __webpack_require__(/*! ../id3v2/ID3v2Token */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Token.js");\n/**\n * Data Type: Specifies the type of information being stored. The following values are recognized.\n */\nvar DataType;\n(function (DataType) {\n    /**\n     * Unicode string. The data consists of a sequence of Unicode characters.\n     */\n    DataType[DataType["UnicodeString"] = 0] = "UnicodeString";\n    /**\n     * BYTE array. The type of data is implementation-specific.\n     */\n    DataType[DataType["ByteArray"] = 1] = "ByteArray";\n    /**\n     * BOOL. The data is 2 bytes long and should be interpreted as a 16-bit unsigned integer. Only 0x0000 or 0x0001 are permitted values.\n     */\n    DataType[DataType["Bool"] = 2] = "Bool";\n    /**\n     * DWORD. The data is 4 bytes long and should be interpreted as a 32-bit unsigned integer.\n     */\n    DataType[DataType["DWord"] = 3] = "DWord";\n    /**\n     * QWORD. The data is 8 bytes long and should be interpreted as a 64-bit unsigned integer.\n     */\n    DataType[DataType["QWord"] = 4] = "QWord";\n    /**\n     * WORD. The data is 2 bytes long and should be interpreted as a 16-bit unsigned integer.\n     */\n    DataType[DataType["Word"] = 5] = "Word";\n})(DataType = exports.DataType || (exports.DataType = {}));\n/**\n * Token for: 3. ASF top-level Header Object\n * Ref: http://drang.s4.xrea.com/program/tips/id3tag/wmp/03_asf_top_level_header_object.html#3\n */\nexports.TopLevelHeaderObjectToken = {\n    len: 30,\n    get: (buf, off) => {\n        return {\n            objectId: GUID_1.default.fromBin(new Token.BufferType(16).get(buf, off)),\n            objectSize: Number(Token.UINT64_LE.get(buf, off + 16)),\n            numberOfHeaderObjects: Token.UINT32_LE.get(buf, off + 24)\n            // Reserved: 2 bytes\n        };\n    }\n};\n/**\n * Token for: 3.1 Header Object (mandatory, one only)\n * Ref: http://drang.s4.xrea.com/program/tips/id3tag/wmp/03_asf_top_level_header_object.html#3_1\n */\nexports.HeaderObjectToken = {\n    len: 24,\n    get: (buf, off) => {\n        return {\n            objectId: GUID_1.default.fromBin(new Token.BufferType(16).get(buf, off)),\n            objectSize: Number(Token.UINT64_LE.get(buf, off + 16))\n        };\n    }\n};\nclass State {\n    constructor(header) {\n        this.len = Number(header.objectSize) - exports.HeaderObjectToken.len;\n    }\n    postProcessTag(tags, name, valueType, data) {\n        if (name === \'WM/Picture\') {\n            tags.push({ id: name, value: WmPictureToken.fromBuffer(data) });\n        }\n        else {\n            const parseAttr = AsfUtil_1.AsfUtil.getParserForAttr(valueType);\n            if (!parseAttr) {\n                throw new Error(\'unexpected value headerType: \' + valueType);\n            }\n            tags.push({ id: name, value: parseAttr(data) });\n        }\n    }\n}\nexports.State = State;\n// ToDo: use ignore type\nclass IgnoreObjectState extends State {\n    constructor(header) {\n        super(header);\n    }\n    get(buf, off) {\n        return null;\n    }\n}\nexports.IgnoreObjectState = IgnoreObjectState;\n/**\n * Token for: 3.2: File Properties Object (mandatory, one only)\n * Ref: http://drang.s4.xrea.com/program/tips/id3tag/wmp/03_asf_top_level_header_object.html#3_2\n */\nclass FilePropertiesObject extends State {\n    constructor(header) {\n        super(header);\n    }\n    get(buf, off) {\n        return {\n            fileId: GUID_1.default.fromBin(buf, off),\n            fileSize: Token.UINT64_LE.get(buf, off + 16),\n            creationDate: Token.UINT64_LE.get(buf, off + 24),\n            dataPacketsCount: Token.UINT64_LE.get(buf, off + 32),\n            playDuration: Token.UINT64_LE.get(buf, off + 40),\n            sendDuration: Token.UINT64_LE.get(buf, off + 48),\n            preroll: Token.UINT64_LE.get(buf, off + 56),\n            flags: {\n                broadcast: util.getBit(buf, off + 64, 24),\n                seekable: util.getBit(buf, off + 64, 25)\n            },\n            // flagsNumeric: Token.UINT32_LE.get(buf, off + 64),\n            minimumDataPacketSize: Token.UINT32_LE.get(buf, off + 68),\n            maximumDataPacketSize: Token.UINT32_LE.get(buf, off + 72),\n            maximumBitrate: Token.UINT32_LE.get(buf, off + 76)\n        };\n    }\n}\nFilePropertiesObject.guid = GUID_1.default.FilePropertiesObject;\nexports.FilePropertiesObject = FilePropertiesObject;\n/**\n * Token for: 3.3 Stream Properties Object (mandatory, one per stream)\n * Ref: http://drang.s4.xrea.com/program/tips/id3tag/wmp/03_asf_top_level_header_object.html#3_3\n */\nclass StreamPropertiesObject extends State {\n    constructor(header) {\n        super(header);\n    }\n    get(buf, off) {\n        return {\n            streamType: GUID_1.default.decodeMediaType(GUID_1.default.fromBin(buf, off)),\n            errorCorrectionType: GUID_1.default.fromBin(buf, off + 8)\n            // ToDo\n        };\n    }\n}\nStreamPropertiesObject.guid = GUID_1.default.StreamPropertiesObject;\nexports.StreamPropertiesObject = StreamPropertiesObject;\n/**\n * 3.4: Header Extension Object (mandatory, one only)\n * Ref: http://drang.s4.xrea.com/program/tips/id3tag/wmp/03_asf_top_level_header_object.html#3_4\n */\nclass HeaderExtensionObject {\n    constructor() {\n        this.len = 22;\n    }\n    get(buf, off) {\n        return {\n            reserved1: GUID_1.default.fromBin(buf, off),\n            reserved2: buf.readUInt16LE(off + 16),\n            extensionDataSize: buf.readUInt32LE(off + 18)\n        };\n    }\n}\nHeaderExtensionObject.guid = GUID_1.default.HeaderExtensionObject;\nexports.HeaderExtensionObject = HeaderExtensionObject;\n/**\n * 3.5: The Codec List Object provides user-friendly information about the codecs and formats used to encode the content found in the ASF file.\n * Ref: http://drang.s4.xrea.com/program/tips/id3tag/wmp/03_asf_top_level_header_object.html#3_5\n */\nconst CodecListObjectHeader = {\n    len: 20,\n    get: (buf, off) => {\n        return {\n            entryCount: buf.readUInt16LE(off + 16)\n        };\n    }\n};\nasync function readString(tokenizer) {\n    const length = await tokenizer.readNumber(Token.UINT16_LE);\n    return (await tokenizer.readToken(new Token.StringType(length * 2, \'utf16le\'))).replace(\'\\0\', \'\');\n}\n/**\n * 3.5: Read the Codec-List-Object, which provides user-friendly information about the codecs and formats used to encode the content found in the ASF file.\n * Ref: http://drang.s4.xrea.com/program/tips/id3tag/wmp/03_asf_top_level_header_object.html#3_5\n */\nasync function readCodecEntries(tokenizer) {\n    const codecHeader = await tokenizer.readToken(CodecListObjectHeader);\n    const entries = [];\n    for (let i = 0; i < codecHeader.entryCount; ++i) {\n        entries.push(await readCodecEntry(tokenizer));\n    }\n    return entries;\n}\nexports.readCodecEntries = readCodecEntries;\nasync function readInformation(tokenizer) {\n    const length = await tokenizer.readNumber(Token.UINT16_LE);\n    const buf = Buffer.alloc(length);\n    await tokenizer.readBuffer(buf);\n    return buf;\n}\n/**\n * Read Codec-Entries\n * @param tokenizer\n */\nasync function readCodecEntry(tokenizer) {\n    const type = await tokenizer.readNumber(Token.UINT16_LE);\n    return {\n        type: {\n            videoCodec: (type & 0x0001) === 0x0001,\n            audioCodec: (type & 0x0002) === 0x0002\n        },\n        codecName: await readString(tokenizer),\n        description: await readString(tokenizer),\n        information: await readInformation(tokenizer)\n    };\n}\n/**\n * 3.10 Content Description Object (optional, one only)\n * Ref: http://drang.s4.xrea.com/program/tips/id3tag/wmp/03_asf_top_level_header_object.html#3_10\n */\nclass ContentDescriptionObjectState extends State {\n    constructor(header) {\n        super(header);\n    }\n    get(buf, off) {\n        const tags = [];\n        let pos = off + 10;\n        for (let i = 0; i < ContentDescriptionObjectState.contentDescTags.length; ++i) {\n            const length = buf.readUInt16LE(off + i * 2);\n            if (length > 0) {\n                const tagName = ContentDescriptionObjectState.contentDescTags[i];\n                const end = pos + length;\n                tags.push({ id: tagName, value: AsfUtil_1.AsfUtil.parseUnicodeAttr(buf.slice(pos, end)) });\n                pos = end;\n            }\n        }\n        return tags;\n    }\n}\nContentDescriptionObjectState.guid = GUID_1.default.ContentDescriptionObject;\nContentDescriptionObjectState.contentDescTags = [\'Title\', \'Author\', \'Copyright\', \'Description\', \'Rating\'];\nexports.ContentDescriptionObjectState = ContentDescriptionObjectState;\n/**\n * 3.11 Extended Content Description Object (optional, one only)\n * Ref: http://drang.s4.xrea.com/program/tips/id3tag/wmp/03_asf_top_level_header_object.html#3_11\n */\nclass ExtendedContentDescriptionObjectState extends State {\n    constructor(header) {\n        super(header);\n    }\n    get(buf, off) {\n        const tags = [];\n        const attrCount = buf.readUInt16LE(off);\n        let pos = off + 2;\n        for (let i = 0; i < attrCount; i += 1) {\n            const nameLen = buf.readUInt16LE(pos);\n            pos += 2;\n            const name = AsfUtil_1.AsfUtil.parseUnicodeAttr(buf.slice(pos, pos + nameLen));\n            pos += nameLen;\n            const valueType = buf.readUInt16LE(pos);\n            pos += 2;\n            const valueLen = buf.readUInt16LE(pos);\n            pos += 2;\n            const value = buf.slice(pos, pos + valueLen);\n            pos += valueLen;\n            this.postProcessTag(tags, name, valueType, value);\n        }\n        return tags;\n    }\n}\nExtendedContentDescriptionObjectState.guid = GUID_1.default.ExtendedContentDescriptionObject;\nexports.ExtendedContentDescriptionObjectState = ExtendedContentDescriptionObjectState;\n/**\n * 4.1 Extended Stream Properties Object (optional, 1 per media stream)\n * Ref: http://drang.s4.xrea.com/program/tips/id3tag/wmp/04_objects_in_the_asf_header_extension_object.html#4_1\n */\nclass ExtendedStreamPropertiesObjectState extends State {\n    constructor(header) {\n        super(header);\n    }\n    get(buf, off) {\n        return {\n            startTime: Token.UINT64_LE.get(buf, off),\n            endTime: Token.UINT64_LE.get(buf, off + 8),\n            dataBitrate: buf.readInt32LE(off + 12),\n            bufferSize: buf.readInt32LE(off + 16),\n            initialBufferFullness: buf.readInt32LE(off + 20),\n            alternateDataBitrate: buf.readInt32LE(off + 24),\n            alternateBufferSize: buf.readInt32LE(off + 28),\n            alternateInitialBufferFullness: buf.readInt32LE(off + 32),\n            maximumObjectSize: buf.readInt32LE(off + 36),\n            flags: {\n                reliableFlag: util.getBit(buf, off + 40, 0),\n                seekableFlag: util.getBit(buf, off + 40, 1),\n                resendLiveCleanpointsFlag: util.getBit(buf, off + 40, 2)\n            },\n            // flagsNumeric: Token.UINT32_LE.get(buf, off + 64),\n            streamNumber: buf.readInt16LE(off + 42),\n            streamLanguageId: buf.readInt16LE(off + 44),\n            averageTimePerFrame: buf.readInt32LE(off + 52),\n            streamNameCount: buf.readInt32LE(off + 54),\n            payloadExtensionSystems: buf.readInt32LE(off + 56),\n            streamNames: [],\n            streamPropertiesObject: null\n        };\n    }\n}\nExtendedStreamPropertiesObjectState.guid = GUID_1.default.ExtendedStreamPropertiesObject;\nexports.ExtendedStreamPropertiesObjectState = ExtendedStreamPropertiesObjectState;\n/**\n * 4.7  Metadata Object (optional, 0 or 1)\n * Ref: http://drang.s4.xrea.com/program/tips/id3tag/wmp/04_objects_in_the_asf_header_extension_object.html#4_7\n */\nclass MetadataObjectState extends State {\n    constructor(header) {\n        super(header);\n    }\n    get(uint8Array, off) {\n        const tags = [];\n        const buf = Buffer.from(uint8Array);\n        const descriptionRecordsCount = buf.readUInt16LE(off);\n        let pos = off + 2;\n        for (let i = 0; i < descriptionRecordsCount; i += 1) {\n            pos += 4;\n            const nameLen = buf.readUInt16LE(pos);\n            pos += 2;\n            const dataType = buf.readUInt16LE(pos);\n            pos += 2;\n            const dataLen = buf.readUInt32LE(pos);\n            pos += 4;\n            const name = AsfUtil_1.AsfUtil.parseUnicodeAttr(buf.slice(pos, pos + nameLen));\n            pos += nameLen;\n            const data = buf.slice(pos, pos + dataLen);\n            pos += dataLen;\n            this.postProcessTag(tags, name, dataType, data);\n        }\n        return tags;\n    }\n}\nMetadataObjectState.guid = GUID_1.default.MetadataObject;\nexports.MetadataObjectState = MetadataObjectState;\n// 4.8\tMetadata Library Object (optional, 0 or 1)\nclass MetadataLibraryObjectState extends MetadataObjectState {\n    constructor(header) {\n        super(header);\n    }\n}\nMetadataLibraryObjectState.guid = GUID_1.default.MetadataLibraryObject;\nexports.MetadataLibraryObjectState = MetadataLibraryObjectState;\n/**\n * Ref: https://msdn.microsoft.com/en-us/library/windows/desktop/dd757977(v=vs.85).aspx\n */\nclass WmPictureToken {\n    static fromBase64(base64str) {\n        return this.fromBuffer(Buffer.from(base64str, \'base64\'));\n    }\n    static fromBuffer(buffer) {\n        const pic = new WmPictureToken(buffer.length);\n        return pic.get(buffer, 0);\n    }\n    constructor(len) {\n        this.len = len;\n    }\n    get(buffer, offset) {\n        const typeId = buffer.readUInt8(offset++);\n        const size = buffer.readInt32LE(offset);\n        let index = 5;\n        while (buffer.readUInt16BE(index) !== 0) {\n            index += 2;\n        }\n        const format = buffer.slice(5, index).toString(\'utf16le\');\n        while (buffer.readUInt16BE(index) !== 0) {\n            index += 2;\n        }\n        const description = buffer.slice(5, index).toString(\'utf16le\');\n        return {\n            type: ID3v2Token_1.AttachedPictureType[typeId],\n            format,\n            description,\n            size,\n            data: buffer.slice(index + 4)\n        };\n    }\n}\nexports.WmPictureToken = WmPictureToken;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfObject.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfParser.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfParser.js ***!
  \***************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AsfParser = void 0;\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst type_1 = __webpack_require__(/*! ../type */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/type.js\");\nconst GUID_1 = __webpack_require__(/*! ./GUID */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/GUID.js\");\nconst AsfObject = __webpack_require__(/*! ./AsfObject */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfObject.js\");\nconst BasicParser_1 = __webpack_require__(/*! ../common/BasicParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:ASF');\nconst headerType = 'asf';\n/**\n * Windows Media Metadata Usage Guidelines\n * - Ref: https://msdn.microsoft.com/en-us/library/ms867702.aspx\n *\n * Ref:\n * - https://tools.ietf.org/html/draft-fleischman-asf-01\n * - https://hwiegman.home.xs4all.nl/fileformats/asf/ASF_Specification.pdf\n * - http://drang.s4.xrea.com/program/tips/id3tag/wmp/index.html\n * - https://msdn.microsoft.com/en-us/library/windows/desktop/ee663575(v=vs.85).aspx\n */\nclass AsfParser extends BasicParser_1.BasicParser {\n    async parse() {\n        const header = await this.tokenizer.readToken(AsfObject.TopLevelHeaderObjectToken);\n        if (!header.objectId.equals(GUID_1.default.HeaderObject)) {\n            throw new Error('expected asf header; but was not found; got: ' + header.objectId.str);\n        }\n        try {\n            await this.parseObjectHeader(header.numberOfHeaderObjects);\n        }\n        catch (err) {\n            debug('Error while parsing ASF: %s', err);\n        }\n    }\n    async parseObjectHeader(numberOfObjectHeaders) {\n        let tags;\n        do {\n            // Parse common header of the ASF Object (3.1)\n            const header = await this.tokenizer.readToken(AsfObject.HeaderObjectToken);\n            // Parse data part of the ASF Object\n            debug('header GUID=%s', header.objectId.str);\n            switch (header.objectId.str) {\n                case AsfObject.FilePropertiesObject.guid.str: // 3.2\n                    const fpo = await this.tokenizer.readToken(new AsfObject.FilePropertiesObject(header));\n                    this.metadata.setFormat('duration', Number(fpo.playDuration / BigInt(1000)) / 10000 - Number(fpo.preroll) / 1000);\n                    this.metadata.setFormat('bitrate', fpo.maximumBitrate);\n                    break;\n                case AsfObject.StreamPropertiesObject.guid.str: // 3.3\n                    const spo = await this.tokenizer.readToken(new AsfObject.StreamPropertiesObject(header));\n                    this.metadata.setFormat('container', 'ASF/' + spo.streamType);\n                    break;\n                case AsfObject.HeaderExtensionObject.guid.str: // 3.4\n                    const extHeader = await this.tokenizer.readToken(new AsfObject.HeaderExtensionObject());\n                    await this.parseExtensionObject(extHeader.extensionDataSize);\n                    break;\n                case AsfObject.ContentDescriptionObjectState.guid.str: // 3.10\n                    tags = await this.tokenizer.readToken(new AsfObject.ContentDescriptionObjectState(header));\n                    this.addTags(tags);\n                    break;\n                case AsfObject.ExtendedContentDescriptionObjectState.guid.str: // 3.11\n                    tags = await this.tokenizer.readToken(new AsfObject.ExtendedContentDescriptionObjectState(header));\n                    this.addTags(tags);\n                    break;\n                case GUID_1.default.CodecListObject.str:\n                    const codecs = await AsfObject.readCodecEntries(this.tokenizer);\n                    codecs.forEach(codec => {\n                        this.metadata.addStreamInfo({\n                            type: codec.type.videoCodec ? type_1.TrackType.video : type_1.TrackType.audio,\n                            codecName: codec.codecName\n                        });\n                    });\n                    const audioCodecs = codecs.filter(codec => codec.type.audioCodec).map(codec => codec.codecName).join('/');\n                    this.metadata.setFormat('codec', audioCodecs);\n                    break;\n                case GUID_1.default.StreamBitratePropertiesObject.str:\n                    // ToDo?\n                    await this.tokenizer.ignore(header.objectSize - AsfObject.HeaderObjectToken.len);\n                    break;\n                case GUID_1.default.PaddingObject.str:\n                    // ToDo: register bytes pad\n                    debug('Padding: %s bytes', header.objectSize - AsfObject.HeaderObjectToken.len);\n                    await this.tokenizer.ignore(header.objectSize - AsfObject.HeaderObjectToken.len);\n                    break;\n                default:\n                    this.metadata.addWarning('Ignore ASF-Object-GUID: ' + header.objectId.str);\n                    debug('Ignore ASF-Object-GUID: %s', header.objectId.str);\n                    await this.tokenizer.readToken(new AsfObject.IgnoreObjectState(header));\n            }\n        } while (--numberOfObjectHeaders);\n        // done\n    }\n    addTags(tags) {\n        tags.forEach(tag => {\n            this.metadata.addTag(headerType, tag.id, tag.value);\n        });\n    }\n    async parseExtensionObject(extensionSize) {\n        do {\n            // Parse common header of the ASF Object (3.1)\n            const header = await this.tokenizer.readToken(AsfObject.HeaderObjectToken);\n            const remaining = header.objectSize - AsfObject.HeaderObjectToken.len;\n            // Parse data part of the ASF Object\n            switch (header.objectId.str) {\n                case AsfObject.ExtendedStreamPropertiesObjectState.guid.str: // 4.1\n                    // ToDo: extended stream header properties are ignored\n                    await this.tokenizer.readToken(new AsfObject.ExtendedStreamPropertiesObjectState(header));\n                    break;\n                case AsfObject.MetadataObjectState.guid.str: // 4.7\n                    const moTags = await this.tokenizer.readToken(new AsfObject.MetadataObjectState(header));\n                    this.addTags(moTags);\n                    break;\n                case AsfObject.MetadataLibraryObjectState.guid.str: // 4.8\n                    const mlTags = await this.tokenizer.readToken(new AsfObject.MetadataLibraryObjectState(header));\n                    this.addTags(mlTags);\n                    break;\n                case GUID_1.default.PaddingObject.str:\n                    // ToDo: register bytes pad\n                    await this.tokenizer.ignore(remaining);\n                    break;\n                case GUID_1.default.CompatibilityObject.str:\n                    this.tokenizer.ignore(remaining);\n                    break;\n                case GUID_1.default.ASF_Index_Placeholder_Object.str:\n                    await this.tokenizer.ignore(remaining);\n                    break;\n                default:\n                    this.metadata.addWarning('Ignore ASF-Object-GUID: ' + header.objectId.str);\n                    // console.log(\"Ignore ASF-Object-GUID: %s\", header.objectId.str);\n                    await this.tokenizer.readToken(new AsfObject.IgnoreObjectState(header));\n                    break;\n            }\n            extensionSize -= header.objectSize;\n        } while (extensionSize > 0);\n    }\n}\nexports.AsfParser = AsfParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfParser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfTagMapper.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfTagMapper.js ***!
  \******************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.AsfTagMapper = void 0;\nconst GenericTagMapper_1 = __webpack_require__(/*! ../common/GenericTagMapper */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/GenericTagMapper.js\");\n/**\n * ASF Metadata tag mappings.\n * See http://msdn.microsoft.com/en-us/library/ms867702.aspx\n */\nconst asfTagMap = {\n    Title: 'title',\n    Author: 'artist',\n    'WM/AlbumArtist': 'albumartist',\n    'WM/AlbumTitle': 'album',\n    'WM/Year': 'date',\n    'WM/OriginalReleaseTime': 'originaldate',\n    'WM/OriginalReleaseYear': 'originalyear',\n    Description: 'comment',\n    'WM/TrackNumber': 'track',\n    'WM/PartOfSet': 'disk',\n    'WM/Genre': 'genre',\n    'WM/Composer': 'composer',\n    'WM/Lyrics': 'lyrics',\n    'WM/AlbumSortOrder': 'albumsort',\n    'WM/TitleSortOrder': 'titlesort',\n    'WM/ArtistSortOrder': 'artistsort',\n    'WM/AlbumArtistSortOrder': 'albumartistsort',\n    'WM/ComposerSortOrder': 'composersort',\n    'WM/Writer': 'lyricist',\n    'WM/Conductor': 'conductor',\n    'WM/ModifiedBy': 'remixer',\n    'WM/Engineer': 'engineer',\n    'WM/Producer': 'producer',\n    'WM/DJMixer': 'djmixer',\n    'WM/Mixer': 'mixer',\n    'WM/Publisher': 'label',\n    'WM/ContentGroupDescription': 'grouping',\n    'WM/SubTitle': 'subtitle',\n    'WM/SetSubTitle': 'discsubtitle',\n    // 'WM/PartOfSet': 'totaldiscs',\n    'WM/IsCompilation': 'compilation',\n    'WM/SharedUserRating': 'rating',\n    'WM/BeatsPerMinute': 'bpm',\n    'WM/Mood': 'mood',\n    'WM/Media': 'media',\n    'WM/CatalogNo': 'catalognumber',\n    'MusicBrainz/Album Status': 'releasestatus',\n    'MusicBrainz/Album Type': 'releasetype',\n    'MusicBrainz/Album Release Country': 'releasecountry',\n    'WM/Script': 'script',\n    'WM/Language': 'language',\n    Copyright: 'copyright',\n    LICENSE: 'license',\n    'WM/EncodedBy': 'encodedby',\n    'WM/EncodingSettings': 'encodersettings',\n    'WM/Barcode': 'barcode',\n    'WM/ISRC': 'isrc',\n    'MusicBrainz/Track Id': 'musicbrainz_recordingid',\n    'MusicBrainz/Release Track Id': 'musicbrainz_trackid',\n    'MusicBrainz/Album Id': 'musicbrainz_albumid',\n    'MusicBrainz/Artist Id': 'musicbrainz_artistid',\n    'MusicBrainz/Album Artist Id': 'musicbrainz_albumartistid',\n    'MusicBrainz/Release Group Id': 'musicbrainz_releasegroupid',\n    'MusicBrainz/Work Id': 'musicbrainz_workid',\n    'MusicBrainz/TRM Id': 'musicbrainz_trmid',\n    'MusicBrainz/Disc Id': 'musicbrainz_discid',\n    'Acoustid/Id': 'acoustid_id',\n    'Acoustid/Fingerprint': 'acoustid_fingerprint',\n    'MusicIP/PUID': 'musicip_puid',\n    'WM/ARTISTS': 'artists',\n    'WM/InitialKey': 'key',\n    ASIN: 'asin',\n    'WM/Work': 'work',\n    'WM/AuthorURL': 'website',\n    'WM/Picture': 'picture'\n};\nclass AsfTagMapper extends GenericTagMapper_1.CommonTagMapper {\n    static toRating(rating) {\n        return {\n            rating: parseFloat(rating + 1) / 5\n        };\n    }\n    constructor() {\n        super(['asf'], asfTagMap);\n    }\n    postMap(tag) {\n        switch (tag.id) {\n            case 'WM/SharedUserRating':\n                const keys = tag.id.split(':');\n                tag.value = AsfTagMapper.toRating(tag.value);\n                tag.id = keys[0];\n                break;\n        }\n    }\n}\nexports.AsfTagMapper = AsfTagMapper;\n//# sourceMappingURL=AsfTagMapper.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfTagMapper.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfUtil.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfUtil.js ***!
  \*************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ "./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js")["Buffer"];\n\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.AsfUtil = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nconst util = __webpack_require__(/*! ../common/Util */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js");\nclass AsfUtil {\n    static getParserForAttr(i) {\n        return AsfUtil.attributeParsers[i];\n    }\n    static parseUnicodeAttr(uint8Array) {\n        return util.stripNulls(util.decodeString(uint8Array, \'utf16le\'));\n    }\n    static parseByteArrayAttr(buf) {\n        return Buffer.from(buf);\n    }\n    static parseBoolAttr(buf, offset = 0) {\n        return AsfUtil.parseWordAttr(buf, offset) === 1;\n    }\n    static parseDWordAttr(buf, offset = 0) {\n        return buf.readUInt32LE(offset);\n    }\n    static parseQWordAttr(buf, offset = 0) {\n        return Token.UINT64_LE.get(buf, offset);\n    }\n    static parseWordAttr(buf, offset = 0) {\n        return buf.readUInt16LE(offset);\n    }\n}\nAsfUtil.attributeParsers = [\n    AsfUtil.parseUnicodeAttr,\n    AsfUtil.parseByteArrayAttr,\n    AsfUtil.parseBoolAttr,\n    AsfUtil.parseDWordAttr,\n    AsfUtil.parseQWordAttr,\n    AsfUtil.parseWordAttr,\n    AsfUtil.parseByteArrayAttr\n];\nexports.AsfUtil = AsfUtil;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfUtil.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/GUID.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/GUID.js ***!
  \**********************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ "./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js")["Buffer"];\n\nObject.defineProperty(exports, "__esModule", ({ value: true }));\n/**\n * Ref:\n * - https://tools.ietf.org/html/draft-fleischman-asf-01, Appendix A: ASF GUIDs\n * - http://drang.s4.xrea.com/program/tips/id3tag/wmp/10_asf_guids.html\n * - http://drang.s4.xrea.com/program/tips/id3tag/wmp/index.html\n * - http://drang.s4.xrea.com/program/tips/id3tag/wmp/10_asf_guids.html\n *\n * ASF File Structure:\n * - https://msdn.microsoft.com/en-us/library/windows/desktop/ee663575(v=vs.85).aspx\n *\n * ASF GUIDs:\n * - http://drang.s4.xrea.com/program/tips/id3tag/wmp/10_asf_guids.html\n * - https://github.com/dji-sdk/FFmpeg/blob/master/libavformat/asf.c\n */\nclass GUID {\n    static fromBin(bin, offset = 0) {\n        return new GUID(this.decode(bin, offset));\n    }\n    /**\n     * Decode GUID in format like "B503BF5F-2EA9-CF11-8EE3-00C00C205365"\n     * @param objectId Binary GUID\n     * @param offset Read offset in bytes, default 0\n     * @returns GUID as dashed hexadecimal representation\n     */\n    static decode(objectId, offset = 0) {\n        const guid = objectId.readUInt32LE(offset).toString(16) + "-" +\n            objectId.readUInt16LE(offset + 4).toString(16) + "-" +\n            objectId.readUInt16LE(offset + 6).toString(16) + "-" +\n            objectId.readUInt16BE(offset + 8).toString(16) + "-" +\n            objectId.slice(offset + 10, offset + 16).toString(\'hex\');\n        return guid.toUpperCase();\n    }\n    /**\n     * Decode stream type\n     * @param mediaType Media type GUID\n     * @returns Media type\n     */\n    static decodeMediaType(mediaType) {\n        switch (mediaType.str) {\n            case GUID.AudioMedia.str: return \'audio\';\n            case GUID.VideoMedia.str: return \'video\';\n            case GUID.CommandMedia.str: return \'command\';\n            case GUID.Degradable_JPEG_Media.str: return \'degradable-jpeg\';\n            case GUID.FileTransferMedia.str: return \'file-transfer\';\n            case GUID.BinaryMedia.str: return \'binary\';\n        }\n    }\n    /**\n     * Encode GUID\n     * @param guid GUID like: "B503BF5F-2EA9-CF11-8EE3-00C00C205365"\n     * @returns Encoded Binary GUID\n     */\n    static encode(str) {\n        const bin = Buffer.alloc(16);\n        bin.writeUInt32LE(parseInt(str.slice(0, 8), 16), 0);\n        bin.writeUInt16LE(parseInt(str.slice(9, 13), 16), 4);\n        bin.writeUInt16LE(parseInt(str.slice(14, 18), 16), 6);\n        Buffer.from(str.slice(19, 23), "hex").copy(bin, 8);\n        Buffer.from(str.slice(24), "hex").copy(bin, 10);\n        return bin;\n    }\n    constructor(str) {\n        this.str = str;\n    }\n    equals(guid) {\n        return this.str === guid.str;\n    }\n    toBin() {\n        return GUID.encode(this.str);\n    }\n}\n// 10.1 Top-level ASF object GUIDs\nGUID.HeaderObject = new GUID("75B22630-668E-11CF-A6D9-00AA0062CE6C");\nGUID.DataObject = new GUID("75B22636-668E-11CF-A6D9-00AA0062CE6C");\nGUID.SimpleIndexObject = new GUID("33000890-E5B1-11CF-89F4-00A0C90349CB");\nGUID.IndexObject = new GUID("D6E229D3-35DA-11D1-9034-00A0C90349BE");\nGUID.MediaObjectIndexObject = new GUID("FEB103F8-12AD-4C64-840F-2A1D2F7AD48C");\nGUID.TimecodeIndexObject = new GUID("3CB73FD0-0C4A-4803-953D-EDF7B6228F0C");\n// 10.2 Header Object GUIDs\nGUID.FilePropertiesObject = new GUID("8CABDCA1-A947-11CF-8EE4-00C00C205365");\nGUID.StreamPropertiesObject = new GUID("B7DC0791-A9B7-11CF-8EE6-00C00C205365");\nGUID.HeaderExtensionObject = new GUID("5FBF03B5-A92E-11CF-8EE3-00C00C205365");\nGUID.CodecListObject = new GUID("86D15240-311D-11D0-A3A4-00A0C90348F6");\nGUID.ScriptCommandObject = new GUID("1EFB1A30-0B62-11D0-A39B-00A0C90348F6");\nGUID.MarkerObject = new GUID("F487CD01-A951-11CF-8EE6-00C00C205365");\nGUID.BitrateMutualExclusionObject = new GUID("D6E229DC-35DA-11D1-9034-00A0C90349BE");\nGUID.ErrorCorrectionObject = new GUID("75B22635-668E-11CF-A6D9-00AA0062CE6C");\nGUID.ContentDescriptionObject = new GUID("75B22633-668E-11CF-A6D9-00AA0062CE6C");\nGUID.ExtendedContentDescriptionObject = new GUID("D2D0A440-E307-11D2-97F0-00A0C95EA850");\nGUID.ContentBrandingObject = new GUID("2211B3FA-BD23-11D2-B4B7-00A0C955FC6E");\nGUID.StreamBitratePropertiesObject = new GUID("7BF875CE-468D-11D1-8D82-006097C9A2B2");\nGUID.ContentEncryptionObject = new GUID("2211B3FB-BD23-11D2-B4B7-00A0C955FC6E");\nGUID.ExtendedContentEncryptionObject = new GUID("298AE614-2622-4C17-B935-DAE07EE9289C");\nGUID.DigitalSignatureObject = new GUID("2211B3FC-BD23-11D2-B4B7-00A0C955FC6E");\nGUID.PaddingObject = new GUID("1806D474-CADF-4509-A4BA-9AABCB96AAE8");\n// 10.3 Header Extension Object GUIDs\nGUID.ExtendedStreamPropertiesObject = new GUID("14E6A5CB-C672-4332-8399-A96952065B5A");\nGUID.AdvancedMutualExclusionObject = new GUID("A08649CF-4775-4670-8A16-6E35357566CD");\nGUID.GroupMutualExclusionObject = new GUID("D1465A40-5A79-4338-B71B-E36B8FD6C249");\nGUID.StreamPrioritizationObject = new GUID("D4FED15B-88D3-454F-81F0-ED5C45999E24");\nGUID.BandwidthSharingObject = new GUID("A69609E6-517B-11D2-B6AF-00C04FD908E9");\nGUID.LanguageListObject = new GUID("7C4346A9-EFE0-4BFC-B229-393EDE415C85");\nGUID.MetadataObject = new GUID("C5F8CBEA-5BAF-4877-8467-AA8C44FA4CCA");\nGUID.MetadataLibraryObject = new GUID("44231C94-9498-49D1-A141-1D134E457054");\nGUID.IndexParametersObject = new GUID("D6E229DF-35DA-11D1-9034-00A0C90349BE");\nGUID.MediaObjectIndexParametersObject = new GUID("6B203BAD-3F11-48E4-ACA8-D7613DE2CFA7");\nGUID.TimecodeIndexParametersObject = new GUID("F55E496D-9797-4B5D-8C8B-604DFE9BFB24");\nGUID.CompatibilityObject = new GUID("26F18B5D-4584-47EC-9F5F-0E651F0452C9");\nGUID.AdvancedContentEncryptionObject = new GUID("43058533-6981-49E6-9B74-AD12CB86D58C");\n// 10.4 Stream Properties Object Stream Type GUIDs\nGUID.AudioMedia = new GUID("F8699E40-5B4D-11CF-A8FD-00805F5C442B");\nGUID.VideoMedia = new GUID("BC19EFC0-5B4D-11CF-A8FD-00805F5C442B");\nGUID.CommandMedia = new GUID("59DACFC0-59E6-11D0-A3AC-00A0C90348F6");\nGUID.JFIF_Media = new GUID("B61BE100-5B4E-11CF-A8FD-00805F5C442B");\nGUID.Degradable_JPEG_Media = new GUID("35907DE0-E415-11CF-A917-00805F5C442B");\nGUID.FileTransferMedia = new GUID("91BD222C-F21C-497A-8B6D-5AA86BFC0185");\nGUID.BinaryMedia = new GUID("3AFB65E2-47EF-40F2-AC2C-70A90D71D343");\nGUID.ASF_Index_Placeholder_Object = new GUID("D9AADE20-7C17-4F9C-BC28-8555DD98E2A2");\nexports["default"] = GUID;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/GUID.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js ***!
  \********************************************************************************************************/function(__unused_webpack_module,exports){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.BasicParser = void 0;\nclass BasicParser {\n    /**\n     * Initialize parser with output (metadata), input (tokenizer) & parsing options (options).\n     * @param {INativeMetadataCollector} metadata Output\n     * @param {ITokenizer} tokenizer Input\n     * @param {IOptions} options Parsing options\n     */\n    init(metadata, tokenizer, options) {\n        this.metadata = metadata;\n        this.tokenizer = tokenizer;\n        this.options = options;\n        return this;\n    }\n}\nexports.BasicParser = BasicParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/CaseInsensitiveTagMap.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/CaseInsensitiveTagMap.js ***!
  \******************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.CaseInsensitiveTagMap = void 0;\nconst GenericTagMapper_1 = __webpack_require__(/*! ./GenericTagMapper */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/GenericTagMapper.js");\nclass CaseInsensitiveTagMap extends GenericTagMapper_1.CommonTagMapper {\n    constructor(tagTypes, tagMap) {\n        const upperCaseMap = {};\n        for (const tag of Object.keys(tagMap)) {\n            upperCaseMap[tag.toUpperCase()] = tagMap[tag];\n        }\n        super(tagTypes, upperCaseMap);\n    }\n    /**\n     * @tag  Native header tag\n     * @return common tag name (alias)\n     */\n    getCommonName(tag) {\n        return this.tagMap[tag.toUpperCase()];\n    }\n}\nexports.CaseInsensitiveTagMap = CaseInsensitiveTagMap;\n//# sourceMappingURL=CaseInsensitiveTagMap.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/CaseInsensitiveTagMap.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/CombinedTagMapper.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/CombinedTagMapper.js ***!
  \**************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.CombinedTagMapper = void 0;\nconst ID3v1TagMap_1 = __webpack_require__(/*! ../id3v1/ID3v1TagMap */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v1/ID3v1TagMap.js");\nconst ID3v24TagMapper_1 = __webpack_require__(/*! ../id3v2/ID3v24TagMapper */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v24TagMapper.js");\nconst AsfTagMapper_1 = __webpack_require__(/*! ../asf/AsfTagMapper */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/asf/AsfTagMapper.js");\nconst ID3v22TagMapper_1 = __webpack_require__(/*! ../id3v2/ID3v22TagMapper */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v22TagMapper.js");\nconst APEv2TagMapper_1 = __webpack_require__(/*! ../apev2/APEv2TagMapper */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2TagMapper.js");\nconst MP4TagMapper_1 = __webpack_require__(/*! ../mp4/MP4TagMapper */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/MP4TagMapper.js");\nconst VorbisTagMapper_1 = __webpack_require__(/*! ../ogg/vorbis/VorbisTagMapper */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisTagMapper.js");\nconst RiffInfoTagMap_1 = __webpack_require__(/*! ../riff/RiffInfoTagMap */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/riff/RiffInfoTagMap.js");\nconst MatroskaTagMapper_1 = __webpack_require__(/*! ../matroska/MatroskaTagMapper */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/MatroskaTagMapper.js");\nconst AiffTagMap_1 = __webpack_require__(/*! ../aiff/AiffTagMap */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/aiff/AiffTagMap.js");\nclass CombinedTagMapper {\n    constructor() {\n        this.tagMappers = {};\n        [\n            new ID3v1TagMap_1.ID3v1TagMapper(),\n            new ID3v22TagMapper_1.ID3v22TagMapper(),\n            new ID3v24TagMapper_1.ID3v24TagMapper(),\n            new MP4TagMapper_1.MP4TagMapper(),\n            new MP4TagMapper_1.MP4TagMapper(),\n            new VorbisTagMapper_1.VorbisTagMapper(),\n            new APEv2TagMapper_1.APEv2TagMapper(),\n            new AsfTagMapper_1.AsfTagMapper(),\n            new RiffInfoTagMap_1.RiffInfoTagMapper(),\n            new MatroskaTagMapper_1.MatroskaTagMapper(),\n            new AiffTagMap_1.AiffTagMapper()\n        ].forEach(mapper => {\n            this.registerTagMapper(mapper);\n        });\n    }\n    /**\n     * Convert native to generic (common) tags\n     * @param tagType Originating tag format\n     * @param tag     Native tag to map to a generic tag id\n     * @param warnings\n     * @return Generic tag result (output of this function)\n     */\n    mapTag(tagType, tag, warnings) {\n        const tagMapper = this.tagMappers[tagType];\n        if (tagMapper) {\n            return this.tagMappers[tagType].mapGenericTag(tag, warnings);\n        }\n        throw new Error(\'No generic tag mapper defined for tag-format: \' + tagType);\n    }\n    registerTagMapper(genericTagMapper) {\n        for (const tagType of genericTagMapper.tagTypes) {\n            this.tagMappers[tagType] = genericTagMapper;\n        }\n    }\n}\nexports.CombinedTagMapper = CombinedTagMapper;\n//# sourceMappingURL=CombinedTagMapper.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/CombinedTagMapper.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js ***!
  \***************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ "./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js")["Buffer"];\n\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.FourCcToken = void 0;\nconst util = __webpack_require__(/*! ./Util */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js");\nconst validFourCC = /^[\\x21-\\x7e][\\x20-\\x7e\\x00()]{3}/;\n/**\n * Token for read FourCC\n * Ref: https://en.wikipedia.org/wiki/FourCC\n */\nexports.FourCcToken = {\n    len: 4,\n    get: (buf, off) => {\n        const id = buf.toString(\'binary\', off, off + exports.FourCcToken.len);\n        if (!id.match(validFourCC)) {\n            throw new Error(`FourCC contains invalid characters: ${util.a2hex(id)} "${id}"`);\n        }\n        return id;\n    },\n    put: (buffer, offset, id) => {\n        const str = Buffer.from(id, \'binary\');\n        if (str.length !== 4)\n            throw new Error(\'Invalid length\');\n        return str.copy(buffer, offset);\n    }\n};\n//# sourceMappingURL=FourCC.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/GenericTagMapper.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/GenericTagMapper.js ***!
  \*************************************************************************************************************/function(__unused_webpack_module,exports){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.CommonTagMapper = void 0;\nclass CommonTagMapper {\n    static toIntOrNull(str) {\n        const cleaned = parseInt(str, 10);\n        return isNaN(cleaned) ? null : cleaned;\n    }\n    // TODO: a string of 1of1 would fail to be converted\n    // converts 1/10 to no : 1, of : 10\n    // or 1 to no : 1, of : 0\n    static normalizeTrack(origVal) {\n        const split = origVal.toString().split(\'/\');\n        return {\n            no: parseInt(split[0], 10) || null,\n            of: parseInt(split[1], 10) || null\n        };\n    }\n    constructor(tagTypes, tagMap) {\n        this.tagTypes = tagTypes;\n        this.tagMap = tagMap;\n    }\n    /**\n     * Process and set common tags\n     * write common tags to\n     * @param tag Native tag\n     * @param warnings Register warnings\n     * @return common name\n     */\n    mapGenericTag(tag, warnings) {\n        tag = { id: tag.id, value: tag.value }; // clone object\n        this.postMap(tag, warnings);\n        // Convert native tag event to generic \'alias\' tag\n        const id = this.getCommonName(tag.id);\n        return id ? { id, value: tag.value } : null;\n    }\n    /**\n     * Convert native tag key to common tag key\n     * @tag  Native header tag\n     * @return common tag name (alias)\n     */\n    getCommonName(tag) {\n        return this.tagMap[tag];\n    }\n    /**\n     * Handle post mapping exceptions / correction\n     * @param tag Tag e.g. {"alb", "Buena Vista Social Club")\n     * @param warnings Used to register warnings\n     */\n    postMap(tag, warnings) {\n        return;\n    }\n}\nCommonTagMapper.maxRatingScore = 1;\nexports.CommonTagMapper = CommonTagMapper;\n//# sourceMappingURL=GenericTagMapper.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/GenericTagMapper.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/GenericTagTypes.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/GenericTagTypes.js ***!
  \************************************************************************************************************/function(__unused_webpack_module,exports){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.isUnique = exports.isSingleton = exports.commonTags = void 0;\nexports.commonTags = {\n    year: { multiple: false },\n    track: { multiple: false },\n    disk: { multiple: false },\n    title: { multiple: false },\n    artist: { multiple: false },\n    artists: { multiple: true, unique: true },\n    albumartist: { multiple: false },\n    album: { multiple: false },\n    date: { multiple: false },\n    originaldate: { multiple: false },\n    originalyear: { multiple: false },\n    comment: { multiple: true, unique: false },\n    genre: { multiple: true, unique: true },\n    picture: { multiple: true, unique: true },\n    composer: { multiple: true, unique: true },\n    lyrics: { multiple: true, unique: false },\n    albumsort: { multiple: false, unique: true },\n    titlesort: { multiple: false, unique: true },\n    work: { multiple: false, unique: true },\n    artistsort: { multiple: false, unique: true },\n    albumartistsort: { multiple: false, unique: true },\n    composersort: { multiple: false, unique: true },\n    lyricist: { multiple: true, unique: true },\n    writer: { multiple: true, unique: true },\n    conductor: { multiple: true, unique: true },\n    remixer: { multiple: true, unique: true },\n    arranger: { multiple: true, unique: true },\n    engineer: { multiple: true, unique: true },\n    producer: { multiple: true, unique: true },\n    technician: { multiple: true, unique: true },\n    djmixer: { multiple: true, unique: true },\n    mixer: { multiple: true, unique: true },\n    label: { multiple: true, unique: true },\n    grouping: { multiple: false },\n    subtitle: { multiple: true },\n    discsubtitle: { multiple: false },\n    totaltracks: { multiple: false },\n    totaldiscs: { multiple: false },\n    compilation: { multiple: false },\n    rating: { multiple: true },\n    bpm: { multiple: false },\n    mood: { multiple: false },\n    media: { multiple: false },\n    catalognumber: { multiple: true, unique: true },\n    tvShow: { multiple: false },\n    tvShowSort: { multiple: false },\n    tvSeason: { multiple: false },\n    tvEpisode: { multiple: false },\n    tvEpisodeId: { multiple: false },\n    tvNetwork: { multiple: false },\n    podcast: { multiple: false },\n    podcasturl: { multiple: false },\n    releasestatus: { multiple: false },\n    releasetype: { multiple: true },\n    releasecountry: { multiple: false },\n    script: { multiple: false },\n    language: { multiple: false },\n    copyright: { multiple: false },\n    license: { multiple: false },\n    encodedby: { multiple: false },\n    encodersettings: { multiple: false },\n    gapless: { multiple: false },\n    barcode: { multiple: false },\n    isrc: { multiple: true },\n    asin: { multiple: false },\n    musicbrainz_recordingid: { multiple: false },\n    musicbrainz_trackid: { multiple: false },\n    musicbrainz_albumid: { multiple: false },\n    musicbrainz_artistid: { multiple: true },\n    musicbrainz_albumartistid: { multiple: true },\n    musicbrainz_releasegroupid: { multiple: false },\n    musicbrainz_workid: { multiple: false },\n    musicbrainz_trmid: { multiple: false },\n    musicbrainz_discid: { multiple: false },\n    acoustid_id: { multiple: false },\n    acoustid_fingerprint: { multiple: false },\n    musicip_puid: { multiple: false },\n    musicip_fingerprint: { multiple: false },\n    website: { multiple: false },\n    'performer:instrument': { multiple: true, unique: true },\n    averageLevel: { multiple: false },\n    peakLevel: { multiple: false },\n    notes: { multiple: true, unique: false },\n    key: { multiple: false },\n    originalalbum: { multiple: false },\n    originalartist: { multiple: false },\n    discogs_artist_id: { multiple: true, unique: true },\n    discogs_release_id: { multiple: false },\n    discogs_label_id: { multiple: false },\n    discogs_master_release_id: { multiple: false },\n    discogs_votes: { multiple: false },\n    discogs_rating: { multiple: false },\n    replaygain_track_peak: { multiple: false },\n    replaygain_track_gain: { multiple: false },\n    replaygain_album_peak: { multiple: false },\n    replaygain_album_gain: { multiple: false },\n    replaygain_track_minmax: { multiple: false },\n    replaygain_album_minmax: { multiple: false },\n    replaygain_undo: { multiple: false },\n    description: { multiple: true },\n    longDescription: { multiple: false },\n    category: { multiple: true },\n    hdVideo: { multiple: false },\n    keywords: { multiple: true },\n    movement: { multiple: false },\n    movementIndex: { multiple: false },\n    movementTotal: { multiple: false },\n    podcastId: { multiple: false },\n    showMovement: { multiple: false },\n    stik: { multiple: false }\n};\n/**\n * @param alias Name of common tag\n * @returns {boolean|*} true if given alias is mapped as a singleton', otherwise false\n */\nfunction isSingleton(alias) {\n    return exports.commonTags.hasOwnProperty(alias) && !exports.commonTags[alias].multiple;\n}\nexports.isSingleton = isSingleton;\n/**\n * @param alias Common (generic) tag\n * @returns {boolean|*} true if given alias is a singleton or explicitly marked as unique\n */\nfunction isUnique(alias) {\n    return !exports.commonTags[alias].multiple || exports.commonTags[alias].unique;\n}\nexports.isUnique = isUnique;\n//# sourceMappingURL=GenericTagTypes.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/GenericTagTypes.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/MetadataCollector.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/MetadataCollector.js ***!
  \**************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.joinArtists = exports.MetadataCollector = void 0;\nconst type_1 = __webpack_require__(/*! ../type */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/type.js\");\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst GenericTagTypes_1 = __webpack_require__(/*! ./GenericTagTypes */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/GenericTagTypes.js\");\nconst CombinedTagMapper_1 = __webpack_require__(/*! ./CombinedTagMapper */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/CombinedTagMapper.js\");\nconst GenericTagMapper_1 = __webpack_require__(/*! ./GenericTagMapper */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/GenericTagMapper.js\");\nconst Util_1 = __webpack_require__(/*! ./Util */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js\");\nconst FileType = __webpack_require__(/*! file-type/core */ \"./node_modules/.pnpm/file-type@16.5.4/node_modules/file-type/core.js\");\nconst debug = (0, debug_1.default)('music-metadata:collector');\nconst TagPriority = ['matroska', 'APEv2', 'vorbis', 'ID3v2.4', 'ID3v2.3', 'ID3v2.2', 'exif', 'asf', 'iTunes', 'AIFF', 'ID3v1'];\n/**\n * Provided to the parser to uodate the metadata result.\n * Responsible for triggering async updates\n */\nclass MetadataCollector {\n    constructor(opts) {\n        this.opts = opts;\n        this.format = {\n            tagTypes: [],\n            trackInfo: []\n        };\n        this.native = {};\n        this.common = {\n            track: { no: null, of: null },\n            disk: { no: null, of: null },\n            movementIndex: {}\n        };\n        this.quality = {\n            warnings: []\n        };\n        /**\n         * Keeps track of origin priority for each mapped id\n         */\n        this.commonOrigin = {};\n        /**\n         * Maps a tag type to a priority\n         */\n        this.originPriority = {};\n        this.tagMapper = new CombinedTagMapper_1.CombinedTagMapper();\n        let priority = 1;\n        for (const tagType of TagPriority) {\n            this.originPriority[tagType] = priority++;\n        }\n        this.originPriority.artificial = 500; // Filled using alternative tags\n        this.originPriority.id3v1 = 600; // Consider as the worst because of the field length limit\n    }\n    /**\n     * @returns {boolean} true if one or more tags have been found\n     */\n    hasAny() {\n        return Object.keys(this.native).length > 0;\n    }\n    addStreamInfo(streamInfo) {\n        debug(`streamInfo: type=${type_1.TrackType[streamInfo.type]}, codec=${streamInfo.codecName}`);\n        this.format.trackInfo.push(streamInfo);\n    }\n    setFormat(key, value) {\n        debug(`format: ${key} = ${value}`);\n        this.format[key] = value; // as any to override readonly\n        if (this.opts.observer) {\n            this.opts.observer({ metadata: this, tag: { type: 'format', id: key, value } });\n        }\n    }\n    addTag(tagType, tagId, value) {\n        debug(`tag ${tagType}.${tagId} = ${value}`);\n        if (!this.native[tagType]) {\n            this.format.tagTypes.push(tagType);\n            this.native[tagType] = [];\n        }\n        this.native[tagType].push({ id: tagId, value });\n        this.toCommon(tagType, tagId, value);\n    }\n    addWarning(warning) {\n        this.quality.warnings.push({ message: warning });\n    }\n    postMap(tagType, tag) {\n        // Common tag (alias) found\n        // check if we need to do something special with common tag\n        // if the event has been aliased then we need to clean it before\n        // it is emitted to the user. e.g. genre (20) -> Electronic\n        switch (tag.id) {\n            case 'artist':\n                if (this.commonOrigin.artist === this.originPriority[tagType]) {\n                    // Assume the artist field is used as artists\n                    return this.postMap('artificial', { id: 'artists', value: tag.value });\n                }\n                if (!this.common.artists) {\n                    // Fill artists using artist source\n                    this.setGenericTag('artificial', { id: 'artists', value: tag.value });\n                }\n                break;\n            case 'artists':\n                if (!this.common.artist || this.commonOrigin.artist === this.originPriority.artificial) {\n                    if (!this.common.artists || this.common.artists.indexOf(tag.value) === -1) {\n                        // Fill artist using artists source\n                        const artists = (this.common.artists || []).concat([tag.value]);\n                        const value = joinArtists(artists);\n                        const artistTag = { id: 'artist', value };\n                        this.setGenericTag('artificial', artistTag);\n                    }\n                }\n                break;\n            case 'picture':\n                this.postFixPicture(tag.value).then(picture => {\n                    if (picture !== null) {\n                        tag.value = picture;\n                        this.setGenericTag(tagType, tag);\n                    }\n                });\n                return;\n            case 'totaltracks':\n                this.common.track.of = GenericTagMapper_1.CommonTagMapper.toIntOrNull(tag.value);\n                return;\n            case 'totaldiscs':\n                this.common.disk.of = GenericTagMapper_1.CommonTagMapper.toIntOrNull(tag.value);\n                return;\n            case 'movementTotal':\n                this.common.movementIndex.of = GenericTagMapper_1.CommonTagMapper.toIntOrNull(tag.value);\n                return;\n            case 'track':\n            case 'disk':\n            case 'movementIndex':\n                const of = this.common[tag.id].of; // store of value, maybe maybe overwritten\n                this.common[tag.id] = GenericTagMapper_1.CommonTagMapper.normalizeTrack(tag.value);\n                this.common[tag.id].of = of != null ? of : this.common[tag.id].of;\n                return;\n            case 'bpm':\n            case 'year':\n            case 'originalyear':\n                tag.value = parseInt(tag.value, 10);\n                break;\n            case 'date':\n                // ToDo: be more strict on 'YYYY...'\n                const year = parseInt(tag.value.substr(0, 4), 10);\n                if (!isNaN(year)) {\n                    this.common.year = year;\n                }\n                break;\n            case 'discogs_label_id':\n            case 'discogs_release_id':\n            case 'discogs_master_release_id':\n            case 'discogs_artist_id':\n            case 'discogs_votes':\n                tag.value = typeof tag.value === 'string' ? parseInt(tag.value, 10) : tag.value;\n                break;\n            case 'replaygain_track_gain':\n            case 'replaygain_track_peak':\n            case 'replaygain_album_gain':\n            case 'replaygain_album_peak':\n                tag.value = (0, Util_1.toRatio)(tag.value);\n                break;\n            case 'replaygain_track_minmax':\n                tag.value = tag.value.split(',').map(v => parseInt(v, 10));\n                break;\n            case 'replaygain_undo':\n                const minMix = tag.value.split(',').map(v => parseInt(v, 10));\n                tag.value = {\n                    leftChannel: minMix[0],\n                    rightChannel: minMix[1]\n                };\n                break;\n            case 'gapless': // iTunes gap-less flag\n            case 'compilation':\n            case 'podcast':\n            case 'showMovement':\n                tag.value = tag.value === '1' || tag.value === 1; // boolean\n                break;\n            case 'isrc': // Only keep unique values\n                if (this.common[tag.id] && this.common[tag.id].indexOf(tag.value) !== -1)\n                    return;\n                break;\n            default:\n            // nothing to do\n        }\n        if (tag.value !== null) {\n            this.setGenericTag(tagType, tag);\n        }\n    }\n    /**\n     * Convert native tags to common tags\n     * @returns {IAudioMetadata} Native + common tags\n     */\n    toCommonMetadata() {\n        return {\n            format: this.format,\n            native: this.native,\n            quality: this.quality,\n            common: this.common\n        };\n    }\n    /**\n     * Fix some common issues with picture object\n     * @param picture Picture\n     */\n    async postFixPicture(picture) {\n        if (picture.data && picture.data.length > 0) {\n            if (!picture.format) {\n                const fileType = await FileType.fromBuffer(picture.data);\n                if (fileType) {\n                    picture.format = fileType.mime;\n                }\n                else {\n                    return null;\n                }\n            }\n            picture.format = picture.format.toLocaleLowerCase();\n            switch (picture.format) {\n                case 'image/jpg':\n                    picture.format = 'image/jpeg'; // ToDo: register warning\n            }\n            return picture;\n        }\n        this.addWarning(`Empty picture tag found`);\n        return null;\n    }\n    /**\n     * Convert native tag to common tags\n     */\n    toCommon(tagType, tagId, value) {\n        const tag = { id: tagId, value };\n        const genericTag = this.tagMapper.mapTag(tagType, tag, this);\n        if (genericTag) {\n            this.postMap(tagType, genericTag);\n        }\n    }\n    /**\n     * Set generic tag\n     */\n    setGenericTag(tagType, tag) {\n        debug(`common.${tag.id} = ${tag.value}`);\n        const prio0 = this.commonOrigin[tag.id] || 1000;\n        const prio1 = this.originPriority[tagType];\n        if ((0, GenericTagTypes_1.isSingleton)(tag.id)) {\n            if (prio1 <= prio0) {\n                this.common[tag.id] = tag.value;\n                this.commonOrigin[tag.id] = prio1;\n            }\n            else {\n                return debug(`Ignore native tag (singleton): ${tagType}.${tag.id} = ${tag.value}`);\n            }\n        }\n        else {\n            if (prio1 === prio0) {\n                if (!(0, GenericTagTypes_1.isUnique)(tag.id) || this.common[tag.id].indexOf(tag.value) === -1) {\n                    this.common[tag.id].push(tag.value);\n                }\n                else {\n                    debug(`Ignore duplicate value: ${tagType}.${tag.id} = ${tag.value}`);\n                }\n                // no effect? this.commonOrigin[tag.id] = prio1;\n            }\n            else if (prio1 < prio0) {\n                this.common[tag.id] = [tag.value];\n                this.commonOrigin[tag.id] = prio1;\n            }\n            else {\n                return debug(`Ignore native tag (list): ${tagType}.${tag.id} = ${tag.value}`);\n            }\n        }\n        if (this.opts.observer) {\n            this.opts.observer({ metadata: this, tag: { type: 'common', id: tag.id, value: tag.value } });\n        }\n        // ToDo: trigger metadata event\n    }\n}\nexports.MetadataCollector = MetadataCollector;\nfunction joinArtists(artists) {\n    if (artists.length > 2) {\n        return artists.slice(0, artists.length - 1).join(', ') + ' & ' + artists[artists.length - 1];\n    }\n    return artists.join(' & ');\n}\nexports.joinArtists = joinArtists;\n//# sourceMappingURL=MetadataCollector.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/MetadataCollector.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/RandomUint8ArrayReader.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/RandomUint8ArrayReader.js ***!
  \*******************************************************************************************************************/function(__unused_webpack_module,exports){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.RandomUint8ArrayReader = void 0;\n/**\n * Provides abstract Uint8Array access via the IRandomRead interface\n */\nclass RandomUint8ArrayReader {\n    constructor(uint8Array) {\n        this.uint8Array = uint8Array;\n        this.fileSize = uint8Array.length;\n    }\n    /**\n     * Read from a given position of an abstracted file or buffer.\n     * @param uint8Array - Uint8Array that the data will be written to.\n     * @param offset - Offset in the buffer to start writing at.\n     * @param length - Integer specifying the number of bytes to read.\n     * @param position - Specifies where to begin reading from in the file.\n     * @return Promise providing bytes read\n     */\n    async randomRead(uint8Array, offset, length, position) {\n        uint8Array.set(this.uint8Array.subarray(position, position + length), offset);\n        return length;\n    }\n}\nexports.RandomUint8ArrayReader = RandomUint8ArrayReader;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/RandomUint8ArrayReader.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js ***!
  \*************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ \"./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js\")[\"Buffer\"];\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.toRatio = exports.dbToRatio = exports.ratioToDb = exports.a2hex = exports.isBitSet = exports.getBitAllignedNumber = exports.stripNulls = exports.decodeString = exports.trimRightNull = exports.findZero = exports.getBit = void 0;\nfunction getBit(buf, off, bit) {\n    return (buf[off] & (1 << bit)) !== 0;\n}\nexports.getBit = getBit;\n/**\n * Found delimiting zero in uint8Array\n * @param uint8Array Uint8Array to find the zero delimiter in\n * @param start Offset in uint8Array\n * @param end Last position to parse in uint8Array\n * @param encoding The string encoding used\n * @return Absolute position on uint8Array where zero found\n */\nfunction findZero(uint8Array, start, end, encoding) {\n    let i = start;\n    if (encoding === 'utf16le') {\n        while (uint8Array[i] !== 0 || uint8Array[i + 1] !== 0) {\n            if (i >= end)\n                return end;\n            i += 2;\n        }\n        return i;\n    }\n    else {\n        while (uint8Array[i] !== 0) {\n            if (i >= end)\n                return end;\n            i++;\n        }\n        return i;\n    }\n}\nexports.findZero = findZero;\nfunction trimRightNull(x) {\n    const pos0 = x.indexOf('\\0');\n    return pos0 === -1 ? x : x.substr(0, pos0);\n}\nexports.trimRightNull = trimRightNull;\nfunction swapBytes(uint8Array) {\n    const l = uint8Array.length;\n    if ((l & 1) !== 0)\n        throw new Error('Buffer length must be even');\n    for (let i = 0; i < l; i += 2) {\n        const a = uint8Array[i];\n        uint8Array[i] = uint8Array[i + 1];\n        uint8Array[i + 1] = a;\n    }\n    return uint8Array;\n}\n/**\n * Decode string\n */\nfunction decodeString(uint8Array, encoding) {\n    // annoying workaround for a double BOM issue\n    // https://github.com/leetreveil/musicmetadata/issues/84\n    if (uint8Array[0] === 0xFF && uint8Array[1] === 0xFE) { // little endian\n        return decodeString(uint8Array.subarray(2), encoding);\n    }\n    else if (encoding === 'utf16le' && uint8Array[0] === 0xFE && uint8Array[1] === 0xFF) {\n        // BOM, indicating big endian decoding\n        if ((uint8Array.length & 1) !== 0)\n            throw new Error('Expected even number of octets for 16-bit unicode string');\n        return decodeString(swapBytes(uint8Array), encoding);\n    }\n    return Buffer.from(uint8Array).toString(encoding);\n}\nexports.decodeString = decodeString;\nfunction stripNulls(str) {\n    str = str.replace(/^\\x00+/g, '');\n    str = str.replace(/\\x00+$/g, '');\n    return str;\n}\nexports.stripNulls = stripNulls;\n/**\n * Read bit-aligned number start from buffer\n * Total offset in bits = byteOffset * 8 + bitOffset\n * @param source Byte buffer\n * @param byteOffset Starting offset in bytes\n * @param bitOffset Starting offset in bits: 0 = lsb\n * @param len Length of number in bits\n * @return Decoded bit aligned number\n */\nfunction getBitAllignedNumber(source, byteOffset, bitOffset, len) {\n    const byteOff = byteOffset + ~~(bitOffset / 8);\n    const bitOff = bitOffset % 8;\n    let value = source[byteOff];\n    value &= 0xff >> bitOff;\n    const bitsRead = 8 - bitOff;\n    const bitsLeft = len - bitsRead;\n    if (bitsLeft < 0) {\n        value >>= (8 - bitOff - len);\n    }\n    else if (bitsLeft > 0) {\n        value <<= bitsLeft;\n        value |= getBitAllignedNumber(source, byteOffset, bitOffset + bitsRead, bitsLeft);\n    }\n    return value;\n}\nexports.getBitAllignedNumber = getBitAllignedNumber;\n/**\n * Read bit-aligned number start from buffer\n * Total offset in bits = byteOffset * 8 + bitOffset\n * @param source Byte Uint8Array\n * @param byteOffset Starting offset in bytes\n * @param bitOffset Starting offset in bits: 0 = most significant bit, 7 is the least significant bit\n * @return True if bit is set\n */\nfunction isBitSet(source, byteOffset, bitOffset) {\n    return getBitAllignedNumber(source, byteOffset, bitOffset, 1) === 1;\n}\nexports.isBitSet = isBitSet;\nfunction a2hex(str) {\n    const arr = [];\n    for (let i = 0, l = str.length; i < l; i++) {\n        const hex = Number(str.charCodeAt(i)).toString(16);\n        arr.push(hex.length === 1 ? '0' + hex : hex);\n    }\n    return arr.join(' ');\n}\nexports.a2hex = a2hex;\n/**\n * Convert power ratio to DB\n * ratio: [0..1]\n */\nfunction ratioToDb(ratio) {\n    return 10 * Math.log10(ratio);\n}\nexports.ratioToDb = ratioToDb;\n/**\n * Convert dB to ratio\n * db Decibels\n */\nfunction dbToRatio(dB) {\n    return Math.pow(10, dB / 10);\n}\nexports.dbToRatio = dbToRatio;\n/**\n * Convert replay gain to ratio and Decibel\n * @param value string holding a ratio like '0.034' or '-7.54 dB'\n */\nfunction toRatio(value) {\n    const ps = value.split(' ').map(p => p.trim().toLowerCase());\n    // @ts-ignore\n    if (ps.length >= 1) {\n        const v = parseFloat(ps[0]);\n        return ps.length === 2 && ps[1] === 'db' ? {\n            dB: v,\n            ratio: dbToRatio(v)\n        } : {\n            dB: ratioToDb(v),\n            ratio: v\n        };\n    }\n}\nexports.toRatio = toRatio;\n//# sourceMappingURL=Util.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/core.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/core.js ***!
  \******************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.scanAppendingHeaders = exports.selectCover = exports.ratingToStars = exports.orderTags = exports.parseFromTokenizer = exports.parseBuffer = exports.parseStream = void 0;\nconst strtok3 = __webpack_require__(/*! strtok3/lib/core */ "./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/core.js");\nconst ParserFactory_1 = __webpack_require__(/*! ./ParserFactory */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ParserFactory.js");\nconst RandomUint8ArrayReader_1 = __webpack_require__(/*! ./common/RandomUint8ArrayReader */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/RandomUint8ArrayReader.js");\nconst APEv2Parser_1 = __webpack_require__(/*! ./apev2/APEv2Parser */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2Parser.js");\nconst ID3v1Parser_1 = __webpack_require__(/*! ./id3v1/ID3v1Parser */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v1/ID3v1Parser.js");\nconst Lyrics3_1 = __webpack_require__(/*! ./lyrics3/Lyrics3 */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/lyrics3/Lyrics3.js");\n/**\n * Parse audio from Node Stream.Readable\n * @param stream - Stream to read the audio track from\n * @param options - Parsing options\n * @param fileInfo - File information object or MIME-type string\n * @returns Metadata\n */\nfunction parseStream(stream, fileInfo, options = {}) {\n    return parseFromTokenizer(strtok3.fromStream(stream, typeof fileInfo === \'string\' ? { mimeType: fileInfo } : fileInfo), options);\n}\nexports.parseStream = parseStream;\n/**\n * Parse audio from Node Buffer\n * @param uint8Array - Uint8Array holding audio data\n * @param fileInfo - File information object or MIME-type string\n * @param options - Parsing options\n * @returns Metadata\n * Ref: https://github.com/Borewit/strtok3/blob/e6938c81ff685074d5eb3064a11c0b03ca934c1d/src/index.ts#L15\n */\nasync function parseBuffer(uint8Array, fileInfo, options = {}) {\n    const bufferReader = new RandomUint8ArrayReader_1.RandomUint8ArrayReader(uint8Array);\n    await scanAppendingHeaders(bufferReader, options);\n    const tokenizer = strtok3.fromBuffer(uint8Array, typeof fileInfo === \'string\' ? { mimeType: fileInfo } : fileInfo);\n    return parseFromTokenizer(tokenizer, options);\n}\nexports.parseBuffer = parseBuffer;\n/**\n * Parse audio from ITokenizer source\n * @param tokenizer - Audio source implementing the tokenizer interface\n * @param options - Parsing options\n * @returns Metadata\n */\nfunction parseFromTokenizer(tokenizer, options) {\n    return ParserFactory_1.ParserFactory.parseOnContentType(tokenizer, options);\n}\nexports.parseFromTokenizer = parseFromTokenizer;\n/**\n * Create a dictionary ordered by their tag id (key)\n * @param nativeTags list of tags\n * @returns tags indexed by id\n */\nfunction orderTags(nativeTags) {\n    const tags = {};\n    for (const tag of nativeTags) {\n        (tags[tag.id] = (tags[tag.id] || [])).push(tag.value);\n    }\n    return tags;\n}\nexports.orderTags = orderTags;\n/**\n * Convert rating to 1-5 star rating\n * @param rating: Normalized rating [0..1] (common.rating[n].rating)\n * @returns Number of stars: 1, 2, 3, 4 or 5 stars\n */\nfunction ratingToStars(rating) {\n    return rating === undefined ? 0 : 1 + Math.round(rating * 4);\n}\nexports.ratingToStars = ratingToStars;\n/**\n * Select most likely cover image.\n * @param pictures Usually metadata.common.picture\n * @return Cover image, if any, otherwise null\n */\nfunction selectCover(pictures) {\n    return pictures ? pictures.reduce((acc, cur) => {\n        if (cur.name && cur.name.toLowerCase() in [\'front\', \'cover\', \'cover (front)\'])\n            return cur;\n        return acc;\n    }) : null;\n}\nexports.selectCover = selectCover;\nasync function scanAppendingHeaders(randomReader, options = {}) {\n    let apeOffset = randomReader.fileSize;\n    if (await (0, ID3v1Parser_1.hasID3v1Header)(randomReader)) {\n        apeOffset -= 128;\n        const lyricsLen = await (0, Lyrics3_1.getLyricsHeaderLength)(randomReader);\n        apeOffset -= lyricsLen;\n    }\n    options.apeHeader = await APEv2Parser_1.APEv2Parser.findApeFooterOffset(randomReader, apeOffset);\n}\nexports.scanAppendingHeaders = scanAppendingHeaders;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/core.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsdiff/DsdiffParser.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsdiff/DsdiffParser.js ***!
  \*********************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DsdiffParser = void 0;\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst strtok3 = __webpack_require__(/*! strtok3/lib/core */ \"./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/core.js\");\nconst FourCC_1 = __webpack_require__(/*! ../common/FourCC */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js\");\nconst BasicParser_1 = __webpack_require__(/*! ../common/BasicParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js\");\nconst ID3v2Parser_1 = __webpack_require__(/*! ../id3v2/ID3v2Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Parser.js\");\nconst DsdiffToken_1 = __webpack_require__(/*! ./DsdiffToken */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsdiff/DsdiffToken.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:aiff');\n/**\n * DSDIFF - Direct Stream Digital Interchange File Format (Phillips)\n *\n * Ref:\n * - http://www.sonicstudio.com/pdf/dsd/DSDIFF_1.5_Spec.pdf\n */\nclass DsdiffParser extends BasicParser_1.BasicParser {\n    async parse() {\n        const header = await this.tokenizer.readToken(DsdiffToken_1.ChunkHeader64);\n        if (header.chunkID !== 'FRM8')\n            throw new Error('Unexpected chunk-ID');\n        const type = (await this.tokenizer.readToken(FourCC_1.FourCcToken)).trim();\n        switch (type) {\n            case 'DSD':\n                this.metadata.setFormat('container', `DSDIFF/${type}`);\n                this.metadata.setFormat('lossless', true);\n                return this.readFmt8Chunks(header.chunkSize - BigInt(FourCC_1.FourCcToken.len));\n            default:\n                throw Error(`Unsupported DSDIFF type: ${type}`);\n        }\n    }\n    async readFmt8Chunks(remainingSize) {\n        while (remainingSize >= DsdiffToken_1.ChunkHeader64.len) {\n            const chunkHeader = await this.tokenizer.readToken(DsdiffToken_1.ChunkHeader64);\n            //  If the data is an odd number of bytes in length, a pad byte must be added at the end\n            debug(`Chunk id=${chunkHeader.chunkID}`);\n            await this.readData(chunkHeader);\n            remainingSize -= (BigInt(DsdiffToken_1.ChunkHeader64.len) + chunkHeader.chunkSize);\n        }\n    }\n    async readData(header) {\n        debug(`Reading data of chunk[ID=${header.chunkID}, size=${header.chunkSize}]`);\n        const p0 = this.tokenizer.position;\n        switch (header.chunkID.trim()) {\n            case 'FVER': // 3.1 FORMAT VERSION CHUNK\n                const version = await this.tokenizer.readToken(Token.UINT32_LE);\n                debug(`DSDIFF version=${version}`);\n                break;\n            case 'PROP': // 3.2 PROPERTY CHUNK\n                const propType = await this.tokenizer.readToken(FourCC_1.FourCcToken);\n                if (propType !== 'SND ')\n                    throw new Error('Unexpected PROP-chunk ID');\n                await this.handleSoundPropertyChunks(header.chunkSize - BigInt(FourCC_1.FourCcToken.len));\n                break;\n            case 'ID3': // Unofficial ID3 tag support\n                const id3_data = await this.tokenizer.readToken(new Token.Uint8ArrayType(Number(header.chunkSize)));\n                const rst = strtok3.fromBuffer(id3_data);\n                await new ID3v2Parser_1.ID3v2Parser().parse(this.metadata, rst, this.options);\n                break;\n            default:\n                debug(`Ignore chunk[ID=${header.chunkID}, size=${header.chunkSize}]`);\n                break;\n            case 'DSD':\n                this.metadata.setFormat('numberOfSamples', Number(header.chunkSize * BigInt(8) / BigInt(this.metadata.format.numberOfChannels)));\n                this.metadata.setFormat('duration', this.metadata.format.numberOfSamples / this.metadata.format.sampleRate);\n                break;\n        }\n        const remaining = header.chunkSize - BigInt(this.tokenizer.position - p0);\n        if (remaining > 0) {\n            debug(`After Parsing chunk, remaining ${remaining} bytes`);\n            await this.tokenizer.ignore(Number(remaining));\n        }\n    }\n    async handleSoundPropertyChunks(remainingSize) {\n        debug(`Parsing sound-property-chunks, remainingSize=${remainingSize}`);\n        while (remainingSize > 0) {\n            const sndPropHeader = await this.tokenizer.readToken(DsdiffToken_1.ChunkHeader64);\n            debug(`Sound-property-chunk[ID=${sndPropHeader.chunkID}, size=${sndPropHeader.chunkSize}]`);\n            const p0 = this.tokenizer.position;\n            switch (sndPropHeader.chunkID.trim()) {\n                case 'FS': // 3.2.1 Sample Rate Chunk\n                    const sampleRate = await this.tokenizer.readToken(Token.UINT32_BE);\n                    this.metadata.setFormat('sampleRate', sampleRate);\n                    break;\n                case 'CHNL': // 3.2.2 Channels Chunk\n                    const numChannels = await this.tokenizer.readToken(Token.UINT16_BE);\n                    this.metadata.setFormat('numberOfChannels', numChannels);\n                    await this.handleChannelChunks(sndPropHeader.chunkSize - BigInt(Token.UINT16_BE.len));\n                    break;\n                case 'CMPR': // 3.2.3 Compression Type Chunk\n                    const compressionIdCode = (await this.tokenizer.readToken(FourCC_1.FourCcToken)).trim();\n                    const count = await this.tokenizer.readToken(Token.UINT8);\n                    const compressionName = await this.tokenizer.readToken(new Token.StringType(count, 'ascii'));\n                    if (compressionIdCode === 'DSD') {\n                        this.metadata.setFormat('lossless', true);\n                        this.metadata.setFormat('bitsPerSample', 1);\n                    }\n                    this.metadata.setFormat('codec', `${compressionIdCode} (${compressionName})`);\n                    break;\n                case 'ABSS': // 3.2.4 Absolute Start Time Chunk\n                    const hours = await this.tokenizer.readToken(Token.UINT16_BE);\n                    const minutes = await this.tokenizer.readToken(Token.UINT8);\n                    const seconds = await this.tokenizer.readToken(Token.UINT8);\n                    const samples = await this.tokenizer.readToken(Token.UINT32_BE);\n                    debug(`ABSS ${hours}:${minutes}:${seconds}.${samples}`);\n                    break;\n                case 'LSCO': // 3.2.5 Loudspeaker Configuration Chunk\n                    const lsConfig = await this.tokenizer.readToken(Token.UINT16_BE);\n                    debug(`LSCO lsConfig=${lsConfig}`);\n                    break;\n                case 'COMT':\n                default:\n                    debug(`Unknown sound-property-chunk[ID=${sndPropHeader.chunkID}, size=${sndPropHeader.chunkSize}]`);\n                    await this.tokenizer.ignore(Number(sndPropHeader.chunkSize));\n            }\n            const remaining = sndPropHeader.chunkSize - BigInt(this.tokenizer.position - p0);\n            if (remaining > 0) {\n                debug(`After Parsing sound-property-chunk ${sndPropHeader.chunkSize}, remaining ${remaining} bytes`);\n                await this.tokenizer.ignore(Number(remaining));\n            }\n            remainingSize -= BigInt(DsdiffToken_1.ChunkHeader64.len) + sndPropHeader.chunkSize;\n            debug(`Parsing sound-property-chunks, remainingSize=${remainingSize}`);\n        }\n        if (this.metadata.format.lossless && this.metadata.format.sampleRate && this.metadata.format.numberOfChannels && this.metadata.format.bitsPerSample) {\n            const bitrate = this.metadata.format.sampleRate * this.metadata.format.numberOfChannels * this.metadata.format.bitsPerSample;\n            this.metadata.setFormat('bitrate', bitrate);\n        }\n    }\n    async handleChannelChunks(remainingSize) {\n        debug(`Parsing channel-chunks, remainingSize=${remainingSize}`);\n        const channels = [];\n        while (remainingSize >= FourCC_1.FourCcToken.len) {\n            const channelId = await this.tokenizer.readToken(FourCC_1.FourCcToken);\n            debug(`Channel[ID=${channelId}]`);\n            channels.push(channelId);\n            remainingSize -= BigInt(FourCC_1.FourCcToken.len);\n        }\n        debug(`Channels: ${channels.join(', ')}`);\n        return channels;\n    }\n}\nexports.DsdiffParser = DsdiffParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsdiff/DsdiffParser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsdiff/DsdiffToken.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsdiff/DsdiffToken.js ***!
  \********************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.ChunkHeader64 = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nconst FourCC_1 = __webpack_require__(/*! ../common/FourCC */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js");\n/**\n * DSDIFF chunk header\n * The data-size encoding is deviating from EA-IFF 85\n * Ref: http://www.sonicstudio.com/pdf/dsd/DSDIFF_1.5_Spec.pdf\n */\nexports.ChunkHeader64 = {\n    len: 12,\n    get: (buf, off) => {\n        return {\n            // Group-ID\n            chunkID: FourCC_1.FourCcToken.get(buf, off),\n            // Size\n            chunkSize: Token.INT64_BE.get(buf, off + 4)\n        };\n    }\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsdiff/DsdiffToken.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsf/DsfChunk.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsf/DsfChunk.js ***!
  \**************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.FormatChunk = exports.ChannelType = exports.DsdChunk = exports.ChunkHeader = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nconst FourCC_1 = __webpack_require__(/*! ../common/FourCC */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js");\n/**\n * Common chunk DSD header: the \'chunk name (Four-CC)\' & chunk size\n */\nexports.ChunkHeader = {\n    len: 12,\n    get: (buf, off) => {\n        return { id: FourCC_1.FourCcToken.get(buf, off), size: Token.UINT64_LE.get(buf, off + 4) };\n    }\n};\n/**\n * Common chunk DSD header: the \'chunk name (Four-CC)\' & chunk size\n */\nexports.DsdChunk = {\n    len: 16,\n    get: (buf, off) => {\n        return {\n            fileSize: Token.INT64_LE.get(buf, off),\n            metadataPointer: Token.INT64_LE.get(buf, off + 8)\n        };\n    }\n};\nvar ChannelType;\n(function (ChannelType) {\n    ChannelType[ChannelType["mono"] = 1] = "mono";\n    ChannelType[ChannelType["stereo"] = 2] = "stereo";\n    ChannelType[ChannelType["channels"] = 3] = "channels";\n    ChannelType[ChannelType["quad"] = 4] = "quad";\n    ChannelType[ChannelType["4 channels"] = 5] = "4 channels";\n    ChannelType[ChannelType["5 channels"] = 6] = "5 channels";\n    ChannelType[ChannelType["5.1 channels"] = 7] = "5.1 channels";\n})(ChannelType = exports.ChannelType || (exports.ChannelType = {}));\n/**\n * Common chunk DSD header: the \'chunk name (Four-CC)\' & chunk size\n */\nexports.FormatChunk = {\n    len: 40,\n    get: (buf, off) => {\n        return {\n            formatVersion: Token.INT32_LE.get(buf, off),\n            formatID: Token.INT32_LE.get(buf, off + 4),\n            channelType: Token.INT32_LE.get(buf, off + 8),\n            channelNum: Token.INT32_LE.get(buf, off + 12),\n            samplingFrequency: Token.INT32_LE.get(buf, off + 16),\n            bitsPerSample: Token.INT32_LE.get(buf, off + 20),\n            sampleCount: Token.INT64_LE.get(buf, off + 24),\n            blockSizePerChannel: Token.INT32_LE.get(buf, off + 32)\n        };\n    }\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsf/DsfChunk.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsf/DsfParser.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsf/DsfParser.js ***!
  \***************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DsfParser = void 0;\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst AbstractID3Parser_1 = __webpack_require__(/*! ../id3v2/AbstractID3Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/AbstractID3Parser.js\");\nconst DsfChunk_1 = __webpack_require__(/*! ./DsfChunk */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsf/DsfChunk.js\");\nconst ID3v2Parser_1 = __webpack_require__(/*! ../id3v2/ID3v2Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Parser.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:DSF');\n/**\n * DSF (dsd stream file) File Parser\n * Ref: https://dsd-guide.com/sites/default/files/white-papers/DSFFileFormatSpec_E.pdf\n */\nclass DsfParser extends AbstractID3Parser_1.AbstractID3Parser {\n    async postId3v2Parse() {\n        const p0 = this.tokenizer.position; // mark start position, normally 0\n        const chunkHeader = await this.tokenizer.readToken(DsfChunk_1.ChunkHeader);\n        if (chunkHeader.id !== 'DSD ')\n            throw new Error('Invalid chunk signature');\n        this.metadata.setFormat('container', 'DSF');\n        this.metadata.setFormat('lossless', true);\n        const dsdChunk = await this.tokenizer.readToken(DsfChunk_1.DsdChunk);\n        if (dsdChunk.metadataPointer === BigInt(0)) {\n            debug(`No ID3v2 tag present`);\n        }\n        else {\n            debug(`expect ID3v2 at offset=${dsdChunk.metadataPointer}`);\n            await this.parseChunks(dsdChunk.fileSize - chunkHeader.size);\n            // Jump to ID3 header\n            await this.tokenizer.ignore(Number(dsdChunk.metadataPointer) - this.tokenizer.position - p0);\n            return new ID3v2Parser_1.ID3v2Parser().parse(this.metadata, this.tokenizer, this.options);\n        }\n    }\n    async parseChunks(bytesRemaining) {\n        while (bytesRemaining >= DsfChunk_1.ChunkHeader.len) {\n            const chunkHeader = await this.tokenizer.readToken(DsfChunk_1.ChunkHeader);\n            debug(`Parsing chunk name=${chunkHeader.id} size=${chunkHeader.size}`);\n            switch (chunkHeader.id) {\n                case 'fmt ':\n                    const formatChunk = await this.tokenizer.readToken(DsfChunk_1.FormatChunk);\n                    this.metadata.setFormat('numberOfChannels', formatChunk.channelNum);\n                    this.metadata.setFormat('sampleRate', formatChunk.samplingFrequency);\n                    this.metadata.setFormat('bitsPerSample', formatChunk.bitsPerSample);\n                    this.metadata.setFormat('numberOfSamples', formatChunk.sampleCount);\n                    this.metadata.setFormat('duration', Number(formatChunk.sampleCount) / formatChunk.samplingFrequency);\n                    const bitrate = formatChunk.bitsPerSample * formatChunk.samplingFrequency * formatChunk.channelNum;\n                    this.metadata.setFormat('bitrate', bitrate);\n                    return; // We got what we want, stop further processing of chunks\n                default:\n                    this.tokenizer.ignore(Number(chunkHeader.size) - DsfChunk_1.ChunkHeader.len);\n                    break;\n            }\n            bytesRemaining -= chunkHeader.size;\n        }\n    }\n}\nexports.DsfParser = DsfParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/dsf/DsfParser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/flac/FlacParser.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/flac/FlacParser.js ***!
  \*****************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.FlacParser = void 0;\nconst token_types_1 = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nconst debug_1 = __webpack_require__(/*! debug */ "./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js");\nconst util = __webpack_require__(/*! ../common/Util */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js");\nconst Vorbis_1 = __webpack_require__(/*! ../ogg/vorbis/Vorbis */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/Vorbis.js");\nconst AbstractID3Parser_1 = __webpack_require__(/*! ../id3v2/AbstractID3Parser */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/AbstractID3Parser.js");\nconst FourCC_1 = __webpack_require__(/*! ../common/FourCC */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js");\nconst VorbisParser_1 = __webpack_require__(/*! ../ogg/vorbis/VorbisParser */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisParser.js");\nconst VorbisDecoder_1 = __webpack_require__(/*! ../ogg/vorbis/VorbisDecoder */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisDecoder.js");\nconst debug = (0, debug_1.default)(\'music-metadata:parser:FLAC\');\n/**\n * FLAC supports up to 128 kinds of metadata blocks; currently the following are defined:\n * ref: https://xiph.org/flac/format.html#metadata_block\n */\nvar BlockType;\n(function (BlockType) {\n    BlockType[BlockType["STREAMINFO"] = 0] = "STREAMINFO";\n    BlockType[BlockType["PADDING"] = 1] = "PADDING";\n    BlockType[BlockType["APPLICATION"] = 2] = "APPLICATION";\n    BlockType[BlockType["SEEKTABLE"] = 3] = "SEEKTABLE";\n    BlockType[BlockType["VORBIS_COMMENT"] = 4] = "VORBIS_COMMENT";\n    BlockType[BlockType["CUESHEET"] = 5] = "CUESHEET";\n    BlockType[BlockType["PICTURE"] = 6] = "PICTURE";\n})(BlockType || (BlockType = {}));\nclass FlacParser extends AbstractID3Parser_1.AbstractID3Parser {\n    constructor() {\n        super(...arguments);\n        this.padding = 0;\n    }\n    /**\n     * Initialize parser with output (metadata), input (tokenizer) & parsing options (options).\n     * @param {INativeMetadataCollector} metadata Output\n     * @param {ITokenizer} tokenizer Input\n     * @param {IOptions} options Parsing options\n     */\n    init(metadata, tokenizer, options) {\n        super.init(metadata, tokenizer, options);\n        this.vorbisParser = new VorbisParser_1.VorbisParser(metadata, options);\n        return this;\n    }\n    async postId3v2Parse() {\n        const fourCC = await this.tokenizer.readToken(FourCC_1.FourCcToken);\n        if (fourCC.toString() !== \'fLaC\') {\n            throw new Error(\'Invalid FLAC preamble\');\n        }\n        let blockHeader;\n        do {\n            // Read block header\n            blockHeader = await this.tokenizer.readToken(Metadata.BlockHeader);\n            // Parse block data\n            await this.parseDataBlock(blockHeader);\n        } while (!blockHeader.lastBlock);\n        if (this.tokenizer.fileInfo.size && this.metadata.format.duration) {\n            const dataSize = this.tokenizer.fileInfo.size - this.tokenizer.position;\n            this.metadata.setFormat(\'bitrate\', 8 * dataSize / this.metadata.format.duration);\n        }\n    }\n    parseDataBlock(blockHeader) {\n        debug(`blockHeader type=${blockHeader.type}, length=${blockHeader.length}`);\n        switch (blockHeader.type) {\n            case BlockType.STREAMINFO:\n                return this.parseBlockStreamInfo(blockHeader.length);\n            case BlockType.PADDING:\n                this.padding += blockHeader.length;\n                break;\n            case BlockType.APPLICATION:\n                break;\n            case BlockType.SEEKTABLE:\n                break;\n            case BlockType.VORBIS_COMMENT:\n                return this.parseComment(blockHeader.length);\n            case BlockType.CUESHEET:\n                break;\n            case BlockType.PICTURE:\n                return this.parsePicture(blockHeader.length).then();\n            default:\n                this.metadata.addWarning(\'Unknown block type: \' + blockHeader.type);\n        }\n        // Ignore data block\n        return this.tokenizer.ignore(blockHeader.length).then();\n    }\n    /**\n     * Parse STREAMINFO\n     */\n    async parseBlockStreamInfo(dataLen) {\n        if (dataLen !== Metadata.BlockStreamInfo.len)\n            throw new Error(\'Unexpected block-stream-info length\');\n        const streamInfo = await this.tokenizer.readToken(Metadata.BlockStreamInfo);\n        this.metadata.setFormat(\'container\', \'FLAC\');\n        this.metadata.setFormat(\'codec\', \'FLAC\');\n        this.metadata.setFormat(\'lossless\', true);\n        this.metadata.setFormat(\'numberOfChannels\', streamInfo.channels);\n        this.metadata.setFormat(\'bitsPerSample\', streamInfo.bitsPerSample);\n        this.metadata.setFormat(\'sampleRate\', streamInfo.sampleRate);\n        if (streamInfo.totalSamples > 0) {\n            this.metadata.setFormat(\'duration\', streamInfo.totalSamples / streamInfo.sampleRate);\n        }\n    }\n    /**\n     * Parse VORBIS_COMMENT\n     * Ref: https://www.xiph.org/vorbis/doc/Vorbis_I_spec.html#x1-640004.2.3\n     */\n    async parseComment(dataLen) {\n        const data = await this.tokenizer.readToken(new token_types_1.Uint8ArrayType(dataLen));\n        const decoder = new VorbisDecoder_1.VorbisDecoder(data, 0);\n        decoder.readStringUtf8(); // vendor (skip)\n        const commentListLength = decoder.readInt32();\n        for (let i = 0; i < commentListLength; i++) {\n            const tag = decoder.parseUserComment();\n            this.vorbisParser.addTag(tag.key, tag.value);\n        }\n    }\n    async parsePicture(dataLen) {\n        if (this.options.skipCovers) {\n            return this.tokenizer.ignore(dataLen);\n        }\n        else {\n            const picture = await this.tokenizer.readToken(new Vorbis_1.VorbisPictureToken(dataLen));\n            this.vorbisParser.addTag(\'METADATA_BLOCK_PICTURE\', picture);\n        }\n    }\n}\nexports.FlacParser = FlacParser;\nclass Metadata {\n}\nMetadata.BlockHeader = {\n    len: 4,\n    get: (buf, off) => {\n        return {\n            lastBlock: util.getBit(buf, off, 7),\n            type: util.getBitAllignedNumber(buf, off, 1, 7),\n            length: token_types_1.UINT24_BE.get(buf, off + 1)\n        };\n    }\n};\n/**\n * METADATA_BLOCK_DATA\n * Ref: https://xiph.org/flac/format.html#metadata_block_streaminfo\n */\nMetadata.BlockStreamInfo = {\n    len: 34,\n    get: (buf, off) => {\n        return {\n            // The minimum block size (in samples) used in the stream.\n            minimumBlockSize: token_types_1.UINT16_BE.get(buf, off),\n            // The maximum block size (in samples) used in the stream.\n            // (Minimum blocksize == maximum blocksize) implies a fixed-blocksize stream.\n            maximumBlockSize: token_types_1.UINT16_BE.get(buf, off + 2) / 1000,\n            // The minimum frame size (in bytes) used in the stream.\n            // May be 0 to imply the value is not known.\n            minimumFrameSize: token_types_1.UINT24_BE.get(buf, off + 4),\n            // The maximum frame size (in bytes) used in the stream.\n            // May be 0 to imply the value is not known.\n            maximumFrameSize: token_types_1.UINT24_BE.get(buf, off + 7),\n            // Sample rate in Hz. Though 20 bits are available,\n            // the maximum sample rate is limited by the structure of frame headers to 655350Hz.\n            // Also, a value of 0 is invalid.\n            sampleRate: token_types_1.UINT24_BE.get(buf, off + 10) >> 4,\n            // probably slower: sampleRate: common.getBitAllignedNumber(buf, off + 10, 0, 20),\n            // (number of channels)-1. FLAC supports from 1 to 8 channels\n            channels: util.getBitAllignedNumber(buf, off + 12, 4, 3) + 1,\n            // bits per sample)-1.\n            // FLAC supports from 4 to 32 bits per sample. Currently the reference encoder and decoders only support up to 24 bits per sample.\n            bitsPerSample: util.getBitAllignedNumber(buf, off + 12, 7, 5) + 1,\n            // Total samples in stream.\n            // \'Samples\' means inter-channel sample, i.e. one second of 44.1Khz audio will have 44100 samples regardless of the number of channels.\n            // A value of zero here means the number of total samples is unknown.\n            totalSamples: util.getBitAllignedNumber(buf, off + 13, 4, 36),\n            // the MD5 hash of the file (see notes for usage... it\'s a littly tricky)\n            fileMD5: new token_types_1.Uint8ArrayType(16).get(buf, off + 18)\n        };\n    }\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/flac/FlacParser.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v1/ID3v1Parser.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v1/ID3v1Parser.js ***!
  \*******************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ \"./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js\")[\"Buffer\"];\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.hasID3v1Header = exports.ID3v1Parser = exports.Genres = void 0;\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst token_types_1 = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst util = __webpack_require__(/*! ../common/Util */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js\");\nconst BasicParser_1 = __webpack_require__(/*! ../common/BasicParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js\");\nconst APEv2Parser_1 = __webpack_require__(/*! ../apev2/APEv2Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2Parser.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:ID3v1');\n/**\n * ID3v1 Genre mappings\n * Ref: https://de.wikipedia.org/wiki/Liste_der_ID3v1-Genres\n */\nexports.Genres = [\n    'Blues', 'Classic Rock', 'Country', 'Dance', 'Disco', 'Funk', 'Grunge', 'Hip-Hop',\n    'Jazz', 'Metal', 'New Age', 'Oldies', 'Other', 'Pop', 'R&B', 'Rap', 'Reggae', 'Rock',\n    'Techno', 'Industrial', 'Alternative', 'Ska', 'Death Metal', 'Pranks', 'Soundtrack',\n    'Euro-Techno', 'Ambient', 'Trip-Hop', 'Vocal', 'Jazz+Funk', 'Fusion', 'Trance',\n    'Classical', 'Instrumental', 'Acid', 'House', 'Game', 'Sound Clip', 'Gospel', 'Noise',\n    'Alt. Rock', 'Bass', 'Soul', 'Punk', 'Space', 'Meditative', 'Instrumental Pop',\n    'Instrumental Rock', 'Ethnic', 'Gothic', 'Darkwave', 'Techno-Industrial',\n    'Electronic', 'Pop-Folk', 'Eurodance', 'Dream', 'Southern Rock', 'Comedy', 'Cult',\n    'Gangsta Rap', 'Top 40', 'Christian Rap', 'Pop/Funk', 'Jungle', 'Native American',\n    'Cabaret', 'New Wave', 'Psychedelic', 'Rave', 'Showtunes', 'Trailer', 'Lo-Fi', 'Tribal',\n    'Acid Punk', 'Acid Jazz', 'Polka', 'Retro', 'Musical', 'Rock & Roll', 'Hard Rock',\n    'Folk', 'Folk/Rock', 'National Folk', 'Swing', 'Fast-Fusion', 'Bebob', 'Latin', 'Revival',\n    'Celtic', 'Bluegrass', 'Avantgarde', 'Gothic Rock', 'Progressive Rock', 'Psychedelic Rock',\n    'Symphonic Rock', 'Slow Rock', 'Big Band', 'Chorus', 'Easy Listening', 'Acoustic', 'Humour',\n    'Speech', 'Chanson', 'Opera', 'Chamber Music', 'Sonata', 'Symphony', 'Booty Bass', 'Primus',\n    'Porn Groove', 'Satire', 'Slow Jam', 'Club', 'Tango', 'Samba', 'Folklore',\n    'Ballad', 'Power Ballad', 'Rhythmic Soul', 'Freestyle', 'Duet', 'Punk Rock', 'Drum Solo',\n    'A Cappella', 'Euro-House', 'Dance Hall', 'Goa', 'Drum & Bass', 'Club-House',\n    'Hardcore', 'Terror', 'Indie', 'BritPop', 'Negerpunk', 'Polsk Punk', 'Beat',\n    'Christian Gangsta Rap', 'Heavy Metal', 'Black Metal', 'Crossover', 'Contemporary Christian',\n    'Christian Rock', 'Merengue', 'Salsa', 'Thrash Metal', 'Anime', 'JPop', 'Synthpop',\n    'Abstract', 'Art Rock', 'Baroque', 'Bhangra', 'Big Beat', 'Breakbeat', 'Chillout',\n    'Downtempo', 'Dub', 'EBM', 'Eclectic', 'Electro', 'Electroclash', 'Emo', 'Experimental',\n    'Garage', 'Global', 'IDM', 'Illbient', 'Industro-Goth', 'Jam Band', 'Krautrock',\n    'Leftfield', 'Lounge', 'Math Rock', 'New Romantic', 'Nu-Breakz', 'Post-Punk', 'Post-Rock',\n    'Psytrance', 'Shoegaze', 'Space Rock', 'Trop Rock', 'World Music', 'Neoclassical', 'Audiobook',\n    'Audio Theatre', 'Neue Deutsche Welle', 'Podcast', 'Indie Rock', 'G-Funk', 'Dubstep',\n    'Garage Rock', 'Psybient'\n];\n/**\n * Spec: http://id3.org/ID3v1\n * Wiki: https://en.wikipedia.org/wiki/ID3\n */\nconst Iid3v1Token = {\n    len: 128,\n    /**\n     * @param buf Buffer possibly holding the 128 bytes ID3v1.1 metadata header\n     * @param off Offset in buffer in bytes\n     * @returns ID3v1.1 header if first 3 bytes equals 'TAG', otherwise null is returned\n     */\n    get: (buf, off) => {\n        const header = new Id3v1StringType(3).get(buf, off);\n        return header === 'TAG' ? {\n            header,\n            title: new Id3v1StringType(30).get(buf, off + 3),\n            artist: new Id3v1StringType(30).get(buf, off + 33),\n            album: new Id3v1StringType(30).get(buf, off + 63),\n            year: new Id3v1StringType(4).get(buf, off + 93),\n            comment: new Id3v1StringType(28).get(buf, off + 97),\n            // ID3v1.1 separator for track\n            zeroByte: token_types_1.UINT8.get(buf, off + 127),\n            // track: ID3v1.1 field added by Michael Mutschler\n            track: token_types_1.UINT8.get(buf, off + 126),\n            genre: token_types_1.UINT8.get(buf, off + 127)\n        } : null;\n    }\n};\nclass Id3v1StringType extends token_types_1.StringType {\n    constructor(len) {\n        super(len, 'binary');\n    }\n    get(buf, off) {\n        let value = super.get(buf, off);\n        value = util.trimRightNull(value);\n        value = value.trim();\n        return value.length > 0 ? value : undefined;\n    }\n}\nclass ID3v1Parser extends BasicParser_1.BasicParser {\n    static getGenre(genreIndex) {\n        if (genreIndex < exports.Genres.length) {\n            return exports.Genres[genreIndex];\n        }\n        return undefined; // ToDO: generate warning\n    }\n    async parse() {\n        if (!this.tokenizer.fileInfo.size) {\n            debug('Skip checking for ID3v1 because the file-size is unknown');\n            return;\n        }\n        if (this.options.apeHeader) {\n            this.tokenizer.ignore(this.options.apeHeader.offset - this.tokenizer.position);\n            const apeParser = new APEv2Parser_1.APEv2Parser();\n            apeParser.init(this.metadata, this.tokenizer, this.options);\n            await apeParser.parseTags(this.options.apeHeader.footer);\n        }\n        const offset = this.tokenizer.fileInfo.size - Iid3v1Token.len;\n        if (this.tokenizer.position > offset) {\n            debug('Already consumed the last 128 bytes');\n            return;\n        }\n        const header = await this.tokenizer.readToken(Iid3v1Token, offset);\n        if (header) {\n            debug('ID3v1 header found at: pos=%s', this.tokenizer.fileInfo.size - Iid3v1Token.len);\n            for (const id of ['title', 'artist', 'album', 'comment', 'track', 'year']) {\n                if (header[id] && header[id] !== '')\n                    this.addTag(id, header[id]);\n            }\n            const genre = ID3v1Parser.getGenre(header.genre);\n            if (genre)\n                this.addTag('genre', genre);\n        }\n        else {\n            debug('ID3v1 header not found at: pos=%s', this.tokenizer.fileInfo.size - Iid3v1Token.len);\n        }\n    }\n    addTag(id, value) {\n        this.metadata.addTag('ID3v1', id, value);\n    }\n}\nexports.ID3v1Parser = ID3v1Parser;\nasync function hasID3v1Header(reader) {\n    if (reader.fileSize >= 128) {\n        const tag = Buffer.alloc(3);\n        await reader.randomRead(tag, 0, tag.length, reader.fileSize - 128);\n        return tag.toString('binary') === 'TAG';\n    }\n    return false;\n}\nexports.hasID3v1Header = hasID3v1Header;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v1/ID3v1Parser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v1/ID3v1TagMap.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v1/ID3v1TagMap.js ***!
  \*******************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ID3v1TagMapper = void 0;\nconst GenericTagMapper_1 = __webpack_require__(/*! ../common/GenericTagMapper */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/GenericTagMapper.js\");\n/**\n * ID3v1 tag mappings\n */\nconst id3v1TagMap = {\n    title: 'title',\n    artist: 'artist',\n    album: 'album',\n    year: 'year',\n    comment: 'comment',\n    track: 'track',\n    genre: 'genre'\n};\nclass ID3v1TagMapper extends GenericTagMapper_1.CommonTagMapper {\n    constructor() {\n        super(['ID3v1'], id3v1TagMap);\n    }\n}\nexports.ID3v1TagMapper = ID3v1TagMapper;\n//# sourceMappingURL=ID3v1TagMap.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v1/ID3v1TagMap.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/AbstractID3Parser.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/AbstractID3Parser.js ***!
  \*************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.AbstractID3Parser = void 0;\nconst core_1 = __webpack_require__(/*! strtok3/lib/core */ "./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/core.js");\nconst debug_1 = __webpack_require__(/*! debug */ "./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js");\nconst ID3v2Token_1 = __webpack_require__(/*! ./ID3v2Token */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Token.js");\nconst ID3v2Parser_1 = __webpack_require__(/*! ./ID3v2Parser */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Parser.js");\nconst ID3v1Parser_1 = __webpack_require__(/*! ../id3v1/ID3v1Parser */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v1/ID3v1Parser.js");\nconst BasicParser_1 = __webpack_require__(/*! ../common/BasicParser */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js");\nconst debug = (0, debug_1.default)(\'music-metadata:parser:ID3\');\n/**\n * Abstract parser which tries take ID3v2 and ID3v1 headers.\n */\nclass AbstractID3Parser extends BasicParser_1.BasicParser {\n    constructor() {\n        super(...arguments);\n        this.id3parser = new ID3v2Parser_1.ID3v2Parser();\n    }\n    static async startsWithID3v2Header(tokenizer) {\n        return (await tokenizer.peekToken(ID3v2Token_1.ID3v2Header)).fileIdentifier === \'ID3\';\n    }\n    async parse() {\n        try {\n            await this.parseID3v2();\n        }\n        catch (err) {\n            if (err instanceof core_1.EndOfStreamError) {\n                debug(`End-of-stream`);\n            }\n            else {\n                throw err;\n            }\n        }\n    }\n    finalize() {\n        return;\n    }\n    async parseID3v2() {\n        await this.tryReadId3v2Headers();\n        debug(\'End of ID3v2 header, go to MPEG-parser: pos=%s\', this.tokenizer.position);\n        await this.postId3v2Parse();\n        if (this.options.skipPostHeaders && this.metadata.hasAny()) {\n            this.finalize();\n        }\n        else {\n            const id3v1parser = new ID3v1Parser_1.ID3v1Parser();\n            await id3v1parser.init(this.metadata, this.tokenizer, this.options).parse();\n            this.finalize();\n        }\n    }\n    async tryReadId3v2Headers() {\n        const id3Header = await this.tokenizer.peekToken(ID3v2Token_1.ID3v2Header);\n        if (id3Header.fileIdentifier === \'ID3\') {\n            debug(\'Found ID3v2 header, pos=%s\', this.tokenizer.position);\n            await this.id3parser.parse(this.metadata, this.tokenizer, this.options);\n            return this.tryReadId3v2Headers();\n        }\n    }\n}\nexports.AbstractID3Parser = AbstractID3Parser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/AbstractID3Parser.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/FrameParser.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/FrameParser.js ***!
  \*******************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ \"./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js\")[\"Buffer\"];\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.FrameParser = exports.parseGenre = void 0;\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst util = __webpack_require__(/*! ../common/Util */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js\");\nconst ID3v2Token_1 = __webpack_require__(/*! ./ID3v2Token */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Token.js\");\nconst ID3v1Parser_1 = __webpack_require__(/*! ../id3v1/ID3v1Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v1/ID3v1Parser.js\");\nconst debug = (0, debug_1.default)('music-metadata:id3v2:frame-parser');\nconst defaultEnc = 'latin1'; // latin1 == iso-8859-1;\nfunction parseGenre(origVal) {\n    // match everything inside parentheses\n    const genres = [];\n    let code;\n    let word = '';\n    for (const c of origVal) {\n        if (typeof code === 'string') {\n            if (c === '(' && code === '') {\n                word += '(';\n                code = undefined;\n            }\n            else if (c === ')') {\n                if (word !== '') {\n                    genres.push(word);\n                    word = '';\n                }\n                const genre = parseGenreCode(code);\n                if (genre) {\n                    genres.push(genre);\n                }\n                code = undefined;\n            }\n            else\n                code += c;\n        }\n        else if (c === '(') {\n            code = '';\n        }\n        else {\n            word += c;\n        }\n    }\n    if (word) {\n        if (genres.length === 0 && word.match(/^\\d*$/)) {\n            word = ID3v1Parser_1.Genres[word];\n        }\n        genres.push(word);\n    }\n    return genres;\n}\nexports.parseGenre = parseGenre;\nfunction parseGenreCode(code) {\n    if (code === 'RX')\n        return 'Remix';\n    if (code === 'CR')\n        return 'Cover';\n    if (code.match(/^\\d*$/)) {\n        return ID3v1Parser_1.Genres[code];\n    }\n}\nclass FrameParser {\n    /**\n     * Create id3v2 frame parser\n     * @param major - Major version, e.g. (4) for  id3v2.4\n     * @param warningCollector - Used to collect decode issue\n     */\n    constructor(major, warningCollector) {\n        this.major = major;\n        this.warningCollector = warningCollector;\n    }\n    readData(uint8Array, type, includeCovers) {\n        if (uint8Array.length === 0) {\n            this.warningCollector.addWarning(`id3v2.${this.major} header has empty tag type=${type}`);\n            return;\n        }\n        const { encoding, bom } = ID3v2Token_1.TextEncodingToken.get(uint8Array, 0);\n        const length = uint8Array.length;\n        let offset = 0;\n        let output = []; // ToDo\n        const nullTerminatorLength = FrameParser.getNullTerminatorLength(encoding);\n        let fzero;\n        const out = {};\n        debug(`Parsing tag type=${type}, encoding=${encoding}, bom=${bom}`);\n        switch (type !== 'TXXX' && type[0] === 'T' ? 'T*' : type) {\n            case 'T*': // 4.2.1. Text information frames - details\n            case 'IPLS': // v2.3: Involved people list\n            case 'MVIN':\n            case 'MVNM':\n            case 'PCS':\n            case 'PCST':\n                let text;\n                try {\n                    text = util.decodeString(uint8Array.slice(1), encoding).replace(/\\x00+$/, '');\n                }\n                catch (error) {\n                    this.warningCollector.addWarning(`id3v2.${this.major} type=${type} header has invalid string value: ${error.message}`);\n                }\n                switch (type) {\n                    case 'TMCL': // Musician credits list\n                    case 'TIPL': // Involved people list\n                    case 'IPLS': // Involved people list\n                        output = this.splitValue(type, text);\n                        output = FrameParser.functionList(output);\n                        break;\n                    case 'TRK':\n                    case 'TRCK':\n                    case 'TPOS':\n                        output = text;\n                        break;\n                    case 'TCOM':\n                    case 'TEXT':\n                    case 'TOLY':\n                    case 'TOPE':\n                    case 'TPE1':\n                    case 'TSRC':\n                        // id3v2.3 defines that TCOM, TEXT, TOLY, TOPE & TPE1 values are separated by /\n                        output = this.splitValue(type, text);\n                        break;\n                    case 'TCO':\n                    case 'TCON':\n                        output = this.splitValue(type, text).map(v => parseGenre(v)).reduce((acc, val) => acc.concat(val), []);\n                        break;\n                    case 'PCS':\n                    case 'PCST':\n                        // TODO: Why `default` not results `1` but `''`?\n                        output = this.major >= 4 ? this.splitValue(type, text) : [text];\n                        output = (Array.isArray(output) && output[0] === '') ? 1 : 0;\n                        break;\n                    default:\n                        output = this.major >= 4 ? this.splitValue(type, text) : [text];\n                }\n                break;\n            case 'TXXX':\n                output = FrameParser.readIdentifierAndData(uint8Array, offset + 1, length, encoding);\n                output = {\n                    description: output.id,\n                    text: this.splitValue(type, util.decodeString(output.data, encoding).replace(/\\x00+$/, ''))\n                };\n                break;\n            case 'PIC':\n            case 'APIC':\n                if (includeCovers) {\n                    const pic = {};\n                    offset += 1;\n                    switch (this.major) {\n                        case 2:\n                            pic.format = util.decodeString(uint8Array.slice(offset, offset + 3), 'latin1'); // 'latin1'; // latin1 == iso-8859-1;\n                            offset += 3;\n                            break;\n                        case 3:\n                        case 4:\n                            fzero = util.findZero(uint8Array, offset, length, defaultEnc);\n                            pic.format = util.decodeString(uint8Array.slice(offset, fzero), defaultEnc);\n                            offset = fzero + 1;\n                            break;\n                        default:\n                            throw new Error('Warning: unexpected major versionIndex: ' + this.major);\n                    }\n                    pic.format = FrameParser.fixPictureMimeType(pic.format);\n                    pic.type = ID3v2Token_1.AttachedPictureType[uint8Array[offset]];\n                    offset += 1;\n                    fzero = util.findZero(uint8Array, offset, length, encoding);\n                    pic.description = util.decodeString(uint8Array.slice(offset, fzero), encoding);\n                    offset = fzero + nullTerminatorLength;\n                    pic.data = Buffer.from(uint8Array.slice(offset, length));\n                    output = pic;\n                }\n                break;\n            case 'CNT':\n            case 'PCNT':\n                output = Token.UINT32_BE.get(uint8Array, 0);\n                break;\n            case 'SYLT':\n                // skip text encoding (1 byte),\n                //      language (3 bytes),\n                //      time stamp format (1 byte),\n                //      content tagTypes (1 byte),\n                //      content descriptor (1 byte)\n                offset += 7;\n                output = [];\n                while (offset < length) {\n                    const txt = uint8Array.slice(offset, offset = util.findZero(uint8Array, offset, length, encoding));\n                    offset += 5; // push offset forward one +  4 byte timestamp\n                    output.push(util.decodeString(txt, encoding));\n                }\n                break;\n            case 'ULT':\n            case 'USLT':\n            case 'COM':\n            case 'COMM':\n                offset += 1;\n                out.language = util.decodeString(uint8Array.slice(offset, offset + 3), defaultEnc);\n                offset += 3;\n                fzero = util.findZero(uint8Array, offset, length, encoding);\n                out.description = util.decodeString(uint8Array.slice(offset, fzero), encoding);\n                offset = fzero + nullTerminatorLength;\n                out.text = util.decodeString(uint8Array.slice(offset, length), encoding).replace(/\\x00+$/, '');\n                output = [out];\n                break;\n            case 'UFID':\n                output = FrameParser.readIdentifierAndData(uint8Array, offset, length, defaultEnc);\n                output = { owner_identifier: output.id, identifier: output.data };\n                break;\n            case 'PRIV': // private frame\n                output = FrameParser.readIdentifierAndData(uint8Array, offset, length, defaultEnc);\n                output = { owner_identifier: output.id, data: output.data };\n                break;\n            case 'POPM': // Popularimeter\n                fzero = util.findZero(uint8Array, offset, length, defaultEnc);\n                const email = util.decodeString(uint8Array.slice(offset, fzero), defaultEnc);\n                offset = fzero + 1;\n                const dataLen = length - offset;\n                output = {\n                    email,\n                    rating: Token.UINT8.get(uint8Array, offset),\n                    counter: dataLen >= 5 ? Token.UINT32_BE.get(uint8Array, offset + 1) : undefined\n                };\n                break;\n            case 'GEOB': { // General encapsulated object\n                fzero = util.findZero(uint8Array, offset + 1, length, encoding);\n                const mimeType = util.decodeString(uint8Array.slice(offset + 1, fzero), defaultEnc);\n                offset = fzero + 1;\n                fzero = util.findZero(uint8Array, offset, length - offset, encoding);\n                const filename = util.decodeString(uint8Array.slice(offset, fzero), defaultEnc);\n                offset = fzero + 1;\n                fzero = util.findZero(uint8Array, offset, length - offset, encoding);\n                const description = util.decodeString(uint8Array.slice(offset, fzero), defaultEnc);\n                output = {\n                    type: mimeType,\n                    filename,\n                    description,\n                    data: uint8Array.slice(offset + 1, length)\n                };\n                break;\n            }\n            // W-Frames:\n            case 'WCOM':\n            case 'WCOP':\n            case 'WOAF':\n            case 'WOAR':\n            case 'WOAS':\n            case 'WORS':\n            case 'WPAY':\n            case 'WPUB':\n                // Decode URL\n                output = util.decodeString(uint8Array.slice(offset, fzero), defaultEnc);\n                break;\n            case 'WXXX': {\n                // Decode URL\n                fzero = util.findZero(uint8Array, offset + 1, length, encoding);\n                const description = util.decodeString(uint8Array.slice(offset + 1, fzero), encoding);\n                offset = fzero + (encoding === 'utf16le' ? 2 : 1);\n                output = { description, url: util.decodeString(uint8Array.slice(offset, length), defaultEnc) };\n                break;\n            }\n            case 'WFD':\n            case 'WFED':\n                output = util.decodeString(uint8Array.slice(offset + 1, util.findZero(uint8Array, offset + 1, length, encoding)), encoding);\n                break;\n            case 'MCDI': {\n                // Music CD identifier\n                output = uint8Array.slice(0, length);\n                break;\n            }\n            default:\n                debug('Warning: unsupported id3v2-tag-type: ' + type);\n                break;\n        }\n        return output;\n    }\n    static fixPictureMimeType(pictureType) {\n        pictureType = pictureType.toLocaleLowerCase();\n        switch (pictureType) {\n            case 'jpg':\n                return 'image/jpeg';\n            case 'png':\n                return 'image/png';\n        }\n        return pictureType;\n    }\n    /**\n     * Converts TMCL (Musician credits list) or TIPL (Involved people list)\n     * @param entries\n     */\n    static functionList(entries) {\n        const res = {};\n        for (let i = 0; i + 1 < entries.length; i += 2) {\n            const names = entries[i + 1].split(',');\n            res[entries[i]] = res.hasOwnProperty(entries[i]) ? res[entries[i]].concat(names) : names;\n        }\n        return res;\n    }\n    /**\n     * id3v2.4 defines that multiple T* values are separated by 0x00\n     * id3v2.3 defines that TCOM, TEXT, TOLY, TOPE & TPE1 values are separated by /\n     * @param tag - Tag name\n     * @param text - Concatenated tag value\n     * @returns Split tag value\n     */\n    splitValue(tag, text) {\n        let values;\n        if (this.major < 4) {\n            values = text.split(/\\x00/g);\n            if (values.length > 1) {\n                this.warningCollector.addWarning(`ID3v2.${this.major} ${tag} uses non standard null-separator.`);\n            }\n            else {\n                values = text.split(/\\//g);\n            }\n        }\n        else {\n            values = text.split(/\\x00/g);\n        }\n        return FrameParser.trimArray(values);\n    }\n    static trimArray(values) {\n        return values.map(value => value.replace(/\\x00+$/, '').trim());\n    }\n    static readIdentifierAndData(uint8Array, offset, length, encoding) {\n        const fzero = util.findZero(uint8Array, offset, length, encoding);\n        const id = util.decodeString(uint8Array.slice(offset, fzero), encoding);\n        offset = fzero + FrameParser.getNullTerminatorLength(encoding);\n        return { id, data: uint8Array.slice(offset, length) };\n    }\n    static getNullTerminatorLength(enc) {\n        return enc === 'utf16le' ? 2 : 1;\n    }\n}\nexports.FrameParser = FrameParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/FrameParser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v22TagMapper.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v22TagMapper.js ***!
  \***********************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ID3v22TagMapper = exports.id3v22TagMap = void 0;\nconst CaseInsensitiveTagMap_1 = __webpack_require__(/*! ../common/CaseInsensitiveTagMap */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/CaseInsensitiveTagMap.js\");\n/**\n * ID3v2.2 tag mappings\n */\nexports.id3v22TagMap = {\n    TT2: 'title',\n    TP1: 'artist',\n    TP2: 'albumartist',\n    TAL: 'album',\n    TYE: 'year',\n    COM: 'comment',\n    TRK: 'track',\n    TPA: 'disk',\n    TCO: 'genre',\n    PIC: 'picture',\n    TCM: 'composer',\n    TOR: 'originaldate',\n    TOT: 'originalalbum',\n    TXT: 'lyricist',\n    TP3: 'conductor',\n    TPB: 'label',\n    TT1: 'grouping',\n    TT3: 'subtitle',\n    TLA: 'language',\n    TCR: 'copyright',\n    WCP: 'license',\n    TEN: 'encodedby',\n    TSS: 'encodersettings',\n    WAR: 'website',\n    'COM:iTunPGAP': 'gapless'\n    /* ToDo: iTunes tags:\n    'COM:iTunNORM': ,\n    'COM:iTunSMPB': 'encoder delay',\n    'COM:iTunes_CDDB_IDs'\n    */ ,\n    PCS: 'podcast',\n    TCP: \"compilation\",\n    TDR: 'date',\n    TS2: 'albumartistsort',\n    TSA: 'albumsort',\n    TSC: 'composersort',\n    TSP: 'artistsort',\n    TST: 'titlesort',\n    WFD: 'podcasturl',\n    TBP: 'bpm'\n};\nclass ID3v22TagMapper extends CaseInsensitiveTagMap_1.CaseInsensitiveTagMap {\n    constructor() {\n        super(['ID3v2.2'], exports.id3v22TagMap);\n    }\n}\nexports.ID3v22TagMapper = ID3v22TagMapper;\n//# sourceMappingURL=ID3v22TagMapper.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v22TagMapper.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v24TagMapper.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v24TagMapper.js ***!
  \***********************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ID3v24TagMapper = void 0;\nconst GenericTagMapper_1 = __webpack_require__(/*! ../common/GenericTagMapper */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/GenericTagMapper.js\");\nconst CaseInsensitiveTagMap_1 = __webpack_require__(/*! ../common/CaseInsensitiveTagMap */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/CaseInsensitiveTagMap.js\");\nconst util = __webpack_require__(/*! ../common/Util */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js\");\n/**\n * ID3v2.3/ID3v2.4 tag mappings\n */\nconst id3v24TagMap = {\n    // id3v2.3\n    TIT2: 'title',\n    TPE1: 'artist',\n    'TXXX:Artists': 'artists',\n    TPE2: 'albumartist',\n    TALB: 'album',\n    TDRV: 'date',\n    /**\n     * Original release year\n     */\n    TORY: 'originalyear',\n    TPOS: 'disk',\n    TCON: 'genre',\n    APIC: 'picture',\n    TCOM: 'composer',\n    'USLT:description': 'lyrics',\n    TSOA: 'albumsort',\n    TSOT: 'titlesort',\n    TOAL: 'originalalbum',\n    TSOP: 'artistsort',\n    TSO2: 'albumartistsort',\n    TSOC: 'composersort',\n    TEXT: 'lyricist',\n    'TXXX:Writer': 'writer',\n    TPE3: 'conductor',\n    // 'IPLS:instrument': 'performer:instrument', // ToDo\n    TPE4: 'remixer',\n    'IPLS:arranger': 'arranger',\n    'IPLS:engineer': 'engineer',\n    'IPLS:producer': 'producer',\n    'IPLS:DJ-mix': 'djmixer',\n    'IPLS:mix': 'mixer',\n    TPUB: 'label',\n    TIT1: 'grouping',\n    TIT3: 'subtitle',\n    TRCK: 'track',\n    TCMP: 'compilation',\n    POPM: 'rating',\n    TBPM: 'bpm',\n    TMED: 'media',\n    'TXXX:CATALOGNUMBER': 'catalognumber',\n    'TXXX:MusicBrainz Album Status': 'releasestatus',\n    'TXXX:MusicBrainz Album Type': 'releasetype',\n    /**\n     * Release country as documented: https://picard.musicbrainz.org/docs/mappings/#cite_note-0\n     */\n    'TXXX:MusicBrainz Album Release Country': 'releasecountry',\n    /**\n     * Release country as implemented // ToDo: report\n     */\n    'TXXX:RELEASECOUNTRY': 'releasecountry',\n    'TXXX:SCRIPT': 'script',\n    TLAN: 'language',\n    TCOP: 'copyright',\n    WCOP: 'license',\n    TENC: 'encodedby',\n    TSSE: 'encodersettings',\n    'TXXX:BARCODE': 'barcode',\n    'TXXX:ISRC': 'isrc',\n    TSRC: 'isrc',\n    'TXXX:ASIN': 'asin',\n    'TXXX:originalyear': 'originalyear',\n    'UFID:http://musicbrainz.org': 'musicbrainz_recordingid',\n    'TXXX:MusicBrainz Release Track Id': 'musicbrainz_trackid',\n    'TXXX:MusicBrainz Album Id': 'musicbrainz_albumid',\n    'TXXX:MusicBrainz Artist Id': 'musicbrainz_artistid',\n    'TXXX:MusicBrainz Album Artist Id': 'musicbrainz_albumartistid',\n    'TXXX:MusicBrainz Release Group Id': 'musicbrainz_releasegroupid',\n    'TXXX:MusicBrainz Work Id': 'musicbrainz_workid',\n    'TXXX:MusicBrainz TRM Id': 'musicbrainz_trmid',\n    'TXXX:MusicBrainz Disc Id': 'musicbrainz_discid',\n    'TXXX:ACOUSTID_ID': 'acoustid_id',\n    'TXXX:Acoustid Id': 'acoustid_id',\n    'TXXX:Acoustid Fingerprint': 'acoustid_fingerprint',\n    'TXXX:MusicIP PUID': 'musicip_puid',\n    'TXXX:MusicMagic Fingerprint': 'musicip_fingerprint',\n    WOAR: 'website',\n    // id3v2.4\n    // ToDo: In same sequence as defined at http://id3.org/id3v2.4.0-frames\n    TDRC: 'date',\n    TYER: 'year',\n    TDOR: 'originaldate',\n    // 'TMCL:instrument': 'performer:instrument',\n    'TIPL:arranger': 'arranger',\n    'TIPL:engineer': 'engineer',\n    'TIPL:producer': 'producer',\n    'TIPL:DJ-mix': 'djmixer',\n    'TIPL:mix': 'mixer',\n    TMOO: 'mood',\n    // additional mappings:\n    SYLT: 'lyrics',\n    TSST: 'discsubtitle',\n    TKEY: 'key',\n    COMM: 'comment',\n    TOPE: 'originalartist',\n    // Windows Media Player\n    'PRIV:AverageLevel': 'averageLevel',\n    'PRIV:PeakLevel': 'peakLevel',\n    // Discogs\n    'TXXX:DISCOGS_ARTIST_ID': 'discogs_artist_id',\n    'TXXX:DISCOGS_ARTISTS': 'artists',\n    'TXXX:DISCOGS_ARTIST_NAME': 'artists',\n    'TXXX:DISCOGS_ALBUM_ARTISTS': 'albumartist',\n    'TXXX:DISCOGS_CATALOG': 'catalognumber',\n    'TXXX:DISCOGS_COUNTRY': 'releasecountry',\n    'TXXX:DISCOGS_DATE': 'originaldate',\n    'TXXX:DISCOGS_LABEL': 'label',\n    'TXXX:DISCOGS_LABEL_ID': 'discogs_label_id',\n    'TXXX:DISCOGS_MASTER_RELEASE_ID': 'discogs_master_release_id',\n    'TXXX:DISCOGS_RATING': 'discogs_rating',\n    'TXXX:DISCOGS_RELEASED': 'date',\n    'TXXX:DISCOGS_RELEASE_ID': 'discogs_release_id',\n    'TXXX:DISCOGS_VOTES': 'discogs_votes',\n    'TXXX:CATALOGID': 'catalognumber',\n    'TXXX:STYLE': 'genre',\n    'TXXX:REPLAYGAIN_TRACK_PEAK': 'replaygain_track_peak',\n    'TXXX:REPLAYGAIN_TRACK_GAIN': 'replaygain_track_gain',\n    'TXXX:REPLAYGAIN_ALBUM_PEAK': 'replaygain_album_peak',\n    'TXXX:REPLAYGAIN_ALBUM_GAIN': 'replaygain_album_gain',\n    'TXXX:MP3GAIN_MINMAX': 'replaygain_track_minmax',\n    'TXXX:MP3GAIN_ALBUM_MINMAX': 'replaygain_album_minmax',\n    'TXXX:MP3GAIN_UNDO': 'replaygain_undo',\n    MVNM: 'movement',\n    MVIN: 'movementIndex',\n    PCST: 'podcast',\n    TCAT: 'category',\n    TDES: 'description',\n    TDRL: 'date',\n    TGID: 'podcastId',\n    TKWD: 'keywords',\n    WFED: 'podcasturl'\n};\nclass ID3v24TagMapper extends CaseInsensitiveTagMap_1.CaseInsensitiveTagMap {\n    static toRating(popm) {\n        return {\n            source: popm.email,\n            rating: popm.rating > 0 ? (popm.rating - 1) / 254 * GenericTagMapper_1.CommonTagMapper.maxRatingScore : undefined\n        };\n    }\n    constructor() {\n        super(['ID3v2.3', 'ID3v2.4'], id3v24TagMap);\n    }\n    /**\n     * Handle post mapping exceptions / correction\n     * @param tag to post map\n     * @param warnings Wil be used to register (collect) warnings\n     * @return Common value e.g. \"Buena Vista Social Club\"\n     */\n    postMap(tag, warnings) {\n        switch (tag.id) {\n            case 'UFID': // decode MusicBrainz Recording Id\n                if (tag.value.owner_identifier === 'http://musicbrainz.org') {\n                    tag.id += ':' + tag.value.owner_identifier;\n                    tag.value = util.decodeString(tag.value.identifier, 'latin1'); // latin1 == iso-8859-1\n                }\n                break;\n            case 'PRIV':\n                switch (tag.value.owner_identifier) {\n                    // decode Windows Media Player\n                    case 'AverageLevel':\n                    case 'PeakValue':\n                        tag.id += ':' + tag.value.owner_identifier;\n                        tag.value = tag.value.data.length === 4 ? tag.value.data.readUInt32LE(0) : null;\n                        if (tag.value === null) {\n                            warnings.addWarning(`Failed to parse PRIV:PeakValue`);\n                        }\n                        break;\n                    default:\n                        warnings.addWarning(`Unknown PRIV owner-identifier: ${tag.value.owner_identifier}`);\n                }\n                break;\n            case 'COMM':\n                tag.value = tag.value ? tag.value.text : null;\n                break;\n            case 'POPM':\n                tag.value = ID3v24TagMapper.toRating(tag.value);\n                break;\n            default:\n                break;\n        }\n    }\n}\nexports.ID3v24TagMapper = ID3v24TagMapper;\n//# sourceMappingURL=ID3v24TagMapper.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v24TagMapper.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Parser.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Parser.js ***!
  \*******************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ \"./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js\")[\"Buffer\"];\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ID3v2Parser = void 0;\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst util = __webpack_require__(/*! ../common/Util */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js\");\nconst FrameParser_1 = __webpack_require__(/*! ./FrameParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/FrameParser.js\");\nconst ID3v2Token_1 = __webpack_require__(/*! ./ID3v2Token */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Token.js\");\nclass ID3v2Parser {\n    static removeUnsyncBytes(buffer) {\n        let readI = 0;\n        let writeI = 0;\n        while (readI < buffer.length - 1) {\n            if (readI !== writeI) {\n                buffer[writeI] = buffer[readI];\n            }\n            readI += (buffer[readI] === 0xFF && buffer[readI + 1] === 0) ? 2 : 1;\n            writeI++;\n        }\n        if (readI < buffer.length) {\n            buffer[writeI++] = buffer[readI];\n        }\n        return buffer.slice(0, writeI);\n    }\n    static getFrameHeaderLength(majorVer) {\n        switch (majorVer) {\n            case 2:\n                return 6;\n            case 3:\n            case 4:\n                return 10;\n            default:\n                throw new Error('header versionIndex is incorrect');\n        }\n    }\n    static readFrameFlags(b) {\n        return {\n            status: {\n                tag_alter_preservation: util.getBit(b, 0, 6),\n                file_alter_preservation: util.getBit(b, 0, 5),\n                read_only: util.getBit(b, 0, 4)\n            },\n            format: {\n                grouping_identity: util.getBit(b, 1, 7),\n                compression: util.getBit(b, 1, 3),\n                encryption: util.getBit(b, 1, 2),\n                unsynchronisation: util.getBit(b, 1, 1),\n                data_length_indicator: util.getBit(b, 1, 0)\n            }\n        };\n    }\n    static readFrameData(uint8Array, frameHeader, majorVer, includeCovers, warningCollector) {\n        const frameParser = new FrameParser_1.FrameParser(majorVer, warningCollector);\n        switch (majorVer) {\n            case 2:\n                return frameParser.readData(uint8Array, frameHeader.id, includeCovers);\n            case 3:\n            case 4:\n                if (frameHeader.flags.format.unsynchronisation) {\n                    uint8Array = ID3v2Parser.removeUnsyncBytes(uint8Array);\n                }\n                if (frameHeader.flags.format.data_length_indicator) {\n                    uint8Array = uint8Array.slice(4, uint8Array.length);\n                }\n                return frameParser.readData(uint8Array, frameHeader.id, includeCovers);\n            default:\n                throw new Error('Unexpected majorVer: ' + majorVer);\n        }\n    }\n    /**\n     * Create a combined tag key, of tag & description\n     * @param tag e.g.: COM\n     * @param description e.g. iTunPGAP\n     * @returns string e.g. COM:iTunPGAP\n     */\n    static makeDescriptionTagName(tag, description) {\n        return tag + (description ? ':' + description : '');\n    }\n    async parse(metadata, tokenizer, options) {\n        this.tokenizer = tokenizer;\n        this.metadata = metadata;\n        this.options = options;\n        const id3Header = await this.tokenizer.readToken(ID3v2Token_1.ID3v2Header);\n        if (id3Header.fileIdentifier !== 'ID3') {\n            throw new Error('expected ID3-header file-identifier \\'ID3\\' was not found');\n        }\n        this.id3Header = id3Header;\n        this.headerType = ('ID3v2.' + id3Header.version.major);\n        return id3Header.flags.isExtendedHeader ? this.parseExtendedHeader() : this.parseId3Data(id3Header.size);\n    }\n    async parseExtendedHeader() {\n        const extendedHeader = await this.tokenizer.readToken(ID3v2Token_1.ExtendedHeader);\n        const dataRemaining = extendedHeader.size - ID3v2Token_1.ExtendedHeader.len;\n        return dataRemaining > 0 ? this.parseExtendedHeaderData(dataRemaining, extendedHeader.size) : this.parseId3Data(this.id3Header.size - extendedHeader.size);\n    }\n    async parseExtendedHeaderData(dataRemaining, extendedHeaderSize) {\n        await this.tokenizer.ignore(dataRemaining);\n        return this.parseId3Data(this.id3Header.size - extendedHeaderSize);\n    }\n    async parseId3Data(dataLen) {\n        const uint8Array = await this.tokenizer.readToken(new Token.Uint8ArrayType(dataLen));\n        for (const tag of this.parseMetadata(uint8Array)) {\n            if (tag.id === 'TXXX') {\n                if (tag.value) {\n                    for (const text of tag.value.text) {\n                        this.addTag(ID3v2Parser.makeDescriptionTagName(tag.id, tag.value.description), text);\n                    }\n                }\n            }\n            else if (tag.id === 'COM') {\n                for (const value of tag.value) {\n                    this.addTag(ID3v2Parser.makeDescriptionTagName(tag.id, value.description), value.text);\n                }\n            }\n            else if (tag.id === 'COMM') {\n                for (const value of tag.value) {\n                    this.addTag(ID3v2Parser.makeDescriptionTagName(tag.id, value.description), value);\n                }\n            }\n            else if (Array.isArray(tag.value)) {\n                for (const value of tag.value) {\n                    this.addTag(tag.id, value);\n                }\n            }\n            else {\n                this.addTag(tag.id, tag.value);\n            }\n        }\n    }\n    addTag(id, value) {\n        this.metadata.addTag(this.headerType, id, value);\n    }\n    parseMetadata(data) {\n        let offset = 0;\n        const tags = [];\n        while (true) {\n            if (offset === data.length)\n                break;\n            const frameHeaderLength = ID3v2Parser.getFrameHeaderLength(this.id3Header.version.major);\n            if (offset + frameHeaderLength > data.length) {\n                this.metadata.addWarning('Illegal ID3v2 tag length');\n                break;\n            }\n            const frameHeaderBytes = data.slice(offset, offset += frameHeaderLength);\n            const frameHeader = this.readFrameHeader(frameHeaderBytes, this.id3Header.version.major);\n            const frameDataBytes = data.slice(offset, offset += frameHeader.length);\n            const values = ID3v2Parser.readFrameData(frameDataBytes, frameHeader, this.id3Header.version.major, !this.options.skipCovers, this.metadata);\n            if (values) {\n                tags.push({ id: frameHeader.id, value: values });\n            }\n        }\n        return tags;\n    }\n    readFrameHeader(uint8Array, majorVer) {\n        let header;\n        switch (majorVer) {\n            case 2:\n                header = {\n                    id: Buffer.from(uint8Array.slice(0, 3)).toString('ascii'),\n                    length: Token.UINT24_BE.get(uint8Array, 3)\n                };\n                if (!header.id.match(/[A-Z0-9]{3}/g)) {\n                    this.metadata.addWarning(`Invalid ID3v2.${this.id3Header.version.major} frame-header-ID: ${header.id}`);\n                }\n                break;\n            case 3:\n            case 4:\n                header = {\n                    id: Buffer.from(uint8Array.slice(0, 4)).toString('ascii'),\n                    length: (majorVer === 4 ? ID3v2Token_1.UINT32SYNCSAFE : Token.UINT32_BE).get(uint8Array, 4),\n                    flags: ID3v2Parser.readFrameFlags(uint8Array.slice(8, 10))\n                };\n                if (!header.id.match(/[A-Z0-9]{4}/g)) {\n                    this.metadata.addWarning(`Invalid ID3v2.${this.id3Header.version.major} frame-header-ID: ${header.id}`);\n                }\n                break;\n            default:\n                throw new Error('Unexpected majorVer: ' + majorVer);\n        }\n        return header;\n    }\n}\nexports.ID3v2Parser = ID3v2Parser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Parser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Token.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Token.js ***!
  \******************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.TextEncodingToken = exports.ExtendedHeader = exports.ID3v2Header = exports.UINT32SYNCSAFE = exports.AttachedPictureType = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nconst util = __webpack_require__(/*! ../common/Util */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js");\n/**\n * The picture type according to the ID3v2 APIC frame\n * Ref: http://id3.org/id3v2.3.0#Attached_picture\n */\nvar AttachedPictureType;\n(function (AttachedPictureType) {\n    AttachedPictureType[AttachedPictureType["Other"] = 0] = "Other";\n    AttachedPictureType[AttachedPictureType["32x32 pixels \'file icon\' (PNG only)"] = 1] = "32x32 pixels \'file icon\' (PNG only)";\n    AttachedPictureType[AttachedPictureType["Other file icon"] = 2] = "Other file icon";\n    AttachedPictureType[AttachedPictureType["Cover (front)"] = 3] = "Cover (front)";\n    AttachedPictureType[AttachedPictureType["Cover (back)"] = 4] = "Cover (back)";\n    AttachedPictureType[AttachedPictureType["Leaflet page"] = 5] = "Leaflet page";\n    AttachedPictureType[AttachedPictureType["Media (e.g. label side of CD)"] = 6] = "Media (e.g. label side of CD)";\n    AttachedPictureType[AttachedPictureType["Lead artist/lead performer/soloist"] = 7] = "Lead artist/lead performer/soloist";\n    AttachedPictureType[AttachedPictureType["Artist/performer"] = 8] = "Artist/performer";\n    AttachedPictureType[AttachedPictureType["Conductor"] = 9] = "Conductor";\n    AttachedPictureType[AttachedPictureType["Band/Orchestra"] = 10] = "Band/Orchestra";\n    AttachedPictureType[AttachedPictureType["Composer"] = 11] = "Composer";\n    AttachedPictureType[AttachedPictureType["Lyricist/text writer"] = 12] = "Lyricist/text writer";\n    AttachedPictureType[AttachedPictureType["Recording Location"] = 13] = "Recording Location";\n    AttachedPictureType[AttachedPictureType["During recording"] = 14] = "During recording";\n    AttachedPictureType[AttachedPictureType["During performance"] = 15] = "During performance";\n    AttachedPictureType[AttachedPictureType["Movie/video screen capture"] = 16] = "Movie/video screen capture";\n    AttachedPictureType[AttachedPictureType["A bright coloured fish"] = 17] = "A bright coloured fish";\n    AttachedPictureType[AttachedPictureType["Illustration"] = 18] = "Illustration";\n    AttachedPictureType[AttachedPictureType["Band/artist logotype"] = 19] = "Band/artist logotype";\n    AttachedPictureType[AttachedPictureType["Publisher/Studio logotype"] = 20] = "Publisher/Studio logotype";\n})(AttachedPictureType = exports.AttachedPictureType || (exports.AttachedPictureType = {}));\n/**\n * 28 bits (representing up to 256MB) integer, the msb is 0 to avoid \'false syncsignals\'.\n * 4 * %0xxxxxxx\n */\nexports.UINT32SYNCSAFE = {\n    get: (buf, off) => {\n        return buf[off + 3] & 0x7f | ((buf[off + 2]) << 7) |\n            ((buf[off + 1]) << 14) | ((buf[off]) << 21);\n    },\n    len: 4\n};\n/**\n * ID3v2 header\n * Ref: http://id3.org/id3v2.3.0#ID3v2_header\n * ToDo\n */\nexports.ID3v2Header = {\n    len: 10,\n    get: (buf, off) => {\n        return {\n            // ID3v2/file identifier   "ID3"\n            fileIdentifier: new Token.StringType(3, \'ascii\').get(buf, off),\n            // ID3v2 versionIndex\n            version: {\n                major: Token.INT8.get(buf, off + 3),\n                revision: Token.INT8.get(buf, off + 4)\n            },\n            // ID3v2 flags\n            flags: {\n                // Unsynchronisation\n                unsynchronisation: util.getBit(buf, off + 5, 7),\n                // Extended header\n                isExtendedHeader: util.getBit(buf, off + 5, 6),\n                // Experimental indicator\n                expIndicator: util.getBit(buf, off + 5, 5),\n                footer: util.getBit(buf, off + 5, 4)\n            },\n            size: exports.UINT32SYNCSAFE.get(buf, off + 6)\n        };\n    }\n};\nexports.ExtendedHeader = {\n    len: 10,\n    get: (buf, off) => {\n        return {\n            // Extended header size\n            size: Token.UINT32_BE.get(buf, off),\n            // Extended Flags\n            extendedFlags: Token.UINT16_BE.get(buf, off + 4),\n            // Size of padding\n            sizeOfPadding: Token.UINT32_BE.get(buf, off + 6),\n            // CRC data present\n            crcDataPresent: util.getBit(buf, off + 4, 31)\n        };\n    }\n};\nexports.TextEncodingToken = {\n    len: 1,\n    get: (uint8Array, off) => {\n        switch (uint8Array[off]) {\n            case 0x00:\n                return { encoding: \'latin1\' }; // binary\n            case 0x01:\n                return { encoding: \'utf16le\', bom: true };\n            case 0x02:\n                return { encoding: \'utf16le\', bom: false };\n            case 0x03:\n                return { encoding: \'utf8\', bom: false };\n            default:\n                return { encoding: \'utf8\', bom: false };\n        }\n    }\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Token.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/iff/index.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/iff/index.js ***!
  \***********************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.Header = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nconst FourCC_1 = __webpack_require__(/*! ../common/FourCC */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js");\n/**\n * Common AIFF chunk header\n */\nexports.Header = {\n    len: 8,\n    get: (buf, off) => {\n        return {\n            // Chunk type ID\n            chunkID: FourCC_1.FourCcToken.get(buf, off),\n            // Chunk size\n            chunkSize: Number(BigInt(Token.UINT32_BE.get(buf, off + 4)))\n        };\n    }\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/iff/index.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/lyrics3/Lyrics3.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/lyrics3/Lyrics3.js ***!
  \*****************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ "./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js")["Buffer"];\n\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.getLyricsHeaderLength = exports.endTag2 = void 0;\nexports.endTag2 = \'LYRICS200\';\nasync function getLyricsHeaderLength(reader) {\n    if (reader.fileSize >= 143) {\n        const buf = Buffer.alloc(15);\n        await reader.randomRead(buf, 0, buf.length, reader.fileSize - 143);\n        const txt = buf.toString(\'binary\');\n        const tag = txt.substr(6);\n        if (tag === exports.endTag2) {\n            return parseInt(txt.substr(0, 6), 10) + 15;\n        }\n    }\n    return 0;\n}\nexports.getLyricsHeaderLength = getLyricsHeaderLength;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/lyrics3/Lyrics3.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/MatroskaDtd.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/MatroskaDtd.js ***!
  \**********************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.elements = void 0;\nconst types_1 = __webpack_require__(/*! ./types */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/types.js\");\n/**\n * Elements of document type description\n * Derived from https://github.com/tungol/EBML/blob/master/doctypes/matroska.dtd\n * Extended with:\n * - https://www.matroska.org/technical/specs/index.html\n */\nexports.elements = {\n    0x1a45dfa3: {\n        name: 'ebml',\n        container: {\n            0x4286: { name: 'ebmlVersion', value: types_1.DataType.uint },\n            0x42f7: { name: 'ebmlReadVersion', value: types_1.DataType.uint },\n            0x42f2: { name: 'ebmlMaxIDWidth', value: types_1.DataType.uint },\n            0x42f3: { name: 'ebmlMaxSizeWidth', value: types_1.DataType.uint },\n            0x4282: { name: 'docType', value: types_1.DataType.string },\n            0x4287: { name: 'docTypeVersion', value: types_1.DataType.uint },\n            0x4285: { name: 'docTypeReadVersion', value: types_1.DataType.uint } // 5.1.7\n        }\n    },\n    // Matroska segments\n    0x18538067: {\n        name: 'segment',\n        container: {\n            // Meta Seek Information\n            0x114d9b74: {\n                name: 'seekHead',\n                container: {\n                    0x4dbb: {\n                        name: 'seek',\n                        container: {\n                            0x53ab: { name: 'seekId', value: types_1.DataType.binary },\n                            0x53ac: { name: 'seekPosition', value: types_1.DataType.uint }\n                        }\n                    }\n                }\n            },\n            // Segment Information\n            0x1549a966: {\n                name: 'info',\n                container: {\n                    0x73a4: { name: 'uid', value: types_1.DataType.uid },\n                    0x7384: { name: 'filename', value: types_1.DataType.string },\n                    0x3cb923: { name: 'prevUID', value: types_1.DataType.uid },\n                    0x3c83ab: { name: 'prevFilename', value: types_1.DataType.string },\n                    0x3eb923: { name: 'nextUID', value: types_1.DataType.uid },\n                    0x3e83bb: { name: 'nextFilename', value: types_1.DataType.string },\n                    0x2ad7b1: { name: 'timecodeScale', value: types_1.DataType.uint },\n                    0x4489: { name: 'duration', value: types_1.DataType.float },\n                    0x4461: { name: 'dateUTC', value: types_1.DataType.uint },\n                    0x7ba9: { name: 'title', value: types_1.DataType.string },\n                    0x4d80: { name: 'muxingApp', value: types_1.DataType.string },\n                    0x5741: { name: 'writingApp', value: types_1.DataType.string }\n                }\n            },\n            // Cluster\n            0x1f43b675: {\n                name: 'cluster',\n                multiple: true,\n                container: {\n                    0xe7: { name: 'timecode', value: types_1.DataType.uid },\n                    0xa3: { name: 'unknown', value: types_1.DataType.binary },\n                    0xa7: { name: 'position', value: types_1.DataType.uid },\n                    0xab: { name: 'prevSize', value: types_1.DataType.uid }\n                }\n            },\n            // Track\n            0x1654ae6b: {\n                name: 'tracks',\n                container: {\n                    0xae: {\n                        name: 'entries',\n                        multiple: true,\n                        container: {\n                            0xd7: { name: 'trackNumber', value: types_1.DataType.uint },\n                            0x73c5: { name: 'uid', value: types_1.DataType.uid },\n                            0x83: { name: 'trackType', value: types_1.DataType.uint },\n                            0xb9: { name: 'flagEnabled', value: types_1.DataType.bool },\n                            0x88: { name: 'flagDefault', value: types_1.DataType.bool },\n                            0x55aa: { name: 'flagForced', value: types_1.DataType.bool },\n                            0x9c: { name: 'flagLacing', value: types_1.DataType.bool },\n                            0x6de7: { name: 'minCache', value: types_1.DataType.uint },\n                            0x6de8: { name: 'maxCache', value: types_1.DataType.uint },\n                            0x23e383: { name: 'defaultDuration', value: types_1.DataType.uint },\n                            0x23314f: { name: 'timecodeScale', value: types_1.DataType.float },\n                            0x536e: { name: 'name', value: types_1.DataType.string },\n                            0x22b59c: { name: 'language', value: types_1.DataType.string },\n                            0x86: { name: 'codecID', value: types_1.DataType.string },\n                            0x63a2: { name: 'codecPrivate', value: types_1.DataType.binary },\n                            0x258688: { name: 'codecName', value: types_1.DataType.string },\n                            0x3a9697: { name: 'codecSettings', value: types_1.DataType.string },\n                            0x3b4040: { name: 'codecInfoUrl', value: types_1.DataType.string },\n                            0x26b240: { name: 'codecDownloadUrl', value: types_1.DataType.string },\n                            0xaa: { name: 'codecDecodeAll', value: types_1.DataType.bool },\n                            0x6fab: { name: 'trackOverlay', value: types_1.DataType.uint },\n                            // Video\n                            0xe0: {\n                                name: 'video',\n                                container: {\n                                    0x9a: { name: 'flagInterlaced', value: types_1.DataType.bool },\n                                    0x53b8: { name: 'stereoMode', value: types_1.DataType.uint },\n                                    0xb0: { name: 'pixelWidth', value: types_1.DataType.uint },\n                                    0xba: { name: 'pixelHeight', value: types_1.DataType.uint },\n                                    0x54b0: { name: 'displayWidth', value: types_1.DataType.uint },\n                                    0x54ba: { name: 'displayHeight', value: types_1.DataType.uint },\n                                    0x54b3: { name: 'aspectRatioType', value: types_1.DataType.uint },\n                                    0x2eb524: { name: 'colourSpace', value: types_1.DataType.uint },\n                                    0x2fb523: { name: 'gammaValue', value: types_1.DataType.float }\n                                }\n                            },\n                            // Audio\n                            0xe1: {\n                                name: 'audio',\n                                container: {\n                                    0xb5: { name: 'samplingFrequency', value: types_1.DataType.float },\n                                    0x78b5: { name: 'outputSamplingFrequency', value: types_1.DataType.float },\n                                    0x9f: { name: 'channels', value: types_1.DataType.uint },\n                                    0x94: { name: 'channels', value: types_1.DataType.uint },\n                                    0x7d7b: { name: 'channelPositions', value: types_1.DataType.binary },\n                                    0x6264: { name: 'bitDepth', value: types_1.DataType.uint }\n                                }\n                            },\n                            // Content Encoding\n                            0x6d80: {\n                                name: 'contentEncodings',\n                                container: {\n                                    0x6240: {\n                                        name: 'contentEncoding',\n                                        container: {\n                                            0x5031: { name: 'order', value: types_1.DataType.uint },\n                                            0x5032: { name: 'scope', value: types_1.DataType.bool },\n                                            0x5033: { name: 'type', value: types_1.DataType.uint },\n                                            0x5034: {\n                                                name: 'contentEncoding',\n                                                container: {\n                                                    0x4254: { name: 'contentCompAlgo', value: types_1.DataType.uint },\n                                                    0x4255: { name: 'contentCompSettings', value: types_1.DataType.binary }\n                                                }\n                                            },\n                                            0x5035: {\n                                                name: 'contentEncoding',\n                                                container: {\n                                                    0x47e1: { name: 'contentEncAlgo', value: types_1.DataType.uint },\n                                                    0x47e2: { name: 'contentEncKeyID', value: types_1.DataType.binary },\n                                                    0x47e3: { name: 'contentSignature ', value: types_1.DataType.binary },\n                                                    0x47e4: { name: 'ContentSigKeyID  ', value: types_1.DataType.binary },\n                                                    0x47e5: { name: 'contentSigAlgo ', value: types_1.DataType.uint },\n                                                    0x47e6: { name: 'contentSigHashAlgo ', value: types_1.DataType.uint }\n                                                }\n                                            },\n                                            0x6264: { name: 'bitDepth', value: types_1.DataType.uint }\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n            },\n            // Cueing Data\n            0x1c53bb6b: {\n                name: 'cues',\n                container: {\n                    0xbb: {\n                        name: 'cuePoint',\n                        container: {\n                            0xb3: { name: 'cueTime', value: types_1.DataType.uid },\n                            0xb7: {\n                                name: 'positions',\n                                container: {\n                                    0xf7: { name: 'track', value: types_1.DataType.uint },\n                                    0xf1: { name: 'clusterPosition', value: types_1.DataType.uint },\n                                    0x5378: { name: 'blockNumber', value: types_1.DataType.uint },\n                                    0xea: { name: 'codecState', value: types_1.DataType.uint },\n                                    0xdb: {\n                                        name: 'reference', container: {\n                                            0x96: { name: 'time', value: types_1.DataType.uint },\n                                            0x97: { name: 'cluster', value: types_1.DataType.uint },\n                                            0x535f: { name: 'number', value: types_1.DataType.uint },\n                                            0xeb: { name: 'codecState', value: types_1.DataType.uint }\n                                        }\n                                    },\n                                    0xf0: { name: 'relativePosition', value: types_1.DataType.uint } // extended\n                                }\n                            }\n                        }\n                    }\n                }\n            },\n            // Attachment\n            0x1941a469: {\n                name: 'attachments',\n                container: {\n                    0x61a7: {\n                        name: 'attachedFiles',\n                        multiple: true,\n                        container: {\n                            0x467e: { name: 'description', value: types_1.DataType.string },\n                            0x466e: { name: 'name', value: types_1.DataType.string },\n                            0x4660: { name: 'mimeType', value: types_1.DataType.string },\n                            0x465c: { name: 'data', value: types_1.DataType.binary },\n                            0x46ae: { name: 'uid', value: types_1.DataType.uid }\n                        }\n                    }\n                }\n            },\n            // Chapters\n            0x1043a770: {\n                name: 'chapters',\n                container: {\n                    0x45b9: {\n                        name: 'editionEntry',\n                        container: {\n                            0xb6: {\n                                name: 'chapterAtom',\n                                container: {\n                                    0x73c4: { name: 'uid', value: types_1.DataType.uid },\n                                    0x91: { name: 'timeStart', value: types_1.DataType.uint },\n                                    0x92: { name: 'timeEnd', value: types_1.DataType.uid },\n                                    0x98: { name: 'hidden', value: types_1.DataType.bool },\n                                    0x4598: { name: 'enabled', value: types_1.DataType.uid },\n                                    0x8f: { name: 'track', container: {\n                                            0x89: { name: 'trackNumber', value: types_1.DataType.uid },\n                                            0x80: {\n                                                name: 'display', container: {\n                                                    0x85: { name: 'string', value: types_1.DataType.string },\n                                                    0x437c: { name: 'language ', value: types_1.DataType.string },\n                                                    0x437e: { name: 'country ', value: types_1.DataType.string }\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n            },\n            // Tagging\n            0x1254c367: {\n                name: 'tags',\n                container: {\n                    0x7373: {\n                        name: 'tag',\n                        multiple: true,\n                        container: {\n                            0x63c0: {\n                                name: 'target',\n                                container: {\n                                    0x63c5: { name: 'tagTrackUID', value: types_1.DataType.uid },\n                                    0x63c4: { name: 'tagChapterUID', value: types_1.DataType.uint },\n                                    0x63c6: { name: 'tagAttachmentUID', value: types_1.DataType.uid },\n                                    0x63ca: { name: 'targetType', value: types_1.DataType.string },\n                                    0x68ca: { name: 'targetTypeValue', value: types_1.DataType.uint },\n                                    0x63c9: { name: 'tagEditionUID', value: types_1.DataType.uid } // extended\n                                }\n                            },\n                            0x67c8: {\n                                name: 'simpleTags',\n                                multiple: true,\n                                container: {\n                                    0x45a3: { name: 'name', value: types_1.DataType.string },\n                                    0x4487: { name: 'string', value: types_1.DataType.string },\n                                    0x4485: { name: 'binary', value: types_1.DataType.binary },\n                                    0x447a: { name: 'language', value: types_1.DataType.string },\n                                    0x447b: { name: 'languageIETF', value: types_1.DataType.string },\n                                    0x4484: { name: 'default', value: types_1.DataType.bool } // extended\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/MatroskaDtd.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/MatroskaParser.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/MatroskaParser.js ***!
  \*************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ \"./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js\")[\"Buffer\"];\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MatroskaParser = void 0;\nconst token_types_1 = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst BasicParser_1 = __webpack_require__(/*! ../common/BasicParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js\");\nconst types_1 = __webpack_require__(/*! ./types */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/types.js\");\nconst matroskaDtd = __webpack_require__(/*! ./MatroskaDtd */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/MatroskaDtd.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:matroska');\n/**\n * Extensible Binary Meta Language (EBML) parser\n * https://en.wikipedia.org/wiki/Extensible_Binary_Meta_Language\n * http://matroska.sourceforge.net/technical/specs/rfc/index.html\n *\n * WEBM VP8 AUDIO FILE\n */\nclass MatroskaParser extends BasicParser_1.BasicParser {\n    constructor() {\n        super();\n        this.padding = 0;\n        this.parserMap = new Map();\n        this.ebmlMaxIDLength = 4;\n        this.ebmlMaxSizeLength = 8;\n        this.parserMap.set(types_1.DataType.uint, e => this.readUint(e));\n        this.parserMap.set(types_1.DataType.string, e => this.readString(e));\n        this.parserMap.set(types_1.DataType.binary, e => this.readBuffer(e));\n        this.parserMap.set(types_1.DataType.uid, async (e) => await this.readUint(e) === 1);\n        this.parserMap.set(types_1.DataType.bool, e => this.readFlag(e));\n        this.parserMap.set(types_1.DataType.float, e => this.readFloat(e));\n    }\n    /**\n     * Initialize parser with output (metadata), input (tokenizer) & parsing options (options).\n     * @param {INativeMetadataCollector} metadata Output\n     * @param {ITokenizer} tokenizer Input\n     * @param {IOptions} options Parsing options\n     */\n    init(metadata, tokenizer, options) {\n        super.init(metadata, tokenizer, options);\n        return this;\n    }\n    async parse() {\n        const matroska = await this.parseContainer(matroskaDtd.elements, this.tokenizer.fileInfo.size, []);\n        this.metadata.setFormat('container', `EBML/${matroska.ebml.docType}`);\n        if (matroska.segment) {\n            const info = matroska.segment.info;\n            if (info) {\n                const timecodeScale = info.timecodeScale ? info.timecodeScale : 1000000;\n                if (typeof info.duration === 'number') {\n                    const duration = info.duration * timecodeScale / 1000000000;\n                    this.addTag('segment:title', info.title);\n                    this.metadata.setFormat('duration', duration);\n                }\n            }\n            const audioTracks = matroska.segment.tracks;\n            if (audioTracks && audioTracks.entries) {\n                audioTracks.entries.forEach(entry => {\n                    const stream = {\n                        codecName: entry.codecID.replace('A_', '').replace('V_', ''),\n                        codecSettings: entry.codecSettings,\n                        flagDefault: entry.flagDefault,\n                        flagLacing: entry.flagLacing,\n                        flagEnabled: entry.flagEnabled,\n                        language: entry.language,\n                        name: entry.name,\n                        type: entry.trackType,\n                        audio: entry.audio,\n                        video: entry.video\n                    };\n                    this.metadata.addStreamInfo(stream);\n                });\n                const audioTrack = audioTracks.entries\n                    .filter(entry => {\n                    return entry.trackType === types_1.TrackType.audio.valueOf();\n                })\n                    .reduce((acc, cur) => {\n                    if (!acc) {\n                        return cur;\n                    }\n                    if (!acc.flagDefault && cur.flagDefault) {\n                        return cur;\n                    }\n                    if (cur.trackNumber && cur.trackNumber < acc.trackNumber) {\n                        return cur;\n                    }\n                    return acc;\n                }, null);\n                if (audioTrack) {\n                    this.metadata.setFormat('codec', audioTrack.codecID.replace('A_', ''));\n                    this.metadata.setFormat('sampleRate', audioTrack.audio.samplingFrequency);\n                    this.metadata.setFormat('numberOfChannels', audioTrack.audio.channels);\n                }\n                if (matroska.segment.tags) {\n                    matroska.segment.tags.tag.forEach(tag => {\n                        const target = tag.target;\n                        const targetType = (target === null || target === void 0 ? void 0 : target.targetTypeValue) ? types_1.TargetType[target.targetTypeValue] : ((target === null || target === void 0 ? void 0 : target.targetType) ? target.targetType : 'track');\n                        tag.simpleTags.forEach(simpleTag => {\n                            const value = simpleTag.string ? simpleTag.string : simpleTag.binary;\n                            this.addTag(`${targetType}:${simpleTag.name}`, value);\n                        });\n                    });\n                }\n                if (matroska.segment.attachments) {\n                    matroska.segment.attachments.attachedFiles\n                        .filter(file => file.mimeType.startsWith('image/'))\n                        .map(file => {\n                        return {\n                            data: file.data,\n                            format: file.mimeType,\n                            description: file.description,\n                            name: file.name\n                        };\n                    }).forEach(picture => {\n                        this.addTag('picture', picture);\n                    });\n                }\n            }\n        }\n    }\n    async parseContainer(container, posDone, path) {\n        const tree = {};\n        while (this.tokenizer.position < posDone) {\n            let element;\n            try {\n                element = await this.readElement();\n            }\n            catch (error) {\n                if (error.message === 'End-Of-Stream') {\n                    break;\n                }\n                throw error;\n            }\n            const type = container[element.id];\n            if (type) {\n                debug(`Element: name=${type.name}, container=${!!type.container}`);\n                if (type.container) {\n                    const res = await this.parseContainer(type.container, element.len >= 0 ? this.tokenizer.position + element.len : -1, path.concat([type.name]));\n                    if (type.multiple) {\n                        if (!tree[type.name]) {\n                            tree[type.name] = [];\n                        }\n                        tree[type.name].push(res);\n                    }\n                    else {\n                        tree[type.name] = res;\n                    }\n                }\n                else {\n                    tree[type.name] = await this.parserMap.get(type.value)(element);\n                }\n            }\n            else {\n                switch (element.id) {\n                    case 0xec: // void\n                        this.padding += element.len;\n                        await this.tokenizer.ignore(element.len);\n                        break;\n                    default:\n                        debug(`parseEbml: path=${path.join('/')}, unknown element: id=${element.id.toString(16)}`);\n                        this.padding += element.len;\n                        await this.tokenizer.ignore(element.len);\n                }\n            }\n        }\n        return tree;\n    }\n    async readVintData(maxLength) {\n        const msb = await this.tokenizer.peekNumber(token_types_1.UINT8);\n        let mask = 0x80;\n        let oc = 1;\n        // Calculate VINT_WIDTH\n        while ((msb & mask) === 0) {\n            if (oc > maxLength) {\n                throw new Error('VINT value exceeding maximum size');\n            }\n            ++oc;\n            mask >>= 1;\n        }\n        const id = Buffer.alloc(oc);\n        await this.tokenizer.readBuffer(id);\n        return id;\n    }\n    async readElement() {\n        const id = await this.readVintData(this.ebmlMaxIDLength);\n        const lenField = await this.readVintData(this.ebmlMaxSizeLength);\n        lenField[0] ^= 0x80 >> (lenField.length - 1);\n        const nrLen = Math.min(6, lenField.length); // JavaScript can max read 6 bytes integer\n        return {\n            id: id.readUIntBE(0, id.length),\n            len: lenField.readUIntBE(lenField.length - nrLen, nrLen)\n        };\n    }\n    isMaxValue(vintData) {\n        if (vintData.length === this.ebmlMaxSizeLength) {\n            for (let n = 1; n < this.ebmlMaxSizeLength; ++n) {\n                if (vintData[n] !== 0xff)\n                    return false;\n            }\n            return true;\n        }\n        return false;\n    }\n    async readFloat(e) {\n        switch (e.len) {\n            case 0:\n                return 0.0;\n            case 4:\n                return this.tokenizer.readNumber(token_types_1.Float32_BE);\n            case 8:\n                return this.tokenizer.readNumber(token_types_1.Float64_BE);\n            case 10:\n                return this.tokenizer.readNumber(token_types_1.Float64_BE);\n            default:\n                throw new Error(`Invalid IEEE-754 float length: ${e.len}`);\n        }\n    }\n    async readFlag(e) {\n        return (await this.readUint(e)) === 1;\n    }\n    async readUint(e) {\n        const buf = await this.readBuffer(e);\n        const nrLen = Math.min(6, e.len); // JavaScript can max read 6 bytes integer\n        return buf.readUIntBE(e.len - nrLen, nrLen);\n    }\n    async readString(e) {\n        const rawString = await this.tokenizer.readToken(new token_types_1.StringType(e.len, 'utf-8'));\n        return rawString.replace(/\\00.*$/g, '');\n    }\n    async readBuffer(e) {\n        const buf = Buffer.alloc(e.len);\n        await this.tokenizer.readBuffer(buf);\n        return buf;\n    }\n    addTag(tagId, value) {\n        this.metadata.addTag('matroska', tagId, value);\n    }\n}\nexports.MatroskaParser = MatroskaParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/MatroskaParser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/MatroskaTagMapper.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/MatroskaTagMapper.js ***!
  \****************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MatroskaTagMapper = void 0;\nconst CaseInsensitiveTagMap_1 = __webpack_require__(/*! ../common/CaseInsensitiveTagMap */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/CaseInsensitiveTagMap.js\");\n/**\n * EBML Tag map\n */\nconst ebmlTagMap = {\n    'segment:title': 'title',\n    'album:ARTIST': 'albumartist',\n    'album:ARTISTSORT': 'albumartistsort',\n    'album:TITLE': 'album',\n    'album:DATE_RECORDED': 'originaldate',\n    'album:PART_NUMBER': 'disk',\n    'album:TOTAL_PARTS': 'totaltracks',\n    'track:ARTIST': 'artist',\n    'track:ARTISTSORT': 'artistsort',\n    'track:TITLE': 'title',\n    'track:PART_NUMBER': 'track',\n    'track:MUSICBRAINZ_TRACKID': 'musicbrainz_recordingid',\n    'track:MUSICBRAINZ_ALBUMID': 'musicbrainz_albumid',\n    'track:MUSICBRAINZ_ARTISTID': 'musicbrainz_artistid',\n    'track:PUBLISHER': 'label',\n    'track:GENRE': 'genre',\n    'track:ENCODER': 'encodedby',\n    'track:ENCODER_OPTIONS': 'encodersettings',\n    'edition:TOTAL_PARTS': 'totaldiscs',\n    picture: 'picture'\n};\nclass MatroskaTagMapper extends CaseInsensitiveTagMap_1.CaseInsensitiveTagMap {\n    constructor() {\n        super(['matroska'], ebmlTagMap);\n    }\n}\nexports.MatroskaTagMapper = MatroskaTagMapper;\n//# sourceMappingURL=MatroskaTagMapper.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/MatroskaTagMapper.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/types.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/types.js ***!
  \****************************************************************************************************/function(__unused_webpack_module,exports){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.TrackType = exports.TargetType = exports.DataType = void 0;\nvar DataType;\n(function (DataType) {\n    DataType[DataType["string"] = 0] = "string";\n    DataType[DataType["uint"] = 1] = "uint";\n    DataType[DataType["uid"] = 2] = "uid";\n    DataType[DataType["bool"] = 3] = "bool";\n    DataType[DataType["binary"] = 4] = "binary";\n    DataType[DataType["float"] = 5] = "float";\n})(DataType = exports.DataType || (exports.DataType = {}));\nvar TargetType;\n(function (TargetType) {\n    TargetType[TargetType["shot"] = 10] = "shot";\n    TargetType[TargetType["scene"] = 20] = "scene";\n    TargetType[TargetType["track"] = 30] = "track";\n    TargetType[TargetType["part"] = 40] = "part";\n    TargetType[TargetType["album"] = 50] = "album";\n    TargetType[TargetType["edition"] = 60] = "edition";\n    TargetType[TargetType["collection"] = 70] = "collection";\n})(TargetType = exports.TargetType || (exports.TargetType = {}));\nvar TrackType;\n(function (TrackType) {\n    TrackType[TrackType["video"] = 1] = "video";\n    TrackType[TrackType["audio"] = 2] = "audio";\n    TrackType[TrackType["complex"] = 3] = "complex";\n    TrackType[TrackType["logo"] = 4] = "logo";\n    TrackType[TrackType["subtitle"] = 17] = "subtitle";\n    TrackType[TrackType["button"] = 18] = "button";\n    TrackType[TrackType["control"] = 32] = "control";\n})(TrackType = exports.TrackType || (exports.TrackType = {}));\n//# sourceMappingURL=types.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/types.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/Atom.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/Atom.js ***!
  \**********************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.Atom = void 0;\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst AtomToken = __webpack_require__(/*! ./AtomToken */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/AtomToken.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:MP4:Atom');\nclass Atom {\n    static async readAtom(tokenizer, dataHandler, parent, remaining) {\n        // Parse atom header\n        const offset = tokenizer.position;\n        // debug(`Reading next token on offset=${offset}...`); //  buf.toString('ascii')\n        const header = await tokenizer.readToken(AtomToken.Header);\n        const extended = header.length === BigInt(1);\n        if (extended) {\n            header.length = await tokenizer.readToken(AtomToken.ExtendedSize);\n        }\n        const atomBean = new Atom(header, header.length === BigInt(1), parent);\n        const payloadLength = atomBean.getPayloadLength(remaining);\n        debug(`parse atom name=${atomBean.atomPath}, extended=${atomBean.extended}, offset=${offset}, len=${atomBean.header.length}`); //  buf.toString('ascii')\n        await atomBean.readData(tokenizer, dataHandler, payloadLength);\n        return atomBean;\n    }\n    constructor(header, extended, parent) {\n        this.header = header;\n        this.extended = extended;\n        this.parent = parent;\n        this.children = [];\n        this.atomPath = (this.parent ? this.parent.atomPath + '.' : '') + this.header.name;\n    }\n    getHeaderLength() {\n        return this.extended ? 16 : 8;\n    }\n    getPayloadLength(remaining) {\n        return (this.header.length === BigInt(0) ? remaining : Number(this.header.length)) - this.getHeaderLength();\n    }\n    async readAtoms(tokenizer, dataHandler, size) {\n        while (size > 0) {\n            const atomBean = await Atom.readAtom(tokenizer, dataHandler, this, size);\n            this.children.push(atomBean);\n            size -= atomBean.header.length === BigInt(0) ? size : Number(atomBean.header.length);\n        }\n    }\n    async readData(tokenizer, dataHandler, remaining) {\n        switch (this.header.name) {\n            // \"Container\" atoms, contains nested atoms\n            case 'moov': // The Movie Atom: contains other atoms\n            case 'udta': // User defined atom\n            case 'trak':\n            case 'mdia': // Media atom\n            case 'minf': // Media Information Atom\n            case 'stbl': // The Sample Table Atom\n            case '<id>':\n            case 'ilst':\n            case 'tref':\n                return this.readAtoms(tokenizer, dataHandler, this.getPayloadLength(remaining));\n            case 'meta': // Metadata Atom, ref: https://developer.apple.com/library/content/documentation/QuickTime/QTFF/Metadata/Metadata.html#//apple_ref/doc/uid/TP40000939-CH1-SW8\n                // meta has 4 bytes of padding, ignore\n                const peekHeader = await tokenizer.peekToken(AtomToken.Header);\n                const paddingLength = peekHeader.name === 'hdlr' ? 0 : 4;\n                await tokenizer.ignore(paddingLength);\n                return this.readAtoms(tokenizer, dataHandler, this.getPayloadLength(remaining) - paddingLength);\n            case 'mdhd': // Media header atom\n            case 'mvhd': // 'movie' => 'mvhd': movie header atom; child of Movie Atom\n            case 'tkhd':\n            case 'stsz':\n            case 'mdat':\n            default:\n                return dataHandler(this, remaining);\n        }\n    }\n}\nexports.Atom = Atom;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/Atom.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/AtomToken.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/AtomToken.js ***!
  \***************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ \"./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js\")[\"Buffer\"];\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ChapterText = exports.StcoAtom = exports.StszAtom = exports.StscAtom = exports.SampleToChunkToken = exports.SttsAtom = exports.TimeToSampleToken = exports.SoundSampleDescriptionV0 = exports.SoundSampleDescriptionVersion = exports.StsdAtom = exports.TrackHeaderAtom = exports.NameAtom = exports.DataAtom = exports.MvhdAtom = exports.MdhdAtom = exports.FixedLengthAtom = exports.mhdr = exports.tkhd = exports.ftyp = exports.ExtendedSize = exports.Header = void 0;\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst FourCC_1 = __webpack_require__(/*! ../common/FourCC */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:MP4:atom');\nexports.Header = {\n    len: 8,\n    get: (buf, off) => {\n        const length = Token.UINT32_BE.get(buf, off);\n        if (length < 0)\n            throw new Error('Invalid atom header length');\n        return {\n            length: BigInt(length),\n            name: new Token.StringType(4, 'binary').get(buf, off + 4)\n        };\n    },\n    put: (buf, off, hdr) => {\n        Token.UINT32_BE.put(buf, off, Number(hdr.length));\n        return FourCC_1.FourCcToken.put(buf, off + 4, hdr.name);\n    }\n};\n/**\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap1/qtff1.html#//apple_ref/doc/uid/TP40000939-CH203-38190\n */\nexports.ExtendedSize = Token.UINT64_BE;\nexports.ftyp = {\n    len: 4,\n    get: (buf, off) => {\n        return {\n            type: new Token.StringType(4, 'ascii').get(buf, off)\n        };\n    }\n};\nexports.tkhd = {\n    len: 4,\n    get: (buf, off) => {\n        return {\n            type: new Token.StringType(4, 'ascii').get(buf, off)\n        };\n    }\n};\n/**\n * Token: Movie Header Atom\n */\nexports.mhdr = {\n    len: 8,\n    get: (buf, off) => {\n        return {\n            version: Token.UINT8.get(buf, off),\n            flags: Token.UINT24_BE.get(buf, off + 1),\n            nextItemID: Token.UINT32_BE.get(buf, off + 4)\n        };\n    }\n};\n/**\n * Base class for 'fixed' length atoms.\n * In some cases these atoms are longer then the sum of the described fields.\n * Issue: https://github.com/Borewit/music-metadata/issues/120\n */\nclass FixedLengthAtom {\n    /**\n     *\n     * @param {number} len Length as specified in the size field\n     * @param {number} expLen Total length of sum of specified fields in the standard\n     */\n    constructor(len, expLen, atomId) {\n        this.len = len;\n        if (len < expLen) {\n            throw new Error(`Atom ${atomId} expected to be ${expLen}, but specifies ${len} bytes long.`);\n        }\n        else if (len > expLen) {\n            debug(`Warning: atom ${atomId} expected to be ${expLen}, but was actually ${len} bytes long.`);\n        }\n    }\n}\nexports.FixedLengthAtom = FixedLengthAtom;\n/**\n * Timestamp stored in seconds since Mac Epoch (1 January 1904)\n */\nconst SecondsSinceMacEpoch = {\n    len: 4,\n    get: (buf, off) => {\n        const secondsSinceUnixEpoch = Token.UINT32_BE.get(buf, off) - 2082844800;\n        return new Date(secondsSinceUnixEpoch * 1000);\n    }\n};\n/**\n * Token: Media Header Atom\n * Ref:\n * - https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-SW34\n * - https://wiki.multimedia.cx/index.php/QuickTime_container#mdhd\n */\nclass MdhdAtom extends FixedLengthAtom {\n    constructor(len) {\n        super(len, 24, 'mdhd');\n        this.len = len;\n    }\n    get(buf, off) {\n        return {\n            version: Token.UINT8.get(buf, off + 0),\n            flags: Token.UINT24_BE.get(buf, off + 1),\n            creationTime: SecondsSinceMacEpoch.get(buf, off + 4),\n            modificationTime: SecondsSinceMacEpoch.get(buf, off + 8),\n            timeScale: Token.UINT32_BE.get(buf, off + 12),\n            duration: Token.UINT32_BE.get(buf, off + 16),\n            language: Token.UINT16_BE.get(buf, off + 20),\n            quality: Token.UINT16_BE.get(buf, off + 22)\n        };\n    }\n}\nexports.MdhdAtom = MdhdAtom;\n/**\n * Token: Movie Header Atom\n */\nclass MvhdAtom extends FixedLengthAtom {\n    constructor(len) {\n        super(len, 100, 'mvhd');\n        this.len = len;\n    }\n    get(buf, off) {\n        return {\n            version: Token.UINT8.get(buf, off),\n            flags: Token.UINT24_BE.get(buf, off + 1),\n            creationTime: SecondsSinceMacEpoch.get(buf, off + 4),\n            modificationTime: SecondsSinceMacEpoch.get(buf, off + 8),\n            timeScale: Token.UINT32_BE.get(buf, off + 12),\n            duration: Token.UINT32_BE.get(buf, off + 16),\n            preferredRate: Token.UINT32_BE.get(buf, off + 20),\n            preferredVolume: Token.UINT16_BE.get(buf, off + 24),\n            // ignore reserver: 10 bytes\n            // ignore matrix structure: 36 bytes\n            previewTime: Token.UINT32_BE.get(buf, off + 72),\n            previewDuration: Token.UINT32_BE.get(buf, off + 76),\n            posterTime: Token.UINT32_BE.get(buf, off + 80),\n            selectionTime: Token.UINT32_BE.get(buf, off + 84),\n            selectionDuration: Token.UINT32_BE.get(buf, off + 88),\n            currentTime: Token.UINT32_BE.get(buf, off + 92),\n            nextTrackID: Token.UINT32_BE.get(buf, off + 96)\n        };\n    }\n}\nexports.MvhdAtom = MvhdAtom;\n/**\n * Data Atom Structure\n */\nclass DataAtom {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        return {\n            type: {\n                set: Token.UINT8.get(buf, off + 0),\n                type: Token.UINT24_BE.get(buf, off + 1)\n            },\n            locale: Token.UINT24_BE.get(buf, off + 4),\n            value: Buffer.from(new Token.Uint8ArrayType(this.len - 8).get(buf, off + 8))\n        };\n    }\n}\nexports.DataAtom = DataAtom;\n/**\n * Data Atom Structure\n * Ref: https://developer.apple.com/library/content/documentation/QuickTime/QTFF/Metadata/Metadata.html#//apple_ref/doc/uid/TP40000939-CH1-SW31\n */\nclass NameAtom {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        return {\n            version: Token.UINT8.get(buf, off),\n            flags: Token.UINT24_BE.get(buf, off + 1),\n            name: new Token.StringType(this.len - 4, 'utf-8').get(buf, off + 4)\n        };\n    }\n}\nexports.NameAtom = NameAtom;\n/**\n * Track Header Atoms structure\n * Ref: https://developer.apple.com/library/content/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25550\n */\nclass TrackHeaderAtom {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        return {\n            version: Token.UINT8.get(buf, off),\n            flags: Token.UINT24_BE.get(buf, off + 1),\n            creationTime: SecondsSinceMacEpoch.get(buf, off + 4),\n            modificationTime: SecondsSinceMacEpoch.get(buf, off + 8),\n            trackId: Token.UINT32_BE.get(buf, off + 12),\n            // reserved 4 bytes\n            duration: Token.UINT32_BE.get(buf, off + 20),\n            layer: Token.UINT16_BE.get(buf, off + 24),\n            alternateGroup: Token.UINT16_BE.get(buf, off + 26),\n            volume: Token.UINT16_BE.get(buf, off + 28) // ToDo: fixed point\n            // ToDo: add remaining fields\n        };\n    }\n}\nexports.TrackHeaderAtom = TrackHeaderAtom;\n/**\n * Atom: Sample Description Atom ('stsd')\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25691\n */\nconst stsdHeader = {\n    len: 8,\n    get: (buf, off) => {\n        return {\n            version: Token.UINT8.get(buf, off),\n            flags: Token.UINT24_BE.get(buf, off + 1),\n            numberOfEntries: Token.UINT32_BE.get(buf, off + 4)\n        };\n    }\n};\n/**\n * Atom: Sample Description Atom ('stsd')\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25691\n */\nclass SampleDescriptionTable {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        return {\n            dataFormat: FourCC_1.FourCcToken.get(buf, off),\n            dataReferenceIndex: Token.UINT16_BE.get(buf, off + 10),\n            description: new Token.Uint8ArrayType(this.len - 12).get(buf, off + 12)\n        };\n    }\n}\n/**\n * Atom: Sample-description Atom ('stsd')\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25691\n */\nclass StsdAtom {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        const header = stsdHeader.get(buf, off);\n        off += stsdHeader.len;\n        const table = [];\n        for (let n = 0; n < header.numberOfEntries; ++n) {\n            const size = Token.UINT32_BE.get(buf, off); // Sample description size\n            off += Token.UINT32_BE.len;\n            table.push(new SampleDescriptionTable(size).get(buf, off));\n            off += size;\n        }\n        return {\n            header,\n            table\n        };\n    }\n}\nexports.StsdAtom = StsdAtom;\n/**\n * Common Sound Sample Description (version & revision)\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap3/qtff3.html#//apple_ref/doc/uid/TP40000939-CH205-57317\n */\nexports.SoundSampleDescriptionVersion = {\n    len: 8,\n    get(buf, off) {\n        return {\n            version: Token.INT16_BE.get(buf, off),\n            revision: Token.INT16_BE.get(buf, off + 2),\n            vendor: Token.INT32_BE.get(buf, off + 4)\n        };\n    }\n};\n/**\n * Sound Sample Description (Version 0)\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap3/qtff3.html#//apple_ref/doc/uid/TP40000939-CH205-130736\n */\nexports.SoundSampleDescriptionV0 = {\n    len: 12,\n    get(buf, off) {\n        return {\n            numAudioChannels: Token.INT16_BE.get(buf, off + 0),\n            sampleSize: Token.INT16_BE.get(buf, off + 2),\n            compressionId: Token.INT16_BE.get(buf, off + 4),\n            packetSize: Token.INT16_BE.get(buf, off + 6),\n            sampleRate: Token.UINT16_BE.get(buf, off + 8) + Token.UINT16_BE.get(buf, off + 10) / 10000\n        };\n    }\n};\nclass SimpleTableAtom {\n    constructor(len, token) {\n        this.len = len;\n        this.token = token;\n    }\n    get(buf, off) {\n        const nrOfEntries = Token.INT32_BE.get(buf, off + 4);\n        return {\n            version: Token.INT8.get(buf, off + 0),\n            flags: Token.INT24_BE.get(buf, off + 1),\n            numberOfEntries: nrOfEntries,\n            entries: readTokenTable(buf, this.token, off + 8, this.len - 8, nrOfEntries)\n        };\n    }\n}\nexports.TimeToSampleToken = {\n    len: 8,\n    get(buf, off) {\n        return {\n            count: Token.INT32_BE.get(buf, off + 0),\n            duration: Token.INT32_BE.get(buf, off + 4)\n        };\n    }\n};\n/**\n * Time-to-sample('stts') atom.\n * Store duration information for a medias samples.\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25696\n */\nclass SttsAtom extends SimpleTableAtom {\n    constructor(len) {\n        super(len, exports.TimeToSampleToken);\n        this.len = len;\n    }\n}\nexports.SttsAtom = SttsAtom;\nexports.SampleToChunkToken = {\n    len: 12,\n    get(buf, off) {\n        return {\n            firstChunk: Token.INT32_BE.get(buf, off),\n            samplesPerChunk: Token.INT32_BE.get(buf, off + 4),\n            sampleDescriptionId: Token.INT32_BE.get(buf, off + 8)\n        };\n    }\n};\n/**\n * Sample-to-Chunk ('stsc') atom interface\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25706\n */\nclass StscAtom extends SimpleTableAtom {\n    constructor(len) {\n        super(len, exports.SampleToChunkToken);\n        this.len = len;\n    }\n}\nexports.StscAtom = StscAtom;\n/**\n * Sample-size ('stsz') atom\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25710\n */\nclass StszAtom {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        const nrOfEntries = Token.INT32_BE.get(buf, off + 8);\n        return {\n            version: Token.INT8.get(buf, off),\n            flags: Token.INT24_BE.get(buf, off + 1),\n            sampleSize: Token.INT32_BE.get(buf, off + 4),\n            numberOfEntries: nrOfEntries,\n            entries: readTokenTable(buf, Token.INT32_BE, off + 12, this.len - 12, nrOfEntries)\n        };\n    }\n}\nexports.StszAtom = StszAtom;\n/**\n * Chunk offset atom, 'stco'\n * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25715\n */\nclass StcoAtom extends SimpleTableAtom {\n    constructor(len) {\n        super(len, Token.INT32_BE);\n        this.len = len;\n    }\n}\nexports.StcoAtom = StcoAtom;\n/**\n * Token used to decode text-track from 'mdat' atom (raw data stream)\n */\nclass ChapterText {\n    constructor(len) {\n        this.len = len;\n    }\n    get(buf, off) {\n        const titleLen = Token.INT16_BE.get(buf, off + 0);\n        const str = new Token.StringType(titleLen, 'utf-8');\n        return str.get(buf, off + 2);\n    }\n}\nexports.ChapterText = ChapterText;\nfunction readTokenTable(buf, token, off, remainingLen, numberOfEntries) {\n    debug(`remainingLen=${remainingLen}, numberOfEntries=${numberOfEntries} * token-len=${token.len}`);\n    if (remainingLen === 0)\n        return [];\n    if (remainingLen !== numberOfEntries * token.len)\n        throw new Error('mismatch number-of-entries with remaining atom-length');\n    const entries = [];\n    // parse offset-table\n    for (let n = 0; n < numberOfEntries; ++n) {\n        entries.push(token.get(buf, off));\n        off += token.len;\n    }\n    return entries;\n}\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/AtomToken.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/MP4Parser.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/MP4Parser.js ***!
  \***************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ \"./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js\")[\"Buffer\"];\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MP4Parser = void 0;\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst BasicParser_1 = __webpack_require__(/*! ../common/BasicParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js\");\nconst ID3v1Parser_1 = __webpack_require__(/*! ../id3v1/ID3v1Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v1/ID3v1Parser.js\");\nconst type_1 = __webpack_require__(/*! ../type */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/type.js\");\nconst Atom_1 = __webpack_require__(/*! ./Atom */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/Atom.js\");\nconst AtomToken = __webpack_require__(/*! ./AtomToken */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/AtomToken.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:MP4');\nconst tagFormat = 'iTunes';\nconst encoderDict = {\n    raw: {\n        lossy: false,\n        format: 'raw'\n    },\n    MAC3: {\n        lossy: true,\n        format: 'MACE 3:1'\n    },\n    MAC6: {\n        lossy: true,\n        format: 'MACE 6:1'\n    },\n    ima4: {\n        lossy: true,\n        format: 'IMA 4:1'\n    },\n    ulaw: {\n        lossy: true,\n        format: 'uLaw 2:1'\n    },\n    alaw: {\n        lossy: true,\n        format: 'uLaw 2:1'\n    },\n    Qclp: {\n        lossy: true,\n        format: 'QUALCOMM PureVoice'\n    },\n    '.mp3': {\n        lossy: true,\n        format: 'MPEG-1 layer 3'\n    },\n    alac: {\n        lossy: false,\n        format: 'ALAC'\n    },\n    'ac-3': {\n        lossy: true,\n        format: 'AC-3'\n    },\n    mp4a: {\n        lossy: true,\n        format: 'MPEG-4/AAC'\n    },\n    mp4s: {\n        lossy: true,\n        format: 'MP4S'\n    },\n    // Closed Captioning Media, https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap3/qtff3.html#//apple_ref/doc/uid/TP40000939-CH205-SW87\n    c608: {\n        lossy: true,\n        format: 'CEA-608'\n    },\n    c708: {\n        lossy: true,\n        format: 'CEA-708'\n    }\n};\nfunction distinct(value, index, self) {\n    return self.indexOf(value) === index;\n}\n/*\n * Parser for the MP4 (MPEG-4 Part 14) container format\n * Standard: ISO/IEC 14496-14\n * supporting:\n * - QuickTime container\n * - MP4 File Format\n * - 3GPP file format\n * - 3GPP2 file format\n *\n * MPEG-4 Audio / Part 3 (.m4a)& MPEG 4 Video (m4v, mp4) extension.\n * Support for Apple iTunes tags as found in a M4A/M4V files.\n * Ref:\n *   https://en.wikipedia.org/wiki/ISO_base_media_file_format\n *   https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/Metadata/Metadata.html\n *   http://atomicparsley.sourceforge.net/mpeg-4files.html\n *   https://github.com/sergiomb2/libmp4v2/wiki/iTunesMetadata\n *   https://wiki.multimedia.cx/index.php/QuickTime_container\n */\nclass MP4Parser extends BasicParser_1.BasicParser {\n    constructor() {\n        super(...arguments);\n        this.atomParsers = {\n            /**\n             * Parse movie header (mvhd) atom\n             * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-56313\n             */\n            mvhd: async (len) => {\n                const mvhd = await this.tokenizer.readToken(new AtomToken.MvhdAtom(len));\n                this.metadata.setFormat('creationTime', mvhd.creationTime);\n                this.metadata.setFormat('modificationTime', mvhd.modificationTime);\n            },\n            /**\n             * Parse media header (mdhd) atom\n             * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap2/qtff2.html#//apple_ref/doc/uid/TP40000939-CH204-25615\n             */\n            mdhd: async (len) => {\n                const mdhd_data = await this.tokenizer.readToken(new AtomToken.MdhdAtom(len));\n                // this.parse_mxhd(mdhd_data, this.currentTrack);\n                const td = this.getTrackDescription();\n                td.creationTime = mdhd_data.creationTime;\n                td.modificationTime = mdhd_data.modificationTime;\n                td.timeScale = mdhd_data.timeScale;\n                td.duration = mdhd_data.duration;\n            },\n            chap: async (len) => {\n                const td = this.getTrackDescription();\n                const trackIds = [];\n                while (len >= Token.UINT32_BE.len) {\n                    trackIds.push(await this.tokenizer.readNumber(Token.UINT32_BE));\n                    len -= Token.UINT32_BE.len;\n                }\n                td.chapterList = trackIds;\n            },\n            tkhd: async (len) => {\n                const track = (await this.tokenizer.readToken(new AtomToken.TrackHeaderAtom(len)));\n                this.tracks.push(track);\n            },\n            /**\n             * Parse mdat atom.\n             * Will scan for chapters\n             */\n            mdat: async (len) => {\n                this.audioLengthInBytes = len;\n                this.calculateBitRate();\n                if (this.options.includeChapters) {\n                    const trackWithChapters = this.tracks.filter(track => track.chapterList);\n                    if (trackWithChapters.length === 1) {\n                        const chapterTrackIds = trackWithChapters[0].chapterList;\n                        const chapterTracks = this.tracks.filter(track => chapterTrackIds.indexOf(track.trackId) !== -1);\n                        if (chapterTracks.length === 1) {\n                            return this.parseChapterTrack(chapterTracks[0], trackWithChapters[0], len);\n                        }\n                    }\n                }\n                await this.tokenizer.ignore(len);\n            },\n            ftyp: async (len) => {\n                const types = [];\n                while (len > 0) {\n                    const ftype = await this.tokenizer.readToken(AtomToken.ftyp);\n                    len -= AtomToken.ftyp.len;\n                    const value = ftype.type.replace(/\\W/g, '');\n                    if (value.length > 0) {\n                        types.push(value); // unshift for backward compatibility\n                    }\n                }\n                debug(`ftyp: ${types.join('/')}`);\n                const x = types.filter(distinct).join('/');\n                this.metadata.setFormat('container', x);\n            },\n            /**\n             * Parse sample description atom\n             */\n            stsd: async (len) => {\n                const stsd = await this.tokenizer.readToken(new AtomToken.StsdAtom(len));\n                const trackDescription = this.getTrackDescription();\n                trackDescription.soundSampleDescription = stsd.table.map(dfEntry => this.parseSoundSampleDescription(dfEntry));\n            },\n            /**\n             * sample-to-Chunk Atoms\n             */\n            stsc: async (len) => {\n                const stsc = await this.tokenizer.readToken(new AtomToken.StscAtom(len));\n                this.getTrackDescription().sampleToChunkTable = stsc.entries;\n            },\n            /**\n             * time-to-sample table\n             */\n            stts: async (len) => {\n                const stts = await this.tokenizer.readToken(new AtomToken.SttsAtom(len));\n                this.getTrackDescription().timeToSampleTable = stts.entries;\n            },\n            /**\n             * Parse sample-sizes atom ('stsz')\n             */\n            stsz: async (len) => {\n                const stsz = await this.tokenizer.readToken(new AtomToken.StszAtom(len));\n                const td = this.getTrackDescription();\n                td.sampleSize = stsz.sampleSize;\n                td.sampleSizeTable = stsz.entries;\n            },\n            /**\n             * Parse chunk-offset atom ('stco')\n             */\n            stco: async (len) => {\n                const stco = await this.tokenizer.readToken(new AtomToken.StcoAtom(len));\n                this.getTrackDescription().chunkOffsetTable = stco.entries; // remember chunk offsets\n            },\n            date: async (len) => {\n                const date = await this.tokenizer.readToken(new Token.StringType(len, 'utf-8'));\n                this.addTag('date', date);\n            }\n        };\n    }\n    static read_BE_Integer(array, signed) {\n        const integerType = (signed ? 'INT' : 'UINT') + array.length * 8 + (array.length > 1 ? '_BE' : '');\n        const token = Token[integerType];\n        if (!token) {\n            throw new Error('Token for integer type not found: \"' + integerType + '\"');\n        }\n        return Number(token.get(array, 0));\n    }\n    async parse() {\n        this.tracks = [];\n        let remainingFileSize = this.tokenizer.fileInfo.size;\n        while (!this.tokenizer.fileInfo.size || remainingFileSize > 0) {\n            try {\n                const token = await this.tokenizer.peekToken(AtomToken.Header);\n                if (token.name === '\\0\\0\\0\\0') {\n                    const errMsg = `Error at offset=${this.tokenizer.position}: box.id=0`;\n                    debug(errMsg);\n                    this.addWarning(errMsg);\n                    break;\n                }\n            }\n            catch (error) {\n                const errMsg = `Error at offset=${this.tokenizer.position}: ${error.message}`;\n                debug(errMsg);\n                this.addWarning(errMsg);\n                break;\n            }\n            const rootAtom = await Atom_1.Atom.readAtom(this.tokenizer, (atom, remaining) => this.handleAtom(atom, remaining), null, remainingFileSize);\n            remainingFileSize -= rootAtom.header.length === BigInt(0) ? remainingFileSize : Number(rootAtom.header.length);\n        }\n        // Post process metadata\n        const formatList = [];\n        this.tracks.forEach(track => {\n            const trackFormats = [];\n            track.soundSampleDescription.forEach(ssd => {\n                const streamInfo = {};\n                const encoderInfo = encoderDict[ssd.dataFormat];\n                if (encoderInfo) {\n                    trackFormats.push(encoderInfo.format);\n                    streamInfo.codecName = encoderInfo.format;\n                }\n                else {\n                    streamInfo.codecName = `<${ssd.dataFormat}>`;\n                }\n                if (ssd.description) {\n                    const { description } = ssd;\n                    if (description.sampleRate > 0) {\n                        streamInfo.type = type_1.TrackType.audio;\n                        streamInfo.audio = {\n                            samplingFrequency: description.sampleRate,\n                            bitDepth: description.sampleSize,\n                            channels: description.numAudioChannels\n                        };\n                    }\n                }\n                this.metadata.addStreamInfo(streamInfo);\n            });\n            if (trackFormats.length >= 1) {\n                formatList.push(trackFormats.join('/'));\n            }\n        });\n        if (formatList.length > 0) {\n            this.metadata.setFormat('codec', formatList.filter(distinct).join('+'));\n        }\n        const audioTracks = this.tracks.filter(track => {\n            return track.soundSampleDescription.length >= 1 && track.soundSampleDescription[0].description && track.soundSampleDescription[0].description.numAudioChannels > 0;\n        });\n        if (audioTracks.length >= 1) {\n            const audioTrack = audioTracks[0];\n            if (audioTrack.timeScale > 0) {\n                const duration = audioTrack.duration / audioTrack.timeScale; // calculate duration in seconds\n                this.metadata.setFormat('duration', duration);\n            }\n            const ssd = audioTrack.soundSampleDescription[0];\n            if (ssd.description) {\n                this.metadata.setFormat('sampleRate', ssd.description.sampleRate);\n                this.metadata.setFormat('bitsPerSample', ssd.description.sampleSize);\n                this.metadata.setFormat('numberOfChannels', ssd.description.numAudioChannels);\n                if (audioTrack.timeScale === 0 && audioTrack.timeToSampleTable.length > 0) {\n                    const totalSampleSize = audioTrack.timeToSampleTable\n                        .map(ttstEntry => ttstEntry.count * ttstEntry.duration)\n                        .reduce((total, sampleSize) => total + sampleSize);\n                    const duration = totalSampleSize / ssd.description.sampleRate;\n                    this.metadata.setFormat('duration', duration);\n                }\n            }\n            const encoderInfo = encoderDict[ssd.dataFormat];\n            if (encoderInfo) {\n                this.metadata.setFormat('lossless', !encoderInfo.lossy);\n            }\n            this.calculateBitRate();\n        }\n    }\n    async handleAtom(atom, remaining) {\n        if (atom.parent) {\n            switch (atom.parent.header.name) {\n                case 'ilst':\n                case '<id>':\n                    return this.parseMetadataItemData(atom);\n            }\n        }\n        // const payloadLength = atom.getPayloadLength(remaining);\n        if (this.atomParsers[atom.header.name]) {\n            return this.atomParsers[atom.header.name](remaining);\n        }\n        else {\n            debug(`No parser for atom path=${atom.atomPath}, payload-len=${remaining}, ignoring atom`);\n            await this.tokenizer.ignore(remaining);\n        }\n    }\n    getTrackDescription() {\n        return this.tracks[this.tracks.length - 1];\n    }\n    calculateBitRate() {\n        if (this.audioLengthInBytes && this.metadata.format.duration) {\n            this.metadata.setFormat('bitrate', 8 * this.audioLengthInBytes / this.metadata.format.duration);\n        }\n    }\n    addTag(id, value) {\n        this.metadata.addTag(tagFormat, id, value);\n    }\n    addWarning(message) {\n        debug('Warning: ' + message);\n        this.metadata.addWarning(message);\n    }\n    /**\n     * Parse data of Meta-item-list-atom (item of 'ilst' atom)\n     * @param metaAtom\n     * Ref: https://developer.apple.com/library/content/documentation/QuickTime/QTFF/Metadata/Metadata.html#//apple_ref/doc/uid/TP40000939-CH1-SW8\n     */\n    parseMetadataItemData(metaAtom) {\n        let tagKey = metaAtom.header.name;\n        return metaAtom.readAtoms(this.tokenizer, async (child, remaining) => {\n            const payLoadLength = child.getPayloadLength(remaining);\n            switch (child.header.name) {\n                case 'data': // value atom\n                    return this.parseValueAtom(tagKey, child);\n                case 'name': // name atom (optional)\n                case 'mean':\n                case 'rate':\n                    const name = await this.tokenizer.readToken(new AtomToken.NameAtom(payLoadLength));\n                    tagKey += ':' + name.name;\n                    break;\n                default:\n                    const dataAtom = await this.tokenizer.readToken(new Token.BufferType(payLoadLength));\n                    this.addWarning('Unsupported meta-item: ' + tagKey + '[' + child.header.name + '] => value=' + dataAtom.toString('hex') + ' ascii=' + dataAtom.toString('ascii'));\n            }\n        }, metaAtom.getPayloadLength(0));\n    }\n    async parseValueAtom(tagKey, metaAtom) {\n        const dataAtom = await this.tokenizer.readToken(new AtomToken.DataAtom(Number(metaAtom.header.length) - AtomToken.Header.len));\n        if (dataAtom.type.set !== 0) {\n            throw new Error('Unsupported type-set != 0: ' + dataAtom.type.set);\n        }\n        // Use well-known-type table\n        // Ref: https://developer.apple.com/library/content/documentation/QuickTime/QTFF/Metadata/Metadata.html#//apple_ref/doc/uid/TP40000939-CH1-SW35\n        switch (dataAtom.type.type) {\n            case 0: // reserved: Reserved for use where no type needs to be indicated\n                switch (tagKey) {\n                    case 'trkn':\n                    case 'disk':\n                        const num = Token.UINT8.get(dataAtom.value, 3);\n                        const of = Token.UINT8.get(dataAtom.value, 5);\n                        // console.log(\"  %s[data] = %s/%s\", tagKey, num, of);\n                        this.addTag(tagKey, num + '/' + of);\n                        break;\n                    case 'gnre':\n                        const genreInt = Token.UINT8.get(dataAtom.value, 1);\n                        const genreStr = ID3v1Parser_1.Genres[genreInt - 1];\n                        // console.log(\"  %s[data] = %s\", tagKey, genreStr);\n                        this.addTag(tagKey, genreStr);\n                        break;\n                    case 'rate':\n                        const rate = dataAtom.value.toString('ascii');\n                        this.addTag(tagKey, rate);\n                        break;\n                    default:\n                        debug('unknown proprietary value type for: ' + metaAtom.atomPath);\n                }\n                break;\n            case 1: // UTF-8: Without any count or NULL terminator\n            case 18: // Unknown: Found in m4b in combination with a 'gen' tag\n                this.addTag(tagKey, dataAtom.value.toString('utf-8'));\n                break;\n            case 13: // JPEG\n                if (this.options.skipCovers)\n                    break;\n                this.addTag(tagKey, {\n                    format: 'image/jpeg',\n                    data: Buffer.from(dataAtom.value)\n                });\n                break;\n            case 14: // PNG\n                if (this.options.skipCovers)\n                    break;\n                this.addTag(tagKey, {\n                    format: 'image/png',\n                    data: Buffer.from(dataAtom.value)\n                });\n                break;\n            case 21: // BE Signed Integer\n                this.addTag(tagKey, MP4Parser.read_BE_Integer(dataAtom.value, true));\n                break;\n            case 22: // BE Unsigned Integer\n                this.addTag(tagKey, MP4Parser.read_BE_Integer(dataAtom.value, false));\n                break;\n            case 65: // An 8-bit signed integer\n                this.addTag(tagKey, dataAtom.value.readInt8(0));\n                break;\n            case 66: // A big-endian 16-bit signed integer\n                this.addTag(tagKey, dataAtom.value.readInt16BE(0));\n                break;\n            case 67: // A big-endian 32-bit signed integer\n                this.addTag(tagKey, dataAtom.value.readInt32BE(0));\n                break;\n            default:\n                this.addWarning(`atom key=${tagKey}, has unknown well-known-type (data-type): ${dataAtom.type.type}`);\n        }\n    }\n    /**\n     * @param sampleDescription\n     * Ref: https://developer.apple.com/library/archive/documentation/QuickTime/QTFF/QTFFChap3/qtff3.html#//apple_ref/doc/uid/TP40000939-CH205-128916\n     */\n    parseSoundSampleDescription(sampleDescription) {\n        const ssd = {\n            dataFormat: sampleDescription.dataFormat,\n            dataReferenceIndex: sampleDescription.dataReferenceIndex\n        };\n        let offset = 0;\n        const version = AtomToken.SoundSampleDescriptionVersion.get(sampleDescription.description, offset);\n        offset += AtomToken.SoundSampleDescriptionVersion.len;\n        if (version.version === 0 || version.version === 1) {\n            // Sound Sample Description (Version 0)\n            ssd.description = AtomToken.SoundSampleDescriptionV0.get(sampleDescription.description, offset);\n        }\n        else {\n            debug(`Warning: sound-sample-description ${version} not implemented`);\n        }\n        return ssd;\n    }\n    async parseChapterTrack(chapterTrack, track, len) {\n        if (!chapterTrack.sampleSize) {\n            if (chapterTrack.chunkOffsetTable.length !== chapterTrack.sampleSizeTable.length)\n                throw new Error('Expected equal chunk-offset-table & sample-size-table length.');\n        }\n        const chapters = [];\n        for (let i = 0; i < chapterTrack.chunkOffsetTable.length && len > 0; ++i) {\n            const chunkOffset = chapterTrack.chunkOffsetTable[i];\n            const nextChunkLen = chunkOffset - this.tokenizer.position;\n            const sampleSize = chapterTrack.sampleSize > 0 ? chapterTrack.sampleSize : chapterTrack.sampleSizeTable[i];\n            len -= nextChunkLen + sampleSize;\n            if (len < 0)\n                throw new Error('Chapter chunk exceeding token length');\n            await this.tokenizer.ignore(nextChunkLen);\n            const title = await this.tokenizer.readToken(new AtomToken.ChapterText(sampleSize));\n            debug(`Chapter ${i + 1}: ${title}`);\n            const chapter = {\n                title,\n                sampleOffset: this.findSampleOffset(track, this.tokenizer.position)\n            };\n            debug(`Chapter title=${chapter.title}, offset=${chapter.sampleOffset}/${this.tracks[0].duration}`);\n            chapters.push(chapter);\n        }\n        this.metadata.setFormat('chapters', chapters);\n        await this.tokenizer.ignore(len);\n    }\n    findSampleOffset(track, chapterOffset) {\n        let totalDuration = 0;\n        track.timeToSampleTable.forEach(e => {\n            totalDuration += e.count * e.duration;\n        });\n        debug(`Total duration=${totalDuration}`);\n        let chunkIndex = 0;\n        while (chunkIndex < track.chunkOffsetTable.length && track.chunkOffsetTable[chunkIndex] < chapterOffset) {\n            ++chunkIndex;\n        }\n        return this.getChunkDuration(chunkIndex + 1, track);\n    }\n    getChunkDuration(chunkId, track) {\n        let ttsi = 0;\n        let ttsc = track.timeToSampleTable[ttsi].count;\n        let ttsd = track.timeToSampleTable[ttsi].duration;\n        let curChunkId = 1;\n        let samplesPerChunk = this.getSamplesPerChunk(curChunkId, track.sampleToChunkTable);\n        let totalDuration = 0;\n        while (curChunkId < chunkId) {\n            const nrOfSamples = Math.min(ttsc, samplesPerChunk);\n            totalDuration += nrOfSamples * ttsd;\n            ttsc -= nrOfSamples;\n            samplesPerChunk -= nrOfSamples;\n            if (samplesPerChunk === 0) {\n                ++curChunkId;\n                samplesPerChunk = this.getSamplesPerChunk(curChunkId, track.sampleToChunkTable);\n            }\n            else {\n                ++ttsi;\n                ttsc = track.timeToSampleTable[ttsi].count;\n                ttsd = track.timeToSampleTable[ttsi].duration;\n            }\n        }\n        return totalDuration;\n    }\n    getSamplesPerChunk(chunkId, stcTable) {\n        for (let i = 0; i < stcTable.length - 1; ++i) {\n            if (chunkId >= stcTable[i].firstChunk && chunkId < stcTable[i + 1].firstChunk) {\n                return stcTable[i].samplesPerChunk;\n            }\n        }\n        return stcTable[stcTable.length - 1].samplesPerChunk;\n    }\n}\nexports.MP4Parser = MP4Parser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/MP4Parser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/MP4TagMapper.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/MP4TagMapper.js ***!
  \******************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MP4TagMapper = exports.tagType = void 0;\nconst CaseInsensitiveTagMap_1 = __webpack_require__(/*! ../common/CaseInsensitiveTagMap */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/CaseInsensitiveTagMap.js\");\n/**\n * Ref: https://github.com/sergiomb2/libmp4v2/wiki/iTunesMetadata\n */\nconst mp4TagMap = {\n    'nam': 'title',\n    'ART': 'artist',\n    aART: 'albumartist',\n    /**\n     * ToDo: Album artist seems to be stored here while Picard documentation says: aART\n     */\n    '----:com.apple.iTunes:Band': 'albumartist',\n    'alb': 'album',\n    'day': 'date',\n    'cmt': 'comment',\n    'com': 'comment',\n    trkn: 'track',\n    disk: 'disk',\n    'gen': 'genre',\n    covr: 'picture',\n    'wrt': 'composer',\n    'lyr': 'lyrics',\n    soal: 'albumsort',\n    sonm: 'titlesort',\n    soar: 'artistsort',\n    soaa: 'albumartistsort',\n    soco: 'composersort',\n    '----:com.apple.iTunes:LYRICIST': 'lyricist',\n    '----:com.apple.iTunes:CONDUCTOR': 'conductor',\n    '----:com.apple.iTunes:REMIXER': 'remixer',\n    '----:com.apple.iTunes:ENGINEER': 'engineer',\n    '----:com.apple.iTunes:PRODUCER': 'producer',\n    '----:com.apple.iTunes:DJMIXER': 'djmixer',\n    '----:com.apple.iTunes:MIXER': 'mixer',\n    '----:com.apple.iTunes:LABEL': 'label',\n    'grp': 'grouping',\n    '----:com.apple.iTunes:SUBTITLE': 'subtitle',\n    '----:com.apple.iTunes:DISCSUBTITLE': 'discsubtitle',\n    cpil: 'compilation',\n    tmpo: 'bpm',\n    '----:com.apple.iTunes:MOOD': 'mood',\n    '----:com.apple.iTunes:MEDIA': 'media',\n    '----:com.apple.iTunes:CATALOGNUMBER': 'catalognumber',\n    tvsh: 'tvShow',\n    tvsn: 'tvSeason',\n    tves: 'tvEpisode',\n    sosn: 'tvShowSort',\n    tven: 'tvEpisodeId',\n    tvnn: 'tvNetwork',\n    pcst: 'podcast',\n    purl: 'podcasturl',\n    '----:com.apple.iTunes:MusicBrainz Album Status': 'releasestatus',\n    '----:com.apple.iTunes:MusicBrainz Album Type': 'releasetype',\n    '----:com.apple.iTunes:MusicBrainz Album Release Country': 'releasecountry',\n    '----:com.apple.iTunes:SCRIPT': 'script',\n    '----:com.apple.iTunes:LANGUAGE': 'language',\n    cprt: 'copyright',\n    'cpy': 'copyright',\n    '----:com.apple.iTunes:LICENSE': 'license',\n    'too': 'encodedby',\n    pgap: 'gapless',\n    '----:com.apple.iTunes:BARCODE': 'barcode',\n    '----:com.apple.iTunes:ISRC': 'isrc',\n    '----:com.apple.iTunes:ASIN': 'asin',\n    '----:com.apple.iTunes:NOTES': 'comment',\n    '----:com.apple.iTunes:MusicBrainz Track Id': 'musicbrainz_recordingid',\n    '----:com.apple.iTunes:MusicBrainz Release Track Id': 'musicbrainz_trackid',\n    '----:com.apple.iTunes:MusicBrainz Album Id': 'musicbrainz_albumid',\n    '----:com.apple.iTunes:MusicBrainz Artist Id': 'musicbrainz_artistid',\n    '----:com.apple.iTunes:MusicBrainz Album Artist Id': 'musicbrainz_albumartistid',\n    '----:com.apple.iTunes:MusicBrainz Release Group Id': 'musicbrainz_releasegroupid',\n    '----:com.apple.iTunes:MusicBrainz Work Id': 'musicbrainz_workid',\n    '----:com.apple.iTunes:MusicBrainz TRM Id': 'musicbrainz_trmid',\n    '----:com.apple.iTunes:MusicBrainz Disc Id': 'musicbrainz_discid',\n    '----:com.apple.iTunes:Acoustid Id': 'acoustid_id',\n    '----:com.apple.iTunes:Acoustid Fingerprint': 'acoustid_fingerprint',\n    '----:com.apple.iTunes:MusicIP PUID': 'musicip_puid',\n    '----:com.apple.iTunes:fingerprint': 'musicip_fingerprint',\n    '----:com.apple.iTunes:replaygain_track_gain': 'replaygain_track_gain',\n    '----:com.apple.iTunes:replaygain_track_peak': 'replaygain_track_peak',\n    '----:com.apple.iTunes:replaygain_album_gain': 'replaygain_album_gain',\n    '----:com.apple.iTunes:replaygain_album_peak': 'replaygain_album_peak',\n    '----:com.apple.iTunes:replaygain_track_minmax': 'replaygain_track_minmax',\n    '----:com.apple.iTunes:replaygain_album_minmax': 'replaygain_album_minmax',\n    '----:com.apple.iTunes:replaygain_undo': 'replaygain_undo',\n    // Additional mappings:\n    gnre: 'genre',\n    '----:com.apple.iTunes:ALBUMARTISTSORT': 'albumartistsort',\n    '----:com.apple.iTunes:ARTISTS': 'artists',\n    '----:com.apple.iTunes:ORIGINALDATE': 'originaldate',\n    '----:com.apple.iTunes:ORIGINALYEAR': 'originalyear',\n    // '----:com.apple.iTunes:PERFORMER': 'performer'\n    desc: 'description',\n    ldes: 'longDescription',\n    'mvn': 'movement',\n    'mvi': 'movementIndex',\n    'mvc': 'movementTotal',\n    'wrk': 'work',\n    catg: 'category',\n    egid: 'podcastId',\n    hdvd: 'hdVideo',\n    keyw: 'keywords',\n    shwm: 'showMovement',\n    stik: 'stik',\n    rate: 'rating'\n};\nexports.tagType = 'iTunes';\nclass MP4TagMapper extends CaseInsensitiveTagMap_1.CaseInsensitiveTagMap {\n    constructor() {\n        super([exports.tagType], mp4TagMap);\n    }\n    postMap(tag, warnings) {\n        switch (tag.id) {\n            case 'rate':\n                tag.value = {\n                    source: undefined,\n                    rating: parseFloat(tag.value) / 100\n                };\n                break;\n        }\n    }\n}\nexports.MP4TagMapper = MP4TagMapper;\n//# sourceMappingURL=MP4TagMapper.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mp4/MP4TagMapper.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/ExtendedLameHeader.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/ExtendedLameHeader.js ***!
  \*************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\n/**\n * Extended Lame Header\n */\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.ExtendedLameHeader = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nconst common = __webpack_require__(/*! ../common/Util */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js");\nconst ReplayGainDataFormat_1 = __webpack_require__(/*! ./ReplayGainDataFormat */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/ReplayGainDataFormat.js");\n/**\n * Info Tag\n * @link http://gabriel.mp3-tech.org/mp3infotag.html\n * @link https://github.com/quodlibet/mutagen/blob/abd58ee58772224334a18817c3fb31103572f70e/mutagen/mp3/_util.py#L112\n */\nexports.ExtendedLameHeader = {\n    len: 27,\n    get: (buf, off) => {\n        const track_peak = Token.UINT32_BE.get(buf, off + 2);\n        return {\n            revision: common.getBitAllignedNumber(buf, off, 0, 4),\n            vbr_method: common.getBitAllignedNumber(buf, off, 4, 4),\n            lowpass_filter: 100 * Token.UINT8.get(buf, off + 1),\n            track_peak: track_peak === 0 ? undefined : track_peak / Math.pow(2, 23),\n            track_gain: ReplayGainDataFormat_1.ReplayGain.get(buf, 6),\n            album_gain: ReplayGainDataFormat_1.ReplayGain.get(buf, 8),\n            music_length: Token.UINT32_BE.get(buf, off + 20),\n            music_crc: Token.UINT8.get(buf, off + 24),\n            header_crc: Token.UINT16_BE.get(buf, off + 24)\n        };\n    }\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/ExtendedLameHeader.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/MpegParser.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/MpegParser.js ***!
  \*****************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ \"./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js\")[\"Buffer\"];\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MpegParser = void 0;\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst core_1 = __webpack_require__(/*! strtok3/lib/core */ \"./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/core.js\");\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst common = __webpack_require__(/*! ../common/Util */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js\");\nconst AbstractID3Parser_1 = __webpack_require__(/*! ../id3v2/AbstractID3Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/AbstractID3Parser.js\");\nconst XingTag_1 = __webpack_require__(/*! ./XingTag */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/XingTag.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:mpeg');\n/**\n * Cache buffer size used for searching synchronization preabmle\n */\nconst maxPeekLen = 1024;\n/**\n * MPEG-4 Audio definitions\n * Ref:  https://wiki.multimedia.cx/index.php/MPEG-4_Audio\n */\nconst MPEG4 = {\n    /**\n     * Audio Object Types\n     */\n    AudioObjectTypes: [\n        'AAC Main',\n        'AAC LC',\n        'AAC SSR',\n        'AAC LTP' // Long Term Prediction\n    ],\n    /**\n     * Sampling Frequencies\n     * https://wiki.multimedia.cx/index.php/MPEG-4_Audio#Sampling_Frequencies\n     */\n    SamplingFrequencies: [\n        96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050, 16000, 12000, 11025, 8000, 7350, undefined, undefined, -1\n    ]\n    /**\n     * Channel Configurations\n     */\n};\nconst MPEG4_ChannelConfigurations = [\n    undefined,\n    ['front-center'],\n    ['front-left', 'front-right'],\n    ['front-center', 'front-left', 'front-right'],\n    ['front-center', 'front-left', 'front-right', 'back-center'],\n    ['front-center', 'front-left', 'front-right', 'back-left', 'back-right'],\n    ['front-center', 'front-left', 'front-right', 'back-left', 'back-right', 'LFE-channel'],\n    ['front-center', 'front-left', 'front-right', 'side-left', 'side-right', 'back-left', 'back-right', 'LFE-channel']\n];\n/**\n * MPEG Audio Layer I/II/III frame header\n * Ref: https://www.mp3-tech.org/programmer/frame_header.html\n * Bit layout: AAAAAAAA AAABBCCD EEEEFFGH IIJJKLMM\n * Ref: https://wiki.multimedia.cx/index.php/ADTS\n */\nclass MpegFrameHeader {\n    constructor(buf, off) {\n        // B(20,19): MPEG Audio versionIndex ID\n        this.versionIndex = common.getBitAllignedNumber(buf, off + 1, 3, 2);\n        // C(18,17): Layer description\n        this.layer = MpegFrameHeader.LayerDescription[common.getBitAllignedNumber(buf, off + 1, 5, 2)];\n        if (this.versionIndex > 1 && this.layer === 0) {\n            this.parseAdtsHeader(buf, off); // Audio Data Transport Stream (ADTS)\n        }\n        else {\n            this.parseMpegHeader(buf, off); // Conventional MPEG header\n        }\n        // D(16): Protection bit (if true 16-bit CRC follows header)\n        this.isProtectedByCRC = !common.isBitSet(buf, off + 1, 7);\n    }\n    calcDuration(numFrames) {\n        return numFrames * this.calcSamplesPerFrame() / this.samplingRate;\n    }\n    calcSamplesPerFrame() {\n        return MpegFrameHeader.samplesInFrameTable[this.version === 1 ? 0 : 1][this.layer];\n    }\n    calculateSideInfoLength() {\n        if (this.layer !== 3)\n            return 2;\n        if (this.channelModeIndex === 3) {\n            // mono\n            if (this.version === 1) {\n                return 17;\n            }\n            else if (this.version === 2 || this.version === 2.5) {\n                return 9;\n            }\n        }\n        else {\n            if (this.version === 1) {\n                return 32;\n            }\n            else if (this.version === 2 || this.version === 2.5) {\n                return 17;\n            }\n        }\n    }\n    calcSlotSize() {\n        return [null, 4, 1, 1][this.layer];\n    }\n    parseMpegHeader(buf, off) {\n        this.container = 'MPEG';\n        // E(15,12): Bitrate index\n        this.bitrateIndex = common.getBitAllignedNumber(buf, off + 2, 0, 4);\n        // F(11,10): Sampling rate frequency index\n        this.sampRateFreqIndex = common.getBitAllignedNumber(buf, off + 2, 4, 2);\n        // G(9): Padding bit\n        this.padding = common.isBitSet(buf, off + 2, 6);\n        // H(8): Private bit\n        this.privateBit = common.isBitSet(buf, off + 2, 7);\n        // I(7,6): Channel Mode\n        this.channelModeIndex = common.getBitAllignedNumber(buf, off + 3, 0, 2);\n        // J(5,4): Mode extension (Only used in Joint stereo)\n        this.modeExtension = common.getBitAllignedNumber(buf, off + 3, 2, 2);\n        // K(3): Copyright\n        this.isCopyrighted = common.isBitSet(buf, off + 3, 4);\n        // L(2): Original\n        this.isOriginalMedia = common.isBitSet(buf, off + 3, 5);\n        // M(3): The original bit indicates, if it is set, that the frame is located on its original media.\n        this.emphasis = common.getBitAllignedNumber(buf, off + 3, 7, 2);\n        this.version = MpegFrameHeader.VersionID[this.versionIndex];\n        this.channelMode = MpegFrameHeader.ChannelMode[this.channelModeIndex];\n        this.codec = `MPEG ${this.version} Layer ${this.layer}`;\n        // Calculate bitrate\n        const bitrateInKbps = this.calcBitrate();\n        if (!bitrateInKbps) {\n            throw new Error('Cannot determine bit-rate');\n        }\n        this.bitrate = bitrateInKbps * 1000;\n        // Calculate sampling rate\n        this.samplingRate = this.calcSamplingRate();\n        if (this.samplingRate == null) {\n            throw new Error('Cannot determine sampling-rate');\n        }\n    }\n    parseAdtsHeader(buf, off) {\n        debug(`layer=0 => ADTS`);\n        this.version = this.versionIndex === 2 ? 4 : 2;\n        this.container = 'ADTS/MPEG-' + this.version;\n        const profileIndex = common.getBitAllignedNumber(buf, off + 2, 0, 2);\n        this.codec = 'AAC';\n        this.codecProfile = MPEG4.AudioObjectTypes[profileIndex];\n        debug(`MPEG-4 audio-codec=${this.codec}`);\n        const samplingFrequencyIndex = common.getBitAllignedNumber(buf, off + 2, 2, 4);\n        this.samplingRate = MPEG4.SamplingFrequencies[samplingFrequencyIndex];\n        debug(`sampling-rate=${this.samplingRate}`);\n        const channelIndex = common.getBitAllignedNumber(buf, off + 2, 7, 3);\n        this.mp4ChannelConfig = MPEG4_ChannelConfigurations[channelIndex];\n        debug(`channel-config=${this.mp4ChannelConfig.join('+')}`);\n        this.frameLength = common.getBitAllignedNumber(buf, off + 3, 6, 2) << 11;\n    }\n    calcBitrate() {\n        if (this.bitrateIndex === 0x00 || // free\n            this.bitrateIndex === 0x0F) { // reserved\n            return;\n        }\n        const codecIndex = `${Math.floor(this.version)}${this.layer}`;\n        return MpegFrameHeader.bitrate_index[this.bitrateIndex][codecIndex];\n    }\n    calcSamplingRate() {\n        if (this.sampRateFreqIndex === 0x03)\n            return null; // 'reserved'\n        return MpegFrameHeader.sampling_rate_freq_index[this.version][this.sampRateFreqIndex];\n    }\n}\nMpegFrameHeader.SyncByte1 = 0xFF;\nMpegFrameHeader.SyncByte2 = 0xE0;\nMpegFrameHeader.VersionID = [2.5, null, 2, 1];\nMpegFrameHeader.LayerDescription = [0, 3, 2, 1];\nMpegFrameHeader.ChannelMode = ['stereo', 'joint_stereo', 'dual_channel', 'mono'];\nMpegFrameHeader.bitrate_index = {\n    0x01: { 11: 32, 12: 32, 13: 32, 21: 32, 22: 8, 23: 8 },\n    0x02: { 11: 64, 12: 48, 13: 40, 21: 48, 22: 16, 23: 16 },\n    0x03: { 11: 96, 12: 56, 13: 48, 21: 56, 22: 24, 23: 24 },\n    0x04: { 11: 128, 12: 64, 13: 56, 21: 64, 22: 32, 23: 32 },\n    0x05: { 11: 160, 12: 80, 13: 64, 21: 80, 22: 40, 23: 40 },\n    0x06: { 11: 192, 12: 96, 13: 80, 21: 96, 22: 48, 23: 48 },\n    0x07: { 11: 224, 12: 112, 13: 96, 21: 112, 22: 56, 23: 56 },\n    0x08: { 11: 256, 12: 128, 13: 112, 21: 128, 22: 64, 23: 64 },\n    0x09: { 11: 288, 12: 160, 13: 128, 21: 144, 22: 80, 23: 80 },\n    0x0A: { 11: 320, 12: 192, 13: 160, 21: 160, 22: 96, 23: 96 },\n    0x0B: { 11: 352, 12: 224, 13: 192, 21: 176, 22: 112, 23: 112 },\n    0x0C: { 11: 384, 12: 256, 13: 224, 21: 192, 22: 128, 23: 128 },\n    0x0D: { 11: 416, 12: 320, 13: 256, 21: 224, 22: 144, 23: 144 },\n    0x0E: { 11: 448, 12: 384, 13: 320, 21: 256, 22: 160, 23: 160 }\n};\nMpegFrameHeader.sampling_rate_freq_index = {\n    1: { 0x00: 44100, 0x01: 48000, 0x02: 32000 },\n    2: { 0x00: 22050, 0x01: 24000, 0x02: 16000 },\n    2.5: { 0x00: 11025, 0x01: 12000, 0x02: 8000 }\n};\nMpegFrameHeader.samplesInFrameTable = [\n    /* Layer   I    II   III */\n    [0, 384, 1152, 1152],\n    [0, 384, 1152, 576] // MPEG-2(.5\n];\n/**\n * MPEG Audio Layer I/II/III\n */\nconst FrameHeader = {\n    len: 4,\n    get: (buf, off) => {\n        return new MpegFrameHeader(buf, off);\n    }\n};\nfunction getVbrCodecProfile(vbrScale) {\n    return 'V' + Math.floor((100 - vbrScale) / 10);\n}\nclass MpegParser extends AbstractID3Parser_1.AbstractID3Parser {\n    constructor() {\n        super(...arguments);\n        this.frameCount = 0;\n        this.syncFrameCount = -1;\n        this.countSkipFrameData = 0;\n        this.totalDataLength = 0;\n        this.bitrates = [];\n        this.calculateEofDuration = false;\n        this.buf_frame_header = Buffer.alloc(4);\n        this.syncPeek = {\n            buf: Buffer.alloc(maxPeekLen),\n            len: 0\n        };\n    }\n    /**\n     * Called after ID3 headers have been parsed\n     */\n    async postId3v2Parse() {\n        this.metadata.setFormat('lossless', false);\n        try {\n            let quit = false;\n            while (!quit) {\n                await this.sync();\n                quit = await this.parseCommonMpegHeader();\n            }\n        }\n        catch (err) {\n            if (err instanceof core_1.EndOfStreamError) {\n                debug(`End-of-stream`);\n                if (this.calculateEofDuration) {\n                    const numberOfSamples = this.frameCount * this.samplesPerFrame;\n                    this.metadata.setFormat('numberOfSamples', numberOfSamples);\n                    const duration = numberOfSamples / this.metadata.format.sampleRate;\n                    debug(`Calculate duration at EOF: ${duration} sec.`, duration);\n                    this.metadata.setFormat('duration', duration);\n                }\n            }\n            else {\n                throw err;\n            }\n        }\n    }\n    /**\n     * Called after file has been fully parsed, this allows, if present, to exclude the ID3v1.1 header length\n     */\n    finalize() {\n        const format = this.metadata.format;\n        const hasID3v1 = this.metadata.native.hasOwnProperty('ID3v1');\n        if (format.duration && this.tokenizer.fileInfo.size) {\n            const mpegSize = this.tokenizer.fileInfo.size - this.mpegOffset - (hasID3v1 ? 128 : 0);\n            if (format.codecProfile && format.codecProfile[0] === 'V') {\n                this.metadata.setFormat('bitrate', mpegSize * 8 / format.duration);\n            }\n        }\n        else if (this.tokenizer.fileInfo.size && format.codecProfile === 'CBR') {\n            const mpegSize = this.tokenizer.fileInfo.size - this.mpegOffset - (hasID3v1 ? 128 : 0);\n            const numberOfSamples = Math.round(mpegSize / this.frame_size) * this.samplesPerFrame;\n            this.metadata.setFormat('numberOfSamples', numberOfSamples);\n            const duration = numberOfSamples / format.sampleRate;\n            debug(\"Calculate CBR duration based on file size: %s\", duration);\n            this.metadata.setFormat('duration', duration);\n        }\n    }\n    async sync() {\n        let gotFirstSync = false;\n        while (true) {\n            let bo = 0;\n            this.syncPeek.len = await this.tokenizer.peekBuffer(this.syncPeek.buf, { length: maxPeekLen, mayBeLess: true });\n            if (this.syncPeek.len <= 163) {\n                throw new core_1.EndOfStreamError();\n            }\n            while (true) {\n                if (gotFirstSync && (this.syncPeek.buf[bo] & 0xE0) === 0xE0) {\n                    this.buf_frame_header[0] = MpegFrameHeader.SyncByte1;\n                    this.buf_frame_header[1] = this.syncPeek.buf[bo];\n                    await this.tokenizer.ignore(bo);\n                    debug(`Sync at offset=${this.tokenizer.position - 1}, frameCount=${this.frameCount}`);\n                    if (this.syncFrameCount === this.frameCount) {\n                        debug(`Re-synced MPEG stream, frameCount=${this.frameCount}`);\n                        this.frameCount = 0;\n                        this.frame_size = 0;\n                    }\n                    this.syncFrameCount = this.frameCount;\n                    return; // sync\n                }\n                else {\n                    gotFirstSync = false;\n                    bo = this.syncPeek.buf.indexOf(MpegFrameHeader.SyncByte1, bo);\n                    if (bo === -1) {\n                        if (this.syncPeek.len < this.syncPeek.buf.length) {\n                            throw new core_1.EndOfStreamError();\n                        }\n                        await this.tokenizer.ignore(this.syncPeek.len);\n                        break; // continue with next buffer\n                    }\n                    else {\n                        ++bo;\n                        gotFirstSync = true;\n                    }\n                }\n            }\n        }\n    }\n    /**\n     * Combined ADTS & MPEG (MP2 & MP3) header handling\n     * @return {Promise<boolean>} true if parser should quit\n     */\n    async parseCommonMpegHeader() {\n        if (this.frameCount === 0) {\n            this.mpegOffset = this.tokenizer.position - 1;\n        }\n        await this.tokenizer.peekBuffer(this.buf_frame_header, { offset: 1, length: 3 });\n        let header;\n        try {\n            header = FrameHeader.get(this.buf_frame_header, 0);\n        }\n        catch (err) {\n            await this.tokenizer.ignore(1);\n            this.metadata.addWarning('Parse error: ' + err.message);\n            return false; // sync\n        }\n        await this.tokenizer.ignore(3);\n        this.metadata.setFormat('container', header.container);\n        this.metadata.setFormat('codec', header.codec);\n        this.metadata.setFormat('lossless', false);\n        this.metadata.setFormat('sampleRate', header.samplingRate);\n        this.frameCount++;\n        return header.version >= 2 && header.layer === 0 ? this.parseAdts(header) : this.parseAudioFrameHeader(header);\n    }\n    /**\n     * @return {Promise<boolean>} true if parser should quit\n     */\n    async parseAudioFrameHeader(header) {\n        this.metadata.setFormat('numberOfChannels', header.channelMode === 'mono' ? 1 : 2);\n        this.metadata.setFormat('bitrate', header.bitrate);\n        if (this.frameCount < 20 * 10000) {\n            debug('offset=%s MP%s bitrate=%s sample-rate=%s', this.tokenizer.position - 4, header.layer, header.bitrate, header.samplingRate);\n        }\n        const slot_size = header.calcSlotSize();\n        if (slot_size === null) {\n            throw new Error('invalid slot_size');\n        }\n        const samples_per_frame = header.calcSamplesPerFrame();\n        debug(`samples_per_frame=${samples_per_frame}`);\n        const bps = samples_per_frame / 8.0;\n        const fsize = (bps * header.bitrate / header.samplingRate) +\n            ((header.padding) ? slot_size : 0);\n        this.frame_size = Math.floor(fsize);\n        this.audioFrameHeader = header;\n        this.bitrates.push(header.bitrate);\n        // xtra header only exists in first frame\n        if (this.frameCount === 1) {\n            this.offset = FrameHeader.len;\n            await this.skipSideInformation();\n            return false;\n        }\n        if (this.frameCount === 3) {\n            // the stream is CBR if the first 3 frame bitrates are the same\n            if (this.areAllSame(this.bitrates)) {\n                // Actual calculation will be done in finalize\n                this.samplesPerFrame = samples_per_frame;\n                this.metadata.setFormat('codecProfile', 'CBR');\n                if (this.tokenizer.fileInfo.size)\n                    return true; // Will calculate duration based on the file size\n            }\n            else if (this.metadata.format.duration) {\n                return true; // We already got the duration, stop processing MPEG stream any further\n            }\n            if (!this.options.duration) {\n                return true; // Enforce duration not enabled, stop processing entire stream\n            }\n        }\n        // once we know the file is VBR attach listener to end of\n        // stream so we can do the duration calculation when we\n        // have counted all the frames\n        if (this.options.duration && this.frameCount === 4) {\n            this.samplesPerFrame = samples_per_frame;\n            this.calculateEofDuration = true;\n        }\n        this.offset = 4;\n        if (header.isProtectedByCRC) {\n            await this.parseCrc();\n            return false;\n        }\n        else {\n            await this.skipSideInformation();\n            return false;\n        }\n    }\n    async parseAdts(header) {\n        const buf = Buffer.alloc(3);\n        await this.tokenizer.readBuffer(buf);\n        header.frameLength += common.getBitAllignedNumber(buf, 0, 0, 11);\n        this.totalDataLength += header.frameLength;\n        this.samplesPerFrame = 1024;\n        const framesPerSec = header.samplingRate / this.samplesPerFrame;\n        const bytesPerFrame = this.frameCount === 0 ? 0 : this.totalDataLength / this.frameCount;\n        const bitrate = 8 * bytesPerFrame * framesPerSec + 0.5;\n        this.metadata.setFormat('bitrate', bitrate);\n        debug(`frame-count=${this.frameCount}, size=${header.frameLength} bytes, bit-rate=${bitrate}`);\n        await this.tokenizer.ignore(header.frameLength > 7 ? header.frameLength - 7 : 1);\n        // Consume remaining header and frame data\n        if (this.frameCount === 3) {\n            this.metadata.setFormat('codecProfile', header.codecProfile);\n            if (header.mp4ChannelConfig) {\n                this.metadata.setFormat('numberOfChannels', header.mp4ChannelConfig.length);\n            }\n            if (this.options.duration) {\n                this.calculateEofDuration = true;\n            }\n            else {\n                return true; // Stop parsing after the third frame\n            }\n        }\n        return false;\n    }\n    async parseCrc() {\n        this.crc = await this.tokenizer.readNumber(Token.INT16_BE);\n        this.offset += 2;\n        return this.skipSideInformation();\n    }\n    async skipSideInformation() {\n        const sideinfo_length = this.audioFrameHeader.calculateSideInfoLength();\n        // side information\n        await this.tokenizer.readToken(new Token.Uint8ArrayType(sideinfo_length));\n        this.offset += sideinfo_length;\n        await this.readXtraInfoHeader();\n        return;\n    }\n    async readXtraInfoHeader() {\n        const headerTag = await this.tokenizer.readToken(XingTag_1.InfoTagHeaderTag);\n        this.offset += XingTag_1.InfoTagHeaderTag.len; // 12\n        switch (headerTag) {\n            case 'Info':\n                this.metadata.setFormat('codecProfile', 'CBR');\n                return this.readXingInfoHeader();\n            case 'Xing':\n                const infoTag = await this.readXingInfoHeader();\n                const codecProfile = getVbrCodecProfile(infoTag.vbrScale);\n                this.metadata.setFormat('codecProfile', codecProfile);\n                return null;\n            case 'Xtra':\n                // ToDo: ???\n                break;\n            case 'LAME':\n                const version = await this.tokenizer.readToken(XingTag_1.LameEncoderVersion);\n                if (this.frame_size >= this.offset + XingTag_1.LameEncoderVersion.len) {\n                    this.offset += XingTag_1.LameEncoderVersion.len;\n                    this.metadata.setFormat('tool', 'LAME ' + version);\n                    await this.skipFrameData(this.frame_size - this.offset);\n                    return null;\n                }\n                else {\n                    this.metadata.addWarning('Corrupt LAME header');\n                    break;\n                }\n            // ToDo: ???\n        }\n        // ToDo: promise duration???\n        const frameDataLeft = this.frame_size - this.offset;\n        if (frameDataLeft < 0) {\n            this.metadata.addWarning('Frame ' + this.frameCount + 'corrupt: negative frameDataLeft');\n        }\n        else {\n            await this.skipFrameData(frameDataLeft);\n        }\n        return null;\n    }\n    /**\n     * Ref: http://gabriel.mp3-tech.org/mp3infotag.html\n     * @returns {Promise<string>}\n     */\n    async readXingInfoHeader() {\n        const offset = this.tokenizer.position;\n        const infoTag = await (0, XingTag_1.readXingHeader)(this.tokenizer);\n        this.offset += this.tokenizer.position - offset;\n        if (infoTag.lame) {\n            this.metadata.setFormat('tool', 'LAME ' + common.stripNulls(infoTag.lame.version));\n            if (infoTag.lame.extended) {\n                // this.metadata.setFormat('trackGain', infoTag.lame.extended.track_gain);\n                this.metadata.setFormat('trackPeakLevel', infoTag.lame.extended.track_peak);\n                if (infoTag.lame.extended.track_gain) {\n                    this.metadata.setFormat('trackGain', infoTag.lame.extended.track_gain.adjustment);\n                }\n                if (infoTag.lame.extended.album_gain) {\n                    this.metadata.setFormat('albumGain', infoTag.lame.extended.album_gain.adjustment);\n                }\n                this.metadata.setFormat('duration', infoTag.lame.extended.music_length / 1000);\n            }\n        }\n        if (infoTag.streamSize) {\n            const duration = this.audioFrameHeader.calcDuration(infoTag.numFrames);\n            this.metadata.setFormat('duration', duration);\n            debug('Get duration from Xing header: %s', this.metadata.format.duration);\n            return infoTag;\n        }\n        // frames field is not present\n        const frameDataLeft = this.frame_size - this.offset;\n        await this.skipFrameData(frameDataLeft);\n        return infoTag;\n    }\n    async skipFrameData(frameDataLeft) {\n        if (frameDataLeft < 0)\n            throw new Error('frame-data-left cannot be negative');\n        await this.tokenizer.ignore(frameDataLeft);\n        this.countSkipFrameData += frameDataLeft;\n    }\n    areAllSame(array) {\n        const first = array[0];\n        return array.every(element => {\n            return element === first;\n        });\n    }\n}\nexports.MpegParser = MpegParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/MpegParser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/ReplayGainDataFormat.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/ReplayGainDataFormat.js ***!
  \***************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.ReplayGain = void 0;\nconst common = __webpack_require__(/*! ../common/Util */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js");\n/**\n * https://github.com/Borewit/music-metadata/wiki/Replay-Gain-Data-Format#name-code\n */\nvar NameCode;\n(function (NameCode) {\n    /**\n     * not set\n     */\n    NameCode[NameCode["not_set"] = 0] = "not_set";\n    /**\n     * Radio Gain Adjustment\n     */\n    NameCode[NameCode["radio"] = 1] = "radio";\n    /**\n     * Audiophile Gain Adjustment\n     */\n    NameCode[NameCode["audiophile"] = 2] = "audiophile";\n})(NameCode || (NameCode = {}));\n/**\n * https://github.com/Borewit/music-metadata/wiki/Replay-Gain-Data-Format#originator-code\n */\nvar ReplayGainOriginator;\n(function (ReplayGainOriginator) {\n    /**\n     * Replay Gain unspecified\n     */\n    ReplayGainOriginator[ReplayGainOriginator["unspecified"] = 0] = "unspecified";\n    /**\n     * Replay Gain pre-set by artist/producer/mastering engineer\n     */\n    ReplayGainOriginator[ReplayGainOriginator["engineer"] = 1] = "engineer";\n    /**\n     * Replay Gain set by user\n     */\n    ReplayGainOriginator[ReplayGainOriginator["user"] = 2] = "user";\n    /**\n     * Replay Gain determined automatically, as described on this site\n     */\n    ReplayGainOriginator[ReplayGainOriginator["automatic"] = 3] = "automatic";\n    /**\n     * Set by simple RMS average\n     */\n    ReplayGainOriginator[ReplayGainOriginator["rms_average"] = 4] = "rms_average";\n})(ReplayGainOriginator || (ReplayGainOriginator = {}));\n/**\n * Replay Gain Data Format\n *\n * https://github.com/Borewit/music-metadata/wiki/Replay-Gain-Data-Format\n */\nexports.ReplayGain = {\n    len: 2,\n    get: (buf, off) => {\n        const gain_type = common.getBitAllignedNumber(buf, off, 0, 3);\n        const sign = common.getBitAllignedNumber(buf, off, 6, 1);\n        const gain_adj = common.getBitAllignedNumber(buf, off, 7, 9) / 10.0;\n        if (gain_type > 0) {\n            return {\n                type: common.getBitAllignedNumber(buf, off, 0, 3),\n                origin: common.getBitAllignedNumber(buf, off, 3, 3),\n                adjustment: (sign ? -gain_adj : gain_adj)\n            };\n        }\n        return undefined;\n    }\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/ReplayGainDataFormat.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/XingTag.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/XingTag.js ***!
  \**************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ "./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js")["Buffer"];\n\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.readXingHeader = exports.XingHeaderFlags = exports.LameEncoderVersion = exports.InfoTagHeaderTag = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nconst util = __webpack_require__(/*! ../common/Util */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js");\nconst ExtendedLameHeader_1 = __webpack_require__(/*! ./ExtendedLameHeader */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/ExtendedLameHeader.js");\n/**\n * Info Tag: Xing, LAME\n */\nexports.InfoTagHeaderTag = new Token.StringType(4, \'ascii\');\n/**\n * LAME TAG value\n * Did not find any official documentation for this\n * Value e.g.: "3.98.4"\n */\nexports.LameEncoderVersion = new Token.StringType(6, \'ascii\');\n/**\n * Info Tag\n * Ref: http://gabriel.mp3-tech.org/mp3infotag.html\n */\nexports.XingHeaderFlags = {\n    len: 4,\n    get: (buf, off) => {\n        return {\n            frames: util.isBitSet(buf, off, 31),\n            bytes: util.isBitSet(buf, off, 30),\n            toc: util.isBitSet(buf, off, 29),\n            vbrScale: util.isBitSet(buf, off, 28)\n        };\n    }\n};\n// /**\n//  * XING Header Tag\n//  * Ref: http://gabriel.mp3-tech.org/mp3infotag.html\n//  */\nasync function readXingHeader(tokenizer) {\n    const flags = await tokenizer.readToken(exports.XingHeaderFlags);\n    const xingInfoTag = {};\n    if (flags.frames) {\n        xingInfoTag.numFrames = await tokenizer.readToken(Token.UINT32_BE);\n    }\n    if (flags.bytes) {\n        xingInfoTag.streamSize = await tokenizer.readToken(Token.UINT32_BE);\n    }\n    if (flags.toc) {\n        xingInfoTag.toc = Buffer.alloc(100);\n        await tokenizer.readBuffer(xingInfoTag.toc);\n    }\n    if (flags.vbrScale) {\n        xingInfoTag.vbrScale = await tokenizer.readToken(Token.UINT32_BE);\n    }\n    const lameTag = await tokenizer.peekToken(new Token.StringType(4, \'ascii\'));\n    if (lameTag === \'LAME\') {\n        await tokenizer.ignore(4);\n        xingInfoTag.lame = {\n            version: await tokenizer.readToken(new Token.StringType(5, \'ascii\'))\n        };\n        const match = xingInfoTag.lame.version.match(/\\d+.\\d+/g);\n        if (match) {\n            const majorMinorVersion = xingInfoTag.lame.version.match(/\\d+.\\d+/g)[0]; // e.g. 3.97\n            const version = majorMinorVersion.split(\'.\').map(n => parseInt(n, 10));\n            if (version[0] >= 3 && version[1] >= 90) {\n                xingInfoTag.lame.extended = await tokenizer.readToken(ExtendedLameHeader_1.ExtendedLameHeader);\n            }\n        }\n    }\n    return xingInfoTag;\n}\nexports.readXingHeader = readXingHeader;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/mpeg/XingTag.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/index.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/index.js ***!
  \****************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst AbstractID3Parser_1 = __webpack_require__(/*! ../id3v2/AbstractID3Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/AbstractID3Parser.js\");\nconst MpcSv8Parser_1 = __webpack_require__(/*! ./sv8/MpcSv8Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv8/MpcSv8Parser.js\");\nconst MpcSv7Parser_1 = __webpack_require__(/*! ./sv7/MpcSv7Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv7/MpcSv7Parser.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:musepack');\nclass MusepackParser extends AbstractID3Parser_1.AbstractID3Parser {\n    async postId3v2Parse() {\n        const signature = await this.tokenizer.peekToken(new Token.StringType(3, 'binary'));\n        let mpcParser;\n        switch (signature) {\n            case 'MP+': {\n                debug('Musepack stream-version 7');\n                mpcParser = new MpcSv7Parser_1.MpcSv7Parser();\n                break;\n            }\n            case 'MPC': {\n                debug('Musepack stream-version 8');\n                mpcParser = new MpcSv8Parser_1.MpcSv8Parser();\n                break;\n            }\n            default: {\n                throw new Error('Invalid Musepack signature prefix');\n            }\n        }\n        mpcParser.init(this.metadata, this.tokenizer, this.options);\n        return mpcParser.parse();\n    }\n}\nexports[\"default\"] = MusepackParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/index.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv7/BitReader.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv7/BitReader.js ***!
  \************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.BitReader = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nclass BitReader {\n    constructor(tokenizer) {\n        this.tokenizer = tokenizer;\n        this.pos = 0;\n        this.dword = undefined;\n    }\n    /**\n     *\n     * @param bits 1..30 bits\n     */\n    async read(bits) {\n        while (this.dword === undefined) {\n            this.dword = await this.tokenizer.readToken(Token.UINT32_LE);\n        }\n        let out = this.dword;\n        this.pos += bits;\n        if (this.pos < 32) {\n            out >>>= (32 - this.pos);\n            return out & ((1 << bits) - 1);\n        }\n        else {\n            this.pos -= 32;\n            if (this.pos === 0) {\n                this.dword = undefined;\n                return out & ((1 << bits) - 1);\n            }\n            else {\n                this.dword = await this.tokenizer.readToken(Token.UINT32_LE);\n                if (this.pos) {\n                    out <<= this.pos;\n                    out |= this.dword >>> (32 - this.pos);\n                }\n                return out & ((1 << bits) - 1);\n            }\n        }\n    }\n    async ignore(bits) {\n        if (this.pos > 0) {\n            const remaining = 32 - this.pos;\n            this.dword = undefined;\n            bits -= remaining;\n            this.pos = 0;\n        }\n        const remainder = bits % 32;\n        const numOfWords = (bits - remainder) / 32;\n        await this.tokenizer.ignore(numOfWords * 4);\n        return this.read(remainder);\n    }\n}\nexports.BitReader = BitReader;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv7/BitReader.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv7/MpcSv7Parser.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv7/MpcSv7Parser.js ***!
  \***************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MpcSv7Parser = void 0;\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst BasicParser_1 = __webpack_require__(/*! ../../common/BasicParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js\");\nconst APEv2Parser_1 = __webpack_require__(/*! ../../apev2/APEv2Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2Parser.js\");\nconst BitReader_1 = __webpack_require__(/*! ./BitReader */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv7/BitReader.js\");\nconst SV7 = __webpack_require__(/*! ./StreamVersion7 */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv7/StreamVersion7.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:musepack');\nclass MpcSv7Parser extends BasicParser_1.BasicParser {\n    constructor() {\n        super(...arguments);\n        this.audioLength = 0;\n    }\n    async parse() {\n        const header = await this.tokenizer.readToken(SV7.Header);\n        if (header.signature !== 'MP+')\n            throw new Error('Unexpected magic number');\n        debug(`stream-version=${header.streamMajorVersion}.${header.streamMinorVersion}`);\n        this.metadata.setFormat('container', 'Musepack, SV7');\n        this.metadata.setFormat('sampleRate', header.sampleFrequency);\n        const numberOfSamples = 1152 * (header.frameCount - 1) + header.lastFrameLength;\n        this.metadata.setFormat('numberOfSamples', numberOfSamples);\n        this.duration = numberOfSamples / header.sampleFrequency;\n        this.metadata.setFormat('duration', this.duration);\n        this.bitreader = new BitReader_1.BitReader(this.tokenizer);\n        this.metadata.setFormat('numberOfChannels', header.midSideStereo || header.intensityStereo ? 2 : 1);\n        const version = await this.bitreader.read(8);\n        this.metadata.setFormat('codec', (version / 100).toFixed(2));\n        await this.skipAudioData(header.frameCount);\n        debug(`End of audio stream, switching to APEv2, offset=${this.tokenizer.position}`);\n        return APEv2Parser_1.APEv2Parser.tryParseApeHeader(this.metadata, this.tokenizer, this.options);\n    }\n    async skipAudioData(frameCount) {\n        while (frameCount-- > 0) {\n            const frameLength = await this.bitreader.read(20);\n            this.audioLength += 20 + frameLength;\n            await this.bitreader.ignore(frameLength);\n        }\n        // last frame\n        const lastFrameLength = await this.bitreader.read(11);\n        this.audioLength += lastFrameLength;\n        this.metadata.setFormat('bitrate', this.audioLength / this.duration);\n    }\n}\nexports.MpcSv7Parser = MpcSv7Parser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv7/MpcSv7Parser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv7/StreamVersion7.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv7/StreamVersion7.js ***!
  \*****************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ "./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js")["Buffer"];\n\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.Header = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nconst util = __webpack_require__(/*! ../../common/Util */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js");\n/**\n * BASIC STRUCTURE\n */\nexports.Header = {\n    len: 6 * 4,\n    get: (buf, off) => {\n        const header = {\n            // word 0\n            signature: Buffer.from(buf).toString(\'latin1\', off, off + 3),\n            // versionIndex number * 1000 (3.81 = 3810) (remember that 4-byte alignment causes this to take 4-bytes)\n            streamMinorVersion: util.getBitAllignedNumber(buf, off + 3, 0, 4),\n            streamMajorVersion: util.getBitAllignedNumber(buf, off + 3, 4, 4),\n            // word 1\n            frameCount: Token.UINT32_LE.get(buf, off + 4),\n            // word 2\n            maxLevel: Token.UINT16_LE.get(buf, off + 8),\n            sampleFrequency: [44100, 48000, 37800, 32000][util.getBitAllignedNumber(buf, off + 10, 0, 2)],\n            link: util.getBitAllignedNumber(buf, off + 10, 2, 2),\n            profile: util.getBitAllignedNumber(buf, off + 10, 4, 4),\n            maxBand: util.getBitAllignedNumber(buf, off + 11, 0, 6),\n            intensityStereo: util.isBitSet(buf, off + 11, 6),\n            midSideStereo: util.isBitSet(buf, off + 11, 7),\n            // word 3\n            titlePeak: Token.UINT16_LE.get(buf, off + 12),\n            titleGain: Token.UINT16_LE.get(buf, off + 14),\n            // word 4\n            albumPeak: Token.UINT16_LE.get(buf, off + 16),\n            albumGain: Token.UINT16_LE.get(buf, off + 18),\n            // word\n            lastFrameLength: (Token.UINT32_LE.get(buf, off + 20) >>> 20) & 0x7FF,\n            trueGapless: util.isBitSet(buf, off + 23, 0)\n        };\n        header.lastFrameLength = header.trueGapless ? (Token.UINT32_LE.get(buf, 20) >>> 20) & 0x7FF : 0;\n        return header;\n    }\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv7/StreamVersion7.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv8/MpcSv8Parser.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv8/MpcSv8Parser.js ***!
  \***************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.MpcSv8Parser = void 0;\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst BasicParser_1 = __webpack_require__(/*! ../../common/BasicParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js\");\nconst APEv2Parser_1 = __webpack_require__(/*! ../../apev2/APEv2Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2Parser.js\");\nconst FourCC_1 = __webpack_require__(/*! ../../common/FourCC */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js\");\nconst SV8 = __webpack_require__(/*! ./StreamVersion8 */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv8/StreamVersion8.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:musepack');\nclass MpcSv8Parser extends BasicParser_1.BasicParser {\n    constructor() {\n        super(...arguments);\n        this.audioLength = 0;\n    }\n    async parse() {\n        const signature = await this.tokenizer.readToken(FourCC_1.FourCcToken);\n        if (signature !== 'MPCK')\n            throw new Error('Invalid Magic number');\n        this.metadata.setFormat('container', 'Musepack, SV8');\n        return this.parsePacket();\n    }\n    async parsePacket() {\n        const sv8reader = new SV8.StreamReader(this.tokenizer);\n        do {\n            const header = await sv8reader.readPacketHeader();\n            debug(`packet-header key=${header.key}, payloadLength=${header.payloadLength}`);\n            switch (header.key) {\n                case 'SH': // Stream Header\n                    const sh = await sv8reader.readStreamHeader(header.payloadLength);\n                    this.metadata.setFormat('numberOfSamples', sh.sampleCount);\n                    this.metadata.setFormat('sampleRate', sh.sampleFrequency);\n                    this.metadata.setFormat('duration', sh.sampleCount / sh.sampleFrequency);\n                    this.metadata.setFormat('numberOfChannels', sh.channelCount);\n                    break;\n                case 'AP': // Audio Packet\n                    this.audioLength += header.payloadLength;\n                    await this.tokenizer.ignore(header.payloadLength);\n                    break;\n                case 'RG': // Replaygain\n                case 'EI': // Encoder Info\n                case 'SO': // Seek Table Offset\n                case 'ST': // Seek Table\n                case 'CT': // Chapter-Tag\n                    await this.tokenizer.ignore(header.payloadLength);\n                    break;\n                case 'SE': // Stream End\n                    this.metadata.setFormat('bitrate', this.audioLength * 8 / this.metadata.format.duration);\n                    return APEv2Parser_1.APEv2Parser.tryParseApeHeader(this.metadata, this.tokenizer, this.options);\n                default:\n                    throw new Error(`Unexpected header: ${header.key}`);\n            }\n        } while (true);\n    }\n}\nexports.MpcSv8Parser = MpcSv8Parser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv8/MpcSv8Parser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv8/StreamVersion8.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv8/StreamVersion8.js ***!
  \*****************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.StreamReader = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nconst debug_1 = __webpack_require__(/*! debug */ "./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js");\nconst util = __webpack_require__(/*! ../../common/Util */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js");\nconst debug = (0, debug_1.default)(\'music-metadata:parser:musepack:sv8\');\nconst PacketKey = new Token.StringType(2, \'binary\');\n/**\n * Stream Header Packet part 1\n * Ref: http://trac.musepack.net/musepack/wiki/SV8Specification#StreamHeaderPacket\n */\nconst SH_part1 = {\n    len: 5,\n    get: (buf, off) => {\n        return {\n            crc: Token.UINT32_LE.get(buf, off),\n            streamVersion: Token.UINT8.get(buf, off + 4)\n        };\n    }\n};\n/**\n * Stream Header Packet part 3\n * Ref: http://trac.musepack.net/musepack/wiki/SV8Specification#StreamHeaderPacket\n */\nconst SH_part3 = {\n    len: 2,\n    get: (buf, off) => {\n        return {\n            sampleFrequency: [44100, 48000, 37800, 32000][util.getBitAllignedNumber(buf, off, 0, 3)],\n            maxUsedBands: util.getBitAllignedNumber(buf, off, 3, 5),\n            channelCount: util.getBitAllignedNumber(buf, off + 1, 0, 4) + 1,\n            msUsed: util.isBitSet(buf, off + 1, 4),\n            audioBlockFrames: util.getBitAllignedNumber(buf, off + 1, 5, 3)\n        };\n    }\n};\nclass StreamReader {\n    constructor(tokenizer) {\n        this.tokenizer = tokenizer;\n    }\n    async readPacketHeader() {\n        const key = await this.tokenizer.readToken(PacketKey);\n        const size = await this.readVariableSizeField();\n        return {\n            key,\n            payloadLength: size.value - 2 - size.len\n        };\n    }\n    async readStreamHeader(size) {\n        const streamHeader = {};\n        debug(`Reading SH at offset=${this.tokenizer.position}`);\n        const part1 = await this.tokenizer.readToken(SH_part1);\n        size -= SH_part1.len;\n        Object.assign(streamHeader, part1);\n        debug(`SH.streamVersion = ${part1.streamVersion}`);\n        const sampleCount = await this.readVariableSizeField();\n        size -= sampleCount.len;\n        streamHeader.sampleCount = sampleCount.value;\n        const bs = await this.readVariableSizeField();\n        size -= bs.len;\n        streamHeader.beginningOfSilence = bs.value;\n        const part3 = await this.tokenizer.readToken(SH_part3);\n        size -= SH_part3.len;\n        Object.assign(streamHeader, part3);\n        // assert.equal(size, 0);\n        await this.tokenizer.ignore(size);\n        return streamHeader;\n    }\n    async readVariableSizeField(len = 1, hb = 0) {\n        let n = await this.tokenizer.readNumber(Token.UINT8);\n        if ((n & 0x80) === 0) {\n            return { len, value: hb + n };\n        }\n        n &= 0x7F;\n        n += hb;\n        return this.readVariableSizeField(len + 1, n << 7);\n    }\n}\nexports.StreamReader = StreamReader;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/musepack/sv8/StreamVersion8.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/OggParser.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/OggParser.js ***!
  \***************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ \"./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js\")[\"Buffer\"];\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OggParser = exports.SegmentTable = void 0;\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst core_1 = __webpack_require__(/*! strtok3/lib/core */ \"./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/core.js\");\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst util = __webpack_require__(/*! ../common/Util */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js\");\nconst FourCC_1 = __webpack_require__(/*! ../common/FourCC */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js\");\nconst BasicParser_1 = __webpack_require__(/*! ../common/BasicParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js\");\nconst VorbisParser_1 = __webpack_require__(/*! ./vorbis/VorbisParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisParser.js\");\nconst OpusParser_1 = __webpack_require__(/*! ./opus/OpusParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/opus/OpusParser.js\");\nconst SpeexParser_1 = __webpack_require__(/*! ./speex/SpeexParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/speex/SpeexParser.js\");\nconst TheoraParser_1 = __webpack_require__(/*! ./theora/TheoraParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/theora/TheoraParser.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:ogg');\nclass SegmentTable {\n    static sum(buf, off, len) {\n        let s = 0;\n        for (let i = off; i < off + len; ++i) {\n            s += buf[i];\n        }\n        return s;\n    }\n    constructor(header) {\n        this.len = header.page_segments;\n    }\n    get(buf, off) {\n        return {\n            totalPageSize: SegmentTable.sum(buf, off, this.len)\n        };\n    }\n}\nexports.SegmentTable = SegmentTable;\n/**\n * Parser for Ogg logical bitstream framing\n */\nclass OggParser extends BasicParser_1.BasicParser {\n    /**\n     * Parse page\n     * @returns {Promise<void>}\n     */\n    async parse() {\n        debug('pos=%s, parsePage()', this.tokenizer.position);\n        try {\n            let header;\n            do {\n                header = await this.tokenizer.readToken(OggParser.Header);\n                if (header.capturePattern !== 'OggS')\n                    throw new Error('Invalid Ogg capture pattern');\n                this.metadata.setFormat('container', 'Ogg');\n                this.header = header;\n                this.pageNumber = header.pageSequenceNo;\n                debug('page#=%s, Ogg.id=%s', header.pageSequenceNo, header.capturePattern);\n                const segmentTable = await this.tokenizer.readToken(new SegmentTable(header));\n                debug('totalPageSize=%s', segmentTable.totalPageSize);\n                const pageData = await this.tokenizer.readToken(new Token.Uint8ArrayType(segmentTable.totalPageSize));\n                debug('firstPage=%s, lastPage=%s, continued=%s', header.headerType.firstPage, header.headerType.lastPage, header.headerType.continued);\n                if (header.headerType.firstPage) {\n                    const id = new Token.StringType(7, 'ascii').get(Buffer.from(pageData), 0);\n                    switch (id) {\n                        case '\\x01vorbis': // Ogg/Vorbis\n                            debug('Set page consumer to Ogg/Vorbis');\n                            this.pageConsumer = new VorbisParser_1.VorbisParser(this.metadata, this.options);\n                            break;\n                        case 'OpusHea': // Ogg/Opus\n                            debug('Set page consumer to Ogg/Opus');\n                            this.pageConsumer = new OpusParser_1.OpusParser(this.metadata, this.options, this.tokenizer);\n                            break;\n                        case 'Speex  ': // Ogg/Speex\n                            debug('Set page consumer to Ogg/Speex');\n                            this.pageConsumer = new SpeexParser_1.SpeexParser(this.metadata, this.options, this.tokenizer);\n                            break;\n                        case 'fishead':\n                        case '\\x00theora': // Ogg/Theora\n                            debug('Set page consumer to Ogg/Theora');\n                            this.pageConsumer = new TheoraParser_1.TheoraParser(this.metadata, this.options, this.tokenizer);\n                            break;\n                        default:\n                            throw new Error('gg audio-codec not recognized (id=' + id + ')');\n                    }\n                }\n                this.pageConsumer.parsePage(header, pageData);\n            } while (!header.headerType.lastPage);\n        }\n        catch (err) {\n            if (err instanceof core_1.EndOfStreamError) {\n                this.metadata.addWarning('Last OGG-page is not marked with last-page flag');\n                debug(`End-of-stream`);\n                this.metadata.addWarning('Last OGG-page is not marked with last-page flag');\n                if (this.header) {\n                    this.pageConsumer.calculateDuration(this.header);\n                }\n            }\n            else if (err.message.startsWith('FourCC')) {\n                if (this.pageNumber > 0) {\n                    // ignore this error: work-around if last OGG-page is not marked with last-page flag\n                    this.metadata.addWarning('Invalid FourCC ID, maybe last OGG-page is not marked with last-page flag');\n                    this.pageConsumer.flush();\n                }\n            }\n            else {\n                throw err;\n            }\n        }\n    }\n}\nOggParser.Header = {\n    len: 27,\n    get: (buf, off) => {\n        return {\n            capturePattern: FourCC_1.FourCcToken.get(buf, off),\n            version: Token.UINT8.get(buf, off + 4),\n            headerType: {\n                continued: util.getBit(buf, off + 5, 0),\n                firstPage: util.getBit(buf, off + 5, 1),\n                lastPage: util.getBit(buf, off + 5, 2)\n            },\n            // packet_flag: buf.readUInt8(off + 5),\n            absoluteGranulePosition: Number(Token.UINT64_LE.get(buf, off + 6)),\n            streamSerialNumber: Token.UINT32_LE.get(buf, off + 14),\n            pageSequenceNo: Token.UINT32_LE.get(buf, off + 18),\n            pageChecksum: Token.UINT32_LE.get(buf, off + 22),\n            page_segments: Token.UINT8.get(buf, off + 26)\n        };\n    }\n};\nexports.OggParser = OggParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/OggParser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/opus/Opus.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/opus/Opus.js ***!
  \***************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.IdHeader = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\n/**\n * Opus ID Header parser\n * Ref: https://wiki.xiph.org/OggOpus#ID_Header\n */\nclass IdHeader {\n    constructor(len) {\n        this.len = len;\n        if (len < 19) {\n            throw new Error("ID-header-page 0 should be at least 19 bytes long");\n        }\n    }\n    get(buf, off) {\n        return {\n            magicSignature: new Token.StringType(8, \'ascii\').get(buf, off + 0),\n            version: buf.readUInt8(off + 8),\n            channelCount: buf.readUInt8(off + 9),\n            preSkip: buf.readInt16LE(off + 10),\n            inputSampleRate: buf.readInt32LE(off + 12),\n            outputGain: buf.readInt16LE(off + 16),\n            channelMapping: buf.readUInt8(off + 18)\n        };\n    }\n}\nexports.IdHeader = IdHeader;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/opus/Opus.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/opus/OpusParser.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/opus/OpusParser.js ***!
  \*********************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.OpusParser = void 0;\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst VorbisParser_1 = __webpack_require__(/*! ../vorbis/VorbisParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisParser.js\");\nconst Opus = __webpack_require__(/*! ./Opus */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/opus/Opus.js\");\n/**\n * Opus parser\n * Internet Engineering Task Force (IETF) - RFC 6716\n * Used by OggParser\n */\nclass OpusParser extends VorbisParser_1.VorbisParser {\n    constructor(metadata, options, tokenizer) {\n        super(metadata, options);\n        this.tokenizer = tokenizer;\n        this.lastPos = -1;\n    }\n    /**\n     * Parse first Opus Ogg page\n     * @param {IPageHeader} header\n     * @param {Buffer} pageData\n     */\n    parseFirstPage(header, pageData) {\n        this.metadata.setFormat('codec', 'Opus');\n        // Parse Opus ID Header\n        this.idHeader = new Opus.IdHeader(pageData.length).get(pageData, 0);\n        if (this.idHeader.magicSignature !== \"OpusHead\")\n            throw new Error(\"Illegal ogg/Opus magic-signature\");\n        this.metadata.setFormat('sampleRate', this.idHeader.inputSampleRate);\n        this.metadata.setFormat('numberOfChannels', this.idHeader.channelCount);\n    }\n    parseFullPage(pageData) {\n        const magicSignature = new Token.StringType(8, 'ascii').get(pageData, 0);\n        switch (magicSignature) {\n            case 'OpusTags':\n                this.parseUserCommentList(pageData, 8);\n                this.lastPos = this.tokenizer.position - pageData.length;\n                break;\n            default:\n                break;\n        }\n    }\n    calculateDuration(header) {\n        if (this.metadata.format.sampleRate && header.absoluteGranulePosition >= 0) {\n            // Calculate duration\n            const pos_48bit = header.absoluteGranulePosition - this.idHeader.preSkip;\n            this.metadata.setFormat('numberOfSamples', pos_48bit);\n            this.metadata.setFormat('duration', pos_48bit / 48000);\n            if (this.lastPos !== -1 && this.tokenizer.fileInfo.size && this.metadata.format.duration) {\n                const dataSize = this.tokenizer.fileInfo.size - this.lastPos;\n                this.metadata.setFormat('bitrate', 8 * dataSize / this.metadata.format.duration);\n            }\n        }\n    }\n}\nexports.OpusParser = OpusParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/opus/OpusParser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/speex/Speex.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/speex/Speex.js ***!
  \*****************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.Header = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nconst util = __webpack_require__(/*! ../../common/Util */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js");\n/**\n * Speex Header Packet\n * Ref: https://www.speex.org/docs/manual/speex-manual/node8.html#SECTION00830000000000000000\n */\nexports.Header = {\n    len: 80,\n    get: (buf, off) => {\n        return {\n            speex: new Token.StringType(8, \'ascii\').get(buf, off + 0),\n            version: util.trimRightNull(new Token.StringType(20, \'ascii\').get(buf, off + 8)),\n            version_id: buf.readInt32LE(off + 28),\n            header_size: buf.readInt32LE(off + 32),\n            rate: buf.readInt32LE(off + 36),\n            mode: buf.readInt32LE(off + 40),\n            mode_bitstream_version: buf.readInt32LE(off + 44),\n            nb_channels: buf.readInt32LE(off + 48),\n            bitrate: buf.readInt32LE(off + 52),\n            frame_size: buf.readInt32LE(off + 56),\n            vbr: buf.readInt32LE(off + 60),\n            frames_per_packet: buf.readInt32LE(off + 64),\n            extra_headers: buf.readInt32LE(off + 68),\n            reserved1: buf.readInt32LE(off + 72),\n            reserved2: buf.readInt32LE(off + 76)\n        };\n    }\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/speex/Speex.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/speex/SpeexParser.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/speex/SpeexParser.js ***!
  \***********************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SpeexParser = void 0;\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst VorbisParser_1 = __webpack_require__(/*! ../vorbis/VorbisParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisParser.js\");\nconst Speex = __webpack_require__(/*! ./Speex */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/speex/Speex.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:ogg:speex');\n/**\n * Speex, RFC 5574\n * Ref:\n * - https://www.speex.org/docs/manual/speex-manual/\n * - https://tools.ietf.org/html/rfc5574\n */\nclass SpeexParser extends VorbisParser_1.VorbisParser {\n    constructor(metadata, options, tokenizer) {\n        super(metadata, options);\n        this.tokenizer = tokenizer;\n    }\n    /**\n     * Parse first Speex Ogg page\n     * @param {IPageHeader} header\n     * @param {Buffer} pageData\n     */\n    parseFirstPage(header, pageData) {\n        debug('First Ogg/Speex page');\n        const speexHeader = Speex.Header.get(pageData, 0);\n        this.metadata.setFormat('codec', `Speex ${speexHeader.version}`);\n        this.metadata.setFormat('numberOfChannels', speexHeader.nb_channels);\n        this.metadata.setFormat('sampleRate', speexHeader.rate);\n        if (speexHeader.bitrate !== -1) {\n            this.metadata.setFormat('bitrate', speexHeader.bitrate);\n        }\n    }\n}\nexports.SpeexParser = SpeexParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/speex/SpeexParser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/theora/Theora.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/theora/Theora.js ***!
  \*******************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.IdentificationHeader = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\n/**\n * 6.2 Identification Header\n * Ref: https://theora.org/doc/Theora.pdf: 6.2 Identification Header Decode\n */\nexports.IdentificationHeader = {\n    len: 42,\n    get: (buf, off) => {\n        return {\n            id: new Token.StringType(7, \'ascii\').get(buf, off),\n            vmaj: buf.readUInt8(off + 7),\n            vmin: buf.readUInt8(off + 8),\n            vrev: buf.readUInt8(off + 9),\n            vmbw: buf.readUInt16BE(off + 10),\n            vmbh: buf.readUInt16BE(off + 17),\n            nombr: Token.UINT24_BE.get(buf, off + 37),\n            nqual: buf.readUInt8(off + 40)\n        };\n    }\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/theora/Theora.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/theora/TheoraParser.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/theora/TheoraParser.js ***!
  \*************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TheoraParser = void 0;\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst Theora_1 = __webpack_require__(/*! ./Theora */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/theora/Theora.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:ogg:theora');\n/**\n * Ref:\n * - https://theora.org/doc/Theora.pdf\n */\nclass TheoraParser {\n    constructor(metadata, options, tokenizer) {\n        this.metadata = metadata;\n        this.tokenizer = tokenizer;\n    }\n    /**\n     * Vorbis 1 parser\n     * @param header Ogg Page Header\n     * @param pageData Page data\n     */\n    parsePage(header, pageData) {\n        if (header.headerType.firstPage) {\n            this.parseFirstPage(header, pageData);\n        }\n    }\n    flush() {\n        debug('flush');\n    }\n    calculateDuration(header) {\n        debug('duration calculation not implemented');\n    }\n    /**\n     * Parse first Theora Ogg page. the initial identification header packet\n     * @param {IPageHeader} header\n     * @param {Buffer} pageData\n     */\n    parseFirstPage(header, pageData) {\n        debug('First Ogg/Theora page');\n        this.metadata.setFormat('codec', 'Theora');\n        const idHeader = Theora_1.IdentificationHeader.get(pageData, 0);\n        this.metadata.setFormat('bitrate', idHeader.nombr);\n    }\n}\nexports.TheoraParser = TheoraParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/theora/TheoraParser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/Vorbis.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/Vorbis.js ***!
  \*******************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ "./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js")["Buffer"];\n\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.IdentificationHeader = exports.CommonHeader = exports.VorbisPictureToken = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nconst ID3v2Token_1 = __webpack_require__(/*! ../../id3v2/ID3v2Token */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Token.js");\n/**\n * Parse the METADATA_BLOCK_PICTURE\n * Ref: https://wiki.xiph.org/VorbisComment#METADATA_BLOCK_PICTURE\n * Ref: https://xiph.org/flac/format.html#metadata_block_picture\n * // ToDo: move to ID3 / APIC?\n */\nclass VorbisPictureToken {\n    static fromBase64(base64str) {\n        return this.fromBuffer(Buffer.from(base64str, \'base64\'));\n    }\n    static fromBuffer(buffer) {\n        const pic = new VorbisPictureToken(buffer.length);\n        return pic.get(buffer, 0);\n    }\n    constructor(len) {\n        this.len = len;\n    }\n    get(buffer, offset) {\n        const type = ID3v2Token_1.AttachedPictureType[Token.UINT32_BE.get(buffer, offset)];\n        const mimeLen = Token.UINT32_BE.get(buffer, offset += 4);\n        const format = buffer.toString(\'utf-8\', offset += 4, offset + mimeLen);\n        const descLen = Token.UINT32_BE.get(buffer, offset += mimeLen);\n        const description = buffer.toString(\'utf-8\', offset += 4, offset + descLen);\n        const width = Token.UINT32_BE.get(buffer, offset += descLen);\n        const height = Token.UINT32_BE.get(buffer, offset += 4);\n        const colour_depth = Token.UINT32_BE.get(buffer, offset += 4);\n        const indexed_color = Token.UINT32_BE.get(buffer, offset += 4);\n        const picDataLen = Token.UINT32_BE.get(buffer, offset += 4);\n        const data = Buffer.from(buffer.slice(offset += 4, offset + picDataLen));\n        return {\n            type,\n            format,\n            description,\n            width,\n            height,\n            colour_depth,\n            indexed_color,\n            data\n        };\n    }\n}\nexports.VorbisPictureToken = VorbisPictureToken;\n/**\n * Comment header decoder\n * Ref: https://xiph.org/vorbis/doc/Vorbis_I_spec.html#x1-620004.2.1\n */\nexports.CommonHeader = {\n    len: 7,\n    get: (buf, off) => {\n        return {\n            packetType: buf.readUInt8(off),\n            vorbis: new Token.StringType(6, \'ascii\').get(buf, off + 1)\n        };\n    }\n};\n/**\n * Identification header decoder\n * Ref: https://xiph.org/vorbis/doc/Vorbis_I_spec.html#x1-630004.2.2\n */\nexports.IdentificationHeader = {\n    len: 23,\n    get: (uint8Array, off) => {\n        const dataView = new DataView(uint8Array.buffer, uint8Array.byteOffset);\n        return {\n            version: dataView.getUint32(off + 0, true),\n            channelMode: dataView.getUint8(off + 4),\n            sampleRate: dataView.getUint32(off + 5, true),\n            bitrateMax: dataView.getUint32(off + 9, true),\n            bitrateNominal: dataView.getUint32(off + 13, true),\n            bitrateMin: dataView.getUint32(off + 17, true)\n        };\n    }\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/Vorbis.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisDecoder.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisDecoder.js ***!
  \**************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ "./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js")["Buffer"];\n\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.VorbisDecoder = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nclass VorbisDecoder {\n    constructor(data, offset) {\n        this.data = data;\n        this.offset = offset;\n    }\n    readInt32() {\n        const value = Token.UINT32_LE.get(this.data, this.offset);\n        this.offset += 4;\n        return value;\n    }\n    readStringUtf8() {\n        const len = this.readInt32();\n        const value = Buffer.from(this.data).toString(\'utf-8\', this.offset, this.offset + len);\n        this.offset += len;\n        return value;\n    }\n    parseUserComment() {\n        const offset0 = this.offset;\n        const v = this.readStringUtf8();\n        const idx = v.indexOf(\'=\');\n        return {\n            key: v.slice(0, idx).toUpperCase(),\n            value: v.slice(idx + 1),\n            len: this.offset - offset0\n        };\n    }\n}\nexports.VorbisDecoder = VorbisDecoder;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisDecoder.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisParser.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisParser.js ***!
  \*************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ \"./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js\")[\"Buffer\"];\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.VorbisParser = void 0;\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst VorbisDecoder_1 = __webpack_require__(/*! ./VorbisDecoder */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisDecoder.js\");\nconst Vorbis_1 = __webpack_require__(/*! ./Vorbis */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/Vorbis.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:ogg:vorbis1');\n/**\n * Vorbis 1 Parser.\n * Used by OggParser\n */\nclass VorbisParser {\n    constructor(metadata, options) {\n        this.metadata = metadata;\n        this.options = options;\n        this.pageSegments = [];\n    }\n    /**\n     * Vorbis 1 parser\n     * @param header Ogg Page Header\n     * @param pageData Page data\n     */\n    parsePage(header, pageData) {\n        if (header.headerType.firstPage) {\n            this.parseFirstPage(header, pageData);\n        }\n        else {\n            if (header.headerType.continued) {\n                if (this.pageSegments.length === 0) {\n                    throw new Error(\"Cannot continue on previous page\");\n                }\n                this.pageSegments.push(pageData);\n            }\n            if (header.headerType.lastPage || !header.headerType.continued) {\n                // Flush page segments\n                if (this.pageSegments.length > 0) {\n                    const fullPage = Buffer.concat(this.pageSegments);\n                    this.parseFullPage(fullPage);\n                }\n                // Reset page segments\n                this.pageSegments = header.headerType.lastPage ? [] : [pageData];\n            }\n        }\n        if (header.headerType.lastPage) {\n            this.calculateDuration(header);\n        }\n    }\n    flush() {\n        this.parseFullPage(Buffer.concat(this.pageSegments));\n    }\n    parseUserComment(pageData, offset) {\n        const decoder = new VorbisDecoder_1.VorbisDecoder(pageData, offset);\n        const tag = decoder.parseUserComment();\n        this.addTag(tag.key, tag.value);\n        return tag.len;\n    }\n    addTag(id, value) {\n        if (id === 'METADATA_BLOCK_PICTURE' && (typeof value === 'string')) {\n            if (this.options.skipCovers) {\n                debug(`Ignore picture`);\n                return;\n            }\n            value = Vorbis_1.VorbisPictureToken.fromBase64(value);\n            debug(`Push picture: id=${id}, format=${value.format}`);\n        }\n        else {\n            debug(`Push tag: id=${id}, value=${value}`);\n        }\n        this.metadata.addTag('vorbis', id, value);\n    }\n    calculateDuration(header) {\n        if (this.metadata.format.sampleRate && header.absoluteGranulePosition >= 0) {\n            // Calculate duration\n            this.metadata.setFormat('numberOfSamples', header.absoluteGranulePosition);\n            this.metadata.setFormat('duration', this.metadata.format.numberOfSamples / this.metadata.format.sampleRate);\n        }\n    }\n    /**\n     * Parse first Ogg/Vorbis page\n     * @param {IPageHeader} header\n     * @param {Buffer} pageData\n     */\n    parseFirstPage(header, pageData) {\n        this.metadata.setFormat('codec', 'Vorbis I');\n        debug(\"Parse first page\");\n        // Parse  Vorbis common header\n        const commonHeader = Vorbis_1.CommonHeader.get(pageData, 0);\n        if (commonHeader.vorbis !== 'vorbis')\n            throw new Error('Metadata does not look like Vorbis');\n        if (commonHeader.packetType === 1) {\n            const idHeader = Vorbis_1.IdentificationHeader.get(pageData, Vorbis_1.CommonHeader.len);\n            this.metadata.setFormat('sampleRate', idHeader.sampleRate);\n            this.metadata.setFormat('bitrate', idHeader.bitrateNominal);\n            this.metadata.setFormat('numberOfChannels', idHeader.channelMode);\n            debug(\"sample-rate=%s[hz], bitrate=%s[b/s], channel-mode=%s\", idHeader.sampleRate, idHeader.bitrateNominal, idHeader.channelMode);\n        }\n        else\n            throw new Error('First Ogg page should be type 1: the identification header');\n    }\n    parseFullPage(pageData) {\n        // New page\n        const commonHeader = Vorbis_1.CommonHeader.get(pageData, 0);\n        debug(\"Parse full page: type=%s, byteLength=%s\", commonHeader.packetType, pageData.byteLength);\n        switch (commonHeader.packetType) {\n            case 3: //  type 3: comment header\n                return this.parseUserCommentList(pageData, Vorbis_1.CommonHeader.len);\n            case 1: // type 1: the identification header\n            case 5: // type 5: setup header type\n                break; // ignore\n        }\n    }\n    /**\n     * Ref: https://xiph.org/vorbis/doc/Vorbis_I_spec.html#x1-840005.2\n     */\n    parseUserCommentList(pageData, offset) {\n        const strLen = Token.UINT32_LE.get(pageData, offset);\n        offset += 4;\n        // const vendorString = new Token.StringType(strLen, 'utf-8').get(pageData, offset);\n        offset += strLen;\n        let userCommentListLength = Token.UINT32_LE.get(pageData, offset);\n        offset += 4;\n        while (userCommentListLength-- > 0) {\n            offset += this.parseUserComment(pageData, offset);\n        }\n    }\n}\nexports.VorbisParser = VorbisParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisParser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisTagMapper.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisTagMapper.js ***!
  \****************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.VorbisTagMapper = void 0;\nconst GenericTagMapper_1 = __webpack_require__(/*! ../../common/GenericTagMapper */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/GenericTagMapper.js\");\n/**\n * Vorbis tag mappings\n *\n * Mapping from native header format to one or possibly more 'common' entries\n * The common entries aim to read the same information from different media files\n * independent of the underlying format\n */\nconst vorbisTagMap = {\n    TITLE: 'title',\n    ARTIST: 'artist',\n    ARTISTS: 'artists',\n    ALBUMARTIST: 'albumartist',\n    'ALBUM ARTIST': 'albumartist',\n    ALBUM: 'album',\n    DATE: 'date',\n    ORIGINALDATE: 'originaldate',\n    ORIGINALYEAR: 'originalyear',\n    COMMENT: 'comment',\n    TRACKNUMBER: 'track',\n    DISCNUMBER: 'disk',\n    GENRE: 'genre',\n    METADATA_BLOCK_PICTURE: 'picture',\n    COMPOSER: 'composer',\n    LYRICS: 'lyrics',\n    ALBUMSORT: 'albumsort',\n    TITLESORT: 'titlesort',\n    WORK: 'work',\n    ARTISTSORT: 'artistsort',\n    ALBUMARTISTSORT: 'albumartistsort',\n    COMPOSERSORT: 'composersort',\n    LYRICIST: 'lyricist',\n    WRITER: 'writer',\n    CONDUCTOR: 'conductor',\n    // 'PERFORMER=artist(instrument)': 'performer:instrument', // ToDo\n    REMIXER: 'remixer',\n    ARRANGER: 'arranger',\n    ENGINEER: 'engineer',\n    PRODUCER: 'producer',\n    DJMIXER: 'djmixer',\n    MIXER: 'mixer',\n    LABEL: 'label',\n    GROUPING: 'grouping',\n    SUBTITLE: 'subtitle',\n    DISCSUBTITLE: 'discsubtitle',\n    TRACKTOTAL: 'totaltracks',\n    DISCTOTAL: 'totaldiscs',\n    COMPILATION: 'compilation',\n    RATING: 'rating',\n    BPM: 'bpm',\n    KEY: 'key',\n    MOOD: 'mood',\n    MEDIA: 'media',\n    CATALOGNUMBER: 'catalognumber',\n    RELEASESTATUS: 'releasestatus',\n    RELEASETYPE: 'releasetype',\n    RELEASECOUNTRY: 'releasecountry',\n    SCRIPT: 'script',\n    LANGUAGE: 'language',\n    COPYRIGHT: 'copyright',\n    LICENSE: 'license',\n    ENCODEDBY: 'encodedby',\n    ENCODERSETTINGS: 'encodersettings',\n    BARCODE: 'barcode',\n    ISRC: 'isrc',\n    ASIN: 'asin',\n    MUSICBRAINZ_TRACKID: 'musicbrainz_recordingid',\n    MUSICBRAINZ_RELEASETRACKID: 'musicbrainz_trackid',\n    MUSICBRAINZ_ALBUMID: 'musicbrainz_albumid',\n    MUSICBRAINZ_ARTISTID: 'musicbrainz_artistid',\n    MUSICBRAINZ_ALBUMARTISTID: 'musicbrainz_albumartistid',\n    MUSICBRAINZ_RELEASEGROUPID: 'musicbrainz_releasegroupid',\n    MUSICBRAINZ_WORKID: 'musicbrainz_workid',\n    MUSICBRAINZ_TRMID: 'musicbrainz_trmid',\n    MUSICBRAINZ_DISCID: 'musicbrainz_discid',\n    ACOUSTID_ID: 'acoustid_id',\n    ACOUSTID_ID_FINGERPRINT: 'acoustid_fingerprint',\n    MUSICIP_PUID: 'musicip_puid',\n    // 'FINGERPRINT=MusicMagic Fingerprint{fingerprint}': 'musicip_fingerprint', // ToDo\n    WEBSITE: 'website',\n    NOTES: 'notes',\n    TOTALTRACKS: 'totaltracks',\n    TOTALDISCS: 'totaldiscs',\n    // Discogs\n    DISCOGS_ARTIST_ID: 'discogs_artist_id',\n    DISCOGS_ARTISTS: 'artists',\n    DISCOGS_ARTIST_NAME: 'artists',\n    DISCOGS_ALBUM_ARTISTS: 'albumartist',\n    DISCOGS_CATALOG: 'catalognumber',\n    DISCOGS_COUNTRY: 'releasecountry',\n    DISCOGS_DATE: 'originaldate',\n    DISCOGS_LABEL: 'label',\n    DISCOGS_LABEL_ID: 'discogs_label_id',\n    DISCOGS_MASTER_RELEASE_ID: 'discogs_master_release_id',\n    DISCOGS_RATING: 'discogs_rating',\n    DISCOGS_RELEASED: 'date',\n    DISCOGS_RELEASE_ID: 'discogs_release_id',\n    DISCOGS_VOTES: 'discogs_votes',\n    CATALOGID: 'catalognumber',\n    STYLE: 'genre',\n    //\n    REPLAYGAIN_TRACK_GAIN: 'replaygain_track_gain',\n    REPLAYGAIN_TRACK_PEAK: 'replaygain_track_peak',\n    REPLAYGAIN_ALBUM_GAIN: 'replaygain_album_gain',\n    REPLAYGAIN_ALBUM_PEAK: 'replaygain_album_peak',\n    // To Sure if these (REPLAYGAIN_MINMAX, REPLAYGAIN_ALBUM_MINMAX & REPLAYGAIN_UNDO) are used for Vorbis:\n    REPLAYGAIN_MINMAX: 'replaygain_track_minmax',\n    REPLAYGAIN_ALBUM_MINMAX: 'replaygain_album_minmax',\n    REPLAYGAIN_UNDO: 'replaygain_undo'\n};\nclass VorbisTagMapper extends GenericTagMapper_1.CommonTagMapper {\n    static toRating(email, rating, maxScore) {\n        return {\n            source: email ? email.toLowerCase() : email,\n            rating: (parseFloat(rating) / maxScore) * GenericTagMapper_1.CommonTagMapper.maxRatingScore\n        };\n    }\n    constructor() {\n        super(['vorbis'], vorbisTagMap);\n    }\n    postMap(tag) {\n        if (tag.id === 'RATING') {\n            // The way Winamp 5.666 assigns rating\n            tag.value = VorbisTagMapper.toRating(undefined, tag.value, 100);\n        }\n        else if (tag.id.indexOf('RATING:') === 0) {\n            const keys = tag.id.split(':');\n            tag.value = VorbisTagMapper.toRating(keys[1], tag.value, 1);\n            tag.id = keys[0];\n        }\n    }\n}\nexports.VorbisTagMapper = VorbisTagMapper;\n//# sourceMappingURL=VorbisTagMapper.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/ogg/vorbis/VorbisTagMapper.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/riff/RiffChunk.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/riff/RiffChunk.js ***!
  \****************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ListInfoTagValue = exports.Header = void 0;\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\n/**\n * Common RIFF chunk header\n */\nexports.Header = {\n    len: 8,\n    get: (buf, off) => {\n        return {\n            // Group-ID\n            chunkID: buf.toString('binary', off, off + 4),\n            // Size\n            chunkSize: Token.UINT32_LE.get(buf, 4)\n        };\n    }\n};\n/**\n * Token to parse RIFF-INFO tag value\n */\nclass ListInfoTagValue {\n    constructor(tagHeader) {\n        this.tagHeader = tagHeader;\n        this.len = tagHeader.chunkSize;\n        this.len += this.len & 1; // if it is an odd length, round up to even\n    }\n    get(buf, off) {\n        return new Token.StringType(this.tagHeader.chunkSize, 'ascii').get(buf, off);\n    }\n}\nexports.ListInfoTagValue = ListInfoTagValue;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/riff/RiffChunk.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/riff/RiffInfoTagMap.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/riff/RiffInfoTagMap.js ***!
  \*********************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.RiffInfoTagMapper = exports.riffInfoTagMap = void 0;\nconst GenericTagMapper_1 = __webpack_require__(/*! ../common/GenericTagMapper */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/GenericTagMapper.js\");\n/**\n * RIFF Info Tags; part of the EXIF 2.3\n * Ref: http://owl.phy.queensu.ca/~phil/exiftool/TagNames/RIFF.html#Info\n */\nexports.riffInfoTagMap = {\n    IART: 'artist',\n    ICRD: 'date',\n    INAM: 'title',\n    TITL: 'title',\n    IPRD: 'album',\n    ITRK: 'track',\n    IPRT: 'track',\n    COMM: 'comment',\n    ICMT: 'comment',\n    ICNT: 'releasecountry',\n    GNRE: 'genre',\n    IWRI: 'writer',\n    RATE: 'rating',\n    YEAR: 'year',\n    ISFT: 'encodedby',\n    CODE: 'encodedby',\n    TURL: 'website',\n    IGNR: 'genre',\n    IENG: 'engineer',\n    ITCH: 'technician',\n    IMED: 'media',\n    IRPD: 'album' // Product, where the file was intended for\n};\nclass RiffInfoTagMapper extends GenericTagMapper_1.CommonTagMapper {\n    constructor() {\n        super(['exif'], exports.riffInfoTagMap);\n    }\n}\nexports.RiffInfoTagMapper = RiffInfoTagMapper;\n//# sourceMappingURL=RiffInfoTagMap.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/riff/RiffInfoTagMap.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/type.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/type.js ***!
  \******************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.TrackType = void 0;\nvar types_1 = __webpack_require__(/*! ./matroska/types */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/matroska/types.js");\nObject.defineProperty(exports, "TrackType", ({ enumerable: true, get: function () { return types_1.TrackType; } }));\n//# sourceMappingURL=type.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/type.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wav/BwfChunk.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wav/BwfChunk.js ***!
  \**************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.BroadcastAudioExtensionChunk = void 0;\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst Util_1 = __webpack_require__(/*! ../common/Util */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js\");\n/**\n * Broadcast Audio Extension Chunk\n * Ref: https://tech.ebu.ch/docs/tech/tech3285.pdf\n */\nexports.BroadcastAudioExtensionChunk = {\n    len: 420,\n    get: (uint8array, off) => {\n        return {\n            description: (0, Util_1.stripNulls)(new Token.StringType(256, 'ascii').get(uint8array, off)).trim(),\n            originator: (0, Util_1.stripNulls)(new Token.StringType(32, 'ascii').get(uint8array, off + 256)).trim(),\n            originatorReference: (0, Util_1.stripNulls)(new Token.StringType(32, 'ascii').get(uint8array, off + 288)).trim(),\n            originationDate: (0, Util_1.stripNulls)(new Token.StringType(10, 'ascii').get(uint8array, off + 320)).trim(),\n            originationTime: (0, Util_1.stripNulls)(new Token.StringType(8, 'ascii').get(uint8array, off + 330)).trim(),\n            timeReferenceLow: Token.UINT32_LE.get(uint8array, off + 338),\n            timeReferenceHigh: Token.UINT32_LE.get(uint8array, off + 342),\n            version: Token.UINT16_LE.get(uint8array, off + 346),\n            umid: new Token.Uint8ArrayType(64).get(uint8array, off + 348),\n            loudnessValue: Token.UINT16_LE.get(uint8array, off + 412),\n            maxTruePeakLevel: Token.UINT16_LE.get(uint8array, off + 414),\n            maxMomentaryLoudness: Token.UINT16_LE.get(uint8array, off + 416),\n            maxShortTermLoudness: Token.UINT16_LE.get(uint8array, off + 418)\n        };\n    }\n};\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wav/BwfChunk.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wav/WaveChunk.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wav/WaveChunk.js ***!
  \***************************************************************************************************/function(__unused_webpack_module,exports){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.FactChunk = exports.Format = exports.WaveFormat = void 0;\n/**\n * Ref: https://msdn.microsoft.com/en-us/library/windows/desktop/dd317599(v=vs.85).aspx\n */\nvar WaveFormat;\n(function (WaveFormat) {\n    WaveFormat[WaveFormat["PCM"] = 1] = "PCM";\n    // MPEG-4 and AAC Audio Types\n    WaveFormat[WaveFormat["ADPCM"] = 2] = "ADPCM";\n    WaveFormat[WaveFormat["IEEE_FLOAT"] = 3] = "IEEE_FLOAT";\n    WaveFormat[WaveFormat["MPEG_ADTS_AAC"] = 5632] = "MPEG_ADTS_AAC";\n    WaveFormat[WaveFormat["MPEG_LOAS"] = 5634] = "MPEG_LOAS";\n    WaveFormat[WaveFormat["RAW_AAC1"] = 255] = "RAW_AAC1";\n    // Dolby Audio Types\n    WaveFormat[WaveFormat["DOLBY_AC3_SPDIF"] = 146] = "DOLBY_AC3_SPDIF";\n    WaveFormat[WaveFormat["DVM"] = 8192] = "DVM";\n    WaveFormat[WaveFormat["RAW_SPORT"] = 576] = "RAW_SPORT";\n    WaveFormat[WaveFormat["ESST_AC3"] = 577] = "ESST_AC3";\n    WaveFormat[WaveFormat["DRM"] = 9] = "DRM";\n    WaveFormat[WaveFormat["DTS2"] = 8193] = "DTS2";\n    WaveFormat[WaveFormat["MPEG"] = 80] = "MPEG";\n})(WaveFormat = exports.WaveFormat || (exports.WaveFormat = {}));\n/**\n * format chunk; chunk-id is "fmt "\n * http://soundfile.sapp.org/doc/WaveFormat/\n */\nclass Format {\n    constructor(header) {\n        if (header.chunkSize < 16)\n            throw new Error(\'Invalid chunk size\');\n        this.len = header.chunkSize;\n    }\n    get(buf, off) {\n        return {\n            wFormatTag: buf.readUInt16LE(off),\n            nChannels: buf.readUInt16LE(off + 2),\n            nSamplesPerSec: buf.readUInt32LE(off + 4),\n            nAvgBytesPerSec: buf.readUInt32LE(off + 8),\n            nBlockAlign: buf.readUInt16LE(off + 12),\n            wBitsPerSample: buf.readUInt16LE(off + 14)\n        };\n    }\n}\nexports.Format = Format;\n/**\n * Fact chunk; chunk-id is "fact"\n * http://www-mmsp.ece.mcgill.ca/Documents/AudioFormats/WAVE/WAVE.html\n * http://www.recordingblogs.com/wiki/fact-chunk-of-a-wave-file\n */\nclass FactChunk {\n    constructor(header) {\n        if (header.chunkSize < 4) {\n            throw new Error(\'Invalid fact chunk size.\');\n        }\n        this.len = header.chunkSize;\n    }\n    get(buf, off) {\n        return {\n            dwSampleLength: buf.readUInt32LE(off)\n        };\n    }\n}\nexports.FactChunk = FactChunk;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wav/WaveChunk.js?')},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wav/WaveParser.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wav/WaveParser.js ***!
  \****************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WaveParser = void 0;\nconst strtok3 = __webpack_require__(/*! strtok3/lib/core */ \"./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/core.js\");\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst riff = __webpack_require__(/*! ../riff/RiffChunk */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/riff/RiffChunk.js\");\nconst WaveChunk = __webpack_require__(/*! ./../wav/WaveChunk */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wav/WaveChunk.js\");\nconst ID3v2Parser_1 = __webpack_require__(/*! ../id3v2/ID3v2Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/id3v2/ID3v2Parser.js\");\nconst util = __webpack_require__(/*! ../common/Util */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/Util.js\");\nconst FourCC_1 = __webpack_require__(/*! ../common/FourCC */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js\");\nconst BasicParser_1 = __webpack_require__(/*! ../common/BasicParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js\");\nconst BwfChunk_1 = __webpack_require__(/*! ../wav/BwfChunk */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wav/BwfChunk.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:RIFF');\n/**\n * Resource Interchange File Format (RIFF) Parser\n *\n * WAVE PCM soundfile format\n *\n * Ref:\n * - http://www.johnloomis.org/cpe102/asgn/asgn1/riff.html\n * - http://soundfile.sapp.org/doc/WaveFormat\n *\n * ToDo: Split WAVE part from RIFF parser\n */\nclass WaveParser extends BasicParser_1.BasicParser {\n    async parse() {\n        const riffHeader = await this.tokenizer.readToken(riff.Header);\n        debug(`pos=${this.tokenizer.position}, parse: chunkID=${riffHeader.chunkID}`);\n        if (riffHeader.chunkID !== 'RIFF')\n            return; // Not RIFF format\n        return this.parseRiffChunk(riffHeader.chunkSize).catch(err => {\n            if (!(err instanceof strtok3.EndOfStreamError)) {\n                throw err;\n            }\n        });\n    }\n    async parseRiffChunk(chunkSize) {\n        const type = await this.tokenizer.readToken(FourCC_1.FourCcToken);\n        this.metadata.setFormat('container', type);\n        switch (type) {\n            case 'WAVE':\n                return this.readWaveChunk(chunkSize - FourCC_1.FourCcToken.len);\n            default:\n                throw new Error(`Unsupported RIFF format: RIFF/${type}`);\n        }\n    }\n    async readWaveChunk(remaining) {\n        while (remaining >= riff.Header.len) {\n            const header = await this.tokenizer.readToken(riff.Header);\n            remaining -= riff.Header.len + header.chunkSize;\n            if (header.chunkSize > remaining) {\n                this.metadata.addWarning('Data chunk size exceeds file size');\n            }\n            this.header = header;\n            debug(`pos=${this.tokenizer.position}, readChunk: chunkID=RIFF/WAVE/${header.chunkID}`);\n            switch (header.chunkID) {\n                case 'LIST':\n                    await this.parseListTag(header);\n                    break;\n                case 'fact': // extended Format chunk,\n                    this.metadata.setFormat('lossless', false);\n                    this.fact = await this.tokenizer.readToken(new WaveChunk.FactChunk(header));\n                    break;\n                case 'fmt ': // The Util Chunk, non-PCM Formats\n                    const fmt = await this.tokenizer.readToken(new WaveChunk.Format(header));\n                    let subFormat = WaveChunk.WaveFormat[fmt.wFormatTag];\n                    if (!subFormat) {\n                        debug('WAVE/non-PCM format=' + fmt.wFormatTag);\n                        subFormat = 'non-PCM (' + fmt.wFormatTag + ')';\n                    }\n                    this.metadata.setFormat('codec', subFormat);\n                    this.metadata.setFormat('bitsPerSample', fmt.wBitsPerSample);\n                    this.metadata.setFormat('sampleRate', fmt.nSamplesPerSec);\n                    this.metadata.setFormat('numberOfChannels', fmt.nChannels);\n                    this.metadata.setFormat('bitrate', fmt.nBlockAlign * fmt.nSamplesPerSec * 8);\n                    this.blockAlign = fmt.nBlockAlign;\n                    break;\n                case 'id3 ': // The way Picard, FooBar currently stores, ID3 meta-data\n                case 'ID3 ': // The way Mp3Tags stores ID3 meta-data\n                    const id3_data = await this.tokenizer.readToken(new Token.Uint8ArrayType(header.chunkSize));\n                    const rst = strtok3.fromBuffer(id3_data);\n                    await new ID3v2Parser_1.ID3v2Parser().parse(this.metadata, rst, this.options);\n                    break;\n                case 'data': // PCM-data\n                    if (this.metadata.format.lossless !== false) {\n                        this.metadata.setFormat('lossless', true);\n                    }\n                    let chunkSize = header.chunkSize;\n                    if (this.tokenizer.fileInfo.size) {\n                        const calcRemaining = this.tokenizer.fileInfo.size - this.tokenizer.position;\n                        if (calcRemaining < chunkSize) {\n                            this.metadata.addWarning('data chunk length exceeding file length');\n                            chunkSize = calcRemaining;\n                        }\n                    }\n                    const numberOfSamples = this.fact ? this.fact.dwSampleLength : (chunkSize === 0xffffffff ? undefined : chunkSize / this.blockAlign);\n                    if (numberOfSamples) {\n                        this.metadata.setFormat('numberOfSamples', numberOfSamples);\n                        this.metadata.setFormat('duration', numberOfSamples / this.metadata.format.sampleRate);\n                    }\n                    if (this.metadata.format.codec === 'ADPCM') { // ADPCM is 4 bits lossy encoding resulting in 352kbps\n                        this.metadata.setFormat('bitrate', 352000);\n                    }\n                    else {\n                        this.metadata.setFormat('bitrate', this.blockAlign * this.metadata.format.sampleRate * 8);\n                    }\n                    await this.tokenizer.ignore(header.chunkSize);\n                    break;\n                case 'bext': // Broadcast Audio Extension chunk\thttps://tech.ebu.ch/docs/tech/tech3285.pdf\n                    const bext = await this.tokenizer.readToken(BwfChunk_1.BroadcastAudioExtensionChunk);\n                    Object.keys(bext).forEach(key => {\n                        this.metadata.addTag('exif', 'bext.' + key, bext[key]);\n                    });\n                    const bextRemaining = header.chunkSize - BwfChunk_1.BroadcastAudioExtensionChunk.len;\n                    await this.tokenizer.ignore(bextRemaining);\n                    break;\n                case '\\x00\\x00\\x00\\x00': // padding ??\n                    debug(`Ignore padding chunk: RIFF/${header.chunkID} of ${header.chunkSize} bytes`);\n                    this.metadata.addWarning('Ignore chunk: RIFF/' + header.chunkID);\n                    await this.tokenizer.ignore(header.chunkSize);\n                    break;\n                default:\n                    debug(`Ignore chunk: RIFF/${header.chunkID} of ${header.chunkSize} bytes`);\n                    this.metadata.addWarning('Ignore chunk: RIFF/' + header.chunkID);\n                    await this.tokenizer.ignore(header.chunkSize);\n            }\n            if (this.header.chunkSize % 2 === 1) {\n                debug('Read odd padding byte'); // https://wiki.multimedia.cx/index.php/RIFF\n                await this.tokenizer.ignore(1);\n            }\n        }\n    }\n    async parseListTag(listHeader) {\n        const listType = await this.tokenizer.readToken(new Token.StringType(4, 'binary'));\n        debug('pos=%s, parseListTag: chunkID=RIFF/WAVE/LIST/%s', this.tokenizer.position, listType);\n        switch (listType) {\n            case 'INFO':\n                return this.parseRiffInfoTags(listHeader.chunkSize - 4);\n            case 'adtl':\n            default:\n                this.metadata.addWarning('Ignore chunk: RIFF/WAVE/LIST/' + listType);\n                debug('Ignoring chunkID=RIFF/WAVE/LIST/' + listType);\n                return this.tokenizer.ignore(listHeader.chunkSize - 4).then();\n        }\n    }\n    async parseRiffInfoTags(chunkSize) {\n        while (chunkSize >= 8) {\n            const header = await this.tokenizer.readToken(riff.Header);\n            const valueToken = new riff.ListInfoTagValue(header);\n            const value = await this.tokenizer.readToken(valueToken);\n            this.addTag(header.chunkID, util.stripNulls(value));\n            chunkSize -= (8 + valueToken.len);\n        }\n        if (chunkSize !== 0) {\n            throw Error('Illegal remaining size: ' + chunkSize);\n        }\n    }\n    addTag(id, value) {\n        this.metadata.addTag('exif', id, value);\n    }\n}\nexports.WaveParser = WaveParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wav/WaveParser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wavpack/WavPackParser.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wavpack/WavPackParser.js ***!
  \***********************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ \"./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js\")[\"Buffer\"];\n\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.WavPackParser = void 0;\nconst Token = __webpack_require__(/*! token-types */ \"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js\");\nconst APEv2Parser_1 = __webpack_require__(/*! ../apev2/APEv2Parser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/apev2/APEv2Parser.js\");\nconst FourCC_1 = __webpack_require__(/*! ../common/FourCC */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js\");\nconst BasicParser_1 = __webpack_require__(/*! ../common/BasicParser */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/BasicParser.js\");\nconst WavPackToken_1 = __webpack_require__(/*! ./WavPackToken */ \"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wavpack/WavPackToken.js\");\nconst debug_1 = __webpack_require__(/*! debug */ \"./node_modules/.pnpm/debug@4.3.7/node_modules/debug/src/browser.js\");\nconst debug = (0, debug_1.default)('music-metadata:parser:WavPack');\n/**\n * WavPack Parser\n */\nclass WavPackParser extends BasicParser_1.BasicParser {\n    async parse() {\n        this.audioDataSize = 0;\n        // First parse all WavPack blocks\n        await this.parseWavPackBlocks();\n        // try to parse APEv2 header\n        return APEv2Parser_1.APEv2Parser.tryParseApeHeader(this.metadata, this.tokenizer, this.options);\n    }\n    async parseWavPackBlocks() {\n        do {\n            const blockId = await this.tokenizer.peekToken(FourCC_1.FourCcToken);\n            if (blockId !== 'wvpk')\n                break;\n            const header = await this.tokenizer.readToken(WavPackToken_1.WavPack.BlockHeaderToken);\n            if (header.BlockID !== 'wvpk')\n                throw new Error('Invalid WavPack Block-ID');\n            debug(`WavPack header blockIndex=${header.blockIndex}, len=${WavPackToken_1.WavPack.BlockHeaderToken.len}`);\n            if (header.blockIndex === 0 && !this.metadata.format.container) {\n                this.metadata.setFormat('container', 'WavPack');\n                this.metadata.setFormat('lossless', !header.flags.isHybrid);\n                // tagTypes: this.type,\n                this.metadata.setFormat('bitsPerSample', header.flags.bitsPerSample);\n                if (!header.flags.isDSD) {\n                    // In case isDSD, these values will ne set in ID_DSD_BLOCK\n                    this.metadata.setFormat('sampleRate', header.flags.samplingRate);\n                    this.metadata.setFormat('duration', header.totalSamples / header.flags.samplingRate);\n                }\n                this.metadata.setFormat('numberOfChannels', header.flags.isMono ? 1 : 2);\n                this.metadata.setFormat('numberOfSamples', header.totalSamples);\n                this.metadata.setFormat('codec', header.flags.isDSD ? 'DSD' : 'PCM');\n            }\n            const ignoreBytes = header.blockSize - (WavPackToken_1.WavPack.BlockHeaderToken.len - 8);\n            await (header.blockIndex === 0 ? this.parseMetadataSubBlock(header, ignoreBytes) : this.tokenizer.ignore(ignoreBytes));\n            if (header.blockSamples > 0) {\n                this.audioDataSize += header.blockSize; // Count audio data for bit-rate calculation\n            }\n        } while (!this.tokenizer.fileInfo.size || this.tokenizer.fileInfo.size - this.tokenizer.position >= WavPackToken_1.WavPack.BlockHeaderToken.len);\n        this.metadata.setFormat('bitrate', this.audioDataSize * 8 / this.metadata.format.duration);\n    }\n    /**\n     * Ref: http://www.wavpack.com/WavPack5FileFormat.pdf, 3.0 Metadata Sub-blocks\n     * @param remainingLength\n     */\n    async parseMetadataSubBlock(header, remainingLength) {\n        while (remainingLength > WavPackToken_1.WavPack.MetadataIdToken.len) {\n            const id = await this.tokenizer.readToken(WavPackToken_1.WavPack.MetadataIdToken);\n            const dataSizeInWords = await this.tokenizer.readNumber(id.largeBlock ? Token.UINT24_LE : Token.UINT8);\n            const data = Buffer.alloc(dataSizeInWords * 2 - (id.isOddSize ? 1 : 0));\n            await this.tokenizer.readBuffer(data);\n            debug(`Metadata Sub-Blocks functionId=0x${id.functionId.toString(16)}, id.largeBlock=${id.largeBlock},data-size=${data.length}`);\n            switch (id.functionId) {\n                case 0x0: // ID_DUMMY: could be used to pad WavPack blocks\n                    break;\n                case 0xe: // ID_DSD_BLOCK\n                    debug('ID_DSD_BLOCK');\n                    // https://github.com/dbry/WavPack/issues/71#issuecomment-483094813\n                    const mp = 1 << data.readUInt8(0);\n                    const samplingRate = header.flags.samplingRate * mp * 8; // ToDo: second factor should be read from DSD-metadata block https://github.com/dbry/WavPack/issues/71#issuecomment-483094813\n                    if (!header.flags.isDSD)\n                        throw new Error('Only expect DSD block if DSD-flag is set');\n                    this.metadata.setFormat('sampleRate', samplingRate);\n                    this.metadata.setFormat('duration', header.totalSamples / samplingRate);\n                    break;\n                case 0x24: // ID_ALT_TRAILER: maybe used to embed original ID3 tag header\n                    debug('ID_ALT_TRAILER: trailer for non-wav files');\n                    break;\n                case 0x26: // ID_MD5_CHECKSUM\n                    this.metadata.setFormat('audioMD5', data);\n                    break;\n                case 0x2f: // ID_BLOCK_CHECKSUM\n                    debug(`ID_BLOCK_CHECKSUM: checksum=${data.toString('hex')}`);\n                    break;\n                default:\n                    debug(`Ignore unsupported meta-sub-block-id functionId=0x${id.functionId.toString(16)}`);\n                    break;\n            }\n            remainingLength -= WavPackToken_1.WavPack.MetadataIdToken.len + (id.largeBlock ? Token.UINT24_LE.len : Token.UINT8.len) + dataSizeInWords * 2;\n            debug(`remainingLength=${remainingLength}`);\n            if (id.isOddSize)\n                this.tokenizer.ignore(1);\n        }\n        if (remainingLength !== 0)\n            throw new Error('metadata-sub-block should fit it remaining length');\n    }\n}\nexports.WavPackParser = WavPackParser;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wavpack/WavPackParser.js?")},"./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wavpack/WavPackToken.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wavpack/WavPackToken.js ***!
  \**********************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.WavPack = void 0;\nconst Token = __webpack_require__(/*! token-types */ "./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js");\nconst FourCC_1 = __webpack_require__(/*! ../common/FourCC */ "./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/common/FourCC.js");\nconst SampleRates = [6000, 8000, 9600, 11025, 12000, 16000, 22050, 24000, 32000, 44100,\n    48000, 64000, 88200, 96000, 192000, -1];\nclass WavPack {\n    static isBitSet(flags, bitOffset) {\n        return WavPack.getBitAllignedNumber(flags, bitOffset, 1) === 1;\n    }\n    static getBitAllignedNumber(flags, bitOffset, len) {\n        return (flags >>> bitOffset) & (0xffffffff >>> (32 - len));\n    }\n}\n/**\n * WavPack Block Header\n *\n * 32-byte little-endian header at the front of every WavPack block\n *\n * Ref: http://www.wavpack.com/WavPack5FileFormat.pdf (page 2/6: 2.0 "Block Header")\n */\nWavPack.BlockHeaderToken = {\n    len: 32,\n    get: (buf, off) => {\n        const flags = Token.UINT32_LE.get(buf, off + 24);\n        const res = {\n            // should equal \'wvpk\'\n            BlockID: FourCC_1.FourCcToken.get(buf, off),\n            //  0x402 to 0x410 are valid for decode\n            blockSize: Token.UINT32_LE.get(buf, off + 4),\n            //  0x402 (1026) to 0x410 are valid for decode\n            version: Token.UINT16_LE.get(buf, off + 8),\n            //  40-bit total samples for entire file (if block_index == 0 and a value of -1 indicates an unknown length)\n            totalSamples: /* replace with bigint? (Token.UINT8.get(buf, off + 11) << 32) + */ Token.UINT32_LE.get(buf, off + 12),\n            // 40-bit block_index\n            blockIndex: /* replace with bigint? (Token.UINT8.get(buf, off + 10) << 32) + */ Token.UINT32_LE.get(buf, off + 16),\n            // 40-bit total samples for entire file (if block_index == 0 and a value of -1 indicates an unknown length)\n            blockSamples: Token.UINT32_LE.get(buf, off + 20),\n            // various flags for id and decoding\n            flags: {\n                bitsPerSample: (1 + WavPack.getBitAllignedNumber(flags, 0, 2)) * 8,\n                isMono: WavPack.isBitSet(flags, 2),\n                isHybrid: WavPack.isBitSet(flags, 3),\n                isJointStereo: WavPack.isBitSet(flags, 4),\n                crossChannel: WavPack.isBitSet(flags, 5),\n                hybridNoiseShaping: WavPack.isBitSet(flags, 6),\n                floatingPoint: WavPack.isBitSet(flags, 7),\n                samplingRate: SampleRates[WavPack.getBitAllignedNumber(flags, 23, 4)],\n                isDSD: WavPack.isBitSet(flags, 31)\n            },\n            // crc for actual decoded data\n            crc: new Token.Uint8ArrayType(4).get(buf, off + 28)\n        };\n        if (res.flags.isDSD) {\n            res.totalSamples *= 8;\n        }\n        return res;\n    }\n};\n/**\n * 3.0 Metadata Sub-Blocks\n * Ref: http://www.wavpack.com/WavPack5FileFormat.pdf (page 4/6: 3.0 "Metadata Sub-Block")\n */\nWavPack.MetadataIdToken = {\n    len: 1,\n    get: (buf, off) => {\n        return {\n            functionId: WavPack.getBitAllignedNumber(buf[off], 0, 6),\n            isOptional: WavPack.isBitSet(buf[off], 5),\n            isOddSize: WavPack.isBitSet(buf[off], 6),\n            largeBlock: WavPack.isBitSet(buf[off], 7)\n        };\n    }\n};\nexports.WavPack = WavPack;\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/music-metadata@7.14.0/node_modules/music-metadata/lib/wavpack/WavPackToken.js?')},"./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/Deferred.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/Deferred.js ***!
  \*******************************************************************************************/function(__unused_webpack_module,exports){"use strict";eval('\r\nObject.defineProperty(exports, "__esModule", ({ value: true }));\r\nexports.Deferred = void 0;\r\nclass Deferred {\r\n    constructor() {\r\n        this.resolve = () => null;\r\n        this.reject = () => null;\r\n        this.promise = new Promise((resolve, reject) => {\r\n            this.reject = reject;\r\n            this.resolve = resolve;\r\n        });\r\n    }\r\n}\r\nexports.Deferred = Deferred;\r\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/Deferred.js?')},"./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/EndOfFileStream.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/EndOfFileStream.js ***!
  \**************************************************************************************************/function(__unused_webpack_module,exports){"use strict";eval("\r\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\r\nexports.EndOfStreamError = exports.defaultMessages = void 0;\r\nexports.defaultMessages = 'End-Of-Stream';\r\n/**\r\n * Thrown on read operation of the end of file or stream has been reached\r\n */\r\nclass EndOfStreamError extends Error {\r\n    constructor() {\r\n        super(exports.defaultMessages);\r\n    }\r\n}\r\nexports.EndOfStreamError = EndOfStreamError;\r\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/EndOfFileStream.js?")},"./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/StreamReader.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/StreamReader.js ***!
  \***********************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval("\r\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\r\nexports.StreamReader = exports.EndOfStreamError = void 0;\r\nconst EndOfFileStream_1 = __webpack_require__(/*! ./EndOfFileStream */ \"./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/EndOfFileStream.js\");\r\nconst Deferred_1 = __webpack_require__(/*! ./Deferred */ \"./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/Deferred.js\");\r\nvar EndOfFileStream_2 = __webpack_require__(/*! ./EndOfFileStream */ \"./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/EndOfFileStream.js\");\r\nObject.defineProperty(exports, \"EndOfStreamError\", ({ enumerable: true, get: function () { return EndOfFileStream_2.EndOfStreamError; } }));\r\nconst maxStreamReadSize = 1 * 1024 * 1024; // Maximum request length on read-stream operation\r\nclass StreamReader {\r\n    constructor(s) {\r\n        this.s = s;\r\n        /**\r\n         * Deferred used for postponed read request (as not data is yet available to read)\r\n         */\r\n        this.deferred = null;\r\n        this.endOfStream = false;\r\n        /**\r\n         * Store peeked data\r\n         * @type {Array}\r\n         */\r\n        this.peekQueue = [];\r\n        if (!s.read || !s.once) {\r\n            throw new Error('Expected an instance of stream.Readable');\r\n        }\r\n        this.s.once('end', () => this.reject(new EndOfFileStream_1.EndOfStreamError()));\r\n        this.s.once('error', err => this.reject(err));\r\n        this.s.once('close', () => this.reject(new Error('Stream closed')));\r\n    }\r\n    /**\r\n     * Read ahead (peek) from stream. Subsequent read or peeks will return the same data\r\n     * @param uint8Array - Uint8Array (or Buffer) to store data read from stream in\r\n     * @param offset - Offset target\r\n     * @param length - Number of bytes to read\r\n     * @returns Number of bytes peeked\r\n     */\r\n    async peek(uint8Array, offset, length) {\r\n        const bytesRead = await this.read(uint8Array, offset, length);\r\n        this.peekQueue.push(uint8Array.subarray(offset, offset + bytesRead)); // Put read data back to peek buffer\r\n        return bytesRead;\r\n    }\r\n    /**\r\n     * Read chunk from stream\r\n     * @param buffer - Target Uint8Array (or Buffer) to store data read from stream in\r\n     * @param offset - Offset target\r\n     * @param length - Number of bytes to read\r\n     * @returns Number of bytes read\r\n     */\r\n    async read(buffer, offset, length) {\r\n        if (length === 0) {\r\n            return 0;\r\n        }\r\n        if (this.peekQueue.length === 0 && this.endOfStream) {\r\n            throw new EndOfFileStream_1.EndOfStreamError();\r\n        }\r\n        let remaining = length;\r\n        let bytesRead = 0;\r\n        // consume peeked data first\r\n        while (this.peekQueue.length > 0 && remaining > 0) {\r\n            const peekData = this.peekQueue.pop(); // Front of queue\r\n            if (!peekData)\r\n                throw new Error('peekData should be defined');\r\n            const lenCopy = Math.min(peekData.length, remaining);\r\n            buffer.set(peekData.subarray(0, lenCopy), offset + bytesRead);\r\n            bytesRead += lenCopy;\r\n            remaining -= lenCopy;\r\n            if (lenCopy < peekData.length) {\r\n                // remainder back to queue\r\n                this.peekQueue.push(peekData.subarray(lenCopy));\r\n            }\r\n        }\r\n        // continue reading from stream if required\r\n        while (remaining > 0 && !this.endOfStream) {\r\n            const reqLen = Math.min(remaining, maxStreamReadSize);\r\n            const chunkLen = await this.readFromStream(buffer, offset + bytesRead, reqLen);\r\n            bytesRead += chunkLen;\r\n            if (chunkLen < reqLen)\r\n                break;\r\n            remaining -= chunkLen;\r\n        }\r\n        return bytesRead;\r\n    }\r\n    /**\r\n     * Read chunk from stream\r\n     * @param buffer Target Uint8Array (or Buffer) to store data read from stream in\r\n     * @param offset Offset target\r\n     * @param length Number of bytes to read\r\n     * @returns Number of bytes read\r\n     */\r\n    async readFromStream(buffer, offset, length) {\r\n        const readBuffer = this.s.read(length);\r\n        if (readBuffer) {\r\n            buffer.set(readBuffer, offset);\r\n            return readBuffer.length;\r\n        }\r\n        else {\r\n            const request = {\r\n                buffer,\r\n                offset,\r\n                length,\r\n                deferred: new Deferred_1.Deferred()\r\n            };\r\n            this.deferred = request.deferred;\r\n            this.s.once('readable', () => {\r\n                this.readDeferred(request);\r\n            });\r\n            return request.deferred.promise;\r\n        }\r\n    }\r\n    /**\r\n     * Process deferred read request\r\n     * @param request Deferred read request\r\n     */\r\n    readDeferred(request) {\r\n        const readBuffer = this.s.read(request.length);\r\n        if (readBuffer) {\r\n            request.buffer.set(readBuffer, request.offset);\r\n            request.deferred.resolve(readBuffer.length);\r\n            this.deferred = null;\r\n        }\r\n        else {\r\n            this.s.once('readable', () => {\r\n                this.readDeferred(request);\r\n            });\r\n        }\r\n    }\r\n    reject(err) {\r\n        this.endOfStream = true;\r\n        if (this.deferred) {\r\n            this.deferred.reject(err);\r\n            this.deferred = null;\r\n        }\r\n    }\r\n}\r\nexports.StreamReader = StreamReader;\r\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/StreamReader.js?")},"./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/index.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/index.js ***!
  \****************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\r\nObject.defineProperty(exports, "__esModule", ({ value: true }));\r\nexports.StreamReader = exports.EndOfStreamError = void 0;\r\nvar EndOfFileStream_1 = __webpack_require__(/*! ./EndOfFileStream */ "./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/EndOfFileStream.js");\r\nObject.defineProperty(exports, "EndOfStreamError", ({ enumerable: true, get: function () { return EndOfFileStream_1.EndOfStreamError; } }));\r\nvar StreamReader_1 = __webpack_require__(/*! ./StreamReader */ "./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/StreamReader.js");\r\nObject.defineProperty(exports, "StreamReader", ({ enumerable: true, get: function () { return StreamReader_1.StreamReader; } }));\r\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/index.js?')},"./node_modules/.pnpm/readable-web-to-node-stream@3.0.2/node_modules/readable-web-to-node-stream/lib/index.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/.pnpm/readable-web-to-node-stream@3.0.2/node_modules/readable-web-to-node-stream/lib/index.js ***!
  \********************************************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.ReadableWebToNodeStream = void 0;\nconst readable_stream_1 = __webpack_require__(/*! readable-stream */ "./node_modules/.pnpm/readable-stream@3.6.2/node_modules/readable-stream/readable-browser.js");\n/**\n * Converts a Web-API stream into Node stream.Readable class\n * Node stream readable: https://nodejs.org/api/stream.html#stream_readable_streams\n * Web API readable-stream: https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream\n * Node readable stream: https://nodejs.org/api/stream.html#stream_readable_streams\n */\nclass ReadableWebToNodeStream extends readable_stream_1.Readable {\n    /**\n     *\n     * @param stream ReadableStream: https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream\n     */\n    constructor(stream) {\n        super();\n        this.bytesRead = 0;\n        this.released = false;\n        this.reader = stream.getReader();\n    }\n    /**\n     * Implementation of readable._read(size).\n     * When readable._read() is called, if data is available from the resource,\n     * the implementation should begin pushing that data into the read queue\n     * https://nodejs.org/api/stream.html#stream_readable_read_size_1\n     */\n    async _read() {\n        // Should start pushing data into the queue\n        // Read data from the underlying Web-API-readable-stream\n        if (this.released) {\n            this.push(null); // Signal EOF\n            return;\n        }\n        this.pendingRead = this.reader.read();\n        const data = await this.pendingRead;\n        // clear the promise before pushing pushing new data to the queue and allow sequential calls to _read()\n        delete this.pendingRead;\n        if (data.done || this.released) {\n            this.push(null); // Signal EOF\n        }\n        else {\n            this.bytesRead += data.value.length;\n            this.push(data.value); // Push new data to the queue\n        }\n    }\n    /**\n     * If there is no unresolved read call to Web-API ReadableStream immediately returns;\n     * otherwise will wait until the read is resolved.\n     */\n    async waitForReadToComplete() {\n        if (this.pendingRead) {\n            await this.pendingRead;\n        }\n    }\n    /**\n     * Close wrapper\n     */\n    async close() {\n        await this.syncAndRelease();\n    }\n    async syncAndRelease() {\n        this.released = true;\n        await this.waitForReadToComplete();\n        await this.reader.releaseLock();\n    }\n}\nexports.ReadableWebToNodeStream = ReadableWebToNodeStream;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/readable-web-to-node-stream@3.0.2/node_modules/readable-web-to-node-stream/lib/index.js?')},"./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/AbstractTokenizer.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/AbstractTokenizer.js ***!
  \****************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ "./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js")["Buffer"];\n\r\nObject.defineProperty(exports, "__esModule", ({ value: true }));\r\nexports.AbstractTokenizer = void 0;\r\nconst peek_readable_1 = __webpack_require__(/*! peek-readable */ "./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/index.js");\r\n/**\r\n * Core tokenizer\r\n */\r\nclass AbstractTokenizer {\r\n    constructor(fileInfo) {\r\n        /**\r\n         * Tokenizer-stream position\r\n         */\r\n        this.position = 0;\r\n        this.numBuffer = new Uint8Array(8);\r\n        this.fileInfo = fileInfo ? fileInfo : {};\r\n    }\r\n    /**\r\n     * Read a token from the tokenizer-stream\r\n     * @param token - The token to read\r\n     * @param position - If provided, the desired position in the tokenizer-stream\r\n     * @returns Promise with token data\r\n     */\r\n    async readToken(token, position = this.position) {\r\n        const uint8Array = Buffer.alloc(token.len);\r\n        const len = await this.readBuffer(uint8Array, { position });\r\n        if (len < token.len)\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        return token.get(uint8Array, 0);\r\n    }\r\n    /**\r\n     * Peek a token from the tokenizer-stream.\r\n     * @param token - Token to peek from the tokenizer-stream.\r\n     * @param position - Offset where to begin reading within the file. If position is null, data will be read from the current file position.\r\n     * @returns Promise with token data\r\n     */\r\n    async peekToken(token, position = this.position) {\r\n        const uint8Array = Buffer.alloc(token.len);\r\n        const len = await this.peekBuffer(uint8Array, { position });\r\n        if (len < token.len)\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        return token.get(uint8Array, 0);\r\n    }\r\n    /**\r\n     * Read a numeric token from the stream\r\n     * @param token - Numeric token\r\n     * @returns Promise with number\r\n     */\r\n    async readNumber(token) {\r\n        const len = await this.readBuffer(this.numBuffer, { length: token.len });\r\n        if (len < token.len)\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        return token.get(this.numBuffer, 0);\r\n    }\r\n    /**\r\n     * Read a numeric token from the stream\r\n     * @param token - Numeric token\r\n     * @returns Promise with number\r\n     */\r\n    async peekNumber(token) {\r\n        const len = await this.peekBuffer(this.numBuffer, { length: token.len });\r\n        if (len < token.len)\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        return token.get(this.numBuffer, 0);\r\n    }\r\n    /**\r\n     * Ignore number of bytes, advances the pointer in under tokenizer-stream.\r\n     * @param length - Number of bytes to ignore\r\n     * @return resolves the number of bytes ignored, equals length if this available, otherwise the number of bytes available\r\n     */\r\n    async ignore(length) {\r\n        if (this.fileInfo.size !== undefined) {\r\n            const bytesLeft = this.fileInfo.size - this.position;\r\n            if (length > bytesLeft) {\r\n                this.position += bytesLeft;\r\n                return bytesLeft;\r\n            }\r\n        }\r\n        this.position += length;\r\n        return length;\r\n    }\r\n    async close() {\r\n        // empty\r\n    }\r\n    normalizeOptions(uint8Array, options) {\r\n        if (options && options.position !== undefined && options.position < this.position) {\r\n            throw new Error(\'`options.position` must be equal or greater than `tokenizer.position`\');\r\n        }\r\n        if (options) {\r\n            return {\r\n                mayBeLess: options.mayBeLess === true,\r\n                offset: options.offset ? options.offset : 0,\r\n                length: options.length ? options.length : (uint8Array.length - (options.offset ? options.offset : 0)),\r\n                position: options.position ? options.position : this.position\r\n            };\r\n        }\r\n        return {\r\n            mayBeLess: false,\r\n            offset: 0,\r\n            length: uint8Array.length,\r\n            position: this.position\r\n        };\r\n    }\r\n}\r\nexports.AbstractTokenizer = AbstractTokenizer;\r\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/AbstractTokenizer.js?')},"./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/BufferTokenizer.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/BufferTokenizer.js ***!
  \**************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\r\nObject.defineProperty(exports, "__esModule", ({ value: true }));\r\nexports.BufferTokenizer = void 0;\r\nconst peek_readable_1 = __webpack_require__(/*! peek-readable */ "./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/index.js");\r\nconst AbstractTokenizer_1 = __webpack_require__(/*! ./AbstractTokenizer */ "./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/AbstractTokenizer.js");\r\nclass BufferTokenizer extends AbstractTokenizer_1.AbstractTokenizer {\r\n    /**\r\n     * Construct BufferTokenizer\r\n     * @param uint8Array - Uint8Array to tokenize\r\n     * @param fileInfo - Pass additional file information to the tokenizer\r\n     */\r\n    constructor(uint8Array, fileInfo) {\r\n        super(fileInfo);\r\n        this.uint8Array = uint8Array;\r\n        this.fileInfo.size = this.fileInfo.size ? this.fileInfo.size : uint8Array.length;\r\n    }\r\n    /**\r\n     * Read buffer from tokenizer\r\n     * @param uint8Array - Uint8Array to tokenize\r\n     * @param options - Read behaviour options\r\n     * @returns {Promise<number>}\r\n     */\r\n    async readBuffer(uint8Array, options) {\r\n        if (options && options.position) {\r\n            if (options.position < this.position) {\r\n                throw new Error(\'`options.position` must be equal or greater than `tokenizer.position`\');\r\n            }\r\n            this.position = options.position;\r\n        }\r\n        const bytesRead = await this.peekBuffer(uint8Array, options);\r\n        this.position += bytesRead;\r\n        return bytesRead;\r\n    }\r\n    /**\r\n     * Peek (read ahead) buffer from tokenizer\r\n     * @param uint8Array\r\n     * @param options - Read behaviour options\r\n     * @returns {Promise<number>}\r\n     */\r\n    async peekBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        const bytes2read = Math.min(this.uint8Array.length - normOptions.position, normOptions.length);\r\n        if ((!normOptions.mayBeLess) && bytes2read < normOptions.length) {\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        }\r\n        else {\r\n            uint8Array.set(this.uint8Array.subarray(normOptions.position, normOptions.position + bytes2read), normOptions.offset);\r\n            return bytes2read;\r\n        }\r\n    }\r\n    async close() {\r\n        // empty\r\n    }\r\n}\r\nexports.BufferTokenizer = BufferTokenizer;\r\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/BufferTokenizer.js?')},"./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/ReadStreamTokenizer.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/ReadStreamTokenizer.js ***!
  \******************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\r\nObject.defineProperty(exports, "__esModule", ({ value: true }));\r\nexports.ReadStreamTokenizer = void 0;\r\nconst AbstractTokenizer_1 = __webpack_require__(/*! ./AbstractTokenizer */ "./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/AbstractTokenizer.js");\r\nconst peek_readable_1 = __webpack_require__(/*! peek-readable */ "./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/index.js");\r\nconst maxBufferSize = 256000;\r\nclass ReadStreamTokenizer extends AbstractTokenizer_1.AbstractTokenizer {\r\n    constructor(stream, fileInfo) {\r\n        super(fileInfo);\r\n        this.streamReader = new peek_readable_1.StreamReader(stream);\r\n    }\r\n    /**\r\n     * Get file information, an HTTP-client may implement this doing a HEAD request\r\n     * @return Promise with file information\r\n     */\r\n    async getFileInfo() {\r\n        return this.fileInfo;\r\n    }\r\n    /**\r\n     * Read buffer from tokenizer\r\n     * @param uint8Array - Target Uint8Array to fill with data read from the tokenizer-stream\r\n     * @param options - Read behaviour options\r\n     * @returns Promise with number of bytes read\r\n     */\r\n    async readBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        const skipBytes = normOptions.position - this.position;\r\n        if (skipBytes > 0) {\r\n            await this.ignore(skipBytes);\r\n            return this.readBuffer(uint8Array, options);\r\n        }\r\n        else if (skipBytes < 0) {\r\n            throw new Error(\'`options.position` must be equal or greater than `tokenizer.position`\');\r\n        }\r\n        if (normOptions.length === 0) {\r\n            return 0;\r\n        }\r\n        const bytesRead = await this.streamReader.read(uint8Array, normOptions.offset, normOptions.length);\r\n        this.position += bytesRead;\r\n        if ((!options || !options.mayBeLess) && bytesRead < normOptions.length) {\r\n            throw new peek_readable_1.EndOfStreamError();\r\n        }\r\n        return bytesRead;\r\n    }\r\n    /**\r\n     * Peek (read ahead) buffer from tokenizer\r\n     * @param uint8Array - Uint8Array (or Buffer) to write data to\r\n     * @param options - Read behaviour options\r\n     * @returns Promise with number of bytes peeked\r\n     */\r\n    async peekBuffer(uint8Array, options) {\r\n        const normOptions = this.normalizeOptions(uint8Array, options);\r\n        let bytesRead = 0;\r\n        if (normOptions.position) {\r\n            const skipBytes = normOptions.position - this.position;\r\n            if (skipBytes > 0) {\r\n                const skipBuffer = new Uint8Array(normOptions.length + skipBytes);\r\n                bytesRead = await this.peekBuffer(skipBuffer, { mayBeLess: normOptions.mayBeLess });\r\n                uint8Array.set(skipBuffer.subarray(skipBytes), normOptions.offset);\r\n                return bytesRead - skipBytes;\r\n            }\r\n            else if (skipBytes < 0) {\r\n                throw new Error(\'Cannot peek from a negative offset in a stream\');\r\n            }\r\n        }\r\n        if (normOptions.length > 0) {\r\n            try {\r\n                bytesRead = await this.streamReader.peek(uint8Array, normOptions.offset, normOptions.length);\r\n            }\r\n            catch (err) {\r\n                if (options && options.mayBeLess && err instanceof peek_readable_1.EndOfStreamError) {\r\n                    return 0;\r\n                }\r\n                throw err;\r\n            }\r\n            if ((!normOptions.mayBeLess) && bytesRead < normOptions.length) {\r\n                throw new peek_readable_1.EndOfStreamError();\r\n            }\r\n        }\r\n        return bytesRead;\r\n    }\r\n    async ignore(length) {\r\n        // debug(`ignore ${this.position}...${this.position + length - 1}`);\r\n        const bufSize = Math.min(maxBufferSize, length);\r\n        const buf = new Uint8Array(bufSize);\r\n        let totBytesRead = 0;\r\n        while (totBytesRead < length) {\r\n            const remaining = length - totBytesRead;\r\n            const bytesRead = await this.readBuffer(buf, { length: Math.min(bufSize, remaining) });\r\n            if (bytesRead < 0) {\r\n                return bytesRead;\r\n            }\r\n            totBytesRead += bytesRead;\r\n        }\r\n        return totBytesRead;\r\n    }\r\n}\r\nexports.ReadStreamTokenizer = ReadStreamTokenizer;\r\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/ReadStreamTokenizer.js?')},"./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/core.js":
/*!***************************************************************************!*\
  !*** ./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/core.js ***!
  \***************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('\r\nObject.defineProperty(exports, "__esModule", ({ value: true }));\r\nexports.fromBuffer = exports.fromStream = exports.EndOfStreamError = void 0;\r\nconst ReadStreamTokenizer_1 = __webpack_require__(/*! ./ReadStreamTokenizer */ "./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/ReadStreamTokenizer.js");\r\nconst BufferTokenizer_1 = __webpack_require__(/*! ./BufferTokenizer */ "./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/BufferTokenizer.js");\r\nvar peek_readable_1 = __webpack_require__(/*! peek-readable */ "./node_modules/.pnpm/peek-readable@4.1.0/node_modules/peek-readable/lib/index.js");\r\nObject.defineProperty(exports, "EndOfStreamError", ({ enumerable: true, get: function () { return peek_readable_1.EndOfStreamError; } }));\r\n/**\r\n * Construct ReadStreamTokenizer from given Stream.\r\n * Will set fileSize, if provided given Stream has set the .path property/\r\n * @param stream - Read from Node.js Stream.Readable\r\n * @param fileInfo - Pass the file information, like size and MIME-type of the corresponding stream.\r\n * @returns ReadStreamTokenizer\r\n */\r\nfunction fromStream(stream, fileInfo) {\r\n    fileInfo = fileInfo ? fileInfo : {};\r\n    return new ReadStreamTokenizer_1.ReadStreamTokenizer(stream, fileInfo);\r\n}\r\nexports.fromStream = fromStream;\r\n/**\r\n * Construct ReadStreamTokenizer from given Buffer.\r\n * @param uint8Array - Uint8Array to tokenize\r\n * @param fileInfo - Pass additional file information to the tokenizer\r\n * @returns BufferTokenizer\r\n */\r\nfunction fromBuffer(uint8Array, fileInfo) {\r\n    return new BufferTokenizer_1.BufferTokenizer(uint8Array, fileInfo);\r\n}\r\nexports.fromBuffer = fromBuffer;\r\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/strtok3@6.3.0/node_modules/strtok3/lib/core.js?')},"./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js":
/*!************************************************************************************!*\
  !*** ./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js ***!
  \************************************************************************************/function(__unused_webpack_module,exports,__webpack_require__){"use strict";eval('/* provided dependency */ var Buffer = __webpack_require__(/*! ./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js */ "./node_modules/.pnpm/buffer@6.0.3/node_modules/buffer/index.js")["Buffer"];\n\nObject.defineProperty(exports, "__esModule", ({ value: true }));\nexports.AnsiStringType = exports.StringType = exports.BufferType = exports.Uint8ArrayType = exports.IgnoreType = exports.Float80_LE = exports.Float80_BE = exports.Float64_LE = exports.Float64_BE = exports.Float32_LE = exports.Float32_BE = exports.Float16_LE = exports.Float16_BE = exports.INT64_BE = exports.UINT64_BE = exports.INT64_LE = exports.UINT64_LE = exports.INT32_LE = exports.INT32_BE = exports.INT24_BE = exports.INT24_LE = exports.INT16_LE = exports.INT16_BE = exports.INT8 = exports.UINT32_BE = exports.UINT32_LE = exports.UINT24_BE = exports.UINT24_LE = exports.UINT16_BE = exports.UINT16_LE = exports.UINT8 = void 0;\nconst ieee754 = __webpack_require__(/*! ieee754 */ "./node_modules/.pnpm/ieee754@1.2.1/node_modules/ieee754/index.js");\n// Primitive types\nfunction dv(array) {\n    return new DataView(array.buffer, array.byteOffset);\n}\n/**\n * 8-bit unsigned integer\n */\nexports.UINT8 = {\n    len: 1,\n    get(array, offset) {\n        return dv(array).getUint8(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setUint8(offset, value);\n        return offset + 1;\n    }\n};\n/**\n * 16-bit unsigned integer, Little Endian byte order\n */\nexports.UINT16_LE = {\n    len: 2,\n    get(array, offset) {\n        return dv(array).getUint16(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setUint16(offset, value, true);\n        return offset + 2;\n    }\n};\n/**\n * 16-bit unsigned integer, Big Endian byte order\n */\nexports.UINT16_BE = {\n    len: 2,\n    get(array, offset) {\n        return dv(array).getUint16(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setUint16(offset, value);\n        return offset + 2;\n    }\n};\n/**\n * 24-bit unsigned integer, Little Endian byte order\n */\nexports.UINT24_LE = {\n    len: 3,\n    get(array, offset) {\n        const dataView = dv(array);\n        return dataView.getUint8(offset) + (dataView.getUint16(offset + 1, true) << 8);\n    },\n    put(array, offset, value) {\n        const dataView = dv(array);\n        dataView.setUint8(offset, value & 0xff);\n        dataView.setUint16(offset + 1, value >> 8, true);\n        return offset + 3;\n    }\n};\n/**\n * 24-bit unsigned integer, Big Endian byte order\n */\nexports.UINT24_BE = {\n    len: 3,\n    get(array, offset) {\n        const dataView = dv(array);\n        return (dataView.getUint16(offset) << 8) + dataView.getUint8(offset + 2);\n    },\n    put(array, offset, value) {\n        const dataView = dv(array);\n        dataView.setUint16(offset, value >> 8);\n        dataView.setUint8(offset + 2, value & 0xff);\n        return offset + 3;\n    }\n};\n/**\n * 32-bit unsigned integer, Little Endian byte order\n */\nexports.UINT32_LE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getUint32(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setUint32(offset, value, true);\n        return offset + 4;\n    }\n};\n/**\n * 32-bit unsigned integer, Big Endian byte order\n */\nexports.UINT32_BE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getUint32(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setUint32(offset, value);\n        return offset + 4;\n    }\n};\n/**\n * 8-bit signed integer\n */\nexports.INT8 = {\n    len: 1,\n    get(array, offset) {\n        return dv(array).getInt8(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setInt8(offset, value);\n        return offset + 1;\n    }\n};\n/**\n * 16-bit signed integer, Big Endian byte order\n */\nexports.INT16_BE = {\n    len: 2,\n    get(array, offset) {\n        return dv(array).getInt16(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setInt16(offset, value);\n        return offset + 2;\n    }\n};\n/**\n * 16-bit signed integer, Little Endian byte order\n */\nexports.INT16_LE = {\n    len: 2,\n    get(array, offset) {\n        return dv(array).getInt16(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setInt16(offset, value, true);\n        return offset + 2;\n    }\n};\n/**\n * 24-bit signed integer, Little Endian byte order\n */\nexports.INT24_LE = {\n    len: 3,\n    get(array, offset) {\n        const unsigned = exports.UINT24_LE.get(array, offset);\n        return unsigned > 0x7fffff ? unsigned - 0x1000000 : unsigned;\n    },\n    put(array, offset, value) {\n        const dataView = dv(array);\n        dataView.setUint8(offset, value & 0xff);\n        dataView.setUint16(offset + 1, value >> 8, true);\n        return offset + 3;\n    }\n};\n/**\n * 24-bit signed integer, Big Endian byte order\n */\nexports.INT24_BE = {\n    len: 3,\n    get(array, offset) {\n        const unsigned = exports.UINT24_BE.get(array, offset);\n        return unsigned > 0x7fffff ? unsigned - 0x1000000 : unsigned;\n    },\n    put(array, offset, value) {\n        const dataView = dv(array);\n        dataView.setUint16(offset, value >> 8);\n        dataView.setUint8(offset + 2, value & 0xff);\n        return offset + 3;\n    }\n};\n/**\n * 32-bit signed integer, Big Endian byte order\n */\nexports.INT32_BE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getInt32(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setInt32(offset, value);\n        return offset + 4;\n    }\n};\n/**\n * 32-bit signed integer, Big Endian byte order\n */\nexports.INT32_LE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getInt32(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setInt32(offset, value, true);\n        return offset + 4;\n    }\n};\n/**\n * 64-bit unsigned integer, Little Endian byte order\n */\nexports.UINT64_LE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getBigUint64(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setBigUint64(offset, value, true);\n        return offset + 8;\n    }\n};\n/**\n * 64-bit signed integer, Little Endian byte order\n */\nexports.INT64_LE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getBigInt64(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setBigInt64(offset, value, true);\n        return offset + 8;\n    }\n};\n/**\n * 64-bit unsigned integer, Big Endian byte order\n */\nexports.UINT64_BE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getBigUint64(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setBigUint64(offset, value);\n        return offset + 8;\n    }\n};\n/**\n * 64-bit signed integer, Big Endian byte order\n */\nexports.INT64_BE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getBigInt64(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setBigInt64(offset, value);\n        return offset + 8;\n    }\n};\n/**\n * IEEE 754 16-bit (half precision) float, big endian\n */\nexports.Float16_BE = {\n    len: 2,\n    get(dataView, offset) {\n        return ieee754.read(dataView, offset, false, 10, this.len);\n    },\n    put(dataView, offset, value) {\n        ieee754.write(dataView, value, offset, false, 10, this.len);\n        return offset + this.len;\n    }\n};\n/**\n * IEEE 754 16-bit (half precision) float, little endian\n */\nexports.Float16_LE = {\n    len: 2,\n    get(array, offset) {\n        return ieee754.read(array, offset, true, 10, this.len);\n    },\n    put(array, offset, value) {\n        ieee754.write(array, value, offset, true, 10, this.len);\n        return offset + this.len;\n    }\n};\n/**\n * IEEE 754 32-bit (single precision) float, big endian\n */\nexports.Float32_BE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getFloat32(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setFloat32(offset, value);\n        return offset + 4;\n    }\n};\n/**\n * IEEE 754 32-bit (single precision) float, little endian\n */\nexports.Float32_LE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getFloat32(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setFloat32(offset, value, true);\n        return offset + 4;\n    }\n};\n/**\n * IEEE 754 64-bit (double precision) float, big endian\n */\nexports.Float64_BE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getFloat64(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setFloat64(offset, value);\n        return offset + 8;\n    }\n};\n/**\n * IEEE 754 64-bit (double precision) float, little endian\n */\nexports.Float64_LE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getFloat64(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setFloat64(offset, value, true);\n        return offset + 8;\n    }\n};\n/**\n * IEEE 754 80-bit (extended precision) float, big endian\n */\nexports.Float80_BE = {\n    len: 10,\n    get(array, offset) {\n        return ieee754.read(array, offset, false, 63, this.len);\n    },\n    put(array, offset, value) {\n        ieee754.write(array, value, offset, false, 63, this.len);\n        return offset + this.len;\n    }\n};\n/**\n * IEEE 754 80-bit (extended precision) float, little endian\n */\nexports.Float80_LE = {\n    len: 10,\n    get(array, offset) {\n        return ieee754.read(array, offset, true, 63, this.len);\n    },\n    put(array, offset, value) {\n        ieee754.write(array, value, offset, true, 63, this.len);\n        return offset + this.len;\n    }\n};\n/**\n * Ignore a given number of bytes\n */\nclass IgnoreType {\n    /**\n     * @param len number of bytes to ignore\n     */\n    constructor(len) {\n        this.len = len;\n    }\n    // ToDo: don\'t read, but skip data\n    get(array, off) {\n    }\n}\nexports.IgnoreType = IgnoreType;\nclass Uint8ArrayType {\n    constructor(len) {\n        this.len = len;\n    }\n    get(array, offset) {\n        return array.subarray(offset, offset + this.len);\n    }\n}\nexports.Uint8ArrayType = Uint8ArrayType;\nclass BufferType {\n    constructor(len) {\n        this.len = len;\n    }\n    get(uint8Array, off) {\n        return Buffer.from(uint8Array.subarray(off, off + this.len));\n    }\n}\nexports.BufferType = BufferType;\n/**\n * Consume a fixed number of bytes from the stream and return a string with a specified encoding.\n */\nclass StringType {\n    constructor(len, encoding) {\n        this.len = len;\n        this.encoding = encoding;\n    }\n    get(uint8Array, offset) {\n        return Buffer.from(uint8Array).toString(this.encoding, offset, offset + this.len);\n    }\n}\nexports.StringType = StringType;\n/**\n * ANSI Latin 1 String\n * Using windows-1252 / ISO 8859-1 decoding\n */\nclass AnsiStringType {\n    constructor(len) {\n        this.len = len;\n    }\n    static decode(buffer, offset, until) {\n        let str = \'\';\n        for (let i = offset; i < until; ++i) {\n            str += AnsiStringType.codePointToString(AnsiStringType.singleByteDecoder(buffer[i]));\n        }\n        return str;\n    }\n    static inRange(a, min, max) {\n        return min <= a && a <= max;\n    }\n    static codePointToString(cp) {\n        if (cp <= 0xFFFF) {\n            return String.fromCharCode(cp);\n        }\n        else {\n            cp -= 0x10000;\n            return String.fromCharCode((cp >> 10) + 0xD800, (cp & 0x3FF) + 0xDC00);\n        }\n    }\n    static singleByteDecoder(bite) {\n        if (AnsiStringType.inRange(bite, 0x00, 0x7F)) {\n            return bite;\n        }\n        const codePoint = AnsiStringType.windows1252[bite - 0x80];\n        if (codePoint === null) {\n            throw Error(\'invaliding encoding\');\n        }\n        return codePoint;\n    }\n    get(buffer, offset = 0) {\n        return AnsiStringType.decode(buffer, offset, offset + this.len);\n    }\n}\nexports.AnsiStringType = AnsiStringType;\nAnsiStringType.windows1252 = [8364, 129, 8218, 402, 8222, 8230, 8224, 8225, 710, 8240, 352,\n    8249, 338, 141, 381, 143, 144, 8216, 8217, 8220, 8221, 8226, 8211, 8212, 732,\n    8482, 353, 8250, 339, 157, 382, 376, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n    169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n    185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,\n    201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n    217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n    233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n    248, 249, 250, 251, 252, 253, 254, 255];\n\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/token-types@4.2.1/node_modules/token-types/lib/index.js?')},"./node_modules/.pnpm/vue-aplayer@1.6.1_vue@2.7.16/node_modules/vue-aplayer/dist/vue-aplayer.min.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/.pnpm/vue-aplayer@1.6.1_vue@2.7.16/node_modules/vue-aplayer/dist/vue-aplayer.min.js ***!
  \**********************************************************************************************************/function(module,__unused_webpack_exports,__webpack_require__){eval('!function(t,e){ true?module.exports=e(__webpack_require__(/*! vue */ "./node_modules/.pnpm/vue@2.7.16/node_modules/vue/dist/vue.esm.js"),function(){try{return __webpack_require__(/*! hls.js */ "./node_modules/.pnpm/hls.js@1.5.17/node_modules/hls.js/dist/hls.js")}catch(t){}}()):0}("undefined"!=typeof self?self:this,function(t,e){return function(t){function e(a){if(i[a])return i[a].exports;var r=i[a]={i:a,l:!1,exports:{}};return t[a].call(r.exports,r,r.exports,e),r.l=!0,r.exports}var i={};return e.m=t,e.c=i,e.d=function(t,i,a){e.o(t,i)||Object.defineProperty(t,i,{configurable:!1,enumerable:!0,get:a})},e.n=function(t){var i=t&&t.__esModule?function(){return t.default}:function(){return t};return e.d(i,"a",i),i},e.o=function(t,e){return Object.prototype.hasOwnProperty.call(t,e)},e.p="",e(e.s=15)}([function(t,e,i){"use strict";function a(t,e,i,a,r,n,o,s){t=t||{};var l=typeof t.default;"object"!==l&&"function"!==l||(t=t.default);var u="function"==typeof t?t.options:t;e&&(u.render=e,u.staticRenderFns=i,u._compiled=!0),a&&(u.functional=!0),n&&(u._scopeId=n);var c;if(o?(c=function(t){t=t||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext,t||"undefined"==typeof __VUE_SSR_CONTEXT__||(t=__VUE_SSR_CONTEXT__),r&&r.call(this,t),t&&t._registeredComponents&&t._registeredComponents.add(o)},u._ssrRegister=c):r&&(c=s?function(){r.call(this,this.$root.$options.shadowRoot)}:r),c)if(u.functional){u._injectStyles=c;var p=u.render;u.render=function(t,e){return c.call(e),p(t,e)}}else{var h=u.beforeCreate;u.beforeCreate=h?[].concat(h,c):[c]}return{exports:t,options:u}}e.a=a},function(t,e){function i(t,e){var i=t[1]||"",r=t[3];if(!r)return i;if(e&&"function"==typeof btoa){var n=a(r);return[i].concat(r.sources.map(function(t){return"/*# sourceURL="+r.sourceRoot+t+" */"})).concat([n]).join("\\n")}return[i].join("\\n")}function a(t){return"/*# sourceMappingURL=data:application/json;charset=utf-8;base64,"+btoa(unescape(encodeURIComponent(JSON.stringify(t))))+" */"}t.exports=function(t){var e=[];return e.toString=function(){return this.map(function(e){var a=i(e,t);return e[2]?"@media "+e[2]+"{"+a+"}":a}).join("")},e.i=function(t,i){"string"==typeof t&&(t=[[null,t,""]]);for(var a={},r=0;r<this.length;r++){var n=this[r][0];"number"==typeof n&&(a[n]=!0)}for(r=0;r<t.length;r++){var o=t[r];"number"==typeof o[0]&&a[o[0]]||(i&&!o[2]?o[2]=i:i&&(o[2]="("+o[2]+") and ("+i+")"),e.push(o))}},e}},function(t,e,i){"use strict";function a(t,e,i,a){v=i,m=a||{};var n=Object(u.a)(t,e);return r(n),function(e){for(var i=[],a=0;a<n.length;a++){var o=n[a],s=p[o.id];s.refs--,i.push(s)}e?(n=Object(u.a)(t,e),r(n)):n=[];for(var a=0;a<i.length;a++){var s=i[a];if(0===s.refs){for(var l=0;l<s.parts.length;l++)s.parts[l]();delete p[s.id]}}}}function r(t){for(var e=0;e<t.length;e++){var i=t[e],a=p[i.id];if(a){a.refs++;for(var r=0;r<a.parts.length;r++)a.parts[r](i.parts[r]);for(;r<i.parts.length;r++)a.parts.push(o(i.parts[r]));a.parts.length>i.parts.length&&(a.parts.length=i.parts.length)}else{for(var n=[],r=0;r<i.parts.length;r++)n.push(o(i.parts[r]));p[i.id]={id:i.id,refs:1,parts:n}}}}function n(){var t=document.createElement("style");return t.type="text/css",h.appendChild(t),t}function o(t){var e,i,a=document.querySelector("style["+g+\'~="\'+t.id+\'"]\');if(a){if(v)return y;a.parentNode.removeChild(a)}if(b){var r=f++;a=d||(d=n()),e=s.bind(null,a,r,!1),i=s.bind(null,a,r,!0)}else a=n(),e=l.bind(null,a),i=function(){a.parentNode.removeChild(a)};return e(t),function(a){if(a){if(a.css===t.css&&a.media===t.media&&a.sourceMap===t.sourceMap)return;e(t=a)}else i()}}function s(t,e,i,a){var r=i?"":a.css;if(t.styleSheet)t.styleSheet.cssText=x(e,r);else{var n=document.createTextNode(r),o=t.childNodes;o[e]&&t.removeChild(o[e]),o.length?t.insertBefore(n,o[e]):t.appendChild(n)}}function l(t,e){var i=e.css,a=e.media,r=e.sourceMap;if(a&&t.setAttribute("media",a),m.ssrId&&t.setAttribute(g,e.id),r&&(i+="\\n/*# sourceURL="+r.sources[0]+" */",i+="\\n/*# sourceMappingURL=data:application/json;base64,"+btoa(unescape(encodeURIComponent(JSON.stringify(r))))+" */"),t.styleSheet)t.styleSheet.cssText=i;else{for(;t.firstChild;)t.removeChild(t.firstChild);t.appendChild(document.createTextNode(i))}}Object.defineProperty(e,"__esModule",{value:!0}),e.default=a;var u=i(18),c="undefined"!=typeof document;if("undefined"!=typeof DEBUG&&DEBUG&&!c)throw new Error("vue-style-loader cannot be used in a non-browser environment. Use { target: \'node\' } in your Webpack config to indicate a server-rendering environment.");var p={},h=c&&(document.head||document.getElementsByTagName("head")[0]),d=null,f=0,v=!1,y=function(){},m=null,g="data-vue-ssr-id",b="undefined"!=typeof navigator&&/msie [6-9]\\b/.test(navigator.userAgent.toLowerCase()),x=function(){var t=[];return function(e,i){return t[e]=i,t.filter(Boolean).join("\\n")}}()},function(t,e,i){"use strict";function a(t){if(t){t=t.replace(/([^\\]^\\n])\\[/g,function(t,e){return e+"\\n["});for(var e=t.split("\\n"),i=[],a=e.length,r=0;r<a;r++){var n=e[r].match(/\\[(\\d{2}):(\\d{2})(\\.(\\d{2,3}))?]/g),o=e[r].replace(/.*\\[(\\d{2}):(\\d{2})(\\.(\\d{2,3}))?]/g,"").replace(/<(\\d{2}):(\\d{2})(\\.(\\d{2,3}))?>/g,"").replace(/^\\s+|\\s+$/g,"");if(n)for(var s=n.length,l=0;l<s;l++){var u=/\\[(\\d{2}):(\\d{2})(\\.(\\d{2,3}))?]/.exec(n[l]),c=60*u[1],p=parseInt(u[2]),h=u[4]?parseInt(u[4])/(2===(u[4]+"").length?100:1e3):0,d=c+p+h;i.push([d,o])}}return i.sort(function(t,e){return t[0]-e[0]}),i}return[]}function r(t,e){if(t===e)return 0;var i=t.split(".").map(Number),a=u(i,3),r=a[0],n=a[1],o=a[2],s=e.split(".").map(Number),l=u(s,3),c=l[0],p=l[1],h=l[2];if(r>c)return 1;if(r===c){if(n>p)return 1;if(n===p&&o>h)return 1}return-1}function n(t){return console.warn("[Vue-APlayer] "+t)}function o(t,e,i){return n("\'"+t+"\' is deprecated since v"+e+", and will be removed in future releases, use \'"+i+"\' instead")}function s(t){for(var e=t.offsetLeft,i=t.offsetParent,a=void 0;null!==i;)e+=i.offsetLeft,i=i.offsetParent;return a=document.body.scrollLeft+document.documentElement.scrollLeft,e-a}function l(t){for(var e=t.offsetTop,i=t.offsetParent,a=void 0;null!==i;)e+=i.offsetTop,i=i.offsetParent;return a=document.body.scrollTop+document.documentElement.scrollTop,e-a}e.d=a,e.e=r,e.f=n,e.a=o,e.b=s,e.c=l;var u=function(){function t(t,e){var i=[],a=!0,r=!1,n=void 0;try{for(var o,s=t[Symbol.iterator]();!(a=(o=s.next()).done)&&(i.push(o.value),!e||i.length!==e);a=!0);}catch(t){r=!0,n=t}finally{try{!a&&s.return&&s.return()}finally{if(r)throw n}}return i}return function(e,i){if(Array.isArray(e))return e;if(Symbol.iterator in Object(e))return t(e,i);throw new TypeError("Invalid attempt to destructure non-iterable instance")}}()},function(t,e,i){"use strict";function a(t){i(25)}var r=i(7),n=i(44),o=i(0),s=a,l=Object(o.a)(r.a,n.a,n.b,!1,s,null,null);e.a=l.exports},function(t,e,i){"use strict";function a(t){if(Array.isArray(t)){for(var e=0,i=Array(t.length);e<t.length;e++)i[e]=t[e];return i}return Array.from(t)}var r=i(19),n=i.n(r),o=i(20),s=i(46),l=i(50),u=i(62),c=i(3),p=function(){function t(t,e){var i=[],a=!0,r=!1,n=void 0;try{for(var o,s=t[Symbol.iterator]();!(a=(o=s.next()).done)&&(i.push(o.value),!e||i.length!==e);a=!0);}catch(t){r=!0,n=t}finally{try{!a&&s.return&&s.return()}finally{if(r)throw n}}return i}return function(e,i){if(Array.isArray(e))return e;if(Symbol.iterator in Object(e))return t(e,i);throw new TypeError("Invalid attempt to destructure non-iterable instance")}}(),h=!1,d=Object(c.e)(n.a.version,"2.3.0")>=0,f={},v=null,y={NONE:"none",MUSIC:"music",LIST:"list",NO_REPEAT:"no-repeat",REPEAT_ONE:"repeat-one",REPEAT_ALL:"repeat-all"},m={name:"APlayer",disableVersionBadge:!1,components:{Thumbnail:o.a,Controls:l.a,MusicList:s.a,Lyrics:u.a},props:{music:{type:Object,required:!0,validator:function(t){return t.url&&Object(c.a)("music.url","1.4.0","music.src"),t.author&&Object(c.a)("music.author","1.4.1","music.artist"),t.src||t.url}},list:{type:Array,default:function(){return[]}},mini:{type:Boolean,default:!1},showLrc:{type:Boolean,default:!1},mutex:{type:Boolean,default:!0},theme:{type:String,default:"#41b883"},listMaxHeight:String,listFolded:{type:Boolean,default:!1},float:{type:Boolean,default:!1},autoplay:{type:Boolean,default:!1},controls:{type:Boolean,default:!1},muted:{type:Boolean,default:!1},preload:String,volume:{type:Number,default:.8,validator:function(t){return t>=0&&t<=1}},shuffle:{type:Boolean,default:!1},repeat:{type:String,default:y.NO_REPEAT},listmaxheight:{type:String,validator:function(t){return t&&Object(c.a)("listmaxheight","1.1.2","listMaxHeight"),!0}},narrow:{type:Boolean,default:!1,validator:function(t){return t&&Object(c.a)("narrow","1.1.2","mini"),!0}},showlrc:{type:Boolean,default:!1,validator:function(t){return t&&Object(c.a)("showlrc","1.2.2","showLrc"),!0}}},data:function(){return{internalMusic:this.music,isPlaying:!1,isSeeking:!1,wasPlayingBeforeSeeking:!1,isMobile:/mobile/i.test(window.navigator.userAgent),playStat:{duration:0,loadedTime:0,playedTime:0},showList:!this.listFolded,audioPlayPromise:Promise.resolve(),floatOriginX:0,floatOriginY:0,floatOffsetLeft:0,floatOffsetTop:0,selfAdaptingTheme:null,internalMuted:this.muted,internalVolume:this.volume,isLoading:!1,internalShuffle:this.shuffle,internalRepeat:this.repeat,shuffledList:[]}},computed:{audio:function(){return this.$refs.audio},currentMusic:{get:function(){return this.internalMusic},set:function(t){d&&this.$emit("update:music",t),this.internalMusic=t}},isMiniMode:function(){return this.mini||this.narrow},shouldShowLrc:function(){return this.showLrc||this.showlrc},currentTheme:function(){return this.selfAdaptingTheme||this.currentMusic.theme||this.theme},isFloatMode:function(){return this.float&&!this.isMobile},shouldAutoplay:function(){return!this.isMobile&&this.autoplay},musicList:function(){return this.list},shouldShowNativeControls:function(){return!1},floatStyleObj:function(){return{transform:"translate("+this.floatOffsetLeft+"px, "+this.floatOffsetTop+"px)",webkitTransform:"translate("+this.floatOffsetLeft+"px, "+this.floatOffsetTop+"px)"}},currentPicStyleObj:function(){return this.currentMusic&&this.currentMusic.pic?{backgroundImage:"url("+this.currentMusic.pic+")"}:{}},loadProgress:function(){return 0===this.playStat.duration?0:this.playStat.loadedTime/this.playStat.duration},playProgress:function(){return 0===this.playStat.duration?0:this.playStat.playedTime/this.playStat.duration},playIndex:{get:function(){return this.shuffledList.indexOf(this.currentMusic)},set:function(t){this.currentMusic=this.shuffledList[t%this.shuffledList.length]}},shouldRepeat:function(){return this.repeatMode!==y.NO_REPEAT},isAudioMuted:{get:function(){return this.internalMuted},set:function(t){d&&this.$emit("update:muted",t),this.internalMuted=t}},audioVolume:{get:function(){return this.internalVolume},set:function(t){d&&this.$emit("update:volume",t),this.internalVolume=t}},shouldShuffle:{get:function(){return this.internalShuffle},set:function(t){d&&this.$emit("update:shuffle",t),this.internalShuffle=t}},repeatMode:{get:function(){switch(this.internalRepeat){case y.NONE:case y.NO_REPEAT:return y.NO_REPEAT;case y.MUSIC:case y.REPEAT_ONE:return y.REPEAT_ONE;default:return y.REPEAT_ALL}},set:function(t){d&&this.$emit("update:repeat",t),this.internalRepeat=t}}},methods:{onDragBegin:function(){this.floatOriginX=this.floatOffsetLeft,this.floatOriginY=this.floatOffsetTop},onDragAround:function(t){var e=t.offsetLeft,i=t.offsetTop;this.floatOffsetLeft=this.floatOriginX+e,this.floatOffsetTop=this.floatOriginY+i},setNextMode:function(){this.repeatMode===y.REPEAT_ALL?this.repeatMode=y.REPEAT_ONE:this.repeatMode===y.REPEAT_ONE?this.repeatMode=y.NO_REPEAT:this.repeatMode=y.REPEAT_ALL},thenPlay:function(){var t=this;this.$nextTick(function(){t.play()})},toggle:function(){this.audio.paused?this.play():this.pause()},play:function(){var t=this;this.mutex&&(v&&v!==this&&v.pause(),v=this);var e=this.audio.play();if(e)return this.audioPlayPromise=new Promise(function(i,a){t.rejectPlayPromise=a,e.then(function(e){t.rejectPlayPromise=null,i(e)}).catch(c.f)})},pause:function(){var t=this;this.audioPlayPromise.then(function(){t.audio.pause()}).catch(function(){t.audio.pause()}),this.rejectPlayPromise&&(this.rejectPlayPromise(),this.rejectPlayPromise=null)},onProgressDragBegin:function(t){this.wasPlayingBeforeSeeking=this.isPlaying,this.pause(),this.isSeeking=!0,isNaN(this.audio.duration)||(this.audio.currentTime=this.audio.duration*t)},onProgressDragging:function(t){isNaN(this.audio.duration)?this.playStat.playedTime=0:this.audio.currentTime=this.audio.duration*t},onProgressDragEnd:function(t){this.isSeeking=!1,this.wasPlayingBeforeSeeking&&this.thenPlay()},toggleMute:function(){this.setAudioMuted(!this.audio.muted)},setAudioMuted:function(t){this.audio.muted=t},setAudioVolume:function(t){this.audio.volume=t,t>0&&this.setAudioMuted(!1)},getShuffledList:function(){if(!this.list.length)return[this.internalMusic];var t=[].concat(a(this.list));if(!this.internalShuffle||t.length<=1)return t;var e=t.indexOf(this.internalMusic);if(2===t.length&&-1!==e)return 0===e?t:[this.internalMusic,t[0]];for(var i=t.length-1;i>0;i--){var r=Math.floor(Math.random()*(i+1)),n=t[i];t[i]=t[r],t[r]=n}if(-1!==e&&0!==(e=t.indexOf(this.internalMusic))){var o=[t[e],t[0]];t[0]=o[0],t[e]=o[1]}return t},onSelectSong:function(t){this.currentMusic===t?this.toggle():(this.currentMusic=t,this.thenPlay())},onAudioPlay:function(){this.isPlaying=!0},onAudioPause:function(){this.isPlaying=!1},onAudioWaiting:function(){this.isLoading=!0},onAudioCanplay:function(){this.isLoading=!1},onAudioDurationChange:function(){1!==this.audio.duration&&(this.playStat.duration=this.audio.duration)},onAudioProgress:function(){this.audio.buffered.length?this.playStat.loadedTime=this.audio.buffered.end(this.audio.buffered.length-1):this.playStat.loadedTime=0},onAudioTimeUpdate:function(){this.playStat.playedTime=this.audio.currentTime},onAudioSeeking:function(){this.playStat.playedTime=this.audio.currentTime},onAudioSeeked:function(){this.playStat.playedTime=this.audio.currentTime},onAudioVolumeChange:function(){this.audioVolume=this.audio.volume,this.isAudioMuted=this.audio.muted},onAudioEnded:function(){this.repeatMode===y.REPEAT_ALL?(this.shouldShuffle&&this.playIndex===this.shuffledList.length-1&&(this.shuffledList=this.getShuffledList()),this.playIndex++,this.thenPlay()):this.repeatMode===y.REPEAT_ONE?this.thenPlay():(this.playIndex++,0!==this.playIndex?this.thenPlay():1===this.shuffledList.length&&(this.audio.currentTime=0))},initAudio:function(){var t=this;this.audio.controls=this.shouldShowNativeControls,this.audio.muted=this.muted,this.audio.preload=this.preload,this.audio.volume=this.volume,["abort","canplay","canplaythrough","durationchange","emptied","encrypted","ended","error","interruptbegin","interruptend","loadeddata","loadedmetadata","loadstart","mozaudioavailable","pause","play","playing","progress","ratechange","seeked","seeking","stalled","suspend","timeupdate","volumechange","waiting"].forEach(function(e){t.audio.addEventListener(e,function(i){return t.$emit(e,i)})}),this.audio.addEventListener("play",this.onAudioPlay),this.audio.addEventListener("pause",this.onAudioPause),this.audio.addEventListener("abort",this.onAudioPause),this.audio.addEventListener("waiting",this.onAudioWaiting),this.audio.addEventListener("canplay",this.onAudioCanplay),this.audio.addEventListener("progress",this.onAudioProgress),this.audio.addEventListener("durationchange",this.onAudioDurationChange),this.audio.addEventListener("seeking",this.onAudioSeeking),this.audio.addEventListener("seeked",this.onAudioSeeked),this.audio.addEventListener("timeupdate",this.onAudioTimeUpdate),this.audio.addEventListener("volumechange",this.onAudioVolumeChange),this.audio.addEventListener("ended",this.onAudioEnded),this.currentMusic&&(this.audio.src=this.currentMusic.src||this.currentMusic.url)},setSelfAdaptingTheme:function(){var t=this;if("pic"===(this.currentMusic.theme||this.theme)){var e=this.currentMusic.pic;if(f[e])this.selfAdaptingTheme=f[e];else try{(new ColorThief).getColorAsync(e,function(i){var a=p(i,3),r=a[0],n=a[1],o=a[2];f[e]="rgb("+r+", "+n+", "+o+")",t.selfAdaptingTheme="rgb("+r+", "+n+", "+o+")"})}catch(t){Object(c.f)("color-thief is required to support self-adapting theme")}}else this.selfAdaptingTheme=null}},watch:{music:function(t){this.internalMusic=t},currentMusic:{handler:function(t){this.setSelfAdaptingTheme();var e=t.src||t.url;if(/\\.m3u8(?=(#|\\?|$))/.test(e))if(this.audio.canPlayType("application/x-mpegURL")||this.audio.canPlayType("application/vnd.apple.mpegURL"))this.audio.src=e;else try{var a=i(66);a.isSupported()?(this.hls||(this.hls=new a),this.hls.loadSource(e),this.hls.attachMedia(this.audio)):(Object(c.f)("HLS is not supported on your browser"),this.audio.src=e)}catch(t){Object(c.f)("hls.js is required to support m3u8"),this.audio.src=e}else this.audio.src=e}},shouldShowNativeControls:function(t){this.audio.controls=t},isAudioMuted:function(t){this.audio.muted=t},preload:function(t){this.audio.preload=t},audioVolume:function(t){this.audio.volume=t},muted:function(t){this.internalMuted=t},volume:function(t){this.internalVolume=t},shuffle:function(t){this.internalShuffle=t},repeat:function(t){this.internalRepeat=t}},beforeCreate:function(){m.disableVersionBadge||h||(console.log("\\n\\n %c Vue-APlayer 1.6.1 %c vue-aplayer.js.org \\n","color: #fff; background:#41b883; padding:5px 0;","color: #fff; background: #35495e; padding:5px 0;"),h=!0)},created:function(){this.shuffledList=this.getShuffledList()},mounted:function(){this.initAudio(),this.setSelfAdaptingTheme(),this.autoplay&&this.play()},beforeDestroy:function(){v===this&&(v=null),this.hls&&this.hls.destroy()}};e.a=m},function(t,e,i){"use strict";var a=i(4);e.a={components:{IconButton:a.a},props:{pic:String,theme:String,playing:{type:Boolean,default:!1},enableDrag:{type:Boolean,default:!1}},data:function(){return{hasMovedSinceMouseDown:!1,dragStartX:0,dragStartY:0}},computed:{currentPicStyleObj:function(){return this.pic?{backgroundImage:"url("+this.pic+")",backgroundColor:this.theme}:{}}},methods:{onDragBegin:function(t){this.enableDrag&&(this.hasMovedSinceMouseDown=!1,this.$emit("dragbegin"),this.dragStartX=t.clientX,this.dragStartY=t.clientY,document.addEventListener("mousemove",this.onDocumentMouseMove),document.addEventListener("mouseup",this.onDocumentMouseUp))},onDocumentMouseMove:function(t){this.hasMovedSinceMouseDown=!0,this.$emit("dragging",{offsetLeft:t.clientX-this.dragStartX,offsetTop:t.clientY-this.dragStartY})},onDocumentMouseUp:function(t){document.removeEventListener("mouseup",this.onDocumentMouseUp),document.removeEventListener("mousemove",this.onDocumentMouseMove),this.$emit("dragend")},onClick:function(){this.hasMovedSinceMouseDown||this.$emit("toggleplay")}}}},function(t,e,i){"use strict";var a=i(8);e.a={components:{Icon:a.a},props:["icon"]}},function(t,e,i){"use strict";var a=i(9),r=i(43),n=i(0),o=Object(n.a)(a.a,r.a,r.b,!1,null,null,null);e.a=o.exports},function(t,e,i){"use strict";var a=function(){function t(t,e){var i=[],a=!0,r=!1,n=void 0;try{for(var o,s=t[Symbol.iterator]();!(a=(o=s.next()).done)&&(i.push(o.value),!e||i.length!==e);a=!0);}catch(t){r=!0,n=t}finally{try{!a&&s.return&&s.return()}finally{if(r)throw n}}return i}return function(e,i){if(Array.isArray(e))return e;if(Symbol.iterator in Object(e))return t(e,i);throw new TypeError("Invalid attempt to destructure non-iterable instance")}}(),r=i(27),n=r.keys().reduce(function(t,e){var i=r(e),n=i.match(/^<svg.+?viewBox="(.+?)".*><path.+?d="(.+?)".*><\\/path><\\/svg>$/),o=a(n,3),s=(o[0],o[1]),l=o[2];return t[e.match(/^.*\\/(.+?)\\.svg$/)[1]]={viewBox:s,d:l},t},{});e.a={props:["type"],computed:{svg:function(){this.type;return"prev"!==this.type&&"next"!==this.type||"skip",n[this.type]||{}},style:function(){if("next"===this.type)return{transform:"rotate(180deg)"}}}}},function(t,e,i){"use strict";e.a={props:{show:{type:Boolean,default:!0},currentMusic:Object,musicList:{type:Array,default:function(){return[]}},playIndex:{type:Number,default:0},theme:String,listmaxheight:String},computed:{listHeightStyle:function(){return{height:33*this.musicList.length-1+"px",maxHeight:this.listmaxheight||""}}}}},function(t,e,i){"use strict";var a=i(4),r=i(53),n=i(57);e.a={components:{IconButton:a.a,VProgress:r.a,Volume:n.a},props:["shuffle","repeat","stat","theme","volume","muted"],computed:{loadProgress:function(){return 0===this.stat.duration?0:this.stat.loadedTime/this.stat.duration},playProgress:function(){return 0===this.stat.duration?0:this.stat.playedTime/this.stat.duration}},methods:{secondToTime:function(t){if(isNaN(t))return"00:00";var e=function(t){return t<10?"0"+t:""+t},i=Math.trunc(t/60),a=Math.trunc(t-60*i),r=Math.trunc(i/60),n=Math.trunc(t/60-60*Math.trunc(t/60/60));return t>=3600?e(r)+":"+e(n)+":"+e(a):e(i)+":"+e(a)}}}},function(t,e,i){"use strict";var a=i(3),r=i(8);e.a={components:{Icon:r.a},props:["loadProgress","playProgress","theme"],data:function(){return{thumbHovered:!1}},methods:{onThumbMouseDown:function(t){var e=this.$refs.barWrap.clientWidth,i=(t.clientX-Object(a.b)(this.$refs.barWrap))/e;i=i>0?i:0,i=i<1?i:1,this.$emit("dragbegin",i),document.addEventListener("mousemove",this.onDocumentMouseMove),document.addEventListener("mouseup",this.onDocumentMouseUp)},onDocumentMouseMove:function(t){var e=this.$refs.barWrap.clientWidth,i=(t.clientX-Object(a.b)(this.$refs.barWrap))/e;i=i>0?i:0,i=i<1?i:1,this.$emit("dragging",i)},onDocumentMouseUp:function(t){document.removeEventListener("mouseup",this.onDocumentMouseUp),document.removeEventListener("mousemove",this.onDocumentMouseMove);var e=this.$refs.barWrap.clientWidth,i=(t.clientX-Object(a.b)(this.$refs.barWrap))/e;i=i>0?i:0,i=i<1?i:1,this.$emit("dragend",i)},onThumbTouchStart:function(t){var e=this.$refs.barWrap.clientWidth,i=(t.clientX-Object(a.b)(this.$refs.barWrap))/e;i=i>0?i:0,i=i<1?i:1,this.$emit("dragbegin",i),document.addEventListener("touchmove",this.onDocumentTouchMove),document.addEventListener("touchend",this.onDocumentTouchEnd)},onDocumentTouchMove:function(t){var e=t.changedTouches[0],i=this.$refs.barWrap.clientWidth,r=(e.clientX-Object(a.b)(this.$refs.barWrap))/i;r=r>0?r:0,r=r<1?r:1,this.$emit("dragging",r)},onDocumentTouchEnd:function(t){document.removeEventListener("touchend",this.onDocumentTouchEnd),document.removeEventListener("touchmove",this.onDocumentTouchMove);var e=t.changedTouches[0],i=this.$refs.barWrap.clientWidth,r=(e.clientX-Object(a.b)(this.$refs.barWrap))/i;r=r>0?r:0,r=r<1?r:1,this.$emit("dragend",r)}}}},function(t,e,i){"use strict";var a=i(4),r=i(3);e.a={components:{IconButton:a.a},props:["volume","muted","theme"],computed:{volumeIcon:function(){return this.muted||this.volume<=0?"volume-off":this.volume>=1?"volume-up":"volume-down"}},methods:{adjustVolume:function(t){var e=(40-t.clientY+Object(r.c)(this.$refs.bar))/40;e=e>0?e:0,e=e<1?e:1,this.$emit("setvolume",e)},onBarMouseDown:function(){document.addEventListener("mousemove",this.onDocumentMouseMove),document.addEventListener("mouseup",this.onDocumentMouseUp)},onDocumentMouseMove:function(t){var e=(40-t.clientY+Object(r.c)(this.$refs.bar))/40;e=e>0?e:0,e=e<1?e:1,this.$emit("setvolume",e)},onDocumentMouseUp:function(t){document.removeEventListener("mouseup",this.onDocumentMouseUp),document.removeEventListener("mousemove",this.onDocumentMouseMove);var e=(40-t.clientY+Object(r.c)(this.$refs.bar))/40;e=e>0?e:0,e=e<1?e:1,this.$emit("setvolume",e)}}}},function(t,e,i){"use strict";var a=i(3);e.a={props:{currentMusic:{type:Object,required:!0},playStat:{type:Object,required:!0}},data:function(){return{displayLrc:"",currentLineIndex:0}},computed:{lrcLines:function(){return Object(a.d)(this.displayLrc)},currentLine:function(){return this.currentLineIndex>this.lrcLines.length-1?null:this.lrcLines[this.currentLineIndex]},transformStyle:function(){return{transform:"translateY("+16*-this.currentLineIndex+"px)",webkitTransform:"translateY("+16*-this.currentLineIndex+"px)"}}},methods:{applyLrc:function(t){/^https?:\\/\\//.test(t)?this.fetchLrc(t):this.displayLrc=t},fetchLrc:function(t){var e=this;fetch(t).then(function(t){return t.text()}).then(function(t){e.displayLrc=t})},hideLrc:function(){this.displayLrc=""}},watch:{currentMusic:{immediate:!0,handler:function(t){this.currentLineIndex=0,t.lrc?this.applyLrc(t.lrc):this.hideLrc()}},"playStat.playedTime":function(t){for(var e=0;e<this.lrcLines.length;e++){var i=this.lrcLines[e],a=this.lrcLines[e+1];t>=i[0]&&(!a||t<a[0])&&(this.currentLineIndex=e)}}}}},function(t,e,i){"use strict";function a(t){i(16)}Object.defineProperty(e,"__esModule",{value:!0});var r=i(5),n=i(67),o=i(0),s=a,l=Object(o.a)(r.a,n.a,n.b,!1,s,null,null);e.default=l.exports},function(t,e,i){var a=i(17);"string"==typeof a&&(a=[[t.i,a,""]]),a.locals&&(t.exports=a.locals);var r=i(2).default;r("48028a76",a,!0,{})},function(t,e,i){e=t.exports=i(1)(!1),e.push([t.i,".aplayer{font-family:Arial,Helvetica,sans-serif;color:#000;background-color:#fff;margin:5px;-webkit-box-shadow:0 2px 2px 0 rgba(0,0,0,.07),0 1px 5px 0 rgba(0,0,0,.1);box-shadow:0 2px 2px 0 rgba(0,0,0,.07),0 1px 5px 0 rgba(0,0,0,.1);border-radius:2px;overflow:hidden;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;line-height:normal;position:relative}.aplayer *{-webkit-box-sizing:content-box;box-sizing:content-box}.aplayer .aplayer-lrc-content{display:none}.aplayer .aplayer-body{display:-webkit-box;display:-ms-flexbox;display:flex;position:relative}.aplayer .aplayer-body .aplayer-info{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;text-align:start;padding:14px 7px 0 10px;height:66px;-webkit-box-sizing:border-box;box-sizing:border-box;overflow:hidden}.aplayer .aplayer-body .aplayer-info .aplayer-music{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;overflow:hidden;white-space:nowrap;text-overflow:ellipsis;margin-left:5px;-webkit-user-select:text;-moz-user-select:text;-ms-user-select:text;user-select:text;cursor:default;padding-bottom:2px}.aplayer .aplayer-body .aplayer-info .aplayer-music .aplayer-title{font-size:14px}.aplayer .aplayer-body .aplayer-info .aplayer-music .aplayer-author{font-size:12px;color:#666}.aplayer .aplayer-body .aplayer-info .aplayer-lrc{z-index:0}.aplayer audio[controls]{display:block;width:100%}.aplayer.aplayer-narrow{width:66px}.aplayer.aplayer-withlrc .aplayer-body .aplayer-pic{height:90px;width:90px}.aplayer.aplayer-withlrc .aplayer-body .aplayer-info{height:90px;padding:10px 7px 0}.aplayer.aplayer-withlist .aplayer-body .aplayer-info{border-bottom:1px solid #e9e9e9}.aplayer.aplayer-withlist .aplayer-body .aplayer-controller .aplayer-time .aplayer-icon.aplayer-icon-menu{display:block}.aplayer.aplayer-float{z-index:1}@-webkit-keyframes aplayer-roll{0%{left:0}to{left:-100%}}@keyframes aplayer-roll{0%{left:0}to{left:-100%}}",""])},function(t,e,i){"use strict";function a(t,e){for(var i=[],a={},r=0;r<e.length;r++){var n=e[r],o=n[0],s=n[1],l=n[2],u=n[3],c={id:t+":"+r,css:s,media:l,sourceMap:u};a[o]?a[o].parts.push(c):i.push(a[o]={id:o,parts:[c]})}return i}e.a=a},function(e,i){e.exports=t},function(t,e,i){"use strict";function a(t){i(21)}var r=i(6),n=i(45),o=i(0),s=a,l=Object(o.a)(r.a,n.a,n.b,!1,s,null,null);e.a=l.exports},function(t,e,i){var a=i(22);"string"==typeof a&&(a=[[t.i,a,""]]),a.locals&&(t.exports=a.locals);var r=i(2).default;r("082b31c5",a,!0,{})},function(t,e,i){var a=i(23);e=t.exports=i(1)(!1),e.push([t.i,".aplayer-float .aplayer-pic:active{cursor:move}.aplayer-pic{-ms-flex-negative:0;flex-shrink:0;position:relative;height:66px;width:66px;background-image:url("+a(i(24))+");background-size:cover;-webkit-transition:all .3s ease;transition:all .3s ease;cursor:pointer}.aplayer-pic:hover .aplayer-button{opacity:1}.aplayer-pic .aplayer-button{position:absolute;border-radius:50%;opacity:.8;text-shadow:0 1px 1px rgba(0,0,0,.2);-webkit-box-shadow:0 1px 1px rgba(0,0,0,.2);box-shadow:0 1px 1px rgba(0,0,0,.2);background:rgba(0,0,0,.2);-webkit-transition:all .1s ease;transition:all .1s ease}.aplayer-pic .aplayer-button .aplayer-fill{fill:#fff}.aplayer-pic .aplayer-play{width:26px;height:26px;border:2px solid #fff;bottom:50%;right:50%;margin:0 -15px -15px 0}.aplayer-pic .aplayer-play .aplayer-icon-play{position:absolute;top:3px;left:4px;height:20px;width:20px}.aplayer-pic .aplayer-pause{width:16px;height:16px;border:2px solid #fff;bottom:4px;right:4px}.aplayer-pic .aplayer-pause .aplayer-icon-pause{position:absolute;top:2px;left:2px;height:12px;width:12px}",""])},function(t,e){t.exports=function(t){return"string"!=typeof t?t:(/^[\'"].*[\'"]$/.test(t)&&(t=t.slice(1,-1)),/["\'() \\t\\n]/.test(t)?\'"\'+t.replace(/"/g,\'\\\\"\').replace(/\\n/g,"\\\\n")+\'"\':t)}},function(t,e){t.exports="data:image/jpeg;base64,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"},function(t,e,i){var a=i(26);"string"==typeof a&&(a=[[t.i,a,""]]),a.locals&&(t.exports=a.locals);var r=i(2).default;r("a4518b4e",a,!0,{})},function(t,e,i){e=t.exports=i(1)(!1),e.push([t.i,".aplayer-icon{width:15px;height:15px;border:none;background-color:transparent;outline:none;cursor:pointer;opacity:.8;vertical-align:middle;padding:0;font-size:12px;margin:0;display:inline}.aplayer-icon:hover{opacity:1}.aplayer-icon .aplayer-fill{-webkit-transition:all .2s ease-in-out;transition:all .2s ease-in-out}",""])},function(t,e,i){function a(t){return i(r(t))}function r(t){var e=n[t];if(!(e+1))throw new Error("Cannot find module \'"+t+"\'.");return e}var n={"./loading.svg":28,"./lrc.svg":29,"./menu.svg":30,"./no-repeat.svg":31,"./pause.svg":32,"./play.svg":33,"./repeat-all-legacy.svg":34,"./repeat-all.svg":35,"./repeat-one-legacy.svg":36,"./repeat-one.svg":37,"./shuffle.svg":38,"./skip.svg":39,"./volume-down.svg":40,"./volume-off.svg":41,"./volume-up.svg":42};a.keys=function(){return Object.keys(n)},a.resolve=r,t.exports=a,a.id=27},function(t,e){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="0 0 32 32"><path d="M4 16c0-6.6 5.4-12 12-12s12 5.4 12 12c0 1.2-0.8 2-2 2s-2-0.8-2-2c0-4.4-3.6-8-8-8s-8 3.6-8 8 3.6 8 8 8c1.2 0 2 0.8 2 2s-0.8 2-2 2c-6.6 0-12-5.4-12-12z"></path></svg>\'},function(t,e){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="0 0 32 32"><path d="M26.667 5.333h-21.333c-0 0-0.001 0-0.001 0-1.472 0-2.666 1.194-2.666 2.666 0 0 0 0.001 0 0.001v-0 16c0 0 0 0.001 0 0.001 0 1.472 1.194 2.666 2.666 2.666 0 0 0.001 0 0.001 0h21.333c0 0 0.001 0 0.001 0 1.472 0 2.666-1.194 2.666-2.666 0-0 0-0.001 0-0.001v0-16c0-0 0-0.001 0-0.001 0-1.472-1.194-2.666-2.666-2.666-0 0-0.001 0-0.001 0h0zM5.333 16h5.333v2.667h-5.333v-2.667zM18.667 24h-13.333v-2.667h13.333v2.667zM26.667 24h-5.333v-2.667h5.333v2.667zM26.667 18.667h-13.333v-2.667h13.333v2.667z"></path></svg>\'},function(t,e){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="-5 0 32 32"><path d="M20.8 14.4q0.704 0 1.152 0.48t0.448 1.12-0.48 1.12-1.12 0.48h-19.2q-0.64 0-1.12-0.48t-0.48-1.12 0.448-1.12 1.152-0.48h19.2zM1.6 11.2q-0.64 0-1.12-0.48t-0.48-1.12 0.448-1.12 1.152-0.48h19.2q0.704 0 1.152 0.48t0.448 1.12-0.48 1.12-1.12 0.48h-19.2zM20.8 20.8q0.704 0 1.152 0.48t0.448 1.12-0.48 1.12-1.12 0.48h-19.2q-0.64 0-1.12-0.48t-0.48-1.12 0.448-1.12 1.152-0.48h19.2z"></path></svg>\'},function(t,e){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="0 0 32 32"><path d="M2.667 7.027l1.707-1.693 22.293 22.293-1.693 1.707-4-4h-11.64v4l-5.333-5.333 5.333-5.333v4h8.973l-8.973-8.973v0.973h-2.667v-3.64l-4-4zM22.667 17.333h2.667v5.573l-2.667-2.667v-2.907zM22.667 6.667v-4l5.333 5.333-5.333 5.333v-4h-10.907l-2.667-2.667h13.573z"></path></svg>\'},function(t,e){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="-8 0 32 32"><path d="M14.080 4.8q2.88 0 2.88 2.048v18.24q0 2.112-2.88 2.112t-2.88-2.112v-18.24q0-2.048 2.88-2.048zM2.88 4.8q2.88 0 2.88 2.048v18.24q0 2.112-2.88 2.112t-2.88-2.112v-18.24q0-2.048 2.88-2.048z"></path></svg>\'},function(t,e){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="-8 0 32 32"><path d="M15.552 15.168q0.448 0.32 0.448 0.832 0 0.448-0.448 0.768l-13.696 8.512q-0.768 0.512-1.312 0.192t-0.544-1.28v-16.448q0-0.96 0.544-1.28t1.312 0.192z"></path></svg>\'},function(t,e){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="-1 0 32 32"><path d="M25.6 9.92q1.344 0 2.272 0.928t0.928 2.272v9.28q0 1.28-0.928 2.24t-2.272 0.96h-22.4q-1.28 0-2.24-0.96t-0.96-2.24v-9.28q0-1.344 0.96-2.272t2.24-0.928h8v-3.52l6.4 5.76-6.4 5.76v-3.52h-6.72v6.72h19.84v-6.72h-4.8v-4.48h6.080z"></path></svg>\'},function(t,e){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="0 0 32 32"><path d="M9.333 9.333h13.333v4l5.333-5.333-5.333-5.333v4h-16v8h2.667v-5.333zM22.667 22.667h-13.333v-4l-5.333 5.333 5.333 5.333v-4h16v-8h-2.667v5.333z"></path></svg>\'},function(t,e){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="0 0 38 32"><path d="M2.072 21.577c0.71-0.197 1.125-0.932 0.928-1.641-0.221-0.796-0.333-1.622-0.333-2.457 0-5.049 4.108-9.158 9.158-9.158h5.428c0.056-0.922 0.221-1.816 0.482-2.667h-5.911c-3.158 0-6.128 1.23-8.361 3.463s-3.463 5.203-3.463 8.361c0 1.076 0.145 2.143 0.431 3.171 0.164 0.59 0.7 0.976 1.284 0.976 0.117 0 0.238-0.016 0.357-0.049zM21.394 25.613h-12.409v-2.362c0-0.758-0.528-1.052-1.172-0.652l-5.685 3.522c-0.644 0.4-0.651 1.063-0.014 1.474l5.712 3.69c0.637 0.411 1.158 0.127 1.158-0.63v-2.374h12.409c3.158 0 6.128-1.23 8.361-3.463 1.424-1.424 2.44-3.148 2.99-5.029-0.985 0.368-2.033 0.606-3.125 0.691-1.492 3.038-4.619 5.135-8.226 5.135zM28.718 0c-4.985 0-9.026 4.041-9.026 9.026s4.041 9.026 9.026 9.026 9.026-4.041 9.026-9.026-4.041-9.026-9.026-9.026zM30.392 13.827h-1.728v-6.822c-0.635 0.576-1.433 1.004-2.407 1.285v-1.713c0.473-0.118 0.975-0.325 1.506-0.62 0.532-0.325 0.975-0.665 1.329-1.034h1.3v8.904z"></path></svg>\'},function(t,e){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="0 0 32 32"><path d="M9.333 9.333h13.333v4l5.333-5.333-5.333-5.333v4h-16v8h2.667v-5.333zM22.667 22.667h-13.333v-4l-5.333 5.333 5.333 5.333v-4h16v-8h-2.667v5.333zM17.333 20v-8h-1.333l-2.667 1.333v1.333h2v5.333h2z"></path></svg>\'},function(t,e){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="0 0 32 32"><path d="M22.667 4l7 6-7 6 7 6-7 6v-4h-3.653l-3.76-3.76 2.827-2.827 2.587 2.587h2v-8h-2l-12 12h-6v-4h4.347l12-12h3.653v-4zM2.667 8h6l3.76 3.76-2.827 2.827-2.587-2.587h-4.347v-4z"></path></svg>\'},function(t,e){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="0 0 32 32"><path d="M25.468 6.947c-0.326-0.172-0.724-0.151-1.030 0.057l-6.438 4.38v-3.553c0-0.371-0.205-0.71-0.532-0.884-0.326-0.172-0.724-0.151-1.030 0.057l-12 8.164c-0.274 0.186-0.438 0.496-0.438 0.827s0.164 0.641 0.438 0.827l12 8.168c0.169 0.115 0.365 0.174 0.562 0.174 0.16 0 0.321-0.038 0.468-0.116 0.327-0.173 0.532-0.514 0.532-0.884v-3.556l6.438 4.382c0.169 0.115 0.365 0.174 0.562 0.174 0.16 0 0.321-0.038 0.468-0.116 0.327-0.173 0.532-0.514 0.532-0.884v-16.333c0-0.371-0.205-0.71-0.532-0.884z"></path></svg>\'},function(t,e){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="0 0 32 32"><path d="M13.728 6.272v19.456q0 0.448-0.352 0.8t-0.8 0.32-0.8-0.32l-5.952-5.952h-4.672q-0.48 0-0.8-0.352t-0.352-0.8v-6.848q0-0.48 0.352-0.8t0.8-0.352h4.672l5.952-5.952q0.32-0.32 0.8-0.32t0.8 0.32 0.352 0.8zM20.576 16q0 1.344-0.768 2.528t-2.016 1.664q-0.16 0.096-0.448 0.096-0.448 0-0.8-0.32t-0.32-0.832q0-0.384 0.192-0.64t0.544-0.448 0.608-0.384 0.512-0.64 0.192-1.024-0.192-1.024-0.512-0.64-0.608-0.384-0.544-0.448-0.192-0.64q0-0.48 0.32-0.832t0.8-0.32q0.288 0 0.448 0.096 1.248 0.48 2.016 1.664t0.768 2.528z"></path></svg>\'},function(t,e){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="0 0 32 32"><path d="M13.728 6.272v19.456q0 0.448-0.352 0.8t-0.8 0.32-0.8-0.32l-5.952-5.952h-4.672q-0.48 0-0.8-0.352t-0.352-0.8v-6.848q0-0.48 0.352-0.8t0.8-0.352h4.672l5.952-5.952q0.32-0.32 0.8-0.32t0.8 0.32 0.352 0.8z"></path></svg>\'},function(t,e){t.exports=\'<svg xmlns="http://www.w3.org/2000/svg" version="1.1" viewBox="0 0 32 32"><path d="M13.728 6.272v19.456q0 0.448-0.352 0.8t-0.8 0.32-0.8-0.32l-5.952-5.952h-4.672q-0.48 0-0.8-0.352t-0.352-0.8v-6.848q0-0.48 0.352-0.8t0.8-0.352h4.672l5.952-5.952q0.32-0.32 0.8-0.32t0.8 0.32 0.352 0.8zM20.576 16q0 1.344-0.768 2.528t-2.016 1.664q-0.16 0.096-0.448 0.096-0.448 0-0.8-0.32t-0.32-0.832q0-0.384 0.192-0.64t0.544-0.448 0.608-0.384 0.512-0.64 0.192-1.024-0.192-1.024-0.512-0.64-0.608-0.384-0.544-0.448-0.192-0.64q0-0.48 0.32-0.832t0.8-0.32q0.288 0 0.448 0.096 1.248 0.48 2.016 1.664t0.768 2.528zM25.152 16q0 2.72-1.536 5.056t-4 3.36q-0.256 0.096-0.448 0.096-0.48 0-0.832-0.352t-0.32-0.8q0-0.704 0.672-1.056 1.024-0.512 1.376-0.8 1.312-0.96 2.048-2.4t0.736-3.104-0.736-3.104-2.048-2.4q-0.352-0.288-1.376-0.8-0.672-0.352-0.672-1.056 0-0.448 0.32-0.8t0.8-0.352q0.224 0 0.48 0.096 2.496 1.056 4 3.36t1.536 5.056zM29.728 16q0 4.096-2.272 7.552t-6.048 5.056q-0.224 0.096-0.448 0.096-0.48 0-0.832-0.352t-0.32-0.8q0-0.64 0.704-1.056 0.128-0.064 0.384-0.192t0.416-0.192q0.8-0.448 1.44-0.896 2.208-1.632 3.456-4.064t1.216-5.152-1.216-5.152-3.456-4.064q-0.64-0.448-1.44-0.896-0.128-0.096-0.416-0.192t-0.384-0.192q-0.704-0.416-0.704-1.056 0-0.448 0.32-0.8t0.832-0.352q0.224 0 0.448 0.096 3.776 1.632 6.048 5.056t2.272 7.552z"></path></svg>\'},function(t,e,i){"use strict";i.d(e,"a",function(){return a}),i.d(e,"b",function(){return r});var a=function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("svg",{style:t.style,attrs:{"xmlns:xlink":"http://www.w3.org/1999/xlink",height:"100%",version:"1.1",viewBox:t.svg.viewBox,width:"100%"}},[i("use",{attrs:{"xlink:href":"#aplayer-${type}"}}),t._v(" "),i("path",{staticClass:"aplayer-fill",attrs:{d:t.svg.d}})])},r=[]},function(t,e,i){"use strict";i.d(e,"a",function(){return a}),i.d(e,"b",function(){return r});var a=function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("button",{staticClass:"aplayer-icon",attrs:{type:"button"}},[i("icon",{attrs:{type:t.icon}})],1)},r=[]},function(t,e,i){"use strict";i.d(e,"a",function(){return a}),i.d(e,"b",function(){return r});var a=function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{staticClass:"aplayer-pic",style:t.currentPicStyleObj,on:{mousedown:t.onDragBegin,click:t.onClick}},[i("div",{staticClass:"aplayer-button",class:t.playing?"aplayer-pause":"aplayer-play"},[i("icon-button",{class:t.playing?"aplayer-icon-pause":"aplayer-icon-play",attrs:{icon:t.playing?"pause":"play"}})],1)])},r=[]},function(t,e,i){"use strict";function a(t){i(47)}var r=i(10),n=i(49),o=i(0),s=a,l=Object(o.a)(r.a,n.a,n.b,!1,s,null,null);e.a=l.exports},function(t,e,i){var a=i(48);"string"==typeof a&&(a=[[t.i,a,""]]),a.locals&&(t.exports=a.locals);var r=i(2).default;r("7b9d1402",a,!0,{})},function(t,e,i){e=t.exports=i(1)(!1),e.push([t.i,".aplayer-list{overflow:hidden}.aplayer-list.slide-v-enter-active,.aplayer-list.slide-v-leave-active{-webkit-transition:height .5s ease;transition:height .5s ease;will-change:height}.aplayer-list.slide-v-enter,.aplayer-list.slide-v-leave-to{height:0!important}.aplayer-list ol{list-style-type:none;margin:0;padding:0;overflow-y:auto}.aplayer-list ol::-webkit-scrollbar{width:5px}.aplayer-list ol::-webkit-scrollbar-track{background-color:#f9f9f9}.aplayer-list ol::-webkit-scrollbar-thumb{border-radius:3px;background-color:#eee}.aplayer-list ol::-webkit-scrollbar-thumb:hover{background-color:#ccc}.aplayer-list ol:hover li.aplayer-list-light:not(:hover){background-color:inherit;-webkit-transition:inherit;transition:inherit}.aplayer-list ol:not(:hover) li.aplayer-list-light{-webkit-transition:background-color .6s ease;transition:background-color .6s ease}.aplayer-list ol li{position:relative;height:32px;line-height:32px;padding:0 15px;font-size:12px;border-top:1px solid #e9e9e9;cursor:pointer;-webkit-transition:all .2s ease;transition:all .2s ease;overflow:hidden;margin:0;text-align:start;display:-webkit-box;display:-ms-flexbox;display:flex}.aplayer-list ol li:first-child{border-top:none}.aplayer-list ol li.aplayer-list-light,.aplayer-list ol li:hover{background:#efefef}.aplayer-list ol li.aplayer-list-light .aplayer-list-cur{display:inline-block}.aplayer-list ol li .aplayer-list-cur{display:none;width:3px;height:22px;position:absolute;left:0;top:5px;-webkit-transition:background-color .3s;transition:background-color .3s}.aplayer-list ol li .aplayer-list-index{color:#666;margin-right:12px}.aplayer-list ol li .aplayer-list-title{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1}.aplayer-list ol li .aplayer-list-author{-ms-flex-negative:0;flex-shrink:0;color:#666;float:right}",""])},function(t,e,i){"use strict";i.d(e,"a",function(){return a}),i.d(e,"b",function(){return r});var a=function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("transition",{attrs:{name:"slide-v"}},[i("div",{directives:[{name:"show",rawName:"v-show",value:t.show,expression:"show"}],ref:"list",staticClass:"aplayer-list",style:t.listHeightStyle},[i("ol",{ref:"ol",style:t.listHeightStyle},t._l(t.musicList,function(e,a){return i("li",{key:a,class:{"aplayer-list-light":e===t.currentMusic},on:{click:function(i){t.$emit("selectsong",e)}}},[i("span",{staticClass:"aplayer-list-cur",style:{background:t.theme}}),t._v(" "),i("span",{staticClass:"aplayer-list-index"},[t._v(t._s(a+1))]),t._v(" "),i("span",{staticClass:"aplayer-list-title"},[t._v(t._s(e.title||"Untitled"))]),t._v(" "),i("span",{staticClass:"aplayer-list-author"},[t._v(t._s(e.artist||e.author||"Unknown"))])])}))])])},r=[]},function(t,e,i){"use strict";function a(t){i(51)}var r=i(11),n=i(61),o=i(0),s=a,l=Object(o.a)(r.a,n.a,n.b,!1,s,null,null);e.a=l.exports},function(t,e,i){var a=i(52);"string"==typeof a&&(a=[[t.i,a,""]]),a.locals&&(t.exports=a.locals);var r=i(2).default;r("c97c1d8a",a,!0,{})},function(t,e,i){e=t.exports=i(1)(!1),e.push([t.i,".aplayer-controller,.aplayer-controller .aplayer-time{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative}.aplayer-controller .aplayer-time{height:17px;color:#999;font-size:11px;padding-left:7px}.aplayer-controller .aplayer-time .aplayer-volume-wrap{margin-left:4px;margin-right:4px}.aplayer-controller .aplayer-time .aplayer-icon{cursor:pointer;-webkit-transition:all .2s ease;transition:all .2s ease;margin-left:4px}.aplayer-controller .aplayer-time .aplayer-icon.inactive{opacity:.3}.aplayer-controller .aplayer-time .aplayer-icon .aplayer-fill{fill:#666}.aplayer-controller .aplayer-time .aplayer-icon:hover .aplayer-fill{fill:#000}.aplayer-controller .aplayer-time .aplayer-icon.aplayer-icon-menu{display:none}.aplayer-controller .aplayer-time .aplayer-volume-wrap+.aplayer-icon{margin-left:0}.aplayer-controller .aplayer-time.aplayer-time-narrow .aplayer-icon-menu,.aplayer-controller .aplayer-time.aplayer-time-narrow .aplayer-icon-mode{display:none}",""])},function(t,e,i){"use strict";function a(t){i(54)}var r=i(12),n=i(56),o=i(0),s=a,l=Object(o.a)(r.a,n.a,n.b,!1,s,null,null);e.a=l.exports},function(t,e,i){var a=i(55);"string"==typeof a&&(a=[[t.i,a,""]]),a.locals&&(t.exports=a.locals);var r=i(2).default;r("6f66d8c5",a,!0,{})},function(t,e,i){e=t.exports=i(1)(!1),e.push([t.i,".aplayer-bar-wrap{margin:0 0 0 5px;padding:4px 0;cursor:pointer;-webkit-box-flex:1;-ms-flex:1;flex:1}.aplayer-bar-wrap .aplayer-bar{position:relative;height:2px;width:100%;background:#cdcdcd}.aplayer-bar-wrap .aplayer-bar .aplayer-loaded{position:absolute;left:0;top:0;bottom:0;background:#aaa;height:2px;-webkit-transition:all .5s ease;transition:all .5s ease;will-change:width}.aplayer-bar-wrap .aplayer-bar .aplayer-played{position:absolute;left:0;top:0;bottom:0;height:2px;-webkit-transition:background-color .3s;transition:background-color .3s;will-change:width}.aplayer-bar-wrap .aplayer-bar .aplayer-played .aplayer-thumb{position:absolute;top:0;right:5px;margin-top:-5px;margin-right:-10px;width:10px;height:10px;border:1px solid;-webkit-transform:scale(.8);transform:scale(.8);will-change:transform;-webkit-transition:background-color .3s,border-color .3s,-webkit-transform .3s;transition:background-color .3s,border-color .3s,-webkit-transform .3s;transition:transform .3s,background-color .3s,border-color .3s;transition:transform .3s,background-color .3s,border-color .3s,-webkit-transform .3s;border-radius:50%;background:#fff;cursor:pointer;overflow:hidden}.aplayer-bar-wrap .aplayer-bar .aplayer-played .aplayer-thumb:hover{-webkit-transform:scale(1);transform:scale(1)}.aplayer-bar-wrap .aplayer-bar .aplayer-played .aplayer-thumb .aplayer-loading-icon{display:none;width:100%;height:100%}.aplayer-bar-wrap .aplayer-bar .aplayer-played .aplayer-thumb .aplayer-loading-icon svg{position:absolute;-webkit-animation:spin 1s linear infinite;animation:spin 1s linear infinite;fill:#fff}.aplayer-loading .aplayer-bar-wrap .aplayer-bar .aplayer-thumb .aplayer-loading-icon{display:block}.aplayer-loading .aplayer-info .aplayer-controller .aplayer-bar-wrap .aplayer-bar .aplayer-played .aplayer-thumb{-webkit-transform:scale(1);transform:scale(1)}@-webkit-keyframes spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}to{-webkit-transform:rotate(1turn);transform:rotate(1turn)}}@keyframes spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}to{-webkit-transform:rotate(1turn);transform:rotate(1turn)}}",""])},function(t,e,i){"use strict";i.d(e,"a",function(){return a}),i.d(e,"b",function(){return r});var a=function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{ref:"barWrap",staticClass:"aplayer-bar-wrap",on:{mousedown:t.onThumbMouseDown,touchstart:t.onThumbTouchStart}},[i("div",{staticClass:"aplayer-bar"},[i("div",{staticClass:"aplayer-loaded",style:{width:100*t.loadProgress+"%"}}),t._v(" "),i("div",{staticClass:"aplayer-played",style:{width:100*t.playProgress+"%",background:t.theme}},[i("span",{ref:"thumb",staticClass:"aplayer-thumb",style:{borderColor:t.theme,backgroundColor:t.thumbHovered?t.theme:"#fff"},on:{mouseover:function(e){t.thumbHovered=!0},mouseout:function(e){t.thumbHovered=!1}}},[i("span",{staticClass:"aplayer-loading-icon",style:{backgroundColor:t.theme}},[i("icon",{attrs:{type:"loading"}})],1)])])])])},r=[]},function(t,e,i){"use strict";function a(t){i(58)}var r=i(13),n=i(60),o=i(0),s=a,l=Object(o.a)(r.a,n.a,n.b,!1,s,null,null);e.a=l.exports},function(t,e,i){var a=i(59);"string"==typeof a&&(a=[[t.i,a,""]]),a.locals&&(t.exports=a.locals);var r=i(2).default;r("28c86b36",a,!0,{})},function(t,e,i){e=t.exports=i(1)(!1),e.push([t.i,\'.aplayer-volume-wrap{position:relative;cursor:pointer;z-index:0}.aplayer-volume-wrap:hover .aplayer-volume-bar-wrap{display:block}.aplayer-volume-wrap .aplayer-volume-bar-wrap{display:none;position:absolute;bottom:15px;left:-4px;right:-4px;height:40px;z-index:-1;-webkit-transition:all .2s ease;transition:all .2s ease}.aplayer-volume-wrap .aplayer-volume-bar-wrap:after{content:"";position:absolute;bottom:-16px;left:0;right:0;height:62px;background-color:#fff;-webkit-box-shadow:0 0 2px 0 rgba(0,0,0,.07),0 0 5px 0 rgba(0,0,0,.1);box-shadow:0 0 2px 0 rgba(0,0,0,.07),0 0 5px 0 rgba(0,0,0,.1)}.aplayer-volume-wrap .aplayer-volume-bar-wrap .aplayer-volume-bar{position:absolute;bottom:0;left:11px;width:5px;height:40px;background:#aaa;border-radius:2.5px;overflow:hidden;z-index:1}.aplayer-volume-wrap .aplayer-volume-bar-wrap .aplayer-volume-bar .aplayer-volume{position:absolute;bottom:0;left:0;right:0;-webkit-transition:height .1s ease,background-color .3s;transition:height .1s ease,background-color .3s;will-change:height}\',""])},function(t,e,i){"use strict";i.d(e,"a",function(){return a}),i.d(e,"b",function(){return r});var a=function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{staticClass:"aplayer-volume-wrap"},[i("icon-button",{class:"aplayer-icon-"+t.volumeIcon,attrs:{icon:t.volumeIcon},nativeOn:{click:function(e){t.$emit("togglemute")}}}),t._v(" "),i("div",{staticClass:"aplayer-volume-bar-wrap",on:{mousedown:t.onBarMouseDown}},[i("div",{ref:"bar",staticClass:"aplayer-volume-bar"},[i("div",{staticClass:"aplayer-volume",style:{height:t.muted?0:Math.trunc(100*t.volume)+"%",background:t.theme}})])])],1)},r=[]},function(t,e,i){"use strict";i.d(e,"a",function(){return a}),i.d(e,"b",function(){return r});var a=function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{staticClass:"aplayer-controller"},[i("v-progress",{attrs:{loadProgress:t.loadProgress,playProgress:t.playProgress,theme:t.theme},on:{dragbegin:function(e){return t.$emit("dragbegin",e)},dragend:function(e){return t.$emit("dragend",e)},dragging:function(e){return t.$emit("dragging",e)}}}),t._v(" "),i("div",{staticClass:"aplayer-time"},[i("div",{staticClass:"aplayer-time-inner"},[t._v("\\n      - "),i("span",{staticClass:"aplayer-ptime"},[t._v(t._s(t.secondToTime(t.stat.playedTime)))]),t._v(" / "),i("span",{staticClass:"aplayer-dtime"},[t._v(t._s(t.secondToTime(t.stat.duration)))])]),t._v(" "),t.$parent.isMobile?t._e():i("volume",{attrs:{volume:t.volume,theme:t.theme,muted:t.muted},on:{togglemute:function(e){t.$emit("togglemute")},setvolume:function(e){return t.$emit("setvolume",e)}}}),t._v(" "),i("icon-button",{staticClass:"aplayer-icon-mode",class:{inactive:!t.shuffle},attrs:{icon:"shuffle"},nativeOn:{click:function(e){t.$emit("toggleshuffle")}}}),t._v(" "),i("icon-button",{staticClass:"aplayer-icon-mode",class:{inactive:"no-repeat"===t.repeat},attrs:{icon:"repeat-one"===t.repeat?"repeat-one":"repeat-all"},nativeOn:{click:function(e){t.$emit("nextmode")}}}),t._v(" "),i("icon-button",{staticClass:"aplayer-icon-menu",class:{inactive:!t.$parent.showList},attrs:{icon:"menu"},nativeOn:{click:function(e){t.$emit("togglelist")}}})],1)],1)},r=[]},function(t,e,i){"use strict";function a(t){i(63)}var r=i(14),n=i(65),o=i(0),s=a,l=Object(o.a)(r.a,n.a,n.b,!1,s,null,null);e.a=l.exports},function(t,e,i){var a=i(64);"string"==typeof a&&(a=[[t.i,a,""]]),a.locals&&(t.exports=a.locals);var r=i(2).default;r("229083b6",a,!0,{})},function(t,e,i){e=t.exports=i(1)(!1),e.push([t.i,\'.aplayer-lrc{position:relative;height:30px;text-align:center;overflow:hidden;margin-bottom:7px}.aplayer-lrc:before{top:0;height:10%;background:-webkit-gradient(linear,left top,left bottom,from(#fff),to(hsla(0,0%,100%,0)));background:linear-gradient(180deg,#fff 0,hsla(0,0%,100%,0));filter:progid:DXImageTransform.Microsoft.gradient(startColorstr="#ffffff",endColorstr="#00ffffff",GradientType=0)}.aplayer-lrc:after,.aplayer-lrc:before{position:absolute;z-index:1;display:block;overflow:hidden;width:100%;content:" "}.aplayer-lrc:after{bottom:0;height:33%;background:-webkit-gradient(linear,left top,left bottom,from(hsla(0,0%,100%,0)),to(hsla(0,0%,100%,.8)));background:linear-gradient(180deg,hsla(0,0%,100%,0) 0,hsla(0,0%,100%,.8));filter:progid:DXImageTransform.Microsoft.gradient(startColorstr="#00ffffff",endColorstr="#ccffffff",GradientType=0)}.aplayer-lrc p{font-size:12px;color:#666;line-height:16px;height:16px;padding:0;margin:0;-webkit-transition:all .5s ease-out;transition:all .5s ease-out;opacity:.4;overflow:hidden}.aplayer-lrc p.aplayer-lrc-current{opacity:1;overflow:visible;height:auto}.aplayer-lrc .aplayer-lrc-contents{width:100%;-webkit-transition:all .5s ease-out;transition:all .5s ease-out;-webkit-user-select:text;-moz-user-select:text;-ms-user-select:text;user-select:text;cursor:default}\',""])},function(t,e,i){"use strict";i.d(e,"a",function(){return a}),i.d(e,"b",function(){return r});var a=function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{staticClass:"aplayer-lrc"},[i("div",{staticClass:"aplayer-lrc-contents",style:t.transformStyle},t._l(t.lrcLines,function(e,a){return i("p",{key:a,class:{"aplayer-lrc-current":a===t.currentLineIndex}},[t._v("\\n      "+t._s(e[1])+"\\n    ")])}))])},r=[]},function(t,i){if(void 0===e){var a=new Error(\'Cannot find module "undefined"\');throw a.code="MODULE_NOT_FOUND",a}t.exports=e},function(t,e,i){"use strict";i.d(e,"a",function(){return a}),i.d(e,"b",function(){return r});var a=function(){var t=this,e=t.$createElement,i=t._self._c||e;return i("div",{staticClass:"aplayer",class:{"aplayer-narrow":t.isMiniMode,"aplayer-withlist":!t.isMiniMode&&t.musicList.length>0,"aplayer-withlrc":!t.isMiniMode&&(!!t.$slots.display||t.shouldShowLrc),"aplayer-float":t.isFloatMode,"aplayer-loading":t.isPlaying&&t.isLoading},style:t.floatStyleObj},[i("div",{staticClass:"aplayer-body"},[i("thumbnail",{attrs:{pic:t.currentMusic.pic,playing:t.isPlaying,"enable-drag":t.isFloatMode,theme:t.currentTheme},on:{toggleplay:t.toggle,dragbegin:t.onDragBegin,dragging:t.onDragAround}}),t._v(" "),i("div",{directives:[{name:"show",rawName:"v-show",value:!t.isMiniMode,expression:"!isMiniMode"}],staticClass:"aplayer-info"},[i("div",{staticClass:"aplayer-music"},[i("span",{staticClass:"aplayer-title"},[t._v(t._s(t.currentMusic.title||"Untitled"))]),t._v(" "),i("span",{staticClass:"aplayer-author"},[t._v(t._s(t.currentMusic.artist||t.currentMusic.author||"Unknown"))])]),t._v(" "),t._t("display",[t.shouldShowLrc?i("lyrics",{attrs:{"current-music":t.currentMusic,"play-stat":t.playStat}}):t._e()],{currentMusic:t.currentMusic,playStat:t.playStat}),t._v(" "),i("controls",{attrs:{shuffle:t.shouldShuffle,repeat:t.repeatMode,stat:t.playStat,volume:t.audioVolume,muted:t.isAudioMuted,theme:t.currentTheme},on:{toggleshuffle:function(e){t.shouldShuffle=!t.shouldShuffle},togglelist:function(e){t.showList=!t.showList},togglemute:t.toggleMute,setvolume:t.setAudioVolume,dragbegin:t.onProgressDragBegin,dragend:t.onProgressDragEnd,dragging:t.onProgressDragging,nextmode:t.setNextMode}})],2)],1),t._v(" "),i("audio",{ref:"audio"}),t._v(" "),i("music-list",{attrs:{show:t.showList&&!t.isMiniMode,"current-music":t.currentMusic,"music-list":t.musicList,"play-index":t.playIndex,listmaxheight:t.listmaxheight||t.listMaxHeight,theme:t.currentTheme},on:{selectsong:t.onSelectSong}})],1)},r=[]}]).default});\n\n//# sourceURL=webpack://casaos-main/./node_modules/.pnpm/vue-aplayer@1.6.1_vue@2.7.16/node_modules/vue-aplayer/dist/vue-aplayer.min.js?')}}]);